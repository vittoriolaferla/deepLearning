{
  "qas": [
    {
      "question": "What is Heat map",
      "answer": "Heat map is a graphical representation of data where values are depicted by color"
    },
    {
      "question": "What is EDA library",
      "answer": ".Pandas Profiling is the auto EDA library is an open source option that is written in python"
    },
    {
      "question": "How can you define an empirical relationship in dataset",
      "answer": "Mean, median, and mode are closely connected by the following relations called an empirical relationship"
    },
    {
      "question": "Which plots used for Plotting the raw data",
      "answer": "For row data histograms, bihistograms, probability plots, lag plots, block plots, and Youden plots"
    },
    {
      "question": "What is the purpose of visualization",
      "answer": ".It gives assessment not exactness"
    },
    {
      "question": "what is data aggregation",
      "answer": "Data aggregation is the process of gathering data and presenting it in a summarized format"
    },
    {
      "question": "What is EDA",
      "answer": "Exploratory Data Analysis the process of investigating the dataset to discover patterns and anomalies or outliers"
    },
    {
      "question": "Where is a graph continuous",
      "answer": "A function is continuous if its graph is an unbroken curve"
    },
    {
      "question": "what is confidence interval",
      "answer": ".A confidence interval displays the probability that a parameter will fall between a pair of values around the mean"
    },
    {
      "question": "How to find the mean",
      "answer": "Adding all numbers in the data set and then dividing by the number of values in the set"
    },
    {
      "question": "What is Unbiased estimate",
      "answer": "An unbiased estimator of a parameter is an estimator whose expected value is equal to the parameter"
    },
    {
      "question": "What is median",
      "answer": "The median is the middle number in a sorted, ascending or descending."
    },
    {
      "question": "Does median influenced by outliers",
      "answer": "No median does not get influenced by outliers"
    },
    {
      "question": "what is Threshold Parameter",
      "answer": "The threshold parameter defines the minimum value in a lognormal distribution"
    },
    {
      "question": "What is Mode",
      "answer": "The mode is the value that appears most often in a set of data values"
    },
    {
      "question": "which statistical methods widely used for analyzing data",
      "answer": "There are two statistical methods widely used for analyzing data Descriptive and inferential statistics"
    },
    {
      "question": "what are the uses of EDA",
      "answer": "Catching mistakes and anomalies,Gaining new insights into data,Detecting outliers in data,Understanding relationships"
    },
    {
      "question": "Define Inter Quartile Range",
      "answer": "Inter Quartile Range is the difference between the third quartile and the first Quartile"
    },
    {
      "question": "what is Scale Parameter",
      "answer": "The scale represents the standard deviation of the normally distributed data"
    },
    {
      "question": "What is Scatter plot",
      "answer": "Scatter plot is used to plot data points on a horizontal and a vertical axis to show how much one variable is affected by anothe"
    },
    {
      "question": "What is a distribution plot",
      "answer": "A distribution plot displays a distribution and range of a set of numeric values plotted against a dimension"
    },
    {
      "question": "what is Noisy data",
      "answer": ".Noisy data is a meaningless data that cannot be interpreted by machines"
    },
    {
      "question": "what is Binning Method",
      "answer": "This method works on sorted data in order to smooth it"
    },
    {
      "question": "What is Bubble chart",
      "answer": "Bubble chart is a data visualization that displays multiple circles in a two-dimensional plot"
    },
    {
      "question": "Which is the important step in Data science",
      "answer": "Exploratory Data Analysis is important step in data science"
    },
    {
      "question": "Which terms comes under the EDA",
      "answer": "Summary statistics for numerical data in the dataset and creating various graphical representations to understand the data better"
    },
    {
      "question": "What is First moment business decision",
      "answer": "Measure of Central Tendency is also called as First Moment Business Decision"
    },
    {
      "question": "What is Measure of central Tendency",
      "answer": "Measure of central Tendency is called as summary statistics"
    },
    {
      "question": "What is mean",
      "answer": "The sum of the values divided by the number of values"
    },
    {
      "question": "Does mean influenced by outliers",
      "answer": "Yes mean influenced by outliers"
    },
    {
      "question": "What is second momemt business decision",
      "answer": "Measure of Dispersion also called as Second Moment Business Decision"
    },
    {
      "question": "Define the Measure of Dispersion",
      "answer": "A measure of dispersion indicates the scattering of data"
    },
    {
      "question": "What are the four measure of dispersion",
      "answer": "The four measure of dispersion are range, interquartile range, standard deviation and variance"
    },
    {
      "question": "What is the best measurement for dispersion",
      "answer": "The best measurement for dispersion is standard deviation"
    },
    {
      "question": "What a variance means",
      "answer": "The term variance refers to a statistical measurement of the spread between numbers in a data set"
    },
    {
      "question": "what is the standard deviation",
      "answer": "In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values"
    },
    {
      "question": "what is range of the dataset",
      "answer": "The range is the simple measurement of the difference between values in a dataset"
    },
    {
      "question": "What is disavantage of the variance",
      "answer": "The disavantage of the variance is unit get squared"
    },
    {
      "question": "What is advantage of standard deviation",
      "answer": "Advantage of standard deviation is we get back the original input from squares units"
    },
    {
      "question": "Which are the tools included in EDA",
      "answer": "Python and R are the tools used for EDA"
    },
    {
      "question": "What is Multivariate nongraphical method",
      "answer": "Multivariate non-graphical EDA techniques generally show the relationship between two or more variables of the data through cross tabulation or statistics"
    },
    {
      "question": "What is Multivariate graphical method",
      "answer": "Scatter plot is used to plot data points on a horizontal and a vertical axis to show how much one variable is affected by another"
    },
    {
      "question": "What is Multivariate chart",
      "answer": "Multivariate chart is a graphical representation of the relationships between factors and a response"
    },
    {
      "question": "What is run chart",
      "answer": "Bubble chart is a data visualization that displays multiple circles in a two-dimensional plot"
    },
    {
      "question": "How can you define Histogram",
      "answer": "s called an empirical relationship"
    },
    {
      "question": "What is the difference Between Mean and Median",
      "answer": "Mean is known as the mathematical average whereas the median is known as the positional average"
    },
    {
      "question": "In Data Science which is the next step after EDA",
      "answer": "In Data Science the next step after EDA is Data Mining"
    },
    {
      "question": "What is the relation between EDA and statistical graphics",
      "answer": "Exploratory Data Analysis is an approach or philosophy for data analysis that employs a variety of techniques mostly graphical"
    },
    {
      "question": "Are EDA and statistical graphics same or different",
      "answer": "EDA is not identical to statistical graphics although the two terms are used almost interchangeably"
    },
    {
      "question": "Which techniques are there in EDA",
      "answer": "Most EDA techniques are graphical in nature with a few quantitative technique"
    },
    {
      "question": "Which plots used for simple statistics",
      "answer": ".Plotting simple statistics such as mean plots, standard deviation plots, box plots are used"
    },
    {
      "question": "which plots are used for continuous data",
      "answer": "Scatter plots are used to display the relationship between two continuous variables x and y"
    },
    {
      "question": "What graphs use continuous data",
      "answer": "Histograms are useful for displaying continuous data. Bar graphs, line graphs, and histograms have an x- and y-axis"
    },
    {
      "question": "Which plotting technique is used for continuous data",
      "answer": "A dot chart or dot plot is a statistical chart consisting of group of data points plotted on a simple scale"
    },
    {
      "question": "What graphs are best for discrete data",
      "answer": "Discrete data is best represented using bar charts"
    },
    {
      "question": "What Are The Steps In Exploratory Data Analysis In Python",
      "answer": "Description of data,Handling missing data,Handling outliers,Understanding relationships and new insights through plots"
    },
    {
      "question": "How to describe Descriptive Analysis",
      "answer": "Descriptive Analysis is the type of analysis of data that helps describe, show or summarize data points"
    },
    {
      "question": "Why is descriptive analysis important",
      "answer": "Descriptive statistics enables us to present the data in a more meaningful way, which allows simpler interpretation of the data"
    },
    {
      "question": "What is Descriptive statistics",
      "answer": "The study of numerical and graphical ways to describe and display your data is called descriptive statistics"
    },
    {
      "question": "In Data Science what does EDA stands for",
      "answer": "EDA stands for Exploratory Data Analysis"
    },
    {
      "question": "Is EDA part of data preprocessing",
      "answer": "Exploratory data analysis is often a precursor to other kinds of work with statistics and data"
    },
    {
      "question": "When the Mode is the most often used",
      "answer": "If your variable of interest is measured in nominal or ordinal or Categorical level then Mode is the most often used"
    },
    {
      "question": "why IQR is preferred over a range",
      "answer": "IQR is preferred over a range as, like a range, IQR does not influence by outliers"
    },
    {
      "question": "How do you find the first quartile range",
      "answer": "first find the median or middle value of the lower and upper half of the data"
    },
    {
      "question": "How do you find lower quartile",
      "answer": "find the median of the data and then find the median of the first half"
    },
    {
      "question": "what is The semi interquartile range",
      "answer": "The semi interquartile range is one half the difference between the first and third quartiles"
    },
    {
      "question": "what is The mid quartile range",
      "answer": "The mid quartile range is the numerical value midway between the first and third quartile"
    },
    {
      "question": "What is Covariance",
      "answer": "Covariance is a measured use to determine how much variable change in randomly"
    },
    {
      "question": "What is significance of variance",
      "answer": "There are two type of dispersion methods in statistics Absolute Measure of Dispersion Relative Measure of Dispersion"
    },
    {
      "question": "How many type of dispersion methods in statistics",
      "answer": "There are two type of dispersion methods in statistics Absolute Measure of Dispersion Relative Measure of Dispersion"
    },
    {
      "question": "Why Is Dispersion Important in Statistics",
      "answer": "The measures of dispersion are important as it helps in understanding how much a data is spread around a central value"
    },
    {
      "question": "How can we show distribution in dataset",
      "answer": "The distribution of a data set is the shape of the graph when all possible values are plotted on a frequency graph "
    },
    {
      "question": "What do you mean by distribution of data",
      "answer": "A data distribution is a function or a listing which shows all the possible values or interval of the data"
    },
    {
      "question": "What are the four types of distribution in statistics",
      "answer": "normal distribution, chi square distribution, binomial distribution, and Poisson distribution"
    },
    {
      "question": "What are the most common distributions",
      "answer": "The Normal or Gaussian distribution is arguably the most famous distribution"
    },
    {
      "question": "What do distributions look like",
      "answer": ".Some distributions are symmetrical evenly distributed about the mean Other are skewed with data tending to the left or right of the mean"
    },
    {
      "question": "How do you summarize data distribution",
      "answer": "The three common ways of looking at the center are average also called mean, mode and median"
    },
    {
      "question": "How do you find the distribution of data in Python",
      "answer": "A simple and commonly used plot to quickly check the distribution of a sample of data is the histogram"
    },
    {
      "question": "How do you visualize data in Python",
      "answer": "Matplotlib is an easy to use, low level data visualization library that is built on NumPy arrays"
    },
    {
      "question": "What are the limitations of visualization",
      "answer": ".It gives assessment not exactnes"
    },
    {
      "question": "What are the challenges of data visualization",
      "answer": "The main challange is Visual noise Most of the objects in dataset are too relative to each other"
    },
    {
      "question": "For two dimensional which visualization library is used",
      "answer": "Tableau and Microsoft Power BI is a data visualization tool that can be used by data analysts, scientists, statisticians"
    },
    {
      "question": "what are the visualization tools",
      "answer": "Tableau and Microsoft Power BI is a data visualization tool that can be used by data analysts, scientists, statisticians"
    },
    {
      "question": "what is third quartile range data set",
      "answer": "The upper quartile, or third quartile, is the value under which seventy five percent of data points are found when arranged in increasing order"
    },
    {
      "question": "which are the two main methods in which data is collected for descriptive analytics",
      "answer": "The two main methods in which data is collected for descriptive analytics are data aggregation and data mining"
    },
    {
      "question": "What is data aggregation used for",
      "answer": "data aggregation used to achieve specific business objectives or conduct process or human analysis at almost any scale"
    },
    {
      "question": "what is the predictive analytics",
      "answer": "Predictive analytics is a branch of advanced analytics that makes predictions about future using historical with statistical modeling, data mining"
    },
    {
      "question": "what is Prescriptive analytics",
      "answer": "Prescriptive analytics is a type of data analytics the use of technology to help businesses make better decisions through the analysis of raw data"
    },
    {
      "question": "How the Prescriptive analytics works",
      "answer": "Prescriptive analytics relies on artificial intelligence techniques, such as machine learning"
    },
    {
      "question": "What is bell curve",
      "answer": "A bell curve is a graph depicting the normal distribution"
    },
    {
      "question": "what is Population parameters",
      "answer": "In statistics, a population parameter is a number that describes something about an entire group or population"
    },
    {
      "question": "What is Biased estimate",
      "answer": "In statistics, the bias of an estimator is the difference between this estimators expected value and the true value of the parameter"
    },
    {
      "question": "How do you know if an estimator is unbiased",
      "answer": "An estimator of a given parameter is said to be unbiased if its expected value is equal to the true value of the parameter"
    },
    {
      "question": "What is Lognormal Distribution",
      "answer": "The lognormal distribution is a continuous probability distribution that models right-skewed data"
    },
    {
      "question": "what is Lognormal Location Parameter",
      "answer": "The Lognormal location represents the peak mean, median, and mode of the normally distributed data"
    },
    {
      "question": "What is the primary purpose of Scatter plot",
      "answer": ".the purpose of Scatter plot to check the direction and strength"
    },
    {
      "question": "What is Positive Correlation in scatterplot",
      "answer": "When one variable increase as the other variable increases, there is a positive correlation"
    },
    {
      "question": "What is Negative correlation in scatterplot",
      "answer": "negative correlation when the increase of one variable leads to decrease in the other"
    },
    {
      "question": "what is mean by No correlation or zero correlation",
      "answer": ".No correlation means there is no relationship between the variables"
    },
    {
      "question": "what are the Advantages of Scatter plots",
      "answer": "Main advantage of scatter plot it Show a relationship and a trend in the data relationship"
    },
    {
      "question": "What is Univaraite analysis used for ",
      "answer": "univariate data for a descriptive study on how one characteristic or attribute varies or to examine how each characteristic or attribute varies before including that variable in a study with two or more variables"
    },
    {
      "question": "why graph needed for univariable analysis ",
      "answer": "Graphing is a way of visually presenting the data.Purpose of the graph is to present,summarise,describe and explore the data"
    },
    {
      "question": "what is the Bar Graph ",
      "answer": ".Bar graphs are used to display the frequency distributions for variables measured at the nominal and ordinal levels"
    },
    {
      "question": "How to represent the Bar graph \n",
      "answer": "Bar graphs use the same width for all the bars on the graph, and there is space between the bars.Label the parts of the graph, including the title, the left Y, right X "
    },
    {
      "question": "what is the Histogram ",
      "answer": "histogram is a chart that is similar to a bar chart, but it is used for interval and ratio level variables"
    },
    {
      "question": "How to represent the histogram ",
      "answer": "With a histogram, the width of the bar is important, since it is the total area under the bar that represents the proportion of the phenomenon accounted for by each category"
    },
    {
      "question": "what is pie chart ",
      "answer": "Pie chart is another  way to show the relationships between classes or categories of a variable is in a pie or circle chart"
    },
    {
      "question": "How to represent the Pie chart ",
      "answer": "In a pie chart, each slice represents the proportion of the total phenomenon that is due to each of the classes or groups"
    },
    {
      "question": "what is the Quantile Quantile Plot",
      "answer": "The Quantile Quantile plot is a graphical technique for determining if two data sets come from populations with a common distribution"
    },
    {
      "question": "What does Quantile Quantile Plot will explain ",
      "answer": "Quantile Quantile plots are used to find the type of distribution for a random variable whether it be a Gaussian Distribution, Uniform Distribution, Exponential Distribution or even Pareto Distribution, etc. You can tell the type of distribution"
    },
    {
      "question": "How do we know Quantile Quantile Plot is normal ",
      "answer": "If the data is normally distributed, the points in the Quantile Quantile Plot lie on a straight diagonal line"
    },
    {
      "question": "Why do we use Quantile Quantile Plot",
      "answer": "The purpose of Quantile Quantile Plot is to find out if two sets of data come from the same distribution"
    },
    {
      "question": "What are the multivariate analysis techniques",
      "answer": "Pairwise plots,Spider Plot,Correlation Analysis,Cluster Analysis,Multivariate Analysis of Variance,Principal Component Analysis and Factor Analysis"
    },
    {
      "question": "What is frequency distribution",
      "answer": "frequency distribution depicts the frequency or count of the different outcomes in a data set or sample"
    },
    {
      "question": "What is the importance  of describe  statistics",
      "answer": "Descriptive statistics allow for the ease of data visualization. It allows for data to be presented in a meaningful and understandable way, which, in turn, allows for a simplified interpretation of the data set in question"
    },
    {
      "question": "What is the imporatance of describe  statistics",
      "answer": "There are 100 students enrolled for a particular module. To find the overall performance of the students taking the respective module and the distribution of the marks, descriptive statistics must be used. Getting the marks as raw data would prove the determination of the overall performance and the distribution of the marks to be challenging"
    },
    {
      "question": "why do we needs to do EDA",
      "answer": "The main purpose of EDA is to detect any errors, outliers as well as to understand different patterns in the data. It allows Analysts to understand the data better before making any assumptions"
    },
    {
      "question": "What are the goals of EDA",
      "answer": "The primary goal of EDA is to maximize the analysts insight into a data set and into the underlying structure of a data set"
    },
    {
      "question": "what is dot plot",
      "answer": "A dot plot, also known as a strip plot or dot chart, is a simple form of data visualization that consists of data points plotted as dots on a graph with an x and y axis"
    },
    {
      "question": "Where do we use the dot plot ",
      "answer": "Dot plot  charts are used to graphically depict certain data trends or groupings"
    },
    {
      "question": "what is an example for dot plot ",
      "answer": "A good example of dot plot would be the choice of foods that you and your friends ate for snacks"
    },
    {
      "question": "How to represent the dot plot",
      "answer": "A dot plot is a visual display in which each piece of data is represented by a dot above a number line, showing the frequency of each data value. The total number of dots in the plot is the total number of values in the data set. The data points must all be in the same units"
    },
    {
      "question": "what is Multivariate analysis",
      "answer": "Multivariate analysis is a Statistical procedure for analysis of data involving more than one type of measurement or observation"
    },
    {
      "question": "what is Quartile value",
      "answer": "Quartiles are the values that divide a list of numerical data into three quarters.There are three quartiles, first, second and third, denoted by Q1, Q2 and Q3. Here, Q2 is nothing but the median of the given data"
    },
    {
      "question": "What do you mean by IQR",
      "answer": "he expansion of IQR is Inter Quartile Range "
    },
    {
      "question": "What is the formula for IQR",
      "answer": "The formula for the interquartile range  is   Q3  upper quartile Minus Lower quartilev Q1"
    },
    {
      "question": "How do you define the median ",
      "answer": "The median is the middle value of the distribution of the given data. IQR is the range of values that resides in the middle of the scores. When a distribution is skewed, and the median is used instead of the mean to show a central tendency,"
    },
    {
      "question": "Where do we use box plot",
      "answer": "We are using box plot to identify the Outlier in the data set "
    },
    {
      "question": "What library will use in python for visual plot representation",
      "answer": "we have to import matplotlib.pyplot for any data visulaization in python "
    },
    {
      "question": "What is the time series plot",
      "answer": ".A time series plot is a graph that displays data collected in a time sequence from any process"
    },
    {
      "question": "What is the purpose of Time series plot",
      "answer": "The chart can be used to determine how the data is trending over time and if the data points are random or exhibit any pattern"
    },
    {
      "question": "what is line chart",
      "answer": "A time series plot is also known as a. line chart. The above image, which depicts time series data, is a. line chart"
    },
    {
      "question": "what is the representation of Time series plot",
      "answer": "Time series analysis is a specific way of analyzing a sequence of data points collected over an interval of time"
    },
    {
      "question": "Is Anova Multivariate analysis",
      "answer": "Multivariate analysis of variance MANOVA is an extension of the univariate analysis of variance ANOVA"
    },
    {
      "question": "what is Anova",
      "answer": "In an ANOVA, we examine for statistical differences on one continuous dependent variable by an independent grouping variable"
    },
    {
      "question": "How do you visualize multivariate data",
      "answer": "visualizing multivariate data for multiple attributes together is to use parallel coordinates"
    },
    {
      "question": "which plots used for multivariate data",
      "answer": "pair plot and interaction plot used for multivariate analysis"
    },
    {
      "question": "What is the difference between multivariate and univariate",
      "answer": "Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables"
    },
    {
      "question": "what is chi square test",
      "answer": "The chi square test is used for determining the association between categorical variables"
    },
    {
      "question": "which test used for Bivariate Analysis of two categorical Variables",
      "answer": "Chi square test used for Bivariate Analysis of two categorical Variables"
    },
    {
      "question": "which method used for Bivariate Analysis of one numerical and one categorical variable",
      "answer": "Z and T tests used for Bivariate Analysis of one numerical and one categorical variable"
    },
    {
      "question": "what is T test",
      "answer": "A t test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups"
    },
    {
      "question": "what is z test",
      "answer": " z test is a statistical test to determine whether two population means are different when the variances are known and the sample size is large "
    },
    {
      "question": "what is the secondary purpose of Scatter plots\n",
      "answer": "the secondary purpose of Scatter plot is to identify the outliers and presence of clusters"
    },
    {
      "question": "What does density mean in histogram",
      "answer": "t is the area of the bar that tells us the frequency in a histogram, not its height"
    },
    {
      "question": "What are Undirected graph",
      "answer": "Undirected graph is directionless This means that the edges have no direction"
    },
    {
      "question": "what is pair plot",
      "answer": ".A pairs plot allows us to see both distribution of single variables and relationships between two variables"
    },
    {
      "question": "What is Seaborn Pairplot",
      "answer": "Pairplot Plot pairwise relationships in a dataset"
    },
    {
      "question": "what is infinite kurtosis",
      "answer": "Infinite kurtosis can be completely normal or flat with no deviation"
    },
    {
      "question": "what is excess kurtosis",
      "answer": "Excess kurtosis means the distribution of event outcomes have lots of instances of outlier results, causing fat tails on the bell shaped distribution curve"
    },
    {
      "question": "what is Directed graph",
      "answer": "Directed graphs have directions associated with them"
    },
    {
      "question": "what is adjacency matrix ",
      "answer": "An adjacency matrix is a square matrix where the number of rows, columns and nodes are the same"
    },
    {
      "question": "what is an interaction plot",
      "answer": "An interaction plot displays the levels of one variable on the X axis and has a separate line for the means of each level of the other variable"
    },
    {
      "question": "what do you mean by Fouth statistical business moment",
      "answer": ".The fouth statistical moment talk about Kurtosis.It focus on the Peakness of distribution in the dataset."
    },
    {
      "question": "what are types of Skewness",
      "answer": "There are two types of skewness.positive skewness or negative skewness"
    },
    {
      "question": "what is r in correlation",
      "answer": "The sample correlation coefficient r is a measure of the closeness of association of the points in a scatter plot"
    },
    {
      "question": "What is density plot",
      "answer": "A density plot is a representation of the distribution of a numeric variable"
    },
    {
      "question": "What is the density curve",
      "answer": "A density curve is a graphical representation of a numerical distribution where the outcomes are continuous"
    },
    {
      "question": "What is Univariate analysis",
      "answer": "Univariate analysis is the simplest form of analyzing data. Unimeans one , so in other words your data has only one variable"
    },
    {
      "question": "What is the disavantage of scatter plots",
      "answer": ".What is the disavantage of scatter plots Interpretation can be subjective"
    },
    {
      "question": "What does strong mean in a scatter plot\n",
      "answer": "The relationship between two variables is generally considered strong when their r value is larger than 0.7"
    },
    {
      "question": "How do outliers affect scatter plots\n",
      "answer": "An outlier for a scatter plot is the point or points that are farthest from the regression line"
    },
    {
      "question": "What is a very weak correlation",
      "answer": ".As a rule of thumb, a correlation coefficient between 0.25 and 0.5 is considered to be a weak correlation between two variables"
    },
    {
      "question": ".How do you know if a correlation is strong or weak",
      "answer": ".When r is near plus 1 or minus 1, the linear relationship is strong when it is near 0, the linear relationship is weak"
    },
    {
      "question": "Describe covariance vs correlation\n",
      "answer": "covariance does not standardise the but correlation standardise the data"
    },
    {
      "question": "what is the difference between covariance and correlation\n",
      "answer": ".covariance determine only direction but correlation determine both direction and strength"
    },
    {
      "question": "What do Pearson correlations mean",
      "answer": ".Pearsons correlation coefficient is the test statistics that measures the statistical relationship, or association, between two continuous variables"
    },
    {
      "question": "why the density plot is used",
      "answer": ".It uses a kernel density estimate to show the probability density function of the variable"
    },
    {
      "question": "what is the significance of Interaction Plots in Statistics",
      "answer": "Interaction plots are used to understand the behavior of one variable depends on the value of another variable"
    },
    {
      "question": "How do you represent bivariate data",
      "answer": "Bivariate data includes data for two set of variables so two sets of data that might be linked"
    },
    {
      "question": "How do we represent bivariate data graphically and how do we analyze it",
      "answer": ".Bivariate data is most often displayed using a scatter plot"
    },
    {
      "question": "How do you analyze a density plot",
      "answer": ".If a density curve is left skewed, then the mean is less than the median,right skewed, then the Mean is greater than the median,no skew, then the mean is equal to the median"
    },
    {
      "question": "Is density same as frequency",
      "answer": "As the area of a bar represents the frequency of its interval, the height of the bar represents the density"
    },
    {
      "question": "What is the difference between a frequency histogram and a density histogram",
      "answer": "In a density histogram or probability density function, the total occurrences is one"
    },
    {
      "question": "What is a kernel plot",
      "answer": "kernel plot is also called as density plot,A Density Plot visualises the distribution of data over a continuous interval or time period"
    },
    {
      "question": "What does a Quantile Quantile plot show",
      "answer": "Quantile Quantile plot is to show if two data sets come from the same distribution"
    },
    {
      "question": "Why Quantile Quantile plot is better than a histogram",
      "answer": "Quantile Quantile Plots overcomes all the limitations of the Histogram plot"
    },
    {
      "question": "What is the difference between Probability plot and Quantile Quantile plot",
      "answer": ".A Probability plot compares the empirical cumulative distribution function,A Qunatile Qunatile plot compares the quantiles of a data distribution with the quantiles"
    },
    {
      "question": "what is unimodal",
      "answer": "Unimodal has just one peak"
    },
    {
      "question": "what is standard error of skewness",
      "answer": "The ratio of skewness to its standard error can be used as a test of normality "
    },
    {
      "question": "How is standard error calculated",
      "answer": "The standard error is calculated by dividing the standard deviation by the sample sizes square root"
    },
    {
      "question": "what is parsimonious model",
      "answer": "Parsimonious models are simple models with great explanatory predictive power"
    },
    {
      "question": "What does a whisker plot tell you",
      "answer": ".Box plots visually show the distribution of numerical data and skewness through displaying the data quartiles or percentiles and averages"
    },
    {
      "question": "what are the vertices or nodes",
      "answer": "A vertex or node of a graph is one of the objects that are connected together"
    },
    {
      "question": "what is edge or link in graph",
      "answer": ".An edge or link of a network or graph is one of the connections between the nodes or vertices of the network"
    },
    {
      "question": "what is the weighted graph",
      "answer": "Weighted graph indicate real values associated with the edges"
    },
    {
      "question": "what are the graphs",
      "answer": "In Graph theory, these networks are called graphs"
    },
    {
      "question": "What is Third business moment",
      "answer": "Skewness  which is the Third  Statistical moment measures asymmetry of data about its mean"
    },
    {
      "question": "What is symmetrical distribution",
      "answer": "Symmetrical distribution means In the data set both tails are symmetrical and Skewness is equal to zero."
    },
    {
      "question": "How to identify the symmetrical distribution ",
      "answer": "We can identify the symmetrical distribution when mean,median and mode are equal"
    },
    {
      "question": "what about  positive  skewness",
      "answer": "Positive skewness means in the dataset when Mode is lesser than Median and Median is lesser than Mean."
    },
    {
      "question": "What about  negative skewness",
      "answer": "Negative skewness means in the dataset when Mean  is lesser than Median and Median is lesser than Mode."
    },
    {
      "question": "what is the kurtosis of normal distribution",
      "answer": "This means that normal distribution may have a kurtosis of 3 or excess kurtosis of 0."
    },
    {
      "question": "What is the threshold for skewness",
      "answer": ".If skewness is less than minus 1 or greater than 1 the distribution is highly skewed, it is between minus 1 and minus0.5 or between 0.5 and 1 the distribution is moderately skewed"
    },
    {
      "question": "what are the  types of  kurtosis",
      "answer": "There are three types of Kurtosis is there.Mesokurtic,leptokurtic and platykurtic"
    },
    {
      "question": "Explain about the mesokurtic",
      "answer": "Mesokurtic having the kurtosis of 3.This group involves the normal distribution and some specific binomial distributions."
    },
    {
      "question": "Explain about the Leptokurtic",
      "answer": "The kurtosis is greater than 3, or excess kurtosis is greater than 0. This is the distribution with fatter tails and a more narrow peak"
    },
    {
      "question": "Explain about the Platykurtic",
      "answer": "The kurtosis is smaller than 3 or negative for excess kurtosis. This is a distribution with very thin tails compared to the normal distribution"
    },
    {
      "question": "What is the example for Univariate analysis",
      "answer": ".A variable in univariate analysis is just a condition or subset that your data falls into"
    },
    {
      "question": "What is the difference between Univariate analysis and Multivariate analysis",
      "answer": "Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables"
    },
    {
      "question": "Why we using boosting",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction"
    },
    {
      "question": "Use of boosting",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction"
    },
    {
      "question": "Why do we use boosting in machine learning",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction."
    },
    {
      "question": "What is boosting technique",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors."
    },
    {
      "question": "Describe Boosting technique",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors."
    },
    {
      "question": "what is boosting",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors."
    },
    {
      "question": "Define boosting",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors"
    },
    {
      "question": "Why is Boosting so effective",
      "answer": "Ensemble methods reduce the bias and variance of our Machine Learning models.Ensemble methods help increase the stability and performance of machine learning models by eliminating the dependency of a single estimator."
    },
    {
      "question": "What are different boosting techniques",
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm"
    },
    {
      "question": "What is the key idea of boosting",
      "answer": "The term Boosting refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor"
    },
    {
      "question": "Describe idea of Boosting",
      "answer": "The term Boosting  refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor"
    },
    {
      "question": "Define key idea of boosting",
      "answer": "The term Boosting  refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor"
    },
    {
      "question": "Why gradient is boosting",
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees are fit and at every step, the goal is to improve the accuracy from the prior tree"
    },
    {
      "question": "What is boost in XGBoost",
      "answer": "XGBoost stands for Extreme Gradient Boosting, where the term Gradient Boosting originates from the paper Greedy Function Approximation  A Gradient Boosting Machine, by Friedman. The gradient boosted trees has been around for a while, and there are a lot of materials on the topic"
    },
    {
      "question": "Who invented boosting",
      "answer": "Robert Schapire and Yoav Freund made a huge impact in machine and statistical learning with their invention of boosting, which has survived the test of time"
    },
    {
      "question": "How does boosting reduce bias",
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models"
    },
    {
      "question": "On which technique boosting Cannot be applied",
      "answer": "overfitting than AdaBoost Boosting techniques tend to have low bias and high variance For basic linear regression classifiers, there is no effect of using Gradient Boosting"
    },
    {
      "question": "On which technique boosting can be applied",
      "answer": "Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series. Firstly, a model is built from the training data"
    },
    {
      "question": "Why is boosting better than bagging",
      "answer": "Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance. In Bagging, each model receives an equal weight. In Boosting, models are weighed based on their performance"
    },
    {
      "question": "Describe why boosting is better than bagging",
      "answer": "Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance. In Bagging, each model receives an equal weight. In Boosting, models are weighed based on their performance"
    },
    {
      "question": "Does boosting speed up model learning",
      "answer": "Boosting is a popular machine learning algorithm that increases accuracy of your model\n"
    },
    {
      "question": "What is boosting decision tree",
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage"
    },
    {
      "question": "Define boosting decision tree",
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage"
    },
    {
      "question": "what is ment by boosting decision tree",
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage"
    },
    {
      "question": "Boosting decision tree",
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage"
    },
    {
      "question": "What is a gradient boosting classifier",
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model"
    },
    {
      "question": "gradient boosting classifier",
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model"
    },
    {
      "question": "What is boosting in stats",
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications"
    },
    {
      "question": "Define boosting in stats",
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications"
    },
    {
      "question": "Describe boosting in stats",
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications"
    },
    {
      "question": "What is the difference between AdaBoost and gradient boosting",
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost"
    },
    {
      "question": "Describe use of Boosting",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction"
    },
    {
      "question": "Diffrentiate AdaBoost and gradient boosting",
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost"
    },
    {
      "question": "Is gradient boosting supervised or unsupervised",
      "answer": "Gradient boosting derived from the term gradient boosting machines is a popular supervised machine learning technique for regression and classification problems that aggregates an ensemble of weak individual models to obtain a more accurate final model"
    },
    {
      "question": "Can boosting be used for regression",
      "answer": "Gradient boosting can be used for regression and classification problems"
    },
    {
      "question": "How does boosting reduce variance",
      "answer": "Compared to the simple base learner,boosting increases variance and reduces bias.If you boost a simple base learner, the resulting model will have lower variance compared to some high variance reference like a too deep decision tree"
    },
    {
      "question": "What is ensemble tree",
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially"
    },
    {
      "question": "Describe ensemble tree",
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially"
    },
    {
      "question": "Define ensemble tree",
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially"
    },
    {
      "question": "ensemble tree",
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially\n"
    },
    {
      "question": "Which option is highlighting the difference between blending and stacking",
      "answer": "The difference between stacking and blending is that Stacking uses out of fold predictions for the train set of the next layer,and Blending uses a validation set to train the next layer"
    },
    {
      "question": "Is Random Forest bagging or boosting",
      "answer": "The random forest algorithm is actually a bagging algorithm also here, we draw random bootstrap samples from your training set. However, in addition to the bootstrap samples, we also draw random subsets of features for training the individual trees in bagging, we provide each tree with the full set of features"
    },
    {
      "question": "Is Random Forest a boosting algorithm",
      "answer": "Random Forest is an boosting algorithm which uses trees as its weak classifiers"
    },
    {
      "question": "Which is best boosting algorithm",
      "answer": "Gradient Boosting"
    },
    {
      "question": "best boosting algorithm",
      "answer": "Gradient Boosting"
    },
    {
      "question": "What is the difference between XGBoost and LightGBM",
      "answer": "In XGBoost, trees grow depth wise while in LightGBM, trees grow leaf wise which is the fundamental difference between the two frameworks"
    },
    {
      "question": "Diffrentiate XGBoost and LightGBM",
      "answer": "In XGBoost, trees grow depth wise while in LightGBM, trees grow leaf wise which is the fundamental difference between the two frameworks"
    },
    {
      "question": "Is boosting an ensemble method",
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers"
    },
    {
      "question": "Does gradient boosting use bagging",
      "answer": "If the classifier is stable and simple high bias then we should apply Boosting. Bagging is extended to Random forest model while Boosting is extended to Gradient boosting\n"
    },
    {
      "question": "Does boosting use bootstrap",
      "answer": "Boosting also requires bootstrapping"
    },
    {
      "question": "What is gradient boosting regression",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n"
    },
    {
      "question": "gradient boosting regression",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
    },
    {
      "question": "What is ment by gradient boosting regression",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n"
    },
    {
      "question": "Define gradient boosting regression",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n"
    },
    {
      "question": "Describe gradient boosting regression",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n"
    },
    {
      "question": "What is loss function in gradient boosting",
      "answer": "n the context of gradient boosting, the training loss is the function that is optimized using gradient descent"
    },
    {
      "question": "Describe loss function in gradient boosting",
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent"
    },
    {
      "question": "Define loss function in gradient boosting",
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent"
    },
    {
      "question": "What is ment by loss function in gradient boosting",
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent\n"
    },
    {
      "question": "loss function in gradient boosting",
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent\n"
    },
    {
      "question": "Does gradient boosting Overfit",
      "answer": "Gradient boosting is a greedy algorithm and can overfit a training dataset quickly"
    },
    {
      "question": "type of boosting technique",
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm"
    },
    {
      "question": "Describe diffrent type of boosting technique",
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm"
    },
    {
      "question": "boosted classification trees",
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "Define boosted classification trees",
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "Describe boosted classification trees",
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "What is ment by boosted classification trees",
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "Is gradient boosting better than random forest",
      "answer": "If you carefully tune parameters, gradient boosting can result in better performance than random forests"
    },
    {
      "question": "Does gradient boosting use gradient descent",
      "answer": "Gradient boosting redefines boosting as a numerical optimisation problem where the objective is to minimise the loss function of the model by adding weak learners using gradient descent"
    },
    {
      "question": "How does gradient boosting tree work",
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error.If a small change in the prediction for a case causes no change in error, then next target outcome of the case is zero"
    },
    {
      "question": "Describe working of gradient boosting tree ",
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error.If a small change in the prediction for a case causes no change in error, then next target outcome of the case is zero"
    },
    {
      "question": "Is gradient boosting used for classification",
      "answer": "Gradient Boosting Trees can be used for both regression and classification"
    },
    {
      "question": "Describe boosting decision tree",
      "answer": "Boosting means that each tree is dependent on prior trees\n"
    },
    {
      "question": "What are the limitations of boosting",
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up"
    },
    {
      "question": "Describe limitations of boosting",
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up"
    },
    {
      "question": "limitations of boosting",
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up"
    },
    {
      "question": "Is gradient boosting linear",
      "answer": "When gradient boosting is done along with linear regression, it is nothing more than another linear model over the existing linear model"
    },
    {
      "question": "What is the difference between adaptive boosting and gradient boosting",
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost"
    },
    {
      "question": "Diffrentiate adaptive boosting and gradient boosting",
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set"
    },
    {
      "question": "How does boosting algorithm work",
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set"
    },
    {
      "question": "Describe working of boosting algorithm",
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set\n"
    },
    {
      "question": "What is ment by working of boosting algorithm",
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set"
    },
    {
      "question": "Why is it called gradient boosting",
      "answer": "The residual is the gradient of loss function and the sign of the residual, , is the gradient of loss function . By adding in approximations to residuals, gradient boosting machines are chasing gradients, hence, the term gradient boosting."
    },
    {
      "question": "Why XGBoost is fast",
      "answer": "To calculate the gain in each split, XGBoost uses CPU cache to store calculated gradients and Hessians to make the necessary calculations fast. When data does not fit into the cache and main memory, then it becomes important to use the disk space"
    },
    {
      "question": "How does Boosting make prediction",
      "answer": "In Boosting, fitting of many models on training examples relies on target values for calculating residuals. This leads to shift in target values in test set"
    },
    {
      "question": "What is ment by gradient boosting classifier",
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model"
    },
    {
      "question": "Why does boosting reduce bias",
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models. The term Boosting refers to a family of algorithms which converts a weak learner to a strong learner. Boosting gets multiple learners"
    },
    {
      "question": "Does boosting reduce variance or bias",
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models. The term Boosting refers to a family of algorithms which converts a weak learner to a strong learner"
    },
    {
      "question": "What are boosting models",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors"
    },
    {
      "question": "boosting model",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors"
    },
    {
      "question": "Define boosting models",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors"
    },
    {
      "question": "Describe boosting models",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors\n"
    },
    {
      "question": "What is ment by boosting models",
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors"
    },
    {
      "question": "Can bagging reduce bias",
      "answer": "The good thing about Bagging is, that it also does not increase the bias again, which we will motivate in the following section. That is why the effect of using Bagging together with Linear Regression is low You can not decrease the bias via Bagging, but with Boosting"
    },
    {
      "question": "Why does bagging increase bias",
      "answer": "That is because bagging allows us to approximate relative complex response surfaces by practically smoothing over the learners decision boundaries. That said, you raise a good point about bagging using less data my understanding is that this is a problem when the learners are potentially weak\n"
    },
    {
      "question": "What the difference between bagging and boosting",
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification"
    },
    {
      "question": "Why is boosting used",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction\n"
    },
    {
      "question": "What are boosted classification trees",
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "What is the primary difference between bagging and boosting algorithms",
      "answer": "Bagging is a method of merging the same type of predictions. Boosting is a method of merging different types of predictions. Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance"
    },
    {
      "question": "Diffrentiate bagging and boosting",
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification"
    },
    {
      "question": "what is boosting used for",
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction"
    },
    {
      "question": "What is the difference between gradient boosting and Random Forest",
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are How trees are built random forests builds each tree independently while gradient boosting builds one tree at a time.\n"
    },
    {
      "question": "Diffrentiate gradient boosting and Random Forest",
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are How trees are built random forests builds each tree independently while gradient boosting builds one tree at a time."
    },
    {
      "question": "Why boosting is better than random forest",
      "answer": "Boosting reduces error mainly by reducing bias . On the other hand, Random Forest uses as you said fully grown decision trees.It tackles the error reduction task in the opposite way by reducing variance\n"
    },
    {
      "question": "What is extreme gradient boost",
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm"
    },
    {
      "question": "extreme gradient boost",
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm"
    },
    {
      "question": "What is ment by extreme gradient boost",
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm"
    },
    {
      "question": "What is boosting regression",
      "answer": "Boosting, or boosted regression, is a recent data mining technique. that has shown considerable success in predictive accuracy"
    },
    {
      "question": "boosting regression",
      "answer": "Boosting, or boosted regression, is a recent data mining technique. that has shown considerable success in predictive accuracy"
    },
    {
      "question": "What is light gradient boosting machine",
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm"
    },
    {
      "question": "light gradient boosting machine",
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm\n"
    },
    {
      "question": "what is ment by light gradient boosting machine",
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm"
    },
    {
      "question": "Does bagging increase variance",
      "answer": "Bootstrap aggregation, or bagging, in machine learning decreases variance through building more advanced models of complex data sets.Since this approach consolidates discovery into more defined boundaries, it decreases variance and helps with overfitting"
    },
    {
      "question": "How do boosting techniques work",
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model"
    },
    {
      "question": "How does boosting work",
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model"
    },
    {
      "question": "What is the difference between bootstrapping bagging and boosting",
      "answer": "In the bagging method all the individual models will take the bootstrap samples and create the models in parallel. Whereas in the boosting each model will build sequentially. The output of the first model will be pass along with the bootstrap samples data."
    },
    {
      "question": "Diffrentiate bootstrapping bagging and boosting",
      "answer": "In the bagging method all the individual models will take the bootstrap samples and create the models in parallel. Whereas in the boosting each model will build sequentially. The output of the first model will be pass along with the bootstrap samples data."
    },
    {
      "question": "How does boost work",
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule"
    },
    {
      "question": "How does boosting make predictionWhy use weak learners in boosting",
      "answer": "In Boosting, fitting of many models on training examples relies on target values for calculating residuals. This leads to shift in target values in test set, i.e. prediction shift. So, it proposes a method to bypass this problem\n"
    },
    {
      "question": "Why use weak learners in boosting",
      "answer": "However, there are times when ML models are weak learners. Boosting is a way to take several weak models and combine them into a stronger one. Doing this allows you to eliminate bias, improve model accuracy, and boost performance"
    },
    {
      "question": "What is Gradient Boosting algorithm",
      "answer": "Gradient boosting algorithm is one of the most powerful algorithms in the field of machine learning.Gradient boosting algorithm can be used for predicting not only continuous target variable  but also categorical target variable \n"
    },
    {
      "question": "what is the main objective of boosting",
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree"
    },
    {
      "question": "Describe main objective of Boosting",
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree"
    },
    {
      "question": "Main objective of Boosting",
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree"
    },
    {
      "question": "How is boosting done",
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model"
    },
    {
      "question": "How do boosted trees work",
      "answer": "Boosting means combining a learning algorithm in series to achieve a strong learner from many sequentially connected weak learners.Trees in boosting are weak learners but adding many trees in series and each focusing on the errors from previous one make boosting a highly efficient and accurate model"
    },
    {
      "question": "What boosted trees",
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "What meant by boosted trees",
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "Describe boosted trees",
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting"
    },
    {
      "question": "What is the learning rate in boosting",
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results"
    },
    {
      "question": "Describe learning rate in boosting",
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results.\n"
    },
    {
      "question": "Define learning rate in boosting",
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results"
    },
    {
      "question": "Is gradient boosting ensemble",
      "answer": "The Gradient Boosting Machine is a powerful ensemble machine learning algorithm that uses decision trees. Boosting is a general ensemble technique that involves sequentially adding models to the ensemble where subsequent models correct the performance of prior models"
    },
    {
      "question": "What is difference between boosting and bagging",
      "answer": "Bagging is a technique for reducing prediction variance by producing additional data for training from a dataset by combining repetitions with combinations to create multi sets of the original data. Boosting is an iterative strategy for adjusting an observations weight based on the previous classification"
    },
    {
      "question": "What is boosting data science",
      "answer": "Lots of analyst misinterpret the term boosting used in data science.Boosting grants power to machine learning models to improve their accuracy of prediction. Boosting algorithms are one of the most widely used algorithm in data science competitions"
    },
    {
      "question": "How many trees are in gradient boosting",
      "answer": "Gradient Boosting is similar to AdaBoost in that they both use an ensemble of decision trees to predict a target label. However, unlike AdaBoost, the Gradient Boost trees have a depth larger than 1. In practice, you will typically see Gradient Boost being used with a maximum number of leaves of between 8 and 32"
    },
    {
      "question": "Does gradient boosting use learning rate",
      "answer": "A problem with gradient boosted decision trees is that they are quick to learn and overfit training data. One effective way to slow down learning in the gradient boosting model is to use a learning rate, also called shrinkage"
    },
    {
      "question": "When to Use bagging vs boosting",
      "answer": "Bagging is usually applied where the classifier is unstable and has a high variance. Boosting is usually applied where the classifier is stable and simple and has high bias.\n"
    },
    {
      "question": "Is AdaBoost sensitive to outliers",
      "answer": "AdaBoost is known to be sensitive to outliers and  noise"
    },
    {
      "question": "What is shrinkage in gradient boosting",
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model."
    },
    {
      "question": "What is ment by shrinkage in gradient boosting",
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model."
    },
    {
      "question": "Describe shrinkage in gradient boosting",
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model."
    },
    {
      "question": "What is Max depth in gradient boosting",
      "answer": "Gradient Boosting is similar to AdaBoost in that they both use an ensemble of decision trees to predict a target label. However, unlike AdaBoost, the Gradient Boost trees have a depth larger than 1. In practice, you will typically see Gradient Boost being used with a maximum number of leaves of between 8 and 32"
    },
    {
      "question": "Why is boosting prone to overfitting",
      "answer": "Unlike what mentioned in tdc comment, most of boosting methods are highly sensitive to the labeling noise and may easily overfit in the presence of labeling noise. In datasets where Bayes error rates are far from 0  boosting methods can easily overfit , as well"
    },
    {
      "question": "What are the advantages of XGBoost",
      "answer": "XGB consists of a number of hyper parameters that can be tuned a primary advantage over gradient boosting machines.XGBoost has an in built capability to handle missing values.It provides various intuitive features, such as parallelisation, distributed computing, cache optimisation, and more. "
    },
    {
      "question": "What are the disadvantages of XGBoost",
      "answer": "Like any other boosting method, XGB is sensitive to outliers.Unlike LightGBM, in XGB, one has to manually create dummy variable, label encoding for categorical features before feeding them into the models."
    },
    {
      "question": "How is boosting model trained",
      "answer": ".In some cases, boosting models are trained with an specific fixed weight for each learner called learning rate and instead of giving each sample an individual weight, the models are trained trying to predict the differences between the previous predictions on the samples and the real values of the objective variable."
    },
    {
      "question": "How to train boosting model",
      "answer": "In some cases, boosting models are trained with an specific fixed weight for each learner called learning rate and instead of giving each sample an individual weight, the models are trained trying to predict the differences between the previous predictions on the samples and the real values of the objective variable."
    },
    {
      "question": "What is a strong learner",
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods\n"
    },
    {
      "question": "Define strong learner",
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods"
    },
    {
      "question": "What is ment by strong learner",
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods"
    },
    {
      "question": "Is boost sequential",
      "answer": "Boosting is a sequential ensemble method that iteratively adjusts the weight of observation as per the last classification. If an observation is incorrectly classified, it increases the weight of that observation"
    },
    {
      "question": "Can gradient boosting handle missing values",
      "answer": "There has been an enhancement in the algorithm gradient boosting due to which you no longer have to handle the missing values because it will handle it of itself.Hist Gradient Boosting Regressor, both classification regression now have the power of native support for missing values or nans "
    },
    {
      "question": "Is gradient boosting a tree based method",
      "answer": "Gradient Boosting Decision Tree Based Method for Predicting Interactions Between Target Genes and Drugs. Determining the target genes that interact with drugs drug target interactions plays an important role in drug discovery"
    },
    {
      "question": "What is boosting XGBoost",
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data"
    },
    {
      "question": "boosting XGBoost",
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data"
    },
    {
      "question": "Describe boosting XGBoost",
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data"
    },
    {
      "question": "What is ment by boosting XGBoost",
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data"
    },
    {
      "question": "What is booster in XGBoost",
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases"
    },
    {
      "question": "booster in XGBoost",
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases\n"
    },
    {
      "question": "Describe booster in XGBoost",
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases"
    },
    {
      "question": "What is ment by booster in XGBoost",
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases"
    },
    {
      "question": "What is gradient boosting Regressor",
      "answer": "Gradient Boosting for regression. GB builds an additive model in a forward stage wise fashion it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function"
    },
    {
      "question": "How many columns can XGBoost handle",
      "answer": "No more than 32 columns per categorical feature"
    },
    {
      "question": "Does XGBoost require a lot of data",
      "answer": "The amount of data you need depends on the problem see this great article on learning curves, but in general xgboost is very data efficient like random forests and has found a lot of use where data is expensive to produce as in medicine"
    },
    {
      "question": "How do boosted decision trees work",
      "answer": ".Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage"
    },
    {
      "question": "What is the difference between XGBoost and gradient boost",
      "answer": "XGBoost is more regularized form of Gradient Boosting. XGBoost uses advanced regularization L1 and L2, which improves model generalization capabilities. XGBoost delivers high performance as compared to Gradient Boosting. Its training is very fast and can be parallelized,distributed across clusters"
    },
    {
      "question": "Diffrentiate XGBoost and gradient boost",
      "answer": "XGBoost is more regularized form of Gradient Boosting. XGBoost uses advanced regularization L1 and L2, which improves model generalization capabilities. XGBoost delivers high performance as compared to Gradient Boosting. Its training is very fast and can be parallelized,distributed across clusters"
    },
    {
      "question": "What is regression tree",
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch"
    },
    {
      "question": "Describe regression tree",
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch"
    },
    {
      "question": "What is ment by regression tree ",
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch"
    },
    {
      "question": "What is a boosted tree model",
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model"
    },
    {
      "question": "Describe boosted tree model",
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model"
    },
    {
      "question": "What is ment by boosted tree model",
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model"
    },
    {
      "question": "Why is gradient boosting used",
      "answer": "Gradient Boosting Algorithm is generally used when we want to decrease the Bias error.Gradient Boosting Algorithm can be used in regression as well as classification problems. In regression problems, the cost function is MSE whereas, in classification problems, the cost function is Log Loss"
    },
    {
      "question": "What is Gamma in XGBoost",
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned"
    },
    {
      "question": "Gamma in XGBoost",
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned"
    },
    {
      "question": "What is ment by Gamma in XGBoost",
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned"
    },
    {
      "question": "Describe Gamma in XGBoost",
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned"
    },
    {
      "question": "Why is gradient boosting called gradient",
      "answer": "The residual is the gradient of loss function and the sign of the residual,is the gradient of loss function.By adding in approximations to residuals, gradient boosting machines are chasing gradients, hence, the term gradient boosting\n"
    },
    {
      "question": "What is gradient boosting framework",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
    },
    {
      "question": "gradient boosting framework",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
    },
    {
      "question": "Describe gradient boosting framework",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
    },
    {
      "question": "What is ment by gradient boosting framework",
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
    },
    {
      "question": "Is boosting linear",
      "answer": "Fits an exponential cost function and is linear with respect to the observation. Thus, boosting is seen to be a specific type of linear regression"
    },
    {
      "question": "What is a learning boost",
      "answer": "Learning boosts are a learning program strategy in which learners are sent short pieces of information, activities, or quiz questions to boost retention of a particular topic or subject"
    },
    {
      "question": "What is boosting in AI",
      "answer": "Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series"
    },
    {
      "question": "How do you boost an algorithm",
      "answer": "Step 1 The base learner takes all the distributions and assign equal weight or attention to each observation.Step 2 If there is any prediction error caused by first base learning algorithm, then we pay higher attention to observations having prediction error. Then, we apply the next base learning algorithm"
    },
    {
      "question": "Who invented gradient boosting",
      "answer": "Jerome Friedman"
    },
    {
      "question": "What is a boost model",
      "answer": "BOOST feedback model is one such popular informal method. It is used to give constructive and continuous feedback about positive behaviour as well as rectifying shortcomings. It has been proven to identify and tackle specific performance issues before they escalate into major problems"
    },
    {
      "question": "What is histogram based gradient boosting",
      "answer": "Histogram based gradient boosting is a technique for training faster decision trees used in the gradient boosting ensemble."
    },
    {
      "question": "What is average path length",
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network."
    },
    {
      "question": "Define nodes ",
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges."
    },
    {
      "question": "What is network analytics",
      "answer": "Network analytics is any process where network data is collected and analyzed to improve the performance, reliability, visibility, or security of the network."
    },
    {
      "question": "Describe depth first search",
      "answer": "The DFS algorithm aims to move as far as possible away from the root node."
    },
    {
      "question": "Methods of network analysis",
      "answer": "Among basic network analysis methods include  Method  Critical Path Method  And  Critical Chain Method PERT Method, Program Evaluation and Review Technique"
    },
    {
      "question": "Describe distances",
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops."
    },
    {
      "question": "What is distances",
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops."
    },
    {
      "question": "What is dyads",
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes."
    },
    {
      "question": "Average path length",
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network."
    },
    {
      "question": "Define average path length",
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network.\n"
    },
    {
      "question": "Types of centrality",
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network\n"
    },
    {
      "question": "What does a network analyst do",
      "answer": "Network analysts are employed by businesses to optimize IT network operations. Their duties include analyzing network requirements, setting up computer networks in one or across multiple locations, and configuring computer hardware and software for optimal network communication."
    },
    {
      "question": "What is network density",
      "answer": "Network density is the number of edges divided by the total possible edges."
    },
    {
      "question": "Types of network analysis",
      "answer": "Point to point analysis. A point to point analysis is the most common routing problem. \nFinding Coverage. \nOptimize Fleet. \nSelect Optimal Site. \nOrigin Destination  OD Cost Matrix.\n"
    },
    {
      "question": "What is centrality",
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network"
    },
    {
      "question": "Types of edges",
      "answer": "a.Bidirectional edges\nb.Unidirectional edges"
    },
    {
      "question": "Network traffic data",
      "answer": "Network traffic is the amount of data moving across a computer network at any given time. Network traffic, also called data traffic, is broken down into data packets and sent over a network before being reassembled by the receiving device or computer."
    },
    {
      "question": "What is OD Matrix",
      "answer": "Origin Destination  matrix describes people movement in a certain area. An OD matrix is necessary for planning a good public transportation system. However, the exact values of OD matrix are difficult to measure."
    },
    {
      "question": "Distances",
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops."
    },
    {
      "question": "Dyads",
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes.\n"
    },
    {
      "question": "Centrality",
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network"
    },
    {
      "question": "What is network analysis PERT CPM",
      "answer": "PERT and CPM are well known network technology.It is espicially using for planning ,scheduling and executing large time bound project,which involve careful co ordination of a variety of complex and inter related activities and resources.\n"
    },
    {
      "question": "Network density",
      "answer": "Network density is the number of edges divided by the total possible edges."
    },
    {
      "question": "Define distances",
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops."
    },
    {
      "question": "Define centrality",
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network"
    },
    {
      "question": "What is abbrevation of CCM",
      "answer": "Abbrevation of  ccm  is critical chain method"
    },
    {
      "question": "Abbrevation of CCM",
      "answer": "Abbrevation of  ccm  is critical chain method"
    },
    {
      "question": "Centrality measure is best",
      "answer": "Freemans closeness centrality, the total geodesic distance from a given vertex to all other vertices, is the best known example. Note that this classification is independent of the type of walk counted i.e. walk, trail, path, geodesic."
    },
    {
      "question": "What is a Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "Define Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "Explain Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "Describes dyads",
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes."
    },
    {
      "question": "Breadth first search",
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level"
    },
    {
      "question": "Describe centrality",
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network"
    },
    {
      "question": "Accessibility",
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network"
    },
    {
      "question": "Cliques",
      "answer": "The maximum number of  points who have all possible ties present among themselves"
    },
    {
      "question": "Define breadth first search",
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level"
    },
    {
      "question": "Describe accessibility",
      "answer": "In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network"
    },
    {
      "question": "What is edges",
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network\n"
    },
    {
      "question": "Edges",
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network"
    },
    {
      "question": "Abbrevation of CPM",
      "answer": "CPM for Critical Path Method \n"
    },
    {
      "question": "Full form of  CCM",
      "answer": "The ArcGIS Network Analyst extension enables the effective movement of goods, efficient organization and coordination of vehicles, and intelligent transport network analysis. Make smarter decisions by developing strategic routing plans."
    },
    {
      "question": "What is the difference between eigenvector centrality and betweenness centrality",
      "answer": "Betweenness centrality quantifies how many times a particular node comes in the shortest chosen path between two other nodes. Eigenvector centrality is a measure of the influence of a node in a network."
    },
    {
      "question": "Defination of Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "What do you mean by Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "What is hops",
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops."
    },
    {
      "question": "Define cliques",
      "answer": "The maximum number of  points who have all possible ties present among themselves"
    },
    {
      "question": "What is depth first search",
      "answer": "The DFS algorithm aims to move as far as possible away from the root node."
    },
    {
      "question": "Define edges",
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network"
    },
    {
      "question": "Example of Network",
      "answer": "If we are studying a social relationship between Facebook users, nodes are target users and edges are relationship such as friendships between users or group memberships."
    },
    {
      "question": "Define hops",
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops."
    },
    {
      "question": "Describe Cliques",
      "answer": "The maximum number of  points who have all possible ties present among themselves"
    },
    {
      "question": "Depth first search",
      "answer": "The DFS algorithm aims to move as far as possible away from the root node."
    },
    {
      "question": "What is nodes ",
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges."
    },
    {
      "question": "Define depth first search",
      "answer": "The DFS algorithm aims to move as far as possible away from the root node."
    },
    {
      "question": "Hops",
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops."
    },
    {
      "question": "What is cliques",
      "answer": "The maximum number of  points who have all possible ties present among themselves"
    },
    {
      "question": "Nodes ",
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges."
    },
    {
      "question": "Why Network Analysis",
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms."
    },
    {
      "question": "Application of network analyst",
      "answer": "Network Analyst provides a vehicle routing problem solver that can be used to determine solutions for such complex fleet management tasks. Consider an example of delivering goods to grocery stores from a central warehouse location. A fleet of three trucks is available at the warehouse and also computational biology, engineering, finance, marketing, neuroscience, political science, and public health"
    },
    {
      "question": "Describe network density",
      "answer": "Network density is the number of edges divided by the total possible edges."
    },
    {
      "question": "What is meant by network density",
      "answer": "Network density is the number of edges divided by the total possible edges."
    },
    {
      "question": "Describe hops",
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops."
    },
    {
      "question": "Define dyads",
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes."
    },
    {
      "question": "Describe average path length",
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network."
    },
    {
      "question": "What is breadth first search",
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level"
    },
    {
      "question": "Describe breadth first search",
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level"
    },
    {
      "question": "What is accessibility",
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network"
    },
    {
      "question": "What is origin destination cost matrix",
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination."
    },
    {
      "question": "Origin destination cost matrix",
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination."
    },
    {
      "question": "Define origin destination cost matrix",
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination."
    },
    {
      "question": "Describe origin destination cost matrix",
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination."
    },
    {
      "question": "Disadvantages of degeree centrality",
      "answer": "It only capture local information of nodes.In many applications, we need more informative measures that can further distinguish among nodes that have almost equally low degrees, or almost equally high degrees"
    },
    {
      "question": "What is the difference between degree centrality and eigenvector centrality",
      "answer": "In degree centrality awards one centrality point for every link a node receives.Eigenvector centrality differs from indegree centrality a node receiving many links does not necessarily have a high eigenvector centrality ,So it might be that all linkers have low or null eigenvector centrality"
    },
    {
      "question": "Difference between degree centrality and eigenvector centrality",
      "answer": "In degree centrality awards one centrality point for every link a node receives.Eigenvector centrality differs from indegree centrality a node receiving many links does not necessarily have a high eigenvector centrality ,So it might be that all linkers have low or null eigenvector centrality"
    },
    {
      "question": "What is the difference between degree centrality and closeness centrality",
      "answer": "Degree centrality is measured as the number of direct links that involve a given node. Closeness centrality is the shortest path between a node and all other reachable nodes."
    },
    {
      "question": "Difference between degree centrality and closeness centrality",
      "answer": "Degree centrality is measured as the number of direct links that involve a given node. Closeness centrality is the shortest path between a node and all other reachable nodes."
    },
    {
      "question": "Algorithms used in network analytics",
      "answer": "Edge betweenness\nFast Greedy\nLeading eigenvector"
    },
    {
      "question": "Properties of  nodes",
      "answer": "Centrality measures\neigenvector centrality\npage rank\ndiffusion centrality"
    },
    {
      "question": "What is page rank ",
      "answer": "PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website"
    },
    {
      "question": "Page rank",
      "answer": "PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website"
    },
    {
      "question": "What are network visualization software",
      "answer": "Gephi\nCytoscape\nIgraph"
    },
    {
      "question": "What is network analysis used for in GIS",
      "answer": "Network analysis is an operation in GIS which analyses the datasets of geographic network or real world network. Network analysis examine the properties of natural and man made network in order to understand the behaviour of flows within and around such networks and locational analysis."
    },
    {
      "question": "What are the two methods of network analysis",
      "answer": "Among basic network analysis methods include  Method  Critical Path Method  And  Critical Chain Method PERT Method, Program Evaluation and Review Technique"
    },
    {
      "question": "Network analysis in Quantitative techniques",
      "answer": "An activity represents an action and consumption of resources time, money, energy required to complete a portion of a project. Activity is represented by an arrow.  An event or node will always occur at the beginning and end of an activity."
    },
    {
      "question": "What is network analysis in quantitative techniques",
      "answer": "An activity represents an action and consumption of resources time, money, energy required to complete a portion of a project. Activity is represented by an arrow.  An event or node will always occur at the beginning and end of an activity."
    },
    {
      "question": "What is network analysis in cyber security",
      "answer": "Network traffic analysis  is a method of monitoring network availability and activity to identify anomalies, including security and operational issues. Collecting a realtime and historical record of whats happening on your network. Detecting malware such as ransomware activity."
    },
    {
      "question": "Type of matrix used in network analysis",
      "answer": "a.Adjacent and edges matrix\nb.Vertices matrix"
    },
    {
      "question": "Which algorithm is used in page rank",
      "answer": "In page rank recursive algorithms is using"
    },
    {
      "question": "What is network traffic data",
      "answer": "Network traffic is the amount of data moving across a computer network at any given time. Network traffic, also called data traffic, is broken down into data packets and sent over a network before being reassembled by the receiving device or computer."
    },
    {
      "question": "What is network traffic analysis ",
      "answer": "Network traffic analysis is a method of monitoring network availability and activity to identify anomalies, including security and operational issues.\n"
    },
    {
      "question": "OD Matrix",
      "answer": "Origin Destination  matrix describes people movement in a certain area. An OD matrix is necessary for planning a good public transportation system. However, the exact values of OD matrix are difficult to measure.\n"
    },
    {
      "question": "What are the types of network analysis",
      "answer": "Point to point analysis. A point to point analysis is the most common routing problem. \nFinding Coverage. \nOptimize Fleet. \nSelect Optimal Site. \nOrigin Destination  OD Cost Matrix."
    },
    {
      "question": "Explain various rules for drawing a network",
      "answer": "Rules for constructing network\n1 Each activity is represented by one and only one arrow. i.e only one activity can connect any two nodes. 2 No two activities can be identified by the same head and tail events. 3 Nodes are numbered to identify an activity uniquely"
    },
    {
      "question": "What is abbrevation of  PERT ",
      "answer": "PERT is the abbreviated form for Program Evaluation and Review Techniques"
    },
    {
      "question": "Abbrevation of  PERT ",
      "answer": "PERT is the abbreviated form for Program Evaluation and Review Techniques"
    },
    {
      "question": "What is abbrevation of CPM",
      "answer": "CPM for Critical Path Method "
    },
    {
      "question": "Full form of CPM",
      "answer": "CPM for Critical Path Method "
    },
    {
      "question": "What is difference between CPM and PERT",
      "answer": "PERT is that technique of project management which is used to manage uncertain i.e  time is not known activities of any project. CPM is that technique of project management which is used to manage only certain  i.e time is known activities of any project."
    },
    {
      "question": "Difference between CPM and PERT",
      "answer": "PERT is that technique of project management which is used to manage uncertain i.e  time is not known activities of any project. CPM is that technique of project management which is used to manage only certain  i.e time is known activities of any project."
    },
    {
      "question": "What is network analytics in IoT",
      "answer": "Network based analytics is critical to managing IoT infrastructure. Network analytics has the power to examine details of the IoT communications patterns made through various protocols and correlate these to data paths traversed throughout the network"
    },
    {
      "question": "What is social network analysis",
      "answer": "Social network analysis , also known as network science, is a field of data analytics that uses networks and graph theory to understand social structures. SNA techniques can also be applied to networks . A common application of SNA techniques is with the internet"
    },
    {
      "question": "What are network visualization applications",
      "answer": "This user friendly open source tool is pegged as a cross platform graphical application for analysis and visualisation of social networks. It enables developers to create and modify social networks and change node attributes."
    },
    {
      "question": "Whats the difference between a network engineer and a network analyst",
      "answer": "Engineers create the network system and handle major changes to it. Analysts typically handle the dynamic ads, moves, changes, events, and minor issues. The analyst monitors and responds to issues on an established network system. Engineers create the network system and handle major changes to it"
    },
    {
      "question": "Difference between a network engineer and a network analyst",
      "answer": "Engineers create the network system and handle major changes to it. Analysts typically handle the dynamic ads, moves, changes, events, and minor issues. The analyst monitors and responds to issues on an established network system. Engineers create the network system and handle major changes to it"
    },
    {
      "question": "What are the 4 centrality measurements",
      "answer": "Degree, betweenness, closeness and eigenvector  each with its own strengths and weaknesses"
    },
    {
      "question": "Network measures are often represented in multiple ways",
      "answer": "Thus, measures of individual network elements such as nodes or links typically quantify connectivity profiles associated with these elements and hence reflect the way in which these elements are embedded in the network."
    },
    {
      "question": "How is network centrality measured",
      "answer": ".To calculate betweenness centrality, you take every pair of the network and count how many times a node can interrupt the shortest paths geodesic distance between the two nodes of the pair."
    },
    {
      "question": "Network centrality measured",
      "answer": "To calculate betweenness centrality, you take every pair of the network and count how many times a node can interrupt the shortest paths geodesic distance between the two nodes of the pair."
    },
    {
      "question": "Which centrality measure is best",
      "answer": "Freemans closeness centrality, the total geodesic distance from a given vertex to all other vertices, is the best known example. Note that this classification is independent of the type of walk counted i.e. walk, trail, path, geodesic."
    },
    {
      "question": "Difference between eigenvector centrality and betweenness centrality",
      "answer": "Betweenness centrality quantifies how many times a particular node comes in the shortest chosen path between two other nodes. Eigenvector centrality is a measure of the influence of a node in a network."
    },
    {
      "question": "How do you increase between centrality",
      "answer": "The betweenness centrality of a node might change if the graph is augmented with a set of arcs. In particular, adding arcs incident to some nodev can increase the betweenness ofv and its ranking."
    },
    {
      "question": "What is network graph visualization",
      "answer": "Network visualization, graph visualization or link analysis is the process of visually presenting networks of connected entities as links and nodes. Nodes represent data points and links represent the connections between them."
    },
    {
      "question": "When would you use a network graph",
      "answer": "Networks graphs are extremely useful in use cases such as intelligence analysis e.g  one person is an associate of a suspect or known criminal, fraud detection e.g., the same social security number was used by different people, and many others"
    },
    {
      "question": "What is graph in network analysis",
      "answer": "Network graph is simply called as graph. It consists of a set of nodes connected by branches. In graphs, a node is a common point of two or more branches.  That means, the line segments in the graph represent the branches corresponding to either passive elements or voltage sources of electric circuit."
    },
    {
      "question": "What is the use of Network Analysis",
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms."
    },
    {
      "question": "Why Analysisng Network is required",
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms."
    },
    {
      "question": "Define network density",
      "answer": "Network density is the number of edges divided by the total possible edges."
    },
    {
      "question": "Define Accessibility",
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network"
    },
    {
      "question": "What does high betweenness mean",
      "answer": "Betweenness centrality measures the extent to which a vertex lies on paths between other vertices. Vertices with high betweenness may have considerable influence within a network by virtue of their control over information passing between others.\n"
    },
    {
      "question": "Describe Network",
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects."
    },
    {
      "question": "How many measures are there to identify centrality of a node",
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality"
    },
    {
      "question": "How to calculate Closeness centrality",
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes.\n"
    },
    {
      "question": "Network analytics  ",
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations."
    },
    {
      "question": "Explain Degree centrality",
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality."
    },
    {
      "question": "Network level analysis",
      "answer": "Network level analysis focuses on topological properties of networks as a whole."
    },
    {
      "question": "What are network analytics",
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations."
    },
    {
      "question": "What is Machine reasoning",
      "answer": "When analytics engines are programmed to reason through logical steps, MR is achieved. This capability can enable an analytics engine to navigate through a number of complex decisions to solve a problem or a complex query. With MR, analytics can compare multiple possible outcomes and solve for an optimal result, using the same process that a human would. This is an important complement to ML."
    },
    {
      "question": "Who uses network analysis",
      "answer": "Network analysis is widely used in several scientific areas as for example physics, computer science, linguistics and social sciences. In biology, network analysis was applied for example to food webs, social organization and more recently to molecular networks."
    },
    {
      "question": "Deep packet inspection DPI",
      "answer": "DPI of select traffic flows is a rich data source for network analytics. An analysis of such traffic using techniques such as Network Based Application Recognition,NBAR and Software Defined Application Visibility and Control can discern the communication protocols being used.Analytics engines can use this information in a variety of ways, such as setting of quality of service parameters automatically or profiling endpoints.\n"
    },
    {
      "question": "What is the Degree centrality",
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality."
    },
    {
      "question": "What is the crucial application of network analysis",
      "answer": "A crucial application of network analysis is identifying the important node in a network.This task is called Measuring Network Centrality. In social network analysis, it can refer to the task of identifying the most influential member, or the representative of the group."
    },
    {
      "question": "What is the important role of network analysis",
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks, a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms. Identifying CM targets."
    },
    {
      "question": "What are the measures of centrality of a node ",
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality"
    },
    {
      "question": "How centrality of a node can be measured",
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality"
    },
    {
      "question": "What are the different measures to identify centrality of a node",
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality"
    },
    {
      "question": "What is machine learning in security",
      "answer": "Machine learning can be applied in various ways in security, for instance, in malware analysis, to make predictions, and for clustering security events. It can also be used to detect previously unknown attacks with no established signature."
    },
    {
      "question": "Define Degree centrality",
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality."
    },
    {
      "question": "Definition of Degree centrality",
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality."
    },
    {
      "question": "Describe Degree centrality",
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality."
    },
    {
      "question": "What is the Closeness centrality",
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network.\n"
    },
    {
      "question": "Define Closeness centrality",
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network."
    },
    {
      "question": "Explain Closeness centrality",
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network."
    },
    {
      "question": "Formula to calculate Closeness centrality",
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes."
    },
    {
      "question": "How Closeness centrality can be calculated",
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes."
    },
    {
      "question": "How to calculate normalized closeness",
      "answer": "Normalized closeness calculated as total number of nodes minus 1 multiplied by closeness centrality"
    },
    {
      "question": "What is the Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "Define Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "What do you mean by Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "Describe Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "Definition of Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "Explain Betweenness centrality",
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node."
    },
    {
      "question": "Formula to calculate the Betweenness centrality\n",
      "answer": "Betweenness centrality is calculated as number of shortest paths between s an t nodes that passes through the node in the question divided by number of shortest path between s and t nodes\nwhere s is source node\nt is target node"
    },
    {
      "question": "What is Eigenvector centrality",
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network."
    },
    {
      "question": "Define Eigenvector centrality",
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network.\n"
    },
    {
      "question": "Describe Eigenvector centrality",
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network."
    },
    {
      "question": "What do you mean by Eigenvector centrality",
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network."
    },
    {
      "question": "What are the levels of network analysis",
      "answer": "There are 3 levels for network analysis, those are,\n1. Element level analysis\n2. Group level analysis\n3. Network level analysis"
    },
    {
      "question": "What is Element level analysis",
      "answer": "Element level analysis involves finding of methods to identify the most important nodes of the network are investigated."
    },
    {
      "question": "What is Group level analysis",
      "answer": "Group level analysis involves methods for defining and finding cohesive groups of nodes in the network."
    },
    {
      "question": "Formula to calculate cluster coefficient",
      "answer": "Clustering coefficient is calculated as Number of links that exists among its neighbors divided byNumber of links that could have existed among its neighbor"
    },
    {
      "question": "What is the adjacency matrix",
      "answer": "We represents nodes and edges in a matrix format which is called adjacency matrix.\n"
    },
    {
      "question": "What is the purpose of network analysis",
      "answer": " Network analysis provides the capacity to estimate complex patterns of relationships and the network structure can be analysed to reveal core features of the network."
    },
    {
      "question": "Define network analytics",
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations."
    },
    {
      "question": "What are the steps in network analysis",
      "answer": "There are 6 steps in Network Analysis, those are,\nStep 1 Configuring the Network Analyst environment.\nStep 2 Adding a network dataset to ArcMap.\nStep 3 Creating the network analysis layer.\nStep 4 Adding network analysis objects.\nStep 5 Setting network analysis layer properties.\nStep 6 Performing the analysis and displaying the results."
    },
    {
      "question": "What is a network analysis diagram",
      "answer": "A network analysis diagram is the visual display of how people or other elements in a network are connected."
    },
    {
      "question": "Where do you apply network analytics ",
      "answer": "Network Analytics can be used in different applications as follow, Assembly line scheduling,Research and development,Inventory planning and control,Shifting of manufacturing plant from one site to another,Launching of new products and advertising campaigns,Control of traffic flow in cities,Budget and audit procedures, etc"
    },
    {
      "question": "Why is network analysis necessary",
      "answer": "Network analysis ensures the effective utilization of limited resources. It also ensures the optimal use of resources and help to control the idle resources so that project can be effectively executed within the budgeted costs and scheduled time.\n"
    },
    {
      "question": "What are major technologies of network analysis",
      "answer": "The major technologies of network analysis are,\n5G and Wi Fi 6 technology,Artificial Intelligence AI and Machine Learning ML,Augmented reality and virtual reality,Cloud computing,DevOps ,Digital transformation ,Intent based networking IBN,Internet of Things IoT,Data Security,SD WAN "
    },
    {
      "question": "What is network analysis in machine learning",
      "answer": "Statistical and Machine Learning Approaches for Network Analysis provides an accessible framework  for structurally analyzing graphs by bringing together known and novel approaches on graph classes and graph measures for classification."
    },
    {
      "question": "Is network analysis data science",
      "answer": "Social network analysis, also known as network science, is a field of data analytics that uses networks and graph theory to understand social structures."
    },
    {
      "question": "What are the objectives of Network Analysis",
      "answer": "The objectives of Network Analysis are,\n1. Minimize Production Delay, Interruptions and Conflicts\n2. Minimization of Total Project Cost\n3. Trade off between Time and Cost of Project\n4. Minimization of Total Project Duration\n5. Minimization of Idle Resources"
    },
    {
      "question": "What are the advantages of Network Analysis",
      "answer": "For planning, scheduling and controlling of operations in large and complicated projects network analysis is very important and powerful tool.For evaluating the performance level of actual performance in comparison to planned target network analysis is a very useful tool."
    },
    {
      "question": "What are the disadvantages of Network Analysis",
      "answer": " Network construction of complex project is very difficult and time consuming in network analysis.Actual time estimation of various activities is a difficult exercise.Analysis of the project is a very difficult work because a number of resource constraints exist in the project."
    },
    {
      "question": "What is network analysis in Analytics",
      "answer": "Network analysis is a technique that uses graph theory to study complex real world problems, such as computational ,biology engineering, finance, marketing, neuroscience, political science, and public health "
    },
    {
      "question": "What are the terminologies in Network Analytics",
      "answer": "Termilogies in Network analysis are,Node is also called as vertex,Edge is also called as Connection"
    },
    {
      "question": "How to evaluate the strength of the node in network analysis",
      "answer": "The strength of the newtwork can be evaluated by using 4 measures , those are, Degree centrality,Closeness centrality,Betweenness centrality ,Eigenvector centrality"
    },
    {
      "question": "What is graph of network",
      "answer": "A network graph or simply a network is a connection of objects that are linked together through a series of nodes representing those objects"
    },
    {
      "question": "How many types of networks are there",
      "answer": "LAN, MAN, and WAN are the three major types of networks designed to operate over the area they cover."
    },
    {
      "question": "How does network analytics work",
      "answer": "In network analytics, a software engine analyzes and extracts intelligence from data collected from various sources,such as network devices switches, routers, and wireless, servers syslog, DHCP, AAA, configuration database, etc. andtraffic flow details wireless congestion, data speeds, latency, etc.Network analytics processes are automated and so are more wide ranging than what can be achieved by manual analysis. "
    },
    {
      "question": "How does network analytics collect data",
      "answer": "Network analytics collects data from a variety of sources, including from servers such as DHCP, Active Directory, RADIUS, DNS, and syslog, and from network traffic such as NetFlow, traceroute, and SNMP. It does so by using techniques such as telemetry and deep packet inspection DPI to build a rich database from which contextual information can be derived."
    },
    {
      "question": "What is Analytics engine",
      "answer": "The analytics engine, the software program that analyzes data and makes decisions, collects data from around the network and performs the desired analysis. This analysis may compare the current state with a model of optimal performance. Whenever the program identifies a deviation from optimal, it may suggest remediations or present its findings to a higher levelprogram or to the IT staff.The analytics engine may also scrutinize endpoint traffic to help identify the endpoint itself or traffic behavior that may signal malware infection.\n"
    },
    {
      "question": "What is difference between Cloud and Local Analytics",
      "answer": "Networking engineers often debate whether network analytics should be performed remotely, in the cloud, or locally, at the customer premises. Placing the analytics engine in the cloud offers access to much more processing power, scale, and communication with other networks. Cloud hosted analytics also benefits from up to the minute algorithms and crowd sourced data. "
    },
    {
      "question": "Why we need Correlation in Network engine",
      "answer": "The analytics engine considers the relationship among variables in the network before offering insights or remediation. The correlation among devices, applications, and services can mean that correcting one problem can lead to problems elsewhere.While correlation greatly increases the number of variables in the decision tree and adds complexity to the system, its essential so that all variables can be evaluated for accurate decisions."
    },
    {
      "question": "What is the role of Decision trees in Analytic Engine",
      "answer": "Most analytics engines offer guidance on performance improvement through decision trees. When an analytics engine receives network data indicating subpar performance, the decision tree calculates the best network device adjustment or reconfiguration to improve performance of that parameter.The decision tree grows based on the number of sources for streaming telemetry and the number of options for optimizing performance in each point. Because of the complexity of processing these very large data sets in real time, analytics was previously performed only on supercomputers."
    },
    {
      "question": "How does network analytics benefit from AI and ML techniques",
      "answer": "Network analytics uses a combination of local and cloud based AI driven analytics engines to make sense of all collected data. Using AI and ML, network analytics customizes the network baseline for alerts, reducing noise and false positives while enabling IT teams to identify issues, trends, anomalies, and root causes accurately. AI,ML techniques along with crowd sourced data are also used to reduce unknowns and improve the level of certainty in decision making."
    },
    {
      "question": "How does network analytics benefit from AI techniques",
      "answer": "Artificial intelligence simulates intelligent decision making in computers. Many sources confuse artificial intelligence with machine learning ML. Machine learning is a subset of the many types of applications that result from the field of artificial intelligence."
    },
    {
      "question": "How does network analytics benefit from ML techniques",
      "answer": "Use of ML can improve analytics engines. With ML, the parameters in the decision tree can be improved based on experience,cognitive learning, peer comparison,prescriptive learning, or complex mathematical regressions,baselining.ML offers large increases in the accuracy of insights and remediation, because with it the decision trees are modified to meet the specific conditions of a networks configuration, its installed hardware and software, and its services and applications."
    },
    {
      "question": "What is Streaming telemetry",
      "answer": "Streaming telemetry reduces delays in data collection. Telemetry provides information on anything from simple packet flow numbers to complex, application specific performance parameters. Systems that can stream more telemetry, from more sources and about more network variables, give the analytics engine better context in which to make decisions."
    },
    {
      "question": "What is the importance of Context in Network Analytics",
      "answer": "Another important factor an analytics engine considers is context. The context is the specific circumstances in which a network anomaly occurs. The same anomaly in different conditions can require very different remediation, so the analytics engine must be programmed with the many variables for contexts, such as network type, service, and application.Other contexts can include wireless interference, network congestion, service duplication, and device limitations."
    },
    {
      "question": "What is graph",
      "answer": "Graph is a mathematical structures used to study pairwise relationships between objects and entities."
    },
    {
      "question": "Why Graphs is needed",
      "answer": "Graphs provide a better way of dealing with abstract concepts like relationships and interactions. They also offer an intuitively visual way of thinking about these concepts. Graphs also form a natural basis for analyzing relationships in a Social context."
    },
    {
      "question": "What are graph types",
      "answer": "Types of graphs are,\n1. Undirected Simple Graph\n2. Directed Simple Graph\n3. With Self loops\n4. With Parellel edges."
    },
    {
      "question": "What are the methods in python to access nodes and edges in python",
      "answer": "Nodes and Edges can be accessed together using the G.nodes function and G.edges function."
    },
    {
      "question": "How is machine learning used in networking",
      "answer": "Machine Learning has major applicability in IT automation, turning relevant data into actionable software, and it also can ensure optimal configuration in networking.Briefly, ML achieves this by analyzing the structure of collected data to find patterns you did not know were there."
    },
    {
      "question": "What is AI in networking",
      "answer": "The purest definition of artificial intelligence is software that performs a task on par with a human expert. AI plays an increasingly critical role in taming complexity for growing IT networks. The proliferation of devices, data, and people has made IT infrastructures more complex than ever to manage."
    },
    {
      "question": "What is graph machine learning",
      "answer": ".Graph Machine Learning provides a new set of tools for processing network data and leveraging the power of the relation between entities that can be used for predictive, modeling, and analytics tasks. "
    },
    {
      "question": "What are the components of network analysis",
      "answer": "Following are the Network analysis components,Route,Service area,Closest facility ,OD cost matrix,Vehicle routing problem,Location allocation,Algorithms used by the ArcGIS Network Analyst extension."
    },
    {
      "question": "What are the objectives of using network analysis",
      "answer": "Network analysis is one of the most popular techniques used for planning, scheduling, monitoring and coordinating large and complex projects comprising a number of activities. It involves the development of a network to indicate logical sequenceof work content elements of a complex situation"
    },
    {
      "question": "How is network analytics beneficial to businesses",
      "answer": "Network Analytics gives a deep insight into the IT network and helps the administrators make smart and informed business decisions. It can be particularly useful in preventing, detecting and responding to security threats."
    },
    {
      "question": "What is network analysis with example",
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks, a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms. Identifying CM targets ,etc."
    },
    {
      "question": "What are the top 3 network analytics use cases",
      "answer": "Performance optimization and capacity planning. When done effectively, network analytics reveals crucial information about hidden bottlenecks and other network design issues that can choke traffic and impede productivity,Credential misuse,Cloud security"
    },
    {
      "question": "What is the python Library Used for studying Graphs And Networks",
      "answer": "NetworkX is a Python library for studying graphs and networks."
    },
    {
      "question": "What are the basic entities required to build the network\n",
      "answer": "The basic entities required for building a network are nodes and the edges connecting the nodes."
    },
    {
      "question": "Why is network analytics important",
      "answer": "Network Analytics gives a deep insight into the IT network and helps the administrators make smart and informed business decisions. It can be particularly useful in preventing, detecting and responding to security threats."
    },
    {
      "question": "What is Pragmatic Ambiguity",
      "answer": "Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.\n\nExample\n\nCheck out the below sentence.\n\nAre you feeling hungry\n\nThe given sentence could be either a question or a formal way of offering food."
    },
    {
      "question": "What is text Summarization",
      "answer": "Text summarization is the process of shortening a long piece of text with its meaning and effect intact. Text summarization intends to create a summary of any given piece of text and outlines the main points of the document. This technique has improved in recent times and is capable of summarizing volumes of text successfully. Text summarization has proved to a blessing since machines can summarise large volumes of text in no time which would otherwise be really time consuming. There are two types of text summarization\n Extraction based summarization \n Abstraction based summarization"
    },
    {
      "question": "What is NLP",
      "answer": "Natural Language Processing"
    },
    {
      "question": "What is the use of NLP",
      "answer": "Natural language processing helps computers communicate with humans in their own language and scales other language related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important."
    },
    {
      "question": "Is NLP an automated practice",
      "answer": "It is an automated process to extract required information from data by applying machine learning algorithms. "
    },
    {
      "question": "Do we need the help of machine learning algorithms for NLP",
      "answer": "Yes, It is an automated process to extract required information from data by applying machine learning algorithms. "
    },
    {
      "question": "What is Naive Bayes algorithm, When we can use this algorithm in NLP",
      "answer": "Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more."
    },
    {
      "question": "Explain Dependency Parsing in NLP",
      "answer": "Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence."
    },
    {
      "question": "What is NLTK? How is it different from Spacy",
      "answer": "NLTK or Natural Language Toolkit is a series of libraries and programs that are used for symbolic and statistical natural language processing. This toolkit contains some of the most powerful libraries that can work on different ML techniques to break down and understand human language. NLTK is used for Lemmatization, Punctuation, Character count, Tokenization, and Stemming. The difference between NLTK and Spacey are as follows\n While NLTK has a collection of programs to choose from, Spacey contains only the best suited algorithm for a problem in its toolkit \n NLTK supports a wider range of languages compared to Spacey Spacey supports only 7 languages \nWhile Spacey has an object oriented library, NLTK has a string processing library \n Spacey can support word vectors while NLTK cannot"
    },
    {
      "question": "What is information extraction",
      "answer": "Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more. \nThe various models of information extraction includes\nTagger Module \n Relation Extraction Module \n Fact Extraction Module \n Entity Extraction Module \n Sentiment Analysis Module \n Network Graph Module \nDocument Classification  Language Modeling Module"
    },
    {
      "question": "What is Bag of Words",
      "answer": "Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order."
    },
    {
      "question": "What is Pragmatic Ambiguity in NLP",
      "answer": "Pragmatic ambiguity refers to those words which have more than one meaning and their use in any sentence can depend entirely on the context. Pragmatic ambiguity can result in multiple interpretations of the same sentence. More often than not, we come across sentences which have words with multiple meanings, making the sentence open to interpretation. This multiple interpretation causes ambiguity and is known as Pragmatic ambiguity in NLP."
    },
    {
      "question": "What is Masked Language Model",
      "answer": "Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence."
    },
    {
      "question": "What is the difference between NLP and CI(Conversational Interface)",
      "answer": "The difference between NLP and CI is as follows\nNatural Language Processing NLP\nNLP attempts to help machines understand and learn how language concepts work\nNLP uses AI technology to identify, understand, and interpret the requests of users through language.\n Conversational Interface CI.\n CI focuses only on providing users with an interface to interact with. \nCI uses voice, chat, videos, images and more such conversational aid to create the user interface."
    },
    {
      "question": "What are the best NLP Tools",
      "answer": "SpaCy  TextBlob  Textacy  Natural language Toolkit NLTK  Retext  NLP.js Stanford NLP  CogcompNLP"
    },
    {
      "question": "What is POS tagging",
      "answer": "Parts of speech tagging better known as POS tagging refers to the process of identifying specific words in a document and group them as part of speech, based on its context. POS tagging is also known as grammatical tagging since it involves understanding grammatical structures and identifying the respective component. POS tagging is a complicated process since the same word can be different parts of speech depending on the context. The same generic process used for word mapping is quite ineffective for POS tagging because of the same reason."
    },
    {
      "question": "What is NES",
      "answer": "Name entity recognition is more commonly known as NER is the process of identifying specific entities in a text document which are more informative and have a unique context. These often denote places, people, organisations, and more. Even though it seems like these entities are proper nouns, the NER process is far from identifying just the nouns. In fact, NER involves entity chunking or extraction wherein entities are segmented to categorise them under different predefined classes. This step further helps in extracting information."
    },
    {
      "question": "Which technique can be used for keyword normalization in NLP, the process of converting a keyword into its base form",
      "answer": " Lemmatization helps to get to the base form of a word, e.g. are playing  play, eating  eat, etc.."
    },
    {
      "question": "What is Lemmatization",
      "answer": "A technique used in NLP which is used to get a base form of the word. Eg playing play."
    },
    {
      "question": "Which technique can be used to compute the distance between two word vectors in NLP",
      "answer": "Distance between two word vectors can be computed using Cosine similarity and Euclidean Distance. Cosine Similarity establishes a cosine angle between the vector of two words. A cosine angle close to each other between two word vectors indicates the words are similar and vice a versa. E.g. cosine angle between two words Football and Cricket will be closer to 1 as compared to angle between the words Football and New Delhi"
    },
    {
      "question": "Is it True that Dissimilarity between words expressed using cosine similarity will have values significantly higher than 0.5",
      "answer": "True"
    },
    {
      "question": "Normalization techniques in NLP",
      "answer": "Named entity recognition"
    },
    {
      "question": "NLP use cases",
      "answer": "Text Summarization is an NLP use case."
    },
    {
      "question": "What is ELMo",
      "answer": "EMLo word embeddings supports same word with multiple embeddings, this helps in \nusing the same word in a different context and thus captures the context than just \nmeaning of the word unlike in GloVe and Word2Vec. Nltk is not a word embedding"
    },
    {
      "question": "List 10 use cases to be solved using NLP techniques",
      "answer": "Sentiment Analysis\n Language Translation \n Document Summarization\n Question Answering\n Sentence Completion\n Attribute extraction \nChatbot interactions\n Topic classification\n Intent extraction\n Grammar or Sentence correction\nImage captioning\n Document Ranking\nNatural Language inference"
    },
    {
      "question": "What does the Transformer model pays attention to ",
      "answer": "The most important word in Sentence"
    },
    {
      "question": "Which NLP model gives the best accuracy",
      "answer": "XLNET"
    },
    {
      "question": "Why do we need NLP",
      "answer": "One of the main reasons why NLP is necessary is because it helps computers \ncommunicate with humans in natural language. It also scales other language related \ntasks. Because of NLP, it is possible for computers to hear speech, interpret this \nspeech, measure it and also determine which parts of the speech are important."
    },
    {
      "question": "What must a natural language program decide",
      "answer": "A natural language program must decide what to say and when to say something."
    },
    {
      "question": "Where can NLP be useful",
      "answer": "NLP can be useful in communicating with humans in their own language. It helps \nimprove the efficiency of the machine translation and is useful in emotional analysis too. \nIt can be helpful in sentiment analysis too. It also helps in structuring highly unstructured \ndata. It can be helpful in creating chatbots, Text Summarization and virtual assistants."
    },
    {
      "question": "How to prepare for an NLP Interview",
      "answer": "The best way to prepare for an NLP Interview is to be clear about the basic concepts. \nGo through blogs that will help you cover all the key aspects and remember the \nimportant topics. Learn specifically for the interviews and be confident while answering \nall the questions."
    },
    {
      "question": "What are the main challenges of NLP",
      "answer": "Breaking sentences into tokens, Parts of speech tagging, Understanding the context, \nLinking components of a created vocabulary, Extracting semantic meaning are currently \nsome of the main challenges of NLP."
    },
    {
      "question": "What are the major tasks of NLP",
      "answer": "Translation, named entity recognition, relationship extraction, sentiment analysis, \nspeech recognition, and topic segmentation are few of the major tasks of NLP. Under \nunstructured data, there can be a lot of untapped information that can help an \norganization grow."
    },
    {
      "question": "Explain about NLP and Naive Bayes Algorithm",
      "answer": "Naive Bayes Algorithm has the highest accuracy when it comes to NLP models."
    },
    {
      "question": "What are stop words in NLP",
      "answer": "Common words that occur in sentences that add weight to the sentence are known as \nstop words. These stop words act as a bridge and ensure that sentences are \ngrammatically correct. In simple terms, words that are filtered out before processing \nnatural language data is known as a stop word and it is a common pre processing \nmethod.\n"
    },
    {
      "question": "What is stemming in NLP",
      "answer": "The process of obtaining the root word from the given word is known as stemming. All \ntokens can be cut down to obtain the root word or the stem with the help of efficient and \nwell generalized rules. It is a rule based process and is well known for its simplicity."
    },
    {
      "question": "Why is NLP so hard",
      "answer": "There are several factors that make the process of Natural Language Processing \ndifficult. There are hundreds of natural languages all over the world, words can be \nambiguous in their meaning, each natural language has a different script and syntax, \nthe meaning of words can change depending on the context, and so the process of NLP \ncan be difficult. If you choose to upskill and continue learning, the process will become \neasier over time."
    },
    {
      "question": "What does a NLP pipeline consist of star symbol",
      "answer": "The overall architecture of an NLP pipeline consists of several layers a user interface \none or several NLP models, depending on the use case a Natural Language \nUnderstanding layer to describe the meaning of words and sentences a preprocessing \nlayer microservices for linking the components together and of course.\n"
    },
    {
      "question": "How many steps of NLP is there",
      "answer": "The five phases of NLP involve lexical structure analysis, parsing, semantic analysis, \ndiscourse integration, and pragmatic analysis"
    },
    {
      "question": "What is TF-IDF",
      "answer": "TFIDF or Term Frequency Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF IDF shows a frequency that helps identify the keywords in a document. The major use of TF IDF in NLP is the extraction of useful information from crucial documents by statistical data. It is ideally used to classify and summarize the text in documents and filter out stop words."
    },
    {
      "question": "What is Pragmatic Analysis",
      "answer": " Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real world data to know the actual meaning of sentences and words."
    },
    {
      "question": "What are unigrams, bigrams, trigrams, and n-grams in NLP",
      "answer": " When we parse a sentence one word at a time, then it is called a unigram. The sentence parsed two words at a time is a bigram.\nWhen the sentence is parsed three words at a time, then it is a trigram. Similarly, ngram refers to the parsing of n words at a time."
    },
    {
      "question": "What are the steps involved in solving an NLP problem",
      "answer": "Below are the steps involved in solving an NLP problem\n\n1.Gather the text from the available dataset or by web scraping\n2.Apply stemming and lemmatization for text cleaning\n3.Apply feature engineering techniques\n4.Embed using word2vec\n5.Train the built model using neural networks or other Machine Learning techniques\n6.Evaluate the models performance\n7.Make appropriate changes in the model\n8.Deploy the model\n"
    },
    {
      "question": "What is Feature Extraction in NLP",
      "answer": "Features or characteristics of a word help in text or document analysis. They also help in sentiment analysis of a text. Feature extraction is one of the techniques that are used by recommendation systems. Reviews such as excellent, good, or great for a movie are positive reviews, recognized by a recommender system. The recommender system also tries to identify the features of the text that help in describing the context of a word or a sentence. Then, it makes a group or category of the words that have some common characteristics. Now, whenever a new word arrives, the system categorizes it as per the labels of such groups."
    },
    {
      "question": "What is precision and recall",
      "answer": "Precision is the ratio of true positive instances and the total number of positively predicted instances.\nRecall is the ratio of true positive instances and the total actual positive instances."
    },
    {
      "question": "What is F1 score in NLP",
      "answer": "F1 score evaluates the weighted average of recall and precision. It considers both false negative and false positive instances while evaluating the model. F1 score is more accountable than accuracy for an NLP model when there is an uneven distribution of class.\n"
    },
    {
      "question": "Explain how we can do parsing",
      "answer": "Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.\n\nWhen the machine parses the text one word at a time, then it is a unigram.\nWhen the text is parsed two words at a time, it is a bigram.\nThe set of words is a trigram when the machine parses three words at a time."
    },
    {
      "question": "What is Parts-of-speech Tagging",
      "answer": "The parts of speech POS tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. The software uses algorithms for the parts of speech tagging. POS tagging is one of the most essential tools in Natural Language Processing. It helps in making the machine understand the meaning of a sentence."
    },
    {
      "question": "Explain Named Entity Recognition",
      "answer": "Named Entity Recognition NER is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text. NER is mostly used in NLP, Artificial Intelligence, and Machine Learning. One of the real life applications of NER is chatbots used for customer support."
    },
    {
      "question": "How to check word similarity using the spacy package",
      "answer": "To find out the similarity among words, we use word similarity. We evaluate the similarity with the help of a number that lies between 0 and 1. We use the spacy library to implement the technique of word similarity."
    },
    {
      "question": "What is perplexity in NLP",
      "answer": "It is a metric that is used to test the performance of language models. Mathematically, it is defined as a function of the probability that the language model represents a test sample. "
    },
    {
      "question": "What do you know about the Masked Language Model",
      "answer": "The Masked Language Model is a model that takes a sentence with a few hidden masked words as input and tries to complete the sentence by correctly guessing those hidden words."
    },
    {
      "question": "Briefly describe the N-gram model in NLP",
      "answer": "N gram model is a model in NLP that predicts the probability of a word in a given sentence using the conditional probability of n minus 1 previous words in the sentence. The basic intuition behind this algorithm is that instead of using all the previous words to predict the next word, we use only a few previous words.\n"
    },
    {
      "question": "What is the Markov assumption for the bigram model",
      "answer": "The Markov assumption assumes for the bigram model that the probability of a word in a sentence depends only on the previous word in that sentence and not on all the previous words.\n"
    },
    {
      "question": "List a few popular methods used for word embedding",
      "answer": "Following are a few methods of word embedding.\n\nEmbedding Layer\nWord2Vec\nGlove"
    },
    {
      "question": "Write the code to count the number of distinct tokens in a text",
      "answer": "len set text"
    },
    {
      "question": "For correcting spelling errors in a corpus, which one is a better choice: a giant dictionary or a smaller dictionary, and why",
      "answer": "Initially, a smaller dictionary is a better choice because most NLP researchers feared that a giant dictionary would contain rare words that may be similar to misspelled words. However, later it was found Damerau and Mays 1989 that in practice, a more extensive dictionary is better at marking rare words as errors."
    },
    {
      "question": "Do you always recommend removing punctuation marks from the corpus you\u2019re dealing with",
      "answer": "No, it is not always a good idea to remove punctuation marks from the corpus as they are necessary for certain NLP applications that require the marks to be counted along with words."
    },
    {
      "question": "List a few libraries that you use for NLP in Python",
      "answer": "NLTK, Scikit learn,GenSim, SpaCy, CoreNLP, TextBlob."
    },
    {
      "question": "Suggest a few machine learning/deep learning models that are used in NLP",
      "answer": "Support Vector Machines, Neural Networks, Decision Tree, Bayesian Networks."
    },
    {
      "question": "Which library contains the Word2Vec model in Python",
      "answer": "GenSim"
    },
    {
      "question": "What is a hapax/hapax legomenon",
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. Each one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton."
    },
    {
      "question": "What is a collocation",
      "answer": "A collocation is a group of two or more words that possess a relationship and provide a classic alternative of saying something. For example, strong breeze, the rich and powerful, weapons of mass destruction."
    },
    {
      "question": "List a few types of linguistic ambiguities",
      "answer": "1. Lexical Ambiguity This type of ambiguity is observed because of homonyms and polysemy in a sentence.\n\n\t2. Syntactic Ambiguity A syntactic ambiguity is observed when based on the sentences syntax, more than one meaning is possible.\n\n\t3. Semantic Ambiguity This ambiguity occurs when a sentence contains ambiguous words or phrases that have ambiguous meanings."
    },
    {
      "question": "What is a Turing Test? Explain with respect to NLP-based systems",
      "answer": " Alan Turing developed a test, called Turing Test, that could differentiate between humans and machines. A computer machine is considered intelligent if it can pass this test through its use of language. Alan believed that if a machine could use language the way humans do, it was sufficient for the machine to prove its intelligence."
    },
    {
      "question": "What do you understand by regular expressions in NLP",
      "answer": "Regular expressions in natural language processing are algebraic notations representing a set of strings. They are mainly used to find or replace strings in a text and can also be used to define a language in a formal way."
    },
    {
      "question": "Define the term parsing concerning NLP",
      "answer": " Parsing refers to the task of generating a linguistic structure for a given input. For example, parsing the word helping will result in verb pass  gerunding."
    },
    {
      "question": "What is meant by TF-IDF",
      "answer": "TFIDF or Term Frequency Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF IDF shows a frequency that helps identify the keywords in a document. The major use of TF IDF in NLP is the extraction of useful information from crucial documents by statistical data. It is ideally used to classify and summarize the text in documents and filter out stop words."
    },
    {
      "question": "What is Dependency Parsing in NLP",
      "answer": "Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence."
    },
    {
      "question": "Explain Pragmatic Analysis",
      "answer": " Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real world data to know the actual meaning of sentences and words."
    },
    {
      "question": "Explain is Pragmatic Ambiguity",
      "answer": " Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.\n\nExample\n\nCheck out the below sentence.\n\nAre you feeling hungry\n\nThe given sentence could be either a question or a formal way of offering food."
    },
    {
      "question": "Explain about unigrams, bigrams, trigrams, and n-grams in NLP",
      "answer": "When we parse a sentence one word at a time, then it is called a unigram. The sentence parsed two words at a time is a bigram.\nWhen the sentence is parsed three words at a time, then it is a trigram. Similarly, ngram refers to the parsing of n words at a time."
    },
    {
      "question": "Explain the steps involved in solving an NLP problem",
      "answer": "Below are the steps involved in solving an NLP problem\n\n1.Gather the text from the available dataset or by web scraping\n2.Apply stemming and lemmatization for text cleaning\n3.Apply feature engineering techniques\n4.Embed using word2vec\n5.Train the built model using neural networks or other Machine Learning techniques\n6.Evaluate the models performance\n7.Make appropriate changes in the model\n8.Deploy the model"
    },
    {
      "question": "What is meant by Feature Extraction in NLP",
      "answer": "Features or characteristics of a word help in text or document analysis. They also help in sentiment analysis of a text. Feature extraction is one of the techniques that are used by recommendation systems. Reviews such as excellent, good, or great for a movie are positive reviews, recognized by a recommender system. The recommender system also tries to identify the features of the text that help in describing the context of a word or a sentence. Then, it makes a group or category of the words that have some common characteristics. Now, whenever a new word arrives, the system categorizes it as per the labels of such groups."
    },
    {
      "question": "What is meant by precision and recall",
      "answer": "Precision is the ratio of true positive instances and the total number of positively predicted instances.\nRecall is the ratio of true positive instances and the total actual positive instances."
    },
    {
      "question": "What is meant by F1 score in NLP",
      "answer": "F1 score evaluates the weighted average of recall and precision. It considers both false negative and false positive instances while evaluating the model. F1 score is more accountable than accuracy for an NLP model when there is an uneven distribution of class."
    },
    {
      "question": "How can we do parsing",
      "answer": "Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.\n\nWhen the machine parses the text one word at a time, then it is a unigram.\nWhen the text is parsed two words at a time, it is a bigram.\nThe set of words is a trigram when the machine parses three words at a time."
    },
    {
      "question": "What is Named Entity Recognition",
      "answer": "Named Entity Recognition NER is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text. NER is mostly used in NLP, Artificial Intelligence, and Machine Learning. One of the real life applications of NER is chatbots used for customer support."
    },
    {
      "question": "How can we check word similarity using the spacy package",
      "answer": "To find out the similarity among words, we use word similarity. We evaluate the similarity with the help of a number that lies between 0 and 1. We use the spacy library to implement the technique of word similarity."
    },
    {
      "question": "Explain perplexity in NLP",
      "answer": "It is a metric that is used to test the performance of language models. Mathematically, it is defined as a function of the probability that the language model represents a test sample. "
    },
    {
      "question": "Explain about the Masked Language Model",
      "answer": "The Masked Language Model is a model that takes a sentence with a few hidden masked words as input and tries to complete the sentence by correctly guessing those hidden words."
    },
    {
      "question": "Describe about the N-gram model in NLP",
      "answer": "N gram model is a model in NLP that predicts the probability of a word in a given sentence using the conditional probability of n minus 1 previous words in the sentence. The basic intuition behind this algorithm is that instead of using all the previous words to predict the next word, we use only a few previous words."
    },
    {
      "question": "What you meant by the Markov assumption for the bigram model",
      "answer": "The Markov assumption assumes for the bigram model that the probability of a word in a sentence depends only on the previous word in that sentence and not on all the previous words."
    },
    {
      "question": "Which are the popular methods used for word embedding",
      "answer": "Following are a few methods of word embedding.\n\nEmbedding Layer\nWord2Vec\nGlove\n"
    },
    {
      "question": "What is the code to count the number of distinct tokens in a text",
      "answer": " len set text"
    },
    {
      "question": "which one is a better choice: a giant dictionary or a smaller dictionary, and why",
      "answer": "Initially, a smaller dictionary is a better choice because most NLP researchers feared that a giant dictionary would contain rare words that may be similar to misspelled words. However, later it was found Damerau and Mays 1989 that in practice, a more extensive dictionary is better at marking rare words as errors."
    },
    {
      "question": "Libraries for doing NLP in Python",
      "answer": "NLTK, Scikit learn,GenSim, SpaCy, CoreNLP, TextBlob."
    },
    {
      "question": "Recommend few machine learning/deep learning models that are used in NLP",
      "answer": "Support Vector Machines, Neural Networks, Decision Tree, Bayesian Networks."
    },
    {
      "question": "Name the library that contains the Word2Vec model in Python",
      "answer": "GenSim"
    },
    {
      "question": "What you meant by a hapax",
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. \nEach one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton."
    },
    {
      "question": "What is meant by hapax legomenon",
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. \nEach one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton."
    },
    {
      "question": "What you meant a collocation",
      "answer": "A collocation is a group of two or more words that possess a relationship and provide a classic alternative of saying something. For example, strong breeze, the rich and powerful, weapons of mass destruction."
    },
    {
      "question": "List out linguistic ambiguities",
      "answer": "1. Lexical Ambiguity This type of ambiguity is observed because of homonyms and polysemy in a sentence.\n\n\t2. Syntactic Ambiguity A syntactic ambiguity is observed when based on the sentences syntax, more than one meaning is possible.\n\n\t3. Semantic Ambiguity This ambiguity occurs when a sentence contains ambiguous words or phrases that have ambiguous meanings."
    },
    {
      "question": "What is a Turing Test",
      "answer": "Alan Turing developed a test, called Turing Test, that could differentiate between humans and machines. A computer machine is considered intelligent if it can pass this test through its use of language. Alan believed that if a machine could use language the way humans do, it was sufficient for the machine to prove its intelligence."
    },
    {
      "question": "What is regular expressions in NLP",
      "answer": "Regular expressions in natural language processing are algebraic notations representing a set of strings. They are mainly used to find or replace strings in a text and can also be used to define a language in a formal way."
    },
    {
      "question": "Describe the term parsing concerning NLP",
      "answer": "Parsing refers to the task of generating a linguistic structure for a given input. For example, parsing the word helping will result in verb pass plus gerunding."
    },
    {
      "question": "Which are the best NLP Tools",
      "answer": "SpaCy  TextBlob  Textacy  Natural language Toolkit NLTK  Retext  NLP.js  Stanford NLP  CogcompNLP"
    },
    {
      "question": "What is inverse error function",
      "answer": "The inverse error function occurs in the solution of nonlinear heat and diffusion problems. It provides exact solutions when the diffusion coefficient is concentration dependent"
    },
    {
      "question": "What is Error",
      "answer": "Error is the difference between Predicted value and Actual value in the test dataset"
    },
    {
      "question": "Who discovered Error function",
      "answer": "Glaisher discovered the Error function"
    },
    {
      "question": "Can the error function be integrated",
      "answer": "Integrals of the error function occur in a great variety of applications, usually in problems involving multiple integration where the integrand contains exponentials of the squares of the arguments"
    },
    {
      "question": "What is Mean Absolute Error",
      "answer": "The Mean Absolute Error is the mean of the sum of absolute differences between predictive values and actual values"
    },
    {
      "question": "How to find Mean Squared Error",
      "answer": "To find the mean square error, take the observed value, subtract the predicted value and square that difference. Repeat that for all observations. Then, sum all of those squared values are divided by the number of observations. Notice that the numerator is the sum of the squared errors, which linear regression minimizes"
    },
    {
      "question": "What is Error Function",
      "answer": "An error function measures the deviation of an observable value from a prediction.The word error represents the penalty for failing to achieve the expected output."
    },
    {
      "question": "Why is it called error function",
      "answer": "Errors functions try and minimize error values and hence the name"
    },
    {
      "question": "Where is Error function used",
      "answer": "The error function erf is a special function. It is widely used in statistical computations for instance, where it is also known as the standard normal cumulative probability"
    },
    {
      "question": "What is Error function in digital communication",
      "answer": "The complementary error function represents the area under the two tails of zero mean Gaussian probability density function of variance. The error function gives the probability that the parameter lies outside that range"
    },
    {
      "question": "Is complementary error function odd function",
      "answer": "Yes, the complementary error function is odd function"
    },
    {
      "question": "What is Python error function",
      "answer": "The python error function is also known as the gauss error function and this function throws an error, if any non number is passed as a parameter"
    },
    {
      "question": "What is the error function of infinity",
      "answer": "The error function at infinity is exactly one"
    },
    {
      "question": "Is Error function same as Loss function",
      "answer": "No, the Error function is not same as Loss function. An error function measures the deviation of an observable value from a prediction, whereas a loss function operates on the error to quantify the negative consequence of an error"
    },
    {
      "question": "What is the difference between Error and loss in Machine learning",
      "answer": "Error is the difference between single actual value and single predicted value. Loss is the average error over training data"
    },
    {
      "question": "What is Error function in neural network",
      "answer": "The Error function in neural network is the function, which you try to minimize"
    },
    {
      "question": "Is sigmoid an error function",
      "answer": "Another classic sigmoid is the error function"
    },
    {
      "question": "What is the error function of zero",
      "answer": "Zero is the error function of zero"
    },
    {
      "question": "Who introduced the symbol error function",
      "answer": "stated by Laplace, proved by Jacobi and rediscovered by Ramanujan"
    },
    {
      "question": "What is complementary Error function",
      "answer": "The complementary error function represents the area under the two tails of a zero mean"
    },
    {
      "question": "What is integration error",
      "answer": "An integration error refers only to a lead not making it to a third party system"
    },
    {
      "question": "Which error function is used by Linear Regression",
      "answer": "The most commonly used error function for linear regression is Least Squared Error"
    },
    {
      "question": "Why error handling is required",
      "answer": "The error handling mechanisms force the application to log the user off and shut down the system"
    },
    {
      "question": "What is the difference between Loss function and Cost function",
      "answer": "A Loss function is for single training sample or input. Loss is calculated for every input,number of times of loss calculation will be equal to number of samples present in training dataset. A Cost function is the average loss over the entire training dataset. Cost will be calculate once over entire training dataset"
    },
    {
      "question": "What is the difference between Residual and Error",
      "answer": "A residual is something left over after being used or removed or subtracted.An example of Residual is the paint remaining after all the rooms in the house have been painted. An Error is simply the measure of true difference between actual and predicted values in a machine learning model"
    },
    {
      "question": "What is Cost Function",
      "answer": "If the loss is averaged across the entire training samples, the loss is called a cost function"
    },
    {
      "question": "What are the other names of Mean Squared Error",
      "answer": "Other names of Mean Squared Error are Mean Squared Deviation, Quadratic Loss, L2 Loss"
    },
    {
      "question": "What is the other name of Mean Absolute Error",
      "answer": "L1 Loss is the other name of Mean Absolute Error"
    },
    {
      "question": "What is the similarity between Mean Squared Error and Mean Absolute Error",
      "answer": "The similarity between Mean Squared Error and Mean Absolute Error is direction is not considered, whereas magnitude is only considered"
    },
    {
      "question": "What is Mean Percentage Error",
      "answer": "The Mean Percentage Error is the average of percent errors of the differences between predicted and actual values"
    },
    {
      "question": "What is Mean Absolute Percentage Error",
      "answer": "The Mean Absolute Percentage Error is a calculation of the average of absolute percent of errors"
    },
    {
      "question": "What is the other name of Mean Absolute Percentage Error",
      "answer": "The other name of Mean Absolute Percentage Error is Mean Absolute Percentage Deviation"
    },
    {
      "question": "What are the advantages of Mean Squared Error",
      "answer": "The advantages of Mean Squared Error are when we plot a quadratic equation,we get a gradient descent with only one global minima,there is no local minima.It penalizes the model for making larger errors by squaring them"
    },
    {
      "question": "What are the disadvantages of Mean Squared Error",
      "answer": "The disadvantage of Mean Squared Error is Outliers are not handled properly"
    },
    {
      "question": "What are the advantages of Mean Absolute Error",
      "answer": "The advantages of Mean Absolute Error is Outliers are handled better than Mean Squared Error,as it is not penalizing the model by squaring error value"
    },
    {
      "question": "What are the disadvantages of Mean Absolute Error",
      "answer": "The disadvantage of Mean Absolute Errors will be they are computationally expensive as they use modulus operator function, they may be a local minima"
    },
    {
      "question": "What are other names for Error function?",
      "answer": "The other names of Error functions are Cost Functions, Loss Functions, Fitted value versus Predicted value, Residual versus Error"
    },
    {
      "question": "What is Residual",
      "answer": "Residual is the difference between Fitted value and Predicted value in the training dataset"
    },
    {
      "question": "What is Mean Squared Error",
      "answer": "Mean Squared Error is the mean or average of squared distances between actual and predicted values.Since the difference is squared, the direction of the error is meaningless and only the magnitude matters"
    },
    {
      "question": "Can Mean Squared Error be negative",
      "answer": "No,Mean Squared Error cannot be negative,because it is an expected value of a non negative random variable"
    },
    {
      "question": "How do you minimize the error function",
      "answer": "To minimize the error with the line,we use gradient descent.The way to descend is to take the gradient of the error function with respect to the weights. This gradient is going to point to a direction where the gradient increases the most"
    },
    {
      "question": "What is Loss function",
      "answer": "A loss function is a measure of how good a prediction model does in terms of being able to predict the expected outcome. If the loss is calculated for a single training example, it is called loss function"
    },
    {
      "question": "What does loss functions compute",
      "answer": "The loss function is the function that computes the distance between the current output of the algorithm and the expected output"
    },
    {
      "question": "Is loss function a error",
      "answer": "A loss function is for a single training example. It is also sometimes called an error function. A cost function, on the other hand, is the average loss over the entire training dataset"
    },
    {
      "question": "Which error function is used for Logistic Regression",
      "answer": "Gradient descent is used for logistic regression"
    },
    {
      "question": "which metric is used to measure error function",
      "answer": "Mean Squared Error is metric used to measure error function"
    },
    {
      "question": "Which loss function can be used for classification problem",
      "answer": "Binary cross entropy is commonly used loss function for binary classification problem"
    },
    {
      "question": "What is a loss function in terms of statistics",
      "answer": "A loss function specifies a penalty for an incorrect estimate from a statistical model"
    },
    {
      "question": "Why is 0 1 loss not used frequently",
      "answer": "The 0 1 loss function is non convex and discontinuous, so gradient methods cannot be applied"
    },
    {
      "question": "Is Mean squared error a convex function",
      "answer": "Mean square error is convex on its input and parameters by itself. But on an arbitrary neural network, it is not always convex due to the presence of non linearities in the form of activation functions"
    },
    {
      "question": "Define Error function in context of mathematics",
      "answer": "It is a complex function of a complex variable. This integral is a special sigmoid function that occurs often in probability,statistics and partial differential equations"
    },
    {
      "question": "Define inverse error function",
      "answer": "The inverse error function occurs in the solution of nonlinear heat and diffusion problems. It provides exact solutions when the diffusion coefficient is concentration dependent"
    },
    {
      "question": "who discovered symbol error function",
      "answer": "The symbol error function was stated by Laplace, proved by Jacobi, and rediscovered by Ramanujan"
    },
    {
      "question": "What does loss function depend on",
      "answer": "Loss fucntion depends on presence of outliers,choice of machine learning algorithm, time efficiency of gradient descent, ease of finding derivatives, confidence of predictions"
    },
    {
      "question": "What are the different types of loss functions based on classification",
      "answer": "The types of loss functions based on classification are Log loss, Focal loss, Relative Entropy, Exponential loss, Hinge loss"
    },
    {
      "question": "What are the different types of loss functions based on regression",
      "answer": "The types of loss functions based on regression are Mean Squared Error, Mean Absolute Error, Huber loss or Smooth Mean Absolute Error, Log cosh loss, Quantile loss"
    },
    {
      "question": "What is Mean Bias Error",
      "answer": "The measure of average magnitude of errors in a set of predictions, considering their direction is called Mean Bias Error"
    },
    {
      "question": "Why do we square the error function in gradient descent",
      "answer": "Squaring the error in gradient descent, ensures that the error for each training example is positive"
    },
    {
      "question": "What is the purpose of gradient descent algorithm",
      "answer": "Gradient Descent is an optimization algorithm used for minimizing the cost function in various machine learning algorithms"
    },
    {
      "question": "Why is the squared error loss function more convenient than the norm function",
      "answer": "The squared error is everywhere differentiable, while the absolute error is not, this makes the squared error more better, when compared to the techniques of mathematical optimization"
    },
    {
      "question": "Do gradient descent steps always decrease the loss",
      "answer": "The gradient descent algorithm takes a step in the direction of the negative gradient, in order to reduce loss as quickly as possible"
    },
    {
      "question": "What is the difference between loss function and objective function",
      "answer": "The function we want to minimize or maximize is called the objective function or criterion. Loss function is usually a function defined on a data point, prediction and label, and measures the penalty"
    },
    {
      "question": "List one usage of loss function",
      "answer": "Loss is used to calculate the gradients"
    },
    {
      "question": "What is the most commonly used loss function",
      "answer": "Mean Squared Error is the most commonly used Loss function"
    },
    {
      "question": "Which loss function is used by Decision trees",
      "answer": "Gini Impurity is the loss function used by decision trees"
    },
    {
      "question": "Which metric is used in multi class classification loss",
      "answer": "Multi class cross entropy is used in multi class classification loss.This is an extension of the binary cross entropy calculation where the losses for each class are calculated separately added as the result"
    },
    {
      "question": "What is Binary Cross Entropy",
      "answer": "Binary cross entropy is the measure of difference between probability distributions for a set of given random variables or events"
    },
    {
      "question": "What is other name for Binary Cross Entropy",
      "answer": "The other name for Binary Cross Entropy is Log Loss"
    },
    {
      "question": "Is binary cross entropy the same as log loss",
      "answer": "Yes Binary cross entropy and log loss are the same. Both terms are used for classification problems,whereas cross entropy is used for multi class classification and log loss is used for binary classification"
    },
    {
      "question": "When does cross entropy loss increases",
      "answer": "Cross entropy loss increases, if the predicted probability is different from the actual label"
    },
    {
      "question": "Which cost function is used in logistic regression",
      "answer": "The cost function used in Logistic Regression is Log Loss"
    },
    {
      "question": "Is mean squared error loss function",
      "answer": "Mean squared error is the simplest and most common loss function"
    },
    {
      "question": "Is mean squared error the same as root mean squared error",
      "answer": "It is just the square root of the mean squared erro"
    },
    {
      "question": "Is mean squared error a cost function",
      "answer": "For Linear Regression, Mean squared error is nothing but the Cost Function. Mean Squared Error is the sum of the squared differences between the prediction and true value"
    },
    {
      "question": "What is Root Mean Squared Error",
      "answer": "Root Mean Squared Error is measure of the average deviation of model predictions from the actual values in the dataset"
    },
    {
      "question": "Is Root Mean Squared Error a cost function or loss function",
      "answer": "Root Mean Squared Error is a cost function, since it is square root of average of squared errors across samples in the dataset"
    },
    {
      "question": "What is the range of Root Mean Squared Error value",
      "answer": "Root Mean Squared Error value ranges from zero to infinity"
    },
    {
      "question": "How to interpret Root Mean Squared Error",
      "answer": "The lower the Root Mean Squared Error, the better a given model is able to fit the dataset"
    },
    {
      "question": "Can Root Mean Squared Error value be greater than 1",
      "answer": "We cannot claim any number as good Root Mean Squared Error value, since it is based upon the dependent variable"
    },
    {
      "question": "What is good range of Root Mean Squared Error",
      "answer": "Based on a rule of thumb, it can be said that Root Mean Squared Error values between 0.2 and 0.5 shows that the model can predict the data accurately"
    },
    {
      "question": "Is Root Mean Squared Error the same as Standard deviation",
      "answer": "Standard deviation is used to measure the spread of data around the mean, while Root Mean Squared Error is used to measure distance between some values and prediction for those values"
    },
    {
      "question": "What are the units of Root Mean Squared Error",
      "answer": "Root Mean Squared Error has the same units as the quantity being estimated"
    },
    {
      "question": "What does lower values of Root Mean Squared Error indicate",
      "answer": "Lower values of Root Mean Squared Error indicates a better fit of model on to the data"
    },
    {
      "question": "What does higher values of Root Mean Squared Error indicate",
      "answer": "If the Root Mean Squared Error for the test set is much higher than that of the training set, it describes that you have badly over fit the data"
    },
    {
      "question": "What are the different types of cost functions",
      "answer": "Linear Cost Function, Quadratic Cost Function, Cubic Cost Function"
    },
    {
      "question": "What is the hyper parameter of Huber loss",
      "answer": "Huber loss approaches Mean Absolute Error when hyperparameter delta is approximately equal to 0 and Huber loss approaches Mean Squared Error when delta is approximately equal to infinity"
    },
    {
      "question": "What is the intuition behind Huber loss",
      "answer": "Quantile loss functions are useful, when predicting an interval instead of only point predictions"
    },
    {
      "question": "When are Quantile loss functions useful",
      "answer": "Binary Cross Entropy loss is the other name of Log loss"
    },
    {
      "question": "What is the other name for Log loss",
      "answer": "Hinge loss is a loss function used for training classifiers"
    },
    {
      "question": "How error value is calculated using gradient descent method",
      "answer": "For a given problem statement, the solution starts with a Random initialization. These initial parameters are then used to generate the predictions that is the output. Once we have the predicted values we can calculate the error or the cost"
    },
    {
      "question": "Should Mean squared error be high or low",
      "answer": "There is no correct value for Mean squared error. Simply put, lower the value will be better and 0 means the model is perfect"
    },
    {
      "question": "What are the problems faced by gradient descent",
      "answer": "If the execution is not done properly while using gradient descent, it may lead to problems like vanishing gradient or exploding gradient problems"
    },
    {
      "question": "What is the goal of gradient descent",
      "answer": "The goal of gradient descent is to minimize the cost function, or the error between predicted and actual output"
    },
    {
      "question": "What standard error tells us",
      "answer": "The standard error tells you, how accurate the mean of any given sample from that population is likely to be compared to the true population mean"
    },
    {
      "question": "What are the steps for using a gradient descent algorithm to calculate error",
      "answer": "Calculate error between the actual value and the predicted value, Reiterate until you find the best weights of network, Pass an input through the network and get values from output layer, Initialize random weight and bias"
    },
    {
      "question": "Which is the fastest gradient descent",
      "answer": "Mini Batch gradient descent works faster than both Batch gradient descent and Stochastic gradient descent"
    },
    {
      "question": "What is the criteria for choosing error function",
      "answer": "The choice of error function depends entirely on how our model will be used. Example is Squared deviation"
    },
    {
      "question": "What is Hinge loss",
      "answer": "Hinge loss is a loss function used for training classifiers"
    },
    {
      "question": "Why Mean squared error is not used as a loss function in Binomial Logistic Regression",
      "answer": "when the Mean Squared loss function is plotted with respect to weights of the logistic regression model, the curve obtained is not a convex curve which makes it very difficult to find the global minimum."
    },
    {
      "question": "Why is cross entropy better than Mean squared error",
      "answer": "Cross entropy is better than Mean squared error for classification, because the decision boundary in a classification task is large in comparison with regression."
    },
    {
      "question": "How do you measure the deviation of an observable value",
      "answer": "The deviation of an observable value is measured by using error function."
    },
    {
      "question": "Is loss function same as objective function",
      "answer": "Yes loss function is same as Objective function, loss function is a part of a cost function which is a type of an objective function."
    },
    {
      "question": "Is Mean square error a good loss function",
      "answer": "The Mean Squared Error, or MSE loss is the default loss to use for regression problems. Mathematically, it is the preferred loss function under the inference framework of maximum likelihood if the distribution of the target variable is Gaussian."
    },
    {
      "question": "What is exponential loss",
      "answer": "The exponential loss is convex and grows exponentially for negative values which makes it more sensitive to outliers. The exponential loss is used in the AdaBoost algorithm."
    },
    {
      "question": "What is contrastive loss used for",
      "answer": "Contrastive loss is used to map vectors that model the similarity of input items. These mappings can support many tasks, like unsupervised learning, one shot learning, and other distance metric learning tasks."
    },
    {
      "question": "Why do we use Standard Error",
      "answer": "If we want to indicate the uncertainty around the estimate of the mean measurement, we quote the standard error of the mean. The standard error is most useful as a means of calculating a confidence interval."
    },
    {
      "question": "Is a low standard error Good",
      "answer": "The smaller the standard error, the less the spread and the more likely it is that any sample mean is close to the population mean. A small standard error is thus a Good Thing."
    },
    {
      "question": "How much standard error is acceptable",
      "answer": "Standard Error value of 0.8 to 0.9 are acceptable."
    },
    {
      "question": "What is Type I error",
      "answer": "Type 1 errors are false positives. They happen when the tester validates a statistically significant difference even though there is not one."
    },
    {
      "question": "What is Type II error",
      "answer": "Type II error are false negatives. A type II error is defined as the probability of incorrectly failing to reject the null hypothesis, when in fact it is not applicable to the entire population."
    },
    {
      "question": "What is Type III error",
      "answer": "Type III error occurs when you get the right answer to the wrong question. Type III error occurs when you correctly conclude that the two groups are statistically different, but you are wrong about the direction of the difference."
    },
    {
      "question": "What is Type IV error",
      "answer": "A type IV error was defined as the incorrect interpretation of a correctly rejected null hypothesis. Statistically significant interactions were classified in any of the categories such as correct interpretation or cell mean interpretation or main effect interpretation or no interpretation."
    },
    {
      "question": "What is the difference between Type I error, Type II error, Type III error and Type IV error",
      "answer": "Type I error is rejecting the null hypothesis when it is true, Type II error is probability of incorrectly failing to reject the null hypothesis, Type III error is getting the right answer to the wrong question, Type IV error is incorrect interpretation of a correctly rejected null hypothesis."
    },
    {
      "question": "What is Alpha Error",
      "answer": "Alpha error occurs when the null hypothesis is erroneously rejected."
    },
    {
      "question": "What is Beta Error",
      "answer": "Beta error occurs when the null hypothesis is wrongly retained."
    },
    {
      "question": "What is the other name of type I error",
      "answer": "The other name of type I error is Alpha Error."
    },
    {
      "question": "What is the other name of type II error",
      "answer": "the other name of type II error is Beta Error."
    },
    {
      "question": "What is the significance level of Type I Error",
      "answer": "The significance level of Type I Error is set as 0.05, which is 5 percentage."
    },
    {
      "question": "What can cause Type I errors",
      "answer": "Type 1 errors can result from two sources such as random chance and improper research techniques."
    },
    {
      "question": "How to prevent Type I errors",
      "answer": "We can control the likelihood of a Type I error by changing the level of significance. The probability of a Type I error is equal to alpha, so if you want to avoid them, lower your significance level maybe from 5 percent down to 1 percent."
    },
    {
      "question": "Why do we use 0.05 level of significance",
      "answer": "The significance level, also denoted as alpha, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5 percent risk of concluding that a difference exists when there is no actual difference."
    },
    {
      "question": "How to avoid Type II Error",
      "answer": "Type II errors can be avoided by increasing the sample size, increasing the significance level."
    },
    {
      "question": "Is Type I error or Type II error worst",
      "answer": "To decide worst type of error, errors depends upon situation, in some cases, a Type I error is preferable to a Type II error, but in other applications, a Type I error is more dangerous to make than a Type II error."
    },
    {
      "question": "What are the types of statistical errors Class 11",
      "answer": "There are two types of statistical errors such as Sampling error and Non sampling error."
    },
    {
      "question": "What is Bias Error",
      "answer": "Bias is the amount that a model prediction differs from the target value, compared to the training data. Bias error results from simplifying the assumptions used in a model so the target functions are easier to approximate."
    },
    {
      "question": "What are the other names of Bias Error",
      "answer": "The other names of Bias Error are Error due, Squared Bias."
    },
    {
      "question": "How do you calculate Bias error",
      "answer": "To calculate the bias of a method used for many estimates, find the errors by subtracting each estimate from the actual or observed value. Add up all the errors and divide by the number of estimates to get the bias."
    },
    {
      "question": "What is Random error",
      "answer": "Random error is a chance difference between the observed and true values of something. For example, a researcher misreading a weighing scale records an incorrect measurement."
    },
    {
      "question": "What does standard error of 1 mean",
      "answer": "If you measure a sample from a wider population, then the average or mean of the sample will be an approximation of the population mean. Thus 68 percent of all sample means will be within one standard error of the population mean and 95 percent within two standard errors."
    },
    {
      "question": "How do you fix high bias",
      "answer": "High Bias can be solved by adding more features to the hypothesis function, if new features are not available, we create new features by combining two or more existing features or by taking a square, cube, etc of the existing feature."
    },
    {
      "question": "What is a negative error",
      "answer": "If the experimental value is less than the accepted value, the error is negative."
    },
    {
      "question": "What is Variance error",
      "answer": "Error variance is the statistical variability of scores caused by the influence of variables other than the independent variable."
    },
    {
      "question": "How standard error is calculated",
      "answer": "The standard error is calculated by dividing the standard deviation by the square root of sample size."
    },
    {
      "question": "What is the difference between standard error and standard deviation",
      "answer": "Standard error and standard deviation are both measures of variability. The standard deviation reflects variability within a sample, while the standard error estimates the variability across samples of a population."
    },
    {
      "question": "What is the difference between standard error and Sampling error",
      "answer": "Sampling error is the difference in size between a sample estimate and the population parameter. The standard error of the mean, sometimes shortened to standard error, provided a measure of the accuracy of the sample mean as an estimate of the population parameter."
    },
    {
      "question": "How do you know if standard error is significant",
      "answer": "When the standard error is large relative to the statistic, the statistic will typically be non significant. However, if the sample size is very large, for example, sample sizes greater than 1000, then virtually any statistical result calculated on that sample will be statistically significant."
    },
    {
      "question": "What are the uses of Standard error",
      "answer": "Standard error is used to estimate the efficiency, accuracy, and consistency of a sample"
    },
    {
      "question": "How do you calculate sampling error",
      "answer": "The sampling error is calculated by dividing the standard deviation of the population by the square root of the size of the sample, and then multiplying the resultant with the Z score value, which is based on the confidence interval."
    },
    {
      "question": "Can sampling error be negative",
      "answer": "Sampling errors may be positive or negative."
    },
    {
      "question": "What is the standard error for a sampling distribution of the mean",
      "answer": "The standard error of the mean is the standard deviation of the sampling distribution of the mean. It is therefore the square root of the variance of the sampling distribution of the mean. "
    },
    {
      "question": "How do you find margin of error",
      "answer": "Margin of error can be calculated by multiplying critical value with standard deviation of population or sample."
    },
    {
      "question": "What are the causes of sampling errors",
      "answer": "Sampling error is affected by a number of factors including sample size, sample design, the sampling fraction and the variability within the population."
    },
    {
      "question": "Is standard deviation margin of error",
      "answer": "Standard deviation is an essential part of calculating the margin of error for your data. If you do not have the value for your sample data proportion, you can use standard deviation to determine the margin of error."
    },
    {
      "question": "Is standard error the same as uncertainty",
      "answer": "Uncertainty is measured with a variance or its square root, which is a standard deviation. The standard deviation of a statistic is also called standard error. Uncertainty emerges because of variability."
    },
    {
      "question": "Can sampling error be eliminated",
      "answer": "The sampling errors can be eliminated by increasing the sample size or the number of samples."
    },
    {
      "question": "What is Sampling error",
      "answer": "Sampling error is the difference between a population parameter and a sample statistic used to estimate it. For example, the difference between a population mean and a sample mean is sampling error."
    },
    {
      "question": "What is non sampling error",
      "answer": "Non sampling error refers to all sources of error that are unrelated to sampling. Non sampling errors are present in all types of survey, including censuses and administrative data."
    },
    {
      "question": "How do you interpret sampling error",
      "answer": "In general, larger sample sizes decrease the sampling error, however this decrease is not directly proportional."
    },
    {
      "question": "What is the difference between sampling error and non sampling error",
      "answer": "Sampling error is a statistical error happens due to the sample selected does not perfectly represents the population of interest. Non sampling error occurs due to sources other than sampling, while conducting survey activities is known as non sampling error."
    },
    {
      "question": "What are the sources of non sampling errors",
      "answer": "Nonsampling errors, arise mainly due to misleading definitions and concepts, inadequate frames, unsatisfactory questionnaires, defective methods of data collection, tabulation, coding, incomplete coverage of sample units."
    },
    {
      "question": "How can we reduce or avoid non sampling error",
      "answer": "Techniques to avoid non sampling error are randomizing the selection, training your team, performing external record checks, completing consistency checks, checking your wording, randomizing question order and sticking to the facts."
    },
    {
      "question": "What is Undercoverage error",
      "answer": "Undercoverage occurs when the sampling frame does not include all members of the target population"
    },
    {
      "question": "What are the types of non sampling errors",
      "answer": "Coverage error, Measurement error, Nonresponse error and Processing error."
    },
    {
      "question": "How can sampling errors be prevented",
      "answer": "Sampling errors can be reduced by increasing sample size, splitting population into smaller groups and by using random sampling."
    },
    {
      "question": "Can standard error be greater than mean",
      "answer": "Yes, the Standard error could be greater than its mean and this might indicates high variation between values and abnormal distribution for data. in such case, it is advisable to use median and range instead of Mean and standard deviation to describe your data."
    },
    {
      "question": "How does standard error relate to sampling error",
      "answer": "Generally, sampling error is the difference in size between a sample estimate and the population parameter. The standard error of the mean, sometimes shortened to standard error, provided a measure of the accuracy of the sample mean as an estimate of the population parameter."
    },
    {
      "question": "Why is Sampling error important",
      "answer": "Sampling error is important in creating estimates of the population value of a particular variable, how much these estimates can be expected to vary across samples, and the level of confidence that can be placed in the results."
    },
    {
      "question": "What is non response error",
      "answer": "Non response errors result from a failure to collect complete information on all units in the selected sample."
    },
    {
      "question": "What are the risks of sampling errors",
      "answer": "The risk of sampling error is, they may create distortions in the results, leading users to draw incorrect conclusions."
    },
    {
      "question": "How can we prevent the risk of sampling errors",
      "answer": "The risk of sampling errors can be prevented, if the analysts select subsets or samples of data to represent the whole population effectively."
    },
    {
      "question": "What are the types of non response errors",
      "answer": "Total and Partial are 2 types of non response errors."
    },
    {
      "question": "When does total non response error occur",
      "answer": "Total nonresponse error occurs when all or almost all data for a sampling unit are missing."
    },
    {
      "question": "When does partial non response error occur",
      "answer": "Partial nonresponse error occurs when respondents provide incomplete information."
    },
    {
      "question": "What is response error",
      "answer": "Response errors represent a lack of accuracy in responses to questions."
    },
    {
      "question": "What are different factors of response error",
      "answer": "They different factors of response error are, including a questionnaire that requires improvements, misinterpretation of questions by interviewers or respondents, and errors in respondent statements."
    },
    {
      "question": "What are the possible ways to control response errors",
      "answer": "The ways to control response errors include using aided recall, replacing open questions with specific questions, using more appropriate time periods, employing bounded recall and records, using diaries, etc."
    },
    {
      "question": "What are the major errors of selection",
      "answer": "False positive error and False negative error are two types of selection errors."
    },
    {
      "question": "What are categories of non response errors",
      "answer": "unit non response error and item non response error are two categories of non response errors."
    },
    {
      "question": "What is Magnet loss function",
      "answer": "Magnet loss is a type of loss function used in distance metric learning of machine learning problems."
    },
    {
      "question": "What is the other name of random error",
      "answer": "Chance Error or chance Variation is the other name of random error."
    },
    {
      "question": "What are chance errors",
      "answer": "Chance variation or chance error or random error is the inherent error in any predictive statistical model."
    },
    {
      "question": "What is absolute error and relative error",
      "answer": "The Absolute error is the difference between the measured value and the actual value. Relative error is the ratio of the absolute error of the measurement to the accepted measurement."
    },
    {
      "question": "Is Huber loss smooth",
      "answer": "Huber loss is a smooth approximation to absolute value."
    },
    {
      "question": "Which loss function is robust to outliers",
      "answer": "Huber loss is more robust to outliers than Mean Squared Error."
    },
    {
      "question": "Is Huber loss function convex",
      "answer": "Yes, Huber loss function is convex."
    },
    {
      "question": "Who invented Huber loss",
      "answer": "The statistician Peter Huber invented Huber loss."
    },
    {
      "question": "What is smooth L1 loss",
      "answer": "Smooth L1 loss can be interpreted as a combination of L1 loss and L2 loss. It behaves as L1 loss when the absolute value of the argument is high, and it behaves like L2 loss when the absolute value of the argument is close to zero."
    },
    {
      "question": "Is logistic loss convex",
      "answer": "The logistic loss is convex and grows linearly for negative values which make it less sensitive to outliers. The logistic loss is used in the LogitBoost algorithm."
    },
    {
      "question": "Why are losses convex",
      "answer": "We should always use a convex loss function so that gradient descent can converge to the global minima."
    },
    {
      "question": "What is Zeroone error",
      "answer": "In multilabel classification, the zero one loss function corresponds to the subset zero one loss, for each sample the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one."
    },
    {
      "question": "Is sigmoid loss convex",
      "answer": "The logarithm of sigmoid function is not convex."
    },
    {
      "question": "What is quadratic loss function",
      "answer": "The quadratic loss function gives a measure of how accurate a predictive model is. It works by taking the difference between the predicted probability and the actual value, so it is used on classification schemes which produce probabilities"
    },
    {
      "question": "State an example of quadratic loss function",
      "answer": "Naive Bayes classifier is an example of quadratic loss function"
    },
    {
      "question": "What is Squared hinge Loss",
      "answer": "Squared Hinge loss is an extension of the hinge loss and it is the square of the hinge loss function."
    },
    {
      "question": "What is Gini impurity",
      "answer": "Gini Impurity is a measure of the likelihood that an instance of a random variable is incorrectly classified per the classes in the data provided the classification is random."
    },
    {
      "question": "Mention the cost function that satisfies triangle inequality",
      "answer": "Hellinger Distance is a cost function that satisfies the triangle inequality."
    },
    {
      "question": "Is Hellinger distance bounded",
      "answer": "The Hellinger distance forms a bounded metric on the space of probability distributions over a given probability space."
    },
    {
      "question": "Is Hellinger distance symmetric",
      "answer": "Yes Hellinger distance is symmetric. The Hellinger distance metric gives an output in the range of 0 to 1 for two probability distributions, with values closer to 0 meaning they are more similar. "
    },
    {
      "question": "Mention range of values for which hinge loss works best",
      "answer": "Hinge loss function typically works best when the values of the output variable are in the set of minus 1 to plus 1."
    },
    {
      "question": "For which type of questions, Squared Hinge loss is suitable",
      "answer": "Squared Hinge loss is perfectly suitable for Yes or No type of questions, where the deviation in probability is not a concern."
    },
    {
      "question": "What is the lower bound for gini impurity",
      "answer": "The lower bound for Gini impurity function is 0"
    },
    {
      "question": "What is the other name of cross entropy loss function",
      "answer": "The other name of cross entropy loss function is logarithmic loss."
    },
    {
      "question": "What is weighted cross entropy loss",
      "answer": "The weighted Cross Entropy loss function is used to solve the problem that the accuracy of the deep learning model overfitting on the test set due to the imbalance of the convergence speed of the loss function decreases."
    },
    {
      "question": "Can cross entropy be more than 1",
      "answer": "Mathematically, if your label is 1 and your predicted probability is low like 0.1, the cross entropy can be greater than 1, like losses"
    },
    {
      "question": "What is weighted loss function",
      "answer": "The weighted loss function  is calculated based on the predicted value and error obtained for each instance. This method is applicable to both prognostic and diagnostic tasks."
    },
    {
      "question": "What is categorical cross entropy loss",
      "answer": "Categorical cross entropy is a loss function that is used in multi class classification tasks. These are tasks where an example can only belong to one out of many possible categories and the model must decide which one."
    },
    {
      "question": "What does it mean if entropy is zero",
      "answer": "Zero entropy means perfect knowledge of a state, no motion, no temperature, no uncertainty. "
    },
    {
      "question": "Is Cross Entropy loss convex",
      "answer": "For logistic regression, this cross entropy loss function is conveniently convex. A convex function has just one minimum, there are no local minima, so gradient descent starting from any point is guaranteed to find the minimum."
    },
    {
      "question": "Define ordinal probability",
      "answer": "An ordinal superiority measure summarizes the probability that an observation from one distribution falls above an independent observation from the other distribution, adjusted for explanatory variables in a model."
    },
    {
      "question": "What is ordinal probability",
      "answer": "An ordinal superiority measure summarizes the probability that an observation from one distribution falls above an independent observation from the other distribution, adjusted for explanatory variables in a model."
    },
    {
      "question": "Is ordinal data qualitative",
      "answer": "The ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered as in between the qualitative data and quantitative data. The ordinal data only shows the sequences and cannot use for statistical analysis"
    },
    {
      "question": "Can you sum ordinal data",
      "answer": ".No. The pairs of ordinal numbers 1 and 4 and, 2 and 3 both sum to 5"
    },
    {
      "question": "When to use Ordinal Logistic Regression",
      "answer": "You want to use one variable in a prediction of another, or you want to quantify the numerical relationship between two variables\nThe variable you want to predict your dependent variable is an ordered categorical ordinal variable"
    },
    {
      "question": "Define ordinal encoding",
      "answer": "In ordinal encoding, each unique category value is assigned an integer value.\n\nFor example, red is 1, green is 2, and blue is 3.\n\nThis is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used."
    },
    {
      "question": "What kind of encoding techniques can you use for categorical variables",
      "answer": "This means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model. The two most popular techniques are an Ordinal Encoding and a One Hot Encoding"
    },
    {
      "question": "What is ordinal and nominal",
      "answer": "Nominal data is classified without a natural order or rank, whereas ordinal data has a predetermined or natural order.On the other hand, numerical or quantitative data will always be a number that can be measured"
    },
    {
      "question": "What is ordinal level",
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them. Ordinal level of measurement is the second of the four measurement scales. Ordinal indicates order"
    },
    {
      "question": "Can ordinal data be skewed",
      "answer": "Ordinal data is frequently skewed or multi modal so violates the assumption of normal distribution. Thus the distribution is not appropriate for analysis as metric data"
    },
    {
      "question": "define ordinal level",
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them. Ordinal level of measurement is the second of the four measurement scales. Ordinal indicates order"
    },
    {
      "question": "What are example of ordinal",
      "answer": "Examples of ordinal variables include socio economic status low income,middle income,high income, education level high school,BS,MS,PhD, income level less than 50K, 50K to 100K, over 100K, satisfaction rating extremely dislike, dislike, neutral, like, extremely like"
    },
    {
      "question": "What is ordinal numbers",
      "answer": "Ordinal numbers tell the order of how things are set, they show the position or the rank of something."
    },
    {
      "question": "Define  ordinal numbers",
      "answer": "Ordinal Numbers are those numerals which are used in identifying the position of objects or persons. They are also called as positioning numbers.The ordinal numbers can be written using numerals as prefix and adjectives as a suffix, for example, 1st, 2nd, 3rd, 4th, 5th, 6th and so on."
    },
    {
      "question": "Which Python library is used for regression",
      "answer": "The package scikit learn is a widely used Python library for machine learning, built on top of NumPy and some other packages. It provides the means for preprocessing data, reducing dimensionality, implementing regression, classification, clustering, and more. Like NumPy, scikit learn is also open source."
    },
    {
      "question": "Is temperature an ordinal variable",
      "answer": "Ordinal refers to quantities that have a natural ordering.Interval data is like ordinal except we can say the intervals between each value are equally split. The most common example is temperature in degrees Fahrenheit."
    },
    {
      "question": "Is ordinal scale continuous",
      "answer": "In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree is ordinal."
    },
    {
      "question": "Define ordinal numbers",
      "answer": "Ordinal numbers tell the order of how things are set, they show the position or the rank of something."
    },
    {
      "question": "Define ordinal loss",
      "answer": "Ordinal regression seeks class label predictions when the penalty incurred for mistakes increases according to an ordering over the labels.The absolute error, between label prediction  and actual label is a canonical ordinal regression loss function."
    },
    {
      "question": "What is ordinal response",
      "answer": "Ordinal responses include Likert scales for agreement with attitude statements e.g., disagree, neither agree nor disagree, and agree and reported frequencies of doing something such as helping children with homework e.g., daily, several times per week, occasionally, and never."
    },
    {
      "question": "Is Likert scale ordinal",
      "answer": "Likert scales fall within the ordinal level of measurement the categories of response have directionality, but the intervals between them cannot be presumed equal.\n"
    },
    {
      "question": "what is ordinal encoding",
      "answer": "In ordinal encoding, each unique category value is assigned an integer value.\n\nFor example, red is 1, green is 2, and blue is 3.\n\nThis is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used."
    },
    {
      "question": "Is age ordinal or nominal",
      "answer": "Age can be both nominal and ordinal data depending on the question types. I.e How old are you is used to collect nominal data while Are you the firstborn or What position are you in your family is used to collect ordinal data. Age becomes ordinal data when there some sort of order to it."
    },
    {
      "question": "What are the types of Regressions",
      "answer": "Linear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression"
    },
    {
      "question": "What is the main difference between linear regression and logistic regression",
      "answer": "Linear Regression is used to handle regression problems whereas Logistic regression is used to handle the classification problems. Linear regression provides a continuous output but Logistic regression provides discreet output"
    },
    {
      "question": "Can you use linear regression for ordinal data",
      "answer": "Now you can usually use linear regression with an ordinal dependent variable but you will see that the diagnostic plots do not look good."
    },
    {
      "question": "How do you display ordinal data",
      "answer": "Ordinal data can be visualized in several different ways. Common visualizations are the bar chart or a pie chart. Tables can also be useful for displaying ordinal data and frequencies. Mosaic plots can be used to show the relationship between an ordinal variable and a nominal or ordinal variable.\n"
    },
    {
      "question": "What are the assumptions for ordinal regression",
      "answer": " Assumptions The dependent variable is measured on an ordinal level One or more of the independent variables are either continious categorical or ordinal No Multi collinearity  that is when two or more independent variables are highly correlated with each other."
    },
    {
      "question": "How do you interpret logistic regression",
      "answer": "Interpret the key results for Binary Logistic Regression\nStep 1 Determine whether the association between the response and the term is statistically significant.\nStep 2 Understand the effects of the predictors.\nStep 3 Determine how well the model fits your data.\nStep 4 Determine whether the model does not fit the data."
    },
    {
      "question": "what is interpretation of logistic regression",
      "answer": "Interpret the key results for Binary Logistic Regression\nStep 1 Determine whether the association between the response and the term is statistically significant.\nStep 2 Understand the effects of the predictors.\nStep 3 Determine how well the model fits your data.\nStep 4 Determine whether the model does not fit the data."
    },
    {
      "question": "What does beta mean in logistic regression",
      "answer": "R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively."
    },
    {
      "question": " What is ordinal regression in machine learning",
      "answer": "ordinal regression also called ordinal classification is a type of regression analysis used for predicting an ordinal variable that is a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant."
    },
    {
      "question": "Define ordinal regression ",
      "answer": " ordinal regression also called ordinal classification is a type of regression analysis used for predicting an ordinal variable that is a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant."
    },
    {
      "question": "Is ordinal regression nonparametric",
      "answer": "Bayesian non parametric ordinal regression under a monotonicity constraint Herein the considered models are non parametric and the only condition imposed is that the effects of the covariates on the outcome categories are stochastically monotone according to the ordinal scale."
    },
    {
      "question": "Is ordinal logistic regression linear",
      "answer": "The assumptions for Ordinal Logistic Regression include Linearity, No Outliers, Independence."
    },
    {
      "question": "What is ordinal data example",
      "answer": "Ordinal data is a kind of categorical data with a set order or scale to it For example ordinal data is said to have been collected when a responder inputs his or her financial happiness level on a scale of 1 10."
    },
    {
      "question": "How do you correlate ordinal data",
      "answer": "To find out relationship between ordinal variables, you can use Spearman rank correlation or Kendalls Tau c In the same way for graphical representation you can use multiple bar chart. check whether there is a positive or negative relationship between two variable."
    },
    {
      "question": "define beta means in logistic regression",
      "answer": "The logistic regression coefficient beta associated with a predictor X is the expected change in log odds of having the outcome per unit change in X."
    },
    {
      "question": "What is r squared in logistic regression",
      "answer": "R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively."
    },
    {
      "question": "Define r squared in logistic regressio",
      "answer": " R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively."
    },
    {
      "question": "What is the difference between linear and ordinal regression",
      "answer": "At a very high level, the main difference ordinal regression and linear regression is that with linear regression the dependent variable is continuous and ordinal the dependent variable is ordinal."
    },
    {
      "question": "What is the difference between logistic regression and ordinal regression",
      "answer": "Logistic regression is usually taken to mean binary logistic regression for a two valued dependent variable Y. Ordinal regression is a general term for any model dedicated to ordinal Y whether Y is discrete or continuous."
    },
    {
      "question": "Which is the best regression model",
      "answer": "The best model was deemed to be the linear model, because it has the highest AIC, and a fairly low R square adjusted in fact, it is within 1 percent of that of model poly31 which has the highest R square adjusted.\n"
    },
    {
      "question": "Can ordinal variables be used in regression",
      "answer": " In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand."
    },
    {
      "question": "How do you measure ordinal data",
      "answer": "The simplest way to analyze ordinal data is to use visualization tools. For instance, the data may be presented in a table in which each row indicates a distinct category. In addition, they can also be visualized using various charts. The most commonly used chart for representing such types of data is the bar chart."
    },
    {
      "question": "Is multinomial the same as ordinal",
      "answer": "Both multinomial and ordinal models are used for categorical outcomes with more than two categories. The simplest decision criterion is whether that outcome is nominali.e., no ordering to the categories or ordinal i.e., the categories have an order."
    },
    {
      "question": "Why do we use ordinal regression",
      "answer": "Ordinal regression is used to predict the dependent variable with ordered multiple categories and independent variables. In other words, it is used to facilitate the interaction of dependent variables having multiple ordered levels with one or more independent variables"
    },
    {
      "question": "What is the difference between ordinal scale and ratio scale",
      "answer": "Ordinal scale has all its variables in a specific order, beyond just naming them. Ratio scale bears all the characteristics of an interval scale, in addition to that, it can also accommodate the value of zero on any of its variables.\n"
    },
    {
      "question": "Can you calculate mean for ordinal data",
      "answer": "The mean cannot be computed with ordinal data. Finding the mean requires you to perform arithmetic operations like addition and division on the values in the data set. Since the differences between adjacent scores are unknown with ordinal data, these operations cannot be performed for meaningful results."
    },
    {
      "question": "Can ordinal data be normally distributed",
      "answer": "Values on 5 point ordinal scales are never normally distributed"
    },
    {
      "question": "Why is median used for ordinal data",
      "answer": "If the variable is ordinal, the median is probably your best bet because it provides more information about the sample than the mode does. But if the variable is interval or ratio, you will need to determine if the distribution is symmetrical or skewed."
    },
    {
      "question": "Why not use mean for ordinal data",
      "answer": "A stronger reason for not using the mean with ordinal data is that its value depends on conventions on coding. Numerical codes such as 1, 2, 3, 4 are usually just chosen for simplicity or convenience, but in principle they could equally well be 1, 23, 456, 7890 as far as corresponding to a defined order as concerned."
    },
    {
      "question": "Is ordinal data categorical or continuous",
      "answer": "An ordinal variable is similar to a categorical variable. The difference between the two is that there is a clear ordering of the categories. For example, suppose you have a variable, economic status, with three categories low, medium and high."
    },
    {
      "question": "Is religion nominal or ordinal",
      "answer": "Religion. There are many different religions, but again these are just different ways of categorizing the religious preferences of people. Consequently religion has only a nominal scale of measurement"
    },
    {
      "question": "Do you test for normality with ordinal data",
      "answer": "If a variable is ordinal and has at least five categories, making a normality assumption can work well, and then it can make sense to check normality.To check normality, compute skewness or kurtosis. Do not rely on significance tests for normality, because these are strongly sample size dependent"
    },
    {
      "question": "Why is mode used for ordinal data",
      "answer": "The mode is most useful when used with categorical nominal, or ordinal variables and when there is a relatively small sample size. The mode can be used with categorical variables because it does not require the data to be in a meaningful order. With large samples, it becomes very tedious to determine the mode."
    },
    {
      "question": "Is median preferred for ordinal scale",
      "answer": "The median is usually preferred to other measures of central tendency when your data set is skewed i.e., forms a skewed distribution or you are dealing with ordinal data. However, the mode can also be appropriate in these situations, but is not as commonly used as the median."
    },
    {
      "question": "Can you run an Anova with ordinal data",
      "answer": "Although a t test or ANOVA will work with ordinal data, such an analysis is incorrect because there is no information on the distance between measurements, only their order. Fortunately, easy to use freeware is available for nonparametric analyses of ordinal data to draw robust conclusions."
    },
    {
      "question": "Which test is best for ordinal data",
      "answer": "The most suitable statistical tests for ordinal data e.g., Likert scale are non parametric tests, such as Mann Whitney U test one variable, no assumption on distribution, Wilcoxon signed rank sum test two variables, normal distribution, Kruskal Wallis test two or more groups, no assumption on distribution."
    },
    {
      "question": "Can ordinal data be qualitative",
      "answer": "The ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered as in between the qualitative data and quantitative data. The ordinal data only shows the sequences and cannot use for statistical analysis"
    },
    {
      "question": "What is the main characteristic of ordinal regression algorithm",
      "answer": "Ordinal regression is used to predict the dependent variable with ordered multiple categories and independent variables. In other words, it is used to facilitate the interaction of dependent variables having multiple ordered levels with one or more independent variables. For example Let us assume a survey is done."
    },
    {
      "question": "Can ordinal data be treated as interval data",
      "answer": "Actually, it is not appropriate to treat ordinal data as if it were continuous interval data."
    },
    {
      "question": "Why are ordinal numbers important",
      "answer": "The purpose of using ordinal numbers is to indicate position, or order of things or objects.Since the counting process requires labeling of things with numbering, when objects or things are placed in an order, ordinal numbers tell their exact position, or they help to put things in an order in a collection."
    },
    {
      "question": "How do you write 12 in ordinal numbers",
      "answer": "one to first.\ntwo to second.\nthree to third.\nfive to fifth.\neight to eighth.\nnine to ninth.\ntwelve to twelfth"
    },
    {
      "question": "What is an example of a ordinal scale",
      "answer": "An ordinal scale is a scale of measurement that uses labels to classify cases measurements into ordered classes.Some examples of variables that use ordinal scales would be movie ratings, political affiliation, military rank, etc. Example. One example of an ordinal scale could be movie ratings."
    },
    {
      "question": "Can I use Chi Square to test ordinal data",
      "answer": "The assumptions of the Chi square include The data in the cells should be frequencies, or counts of cases rather than percentages or some other transformation of the data.However, data may be ordinal data. Interval or ratio data that have been collapsed into ordinal categories may also be used.\n"
    },
    {
      "question": "What type of variable is ordinal",
      "answer": "An ordinal variable is a categorical variable for which the possible values are ordered. Ordinal variables can be considered in between categorical and quantitative variables. Thus it does not make sense to take a mean of the values"
    },
    {
      "question": "What is ordinal scale in research",
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale."
    },
    {
      "question": "Define ordinal scale in research",
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale."
    },
    {
      "question": "Is military rank nominal or ordinal",
      "answer": "Military ranks can be considered ordinal measurements. A General is greater in military rank than a Captain who is greater in rank than a Sergeant. Moh's scale of hardness is another good example of measurement at the ordinal level."
    },
    {
      "question": "what is confidence interval of ordinal regression",
      "answer": "Specify a value greater than or equal to 0 and less than 100."
    },
    {
      "question": "Is ordinal mean median or mode",
      "answer": "All continuous data has a median, mode and mean. However, strictly speaking, ordinal data has a median and mode only, and nominal data has only a mode."
    },
    {
      "question": "which software is used for ordinal regression",
      "answer": "ORCA Ordinal Regression and Classification Algorithms is an Octave/MATLAB framework including a wide set of ordinal regression methods."
    },
    {
      "question": "What is ordinal loss",
      "answer": "Ordinal regression seeks class label predictions when the penalty incurred for mistakes increases according to an ordering over the labels.The absolute error, between label prediction  and actual label is a canonical ordinal regression loss function."
    },
    {
      "question": "What is Regression Analysis",
      "answer": "Regression analysis is a form of predictive modelling technique which investigates the relationship between a dependent target and independent variable s predictor. This technique is used for forecasting, time series modelling and finding the causal effect relationship between the variables. For example, relationship between rash driving and number of road accidents by a driver is best studied through regression."
    },
    {
      "question": "Why do we use Regression Analysis",
      "answer": "regression analysis estimates the relationship between two or more variables. Lets understand this with an easy example\n\nLets say, you want to estimate growth in sales of a company based on current economic conditions. You have the recent company data which indicates that the growth in sales is around two and a half times the growth in the economy. Using this insight, we can predict future sales of the company based on current and past information."
    },
    {
      "question": "Types of Regressions",
      "answer": "Linear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression"
    },
    {
      "question": "Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model",
      "answer": ".For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature."
    },
    {
      "question": "How do you interpret ordinal logistic regression odds ratio",
      "answer": "An odds ratio in an ordinal response model is interpreted the same as in a binary model it gives the change in odds for a unit increase in a continuous predictor or when changing levels of a categorical CLASS predictor\n"
    },
    {
      "question": "How to select the right Regression Model",
      "answer": "Life is usually simple, when you know only one or two techniques. One of the training institutes I know of tells their students  if the outcome is continuous apply linear regression. If it is binary  use logistic regression However, higher the number of options available at our disposal, more difficult it becomes to choose the right one. A similar case happens with regression models."
    },
    {
      "question": "what is linearity does in ordinal regression",
      "answer": "Logistic regression fits a logistic curve to binary data. This logistic curve can be interpreted as the probability associated with each outcome across independent variable values. Logistic regression assumes that the relationship between the natural log of these probabilities when expressed as odds and your predictor variable is linear."
    },
    {
      "question": "Define linearity in ordinal regression",
      "answer": "Logistic regression fits a logistic curve to binary data. This logistic curve can be interpreted as the probability associated with each outcome across independent variable values. Logistic regression assumes that the relationship between the natural log of these probabilities when expressed as odds and your predictor variable is linear."
    },
    {
      "question": "How do I run Ordinal Logistic Regression in SPSS",
      "answer": "SPSS ordinal regression procedure works with the data, because it differs from logistic regression. First, for the dependent outcome variable, SPSS actually models the probability of achieving each level or below rather than each level or above"
    },
    {
      "question": "Do ordinal variables have natural ordering",
      "answer": "Ordinal variables have at least three categories and the categories have a natural order. The categories are ranked but the differences between ranks may not be equal. For example, first, second, and third in a race are ordinal data"
    },
    {
      "question": "How do you deal with ordinal categorical variables",
      "answer": "Ordinal variables are fundamentally categorical. One simple option is to ignore the order in the variables categories and treat it as nominal"
    },
    {
      "question": "Which encoding is best for categorical data",
      "answer": "Binary Encoding\n\nIn this encoding scheme, the categorical feature is first converted into numerical using an ordinal encoder. Then the numbers are transformed in the binary number. After that binary value is split into different columns. Binary encoding works really well when there are a high number of categories."
    },
    {
      "question": "Are ordinal variables categorical",
      "answer": "An ordinal variable is similar to a categorical variable. The difference between the two is that there is a clear ordering of the categories.Even though we can order these from lowest to highest, the spacing between the values may not be the same across the levels of the variables."
    },
    {
      "question": "How do you encoding categorical data with high cardinality",
      "answer": "Encoding of categorical variables with high cardinality\nLabel Encoding scikit learn i.e. mapping integers to classes.\nOne Hot  Dummy Encoding scikit learn i.e. expanding the categorical feature into lots of dummy columns taking values in 0,1"
    },
    {
      "question": "Can you correlate ordinal scale variables",
      "answer": "You can put them on a scale with respect to some other, dependent, variable. So there is no correlation with ordinal variables or nominal variables because correlation is a measure of association between scale variables"
    },
    {
      "question": "Is strongly agree ordinal",
      "answer": "In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree is ordinal."
    },
    {
      "question": "who invented ordinal regression",
      "answer": "developed by Eibe Frank and Mark Hal."
    },
    {
      "question": "what is ordinal numbers",
      "answer": "Ordinal Numbers are those numerals which are used in identifying the position of objects or persons. They are also called as positioning numbers.The ordinal numbers can be written using numerals as prefix and adjectives as a suffix, for example, 1st, 2nd, 3rd, 4th, 5th, 6th and so on."
    },
    {
      "question": "What is ordinal classification",
      "answer": "Ordinal classification is a form of multiclass classification for which there is an inherent order between the classes, but not a meaningful numeric difference between them. The performance of such classifiers is usually assessed by measures appropriate for nominal classes or for regression"
    },
    {
      "question": "Define ordinal classification",
      "answer": "Ordinal classification is a form of multiclass classification for which there is an inherent order between the classes, but not a meaningful numeric difference between them. The performance of such classifiers is usually assessed by measures appropriate for nominal classes or for regression."
    },
    {
      "question": "Can you run a regression with ordinal data",
      "answer": "Ordinal logistic regression often just called ordinal regression is used to predict an ordinal dependent variable given one or more independent variables.As with other types of regression, ordinal regression can also use interactions between independent variables to predict the dependent variable."
    },
    {
      "question": "Can ordinal data be continuous",
      "answer": "Ordinal variables have two are more categories that can be ordered or ranked. Keep in mind that researchers may sometimes treat ordinal variables as continuous if they have more than five categories. To remember this variable type, think ordinal order."
    },
    {
      "question": "Can dichotomous variables be ordinal",
      "answer": "Dichotomous variables those with only two values are a special case, and may sometimes be treated as nominal, ordinal, or interval.Whether it is better to treat a dichotomous variable as nominal or ordinal depends on how we think of the underlying concept being measured"
    },
    {
      "question": "Can binary be ordinal",
      "answer": "Binary data is discrete data that can be in only one of two categories  either yes or no, 1 or 0, off or on, etc. Binary can be thought of as a special case of ordinal, nominal, count, or interval data."
    },
    {
      "question": "How does machine learning deal with ordinal data",
      "answer": "An ordinal encoding involves mapping each unique label to an integer value. This type of encoding is really only appropriate if there is a known relationship between the categories. This relationship does exist for some of the variables in our dataset, and ideally, this should be harnessed when preparing the data."
    },
    {
      "question": "Are hours ordinal or not",
      "answer": "Depending on what you want to model, hours and many other attributes like seasons are actually ordinal cyclic variables. In case of seasons you can consider them to be more or less categorical, and in case of hours you can model them as continuous as well."
    },
    {
      "question": "Define ordinal response",
      "answer": "Ordinal responses include Likert scales for agreement with attitude statements e.g., disagree, neither agree nor disagree, and agree and reported frequencies of doing something such as helping children with homework e.g., daily, several times per week, occasionally, and never."
    },
    {
      "question": "Who invented ordinal numbers",
      "answer": "Von Neumann definition of ordinals"
    },
    {
      "question": "Is the empty set an ordinal\n",
      "answer": "The empty set  is an ordinal and as ordinal is denoted by 0"
    },
    {
      "question": "Is a scale ordinal",
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale."
    },
    {
      "question": "What are ordinal classifications based on",
      "answer": "The standard approach to ordinal classification converts the class value into a numeric quantity and applies a regression learner to the transformed data, translating the output back into a discrete class value in a post processing step."
    },
    {
      "question": "What is threshold in ordinal regression",
      "answer": "First, identify your thresholds estimates. You will have one for each possible increase in the outcome variable. For example, if your outcome has a low, medium, and high category, you have two thresholds.one is for the increase from low to medium, and one is for the increase from medium to high."
    },
    {
      "question": "Define threshold in ordinal regression",
      "answer": "First, identify your thresholds estimates. You will have one for each possible increase in the outcome variable. For example, if your outcome has a low, medium, and high category, you have two thresholds.one is for the increase from low to medium, and one is for the increase from medium to high."
    },
    {
      "question": "What is ordinal dependent variable",
      "answer": ".In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand."
    },
    {
      "question": "Define ordinal dependent variable",
      "answer": "In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand."
    },
    {
      "question": "What test is used for ordinal data",
      "answer": "The most appropriate statistical tests for ordinal data focus on the rankings of your measurements. These are non parametric tests. Parametric tests are used when your data fulfils certain criteria, like a normal distribution. While parametric tests assess means, non parametric tests often assess medians or ranks."
    },
    {
      "question": "How do you handle ordinal data",
      "answer": "Treat ordinal variables as numeric\n\nBecause the ordering of the categories often is central to the research question, many data analysts do the opposite ignore the fact that the ordinal variable really is not numerical and treat the numerals that designate each category as actual numbers."
    },
    {
      "question": "How are ordinal numbers written",
      "answer": "Ordinal numbers can be written out as words second, third or as numerals followed by abbreviations 2nd,3rd\n"
    },
    {
      "question": "How do you do ordinal regression Pytorch",
      "answer": "To perform ordinal regression, we need to expand the targets list into a batch size, num labels tensor, according to our previous encoding, and return the mean squared error loss between predictions and the expanded target Code for the loss function, which first encodes the target label and then calculates MSE"
    },
    {
      "question": "Define Regression Analysis",
      "answer": "Regression analysis is a form of predictive modelling technique which investigates the relationship between a dependent target and independent variable s predictor. This technique is used for forecasting, time series modelling and finding the causal effect relationship between the variables. For example, relationship between rash driving and number of road accidents by a driver is best studied through regression."
    },
    {
      "question": "How to test for goodness of fit in ordinal regression models",
      "answer": "These tests include an ordinal\n        version of the Hosmer Lemeshow test the Pulkstenis Robinson chi squared and\n        deviance tests and the Lipsitz likelihood ratio test"
    },
    {
      "question": "Which of them may be suitable as an outcome variable for ordinal regression",
      "answer": "the explanatory variables"
    },
    {
      "question": "The regression technique to the appropriate type of outcome variable",
      "answer": "Simple linear regression is a technique that is appropriate \n          to understand the association between one independent\n          variable and one continuous dependent"
    },
    {
      "question": "How many interaction effects could be explored in this regression model",
      "answer": "They let me to check and rethink the paradox of significant interactions \n          between the log odds model and the probability on dependent variable"
    },
    {
      "question": "The assumption of proportional odds states that in regression technique",
      "answer": "The odds for each explanatory variable must be the same"
    },
    {
      "question": "Describes an ordinal outcome variable",
      "answer": "Ordinal outcomes are polytomous or multilevel outcomes whose levels can be ordered by for example their clinical significance"
    },
    {
      "question": "when compared to the reference group for the relevant variable for ordinal regression",
      "answer": "It is currently not possible to change the reference category in the Ordinal Regression module"
    },
    {
      "question": "Contribute to the model to a statistically significant degree",
      "answer": "A statistically significant result isnt attributed to chance and depends on two key variables sample size and effect size"
    },
    {
      "question": "What should be done if the proportional odds assumption is violated during an ordinal regression",
      "answer": "If this assumption is violated we cannot reduce the coefficients of the model to a single set across all outcome categories and this modeling approach fails"
    },
    {
      "question": "It could be argued that it is easier to split ordinal outcome variables down in to multiple binary variables",
      "answer": "It could be argued that it is easier to split ordinal outcome variables down in to multiple binary variables and model the data using a series of logistic regression analyses rather than a single ordinal regression analysis"
    },
    {
      "question": "Model the data using a series of logistic regression analyses rather than a single ordinal regression analysis",
      "answer": "Ordinal regression is a general term for any model dedicated to ordinal Y whether Y is discrete or continuous"
    },
    {
      "question": "Is the assumption of Proportional Odds met for this final version of the model",
      "answer": "the test of the P assumption has been described as anti conservative that is it nearly always results in rejection of the proportional odds assumption particularly when the number of explanatory variables is large"
    },
    {
      "question": "However there are other approaches to ordinal regression",
      "answer": "Linear regression and logistic regression are two types of regression analysis"
    },
    {
      "question": "ordinal regression using spss",
      "answer": "Ordinal logistic regression often just called ordinal regression is used to predict an ordinal dependent variable given one or more independent variables"
    },
    {
      "question": "Are there differences in the outcome between the groups",
      "answer": "the two groups deteriorate at about the same rate hence the difference between groups is about the same across occasions"
    },
    {
      "question": "Are the symptoms more severe in one group",
      "answer": "Ordinal regression is a member of the family of regression analyses as a predictive analysis"
    },
    {
      "question": "are the ordinal data has alternative modelling method",
      "answer": "All continuous data has a median mode and mean However strictly speaking ordinal data has a median and mode only and nominal data has only a mode"
    },
    {
      "question": "ordinal regression is done when we have dependent variable",
      "answer": "Ordinal regression is a statistical technique that is used to predict behavior of ordinal level dependent variables"
    },
    {
      "question": "ordinal regression is done when we have independent variable",
      "answer": "Ordinal regression is a statistical technique that is used to predict behavior of ordinal level dependent variables with a set of independent variables"
    },
    {
      "question": "what are the ordinal measurement scale in ordinal regression",
      "answer": "Ordinal Scale is defined as a variable measurement scale used to simply depict the order of variables and not the difference between each of the variables"
    },
    {
      "question": "what are the nominal measurement scale in ordinal regression",
      "answer": "Nominal scale is a naming scale where variables are simply named or labeled with no specific order"
    },
    {
      "question": "if ordinal regression is categorical data which field it is",
      "answer": "In statistics ordinal and nominal variables are both considered categorical variables Even though ordinal data can sometimes be numerical not all mathematical operations can be performed on them"
    },
    {
      "question": "if ordinal regression is scale data which filed it is",
      "answer": "Scales of measurement is how variables are defined and categorised"
    },
    {
      "question": "To define test parallel lines on ordinal regression",
      "answer": "A parallel slopes model is the result of a multiple linear regression model that has both one numeric explanatory variable and one categorical explanatory variable"
    },
    {
      "question": "Describes crosstabulation level in ordinal regression",
      "answer": "Cross tabulation also known as cross tab or contingency table is a statistical tool used for categorical data"
    },
    {
      "question": "Define significant value in ordinal regression",
      "answer": "A significance level of 0.05 indicates a 5 percentage risk of concluding that an association exists when there is no actual association"
    },
    {
      "question": "Describes R Square in the regression model",
      "answer": "R squared R2 is a statistical measure that represents the proportion of the variance for a dependent variable thats explained by an independent variable or variables in a regression model"
    },
    {
      "question": "How to do Regression Analysis for Likert Scale Data",
      "answer": "Now let us start this ordinal regression analysis click analyze in this regression and in this ordinal Now dependent variable is satisfaction And independent variable is factor"
    },
    {
      "question": "what problem at hand and an assessment of model fit",
      "answer": "Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained"
    },
    {
      "question": "how do interpretation of the slope parameters",
      "answer": "If the slope of the line is positive then there is a positive linear relationship i.e as one increases the other increases"
    },
    {
      "question": "will choice of link function affects the interpretation of the parameters",
      "answer": "A link function transforms the probabilities of the levels of a categorical response variable to a continuous scale that is unbounded"
    },
    {
      "question": "ordinal regression models with covariates and interactions",
      "answer": "In its most general sense Covariates are simply the X variables in a statistical model and An interaction model is a design model that binds an application together in a way that supports the conceptual models of its target users"
    },
    {
      "question": "what if parallel assumption is not satisfied",
      "answer": "The parallel trend assumption is the most critical of the above the four assumptions to ensure internal validity of DID models"
    },
    {
      "question": "what if there is a high propartion of empty cells",
      "answer": "This issue is more common with binary outcomes but given that ordinal regression is an extension of logistic regression it is plausible to see it occur here as well The problem is likely a result of empty cells for a given outcome level conditional on the covariates"
    },
    {
      "question": "How well your ordinal regression model predicts the dependent variable",
      "answer": "Regression predictions are for the mean of the dependent variable"
    },
    {
      "question": "The three models differ in which response categories are compared and how",
      "answer": "Like all IRT models it is seeking to predict the probability of a certain response based on examinee ability trait level and some parameters which describe the performance of the item With the 3PL those parameters are a discrimination b difficulty or location and c pseudo guessing"
    },
    {
      "question": "How to calculate an ordinal version of the HL test",
      "answer": "So the Hosmer lemma so test the way it works is it divides the data set into a number of groups according to the fitted probabilities that the binary outcome is a 1 And then it compares"
    },
    {
      "question": "How can be assigned an ordinal score",
      "answer": "In other words falls in assigned score when the latent variable falls in the th interval of values"
    },
    {
      "question": "How heterogeneity calculate in ordinal regression",
      "answer": "Analyzing the Homogeneity of a Dataset\n        Calculate the median\n        Subtract the median from each value in the dataset\n        Count how many times the data will make a run above or below the median i.e persistance of positive or negative values\n        Use significance tables to determine thresholds for homogeneity"
    },
    {
      "question": "How dose PR test calculate in ordinal regression",
      "answer": "The probability that a particular Chi Square test statistic is as extreme as or more so than what has been observed under the null hypothesis is defined by Pr ChiSq"
    },
    {
      "question": "How Lipsitz test calculate in ordinal regression",
      "answer": "The Lipsitz test is a goodness of fit test for ordinal response logistic regression models"
    },
    {
      "question": "what if probit model used in ordinal regression",
      "answer": "The ordered probit and logit models have a dependent variable that are ordered categories Examples include rating systems poor fair good excellent opinion surveys from strongly disagree to strongly agree grades and bond ratings"
    },
    {
      "question": "How coefficients involved in ordinal regression",
      "answer": "Regression coefficients are estimates of the unknown population parameters and describe the relationship between a predictor variable and the response In linear regression coefficients are the values that multiply the predictor values"
    },
    {
      "question": "Which type of problems are best for logistic regression",
      "answer": "Logistic regression is a powerful machine learning algorithm that utilizes a sigmoid function and works best on binary classification problems although it can be used on multi class classification problems through the one vs all method"
    },
    {
      "question": "Which ordinal classifier class used for implement",
      "answer": "We implement the trick described above by creating OrdinalClassifier class that will train k minus 1 binary classifier when fit is called and will return predicted class if predict is called"
    },
    {
      "question": "How to take predicated class",
      "answer": "We can take advantage of the ordered class value by transforming a k class"
    },
    {
      "question": "What if predict proba in ordinal regression",
      "answer": "to get predicted probability of each class first we get all prediction probability from all of our classifiers that stored on clfs after that simply enumerate all possible class label and append its prediction to our predicted list after that return it as a numpy array"
    },
    {
      "question": "How K minus 1  Values fits in ordinal regression",
      "answer": "we store each unique label available then for first k minus 1 value for each iteration we transform its label to a binary label that represents the test A multiply Vi binary y equal to y greater than self.unique class i.astypenp.uint8 then we fit a new classifier on the transformed label binary y finally store our classifier to the clfs dictionary with i as its key"
    },
    {
      "question": "How predicted category probability classified",
      "answer": "Well a predicted probability is essentially in its most basic form the probability of an event that is calculated from available data"
    },
    {
      "question": "How correlation involved in ordinal regression",
      "answer": "The Pearsons correlation coefficient measures linear correlation between two continuous variables Values obtained using an ordinal scale are NOT continuous but their corresponding ranks are Hence you can still use the Pearsons correlation coefficient on those ranks"
    },
    {
      "question": "How Location model classified in ordinal regression",
      "answer": "The model depends on the main effects and interaction effects that you select"
    },
    {
      "question": "How confidence interval specified",
      "answer": "A confidence interval displays the probability that a parameter will fall between a pair of values around the mean Confidence intervals measure the degree of uncertainty or certainty in a sampling method They are most often constructed using confidence levels of 95 percentage or 99 percentage"
    },
    {
      "question": "what if there is an Singularity tolerance",
      "answer": "Used for checking for highly dependent predictors Select a value from the list of options"
    },
    {
      "question": "How do predict multi class ordered variable which technique",
      "answer": "Load dataset from the source\n        Split the dataset into training and test data\n        Train Decision tree SVM and KNN classifiers on the training data\n        Use the above classifiers to predict labels for the test data\n        Measure accuracy and visualize classification"
    },
    {
      "question": "define intercepts of ordinal regression",
      "answer": "The intercepts indicate where the latent variable is cut to make the three groups that we observe in our data"
    },
    {
      "question": "Why we use logistic regression in Machine Learning",
      "answer": "Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable"
    },
    {
      "question": "How does logistic regression algorithm work",
      "answer": "Logistic regression is basically a supervised classification algorithm"
    },
    {
      "question": "What is logistic regression in machine learning with example",
      "answer": "Logistic regression is a statistical analysis method to predict a binary outcome such as yes or no based on prior observations of a data set Based on historical data about earlier outcomes involving the same input criteria it then scores new cases on their probability of falling into one of two outcome categories"
    },
    {
      "question": "Which function is used in logistic regression",
      "answer": "Logistic regression transforms its output using the logistic sigmoid function to return a probability value"
    },
    {
      "question": "What is McFadden pseudo R2",
      "answer": "denotes the corresponding value but for the null model the model with only an intercept and no covariates"
    },
    {
      "question": "Is Machine Learning just logistic regression",
      "answer": "Logistic regression and more generally GLM does NOT belong to Machine Learning Rather these methods belongs to parametric modeling Both parametric and algorithmic ML models use the data but in different ways"
    },
    {
      "question": "Which type of dataset is used for logistic regression",
      "answer": "Logistic regression is used for binary or multi class classification and the target variable always has to be categorical"
    },
    {
      "question": "What is logistic regression in simple terms",
      "answer": "Logistic regression is a statistical analysis method to predict a binary outcome such as yes or no based on prior observations of a data set A logistic regression model predicts a dependent data variable by analyzing the relationship between one or more existing independent variables"
    },
    {
      "question": "What is the advantage of logistic regression",
      "answer": "Logistic regression is easier to implement interpret and very efficient to train If the number of observations is lesser than the number of features Logistic Regression should not be used, otherwise it may lead to overfitting It makes no assumptions about distributions of classes in feature space"
    },
    {
      "question": "Why is DNN better than logistic regression",
      "answer": "A neural network is more complex than logistic regression In practice a neural network model for binary classification can be worse than a logistic regression model because neural networks are more difficult to train and are more prone to overfitting than logistic regression"
    },
    {
      "question": "Can logistic regression use for more than 2 classes",
      "answer": "logistic regression cannot be used for classification tasks that have more than two class labels so called multi class classification A logistic regression model that is adapted to learn and predict a multinomial probability distribution is referred to as Multinomial Logistic Regression"
    },
    {
      "question": "What is the difference between chi square and logistic regression",
      "answer": "With chi square contingency analysis the independent variable is dichotomous and the dependent variable is dichotomous Logistic regression is a more general analysis however because the independent variable i.e the predictor is not restricted to a dichotomous variable"
    },
    {
      "question": "How logistic regression is different from Perceptron",
      "answer": "Originally a perceptron was only referring to neural networks with a step function as the transfer function In that case of course the difference is that the logistic regression uses a logistic function and the perceptron uses a step function"
    },
    {
      "question": "What does P value mean in logistic regression",
      "answer": "The p value for each term tests the null hypothesis that the coefficient is equal to zero no effect"
    },
    {
      "question": "Is logistic regression A statistical test",
      "answer": "Logistic regression LR is a statistical method similar to linear regression since LR finds an equation that predicts an outcome for a binary variable Y from one or more response variables X"
    },
    {
      "question": "What is common to logistic regression perceptron and support vector machines",
      "answer": "The most common form of error for logistic regression perceptron and support vector models is mean squared error"
    },
    {
      "question": "What is output of logistic regression",
      "answer": "The output from the logistic regression analysis gives a p value of which is based on the Wald z score"
    },
    {
      "question": "How is logistic regression trained",
      "answer": "Logistic regression has two phases training we train the system specifically the weights w and b using stochastic gradient descent and the cross entropy loss"
    },
    {
      "question": "What is a good f value in regression",
      "answer": "An F statistic of at least 3.95 is needed to reject the null hypothesis at an alpha level of 0.1"
    },
    {
      "question": "Is logistic regression a hypothesis test",
      "answer": "Like other regression techniques logistic regression involves the use of two hypotheses"
    },
    {
      "question": "How do you conduct a logistic regression",
      "answer": "Lets start by defining the logistic regression cost function for the two points of interest y equal to 1 and y equal to 0 that is when the hypothesis function predicts Male or Female"
    },
    {
      "question": "What is the odds ratio in logistic regression",
      "answer": "Odds ratios are one of those concepts in statistics that are just really hard to wrap your head around For example, in logistic regression the odds ratio represents the constant effect of a predictor X on the likelihood that one outcome will occur"
    },
    {
      "question": "What are the limitations of logistic regression",
      "answer": "The major limitation of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables"
    },
    {
      "question": "What is difference between SVM and logistic regression",
      "answer": "SVM works well with unstructured and semi structured data like text and images while logistic regression works with already identified independent variables"
    },
    {
      "question": "Why logistic regression is very popular",
      "answer": "Logistic Regression is a popular algorithm as it converts the values of the log of odds which can range from  minus inf to plus inf to a range between 0 and 1 Since logistic functions output the probability of occurrence of an event they can be applied to many real life scenarios therefore these models are very popular"
    },
    {
      "question": "What is Anova table",
      "answer": "Analysis of Variance ANOVA is a statistical analysis to test the degree of differences between two or more groups of an experiment"
    },
    {
      "question": "What are odds and log odds",
      "answer": "Probability is the probability an event happens For example there might be an 80 percentage chance of rain today Odds more technically the odds of success is defined as probability of success or probability of failure Log odds is the logarithm of the odds"
    },
    {
      "question": "Is logistic regression a supervised machine learning algorithm",
      "answer": "True Logistic regression is a supervised learning algorithm because it uses true labels for training Supervised learning algorithm should have input variables x and an target variable Y when you train the model"
    },
    {
      "question": "How logistic regression is implemented",
      "answer": "Logistic Regression is a supervised learning algorithm that is used when the target variable is categorica"
    },
    {
      "question": "Do we need to scale data for logistic regression",
      "answer": "Summary We need to perform Feature Scaling when we are dealing with Gradient Descent Based algorithms Linear and Logistic Regression Neural Network and Distance based algorithms KNN K means SVM as these are very sensitive to the range of the data points"
    },
    {
      "question": "What are the parameters in logistic regression",
      "answer": "Parameter estimates also called coefficients are the log odds ratio associated with a one unit change of the predictor all other predictors being held constant The unknown model parameters are estimated using maximum likelihood estimation"
    },
    {
      "question": "What is MIN MAX scaling",
      "answer": "Variables that are measured at different scales do not contribute equally to the model fitting model learned function and might end up creating a bias Thus to deal with this potential problem feature wise normalization such as MinMax Scaling is usually used prior to model fitting"
    },
    {
      "question": "Should you standardize before regression",
      "answer": "In regression analysis you need to standardize the independent variables when your model contains polynomial terms to model curvature or interaction terms"
    },
    {
      "question": "What does logit stand for",
      "answer": "In 1944 Joseph Berkson used log of odds and called this function logit abbreviation for logistic unit following the analogy for probit"
    },
    {
      "question": "How can logistic regression improve accuracy",
      "answer": "One of the way to improve accuracy for logistic regression models is by optimising the prediction probability cutoff scores generated by your logit model"
    },
    {
      "question": "What is penalty in logistic regression",
      "answer": "Penalized logistic regression imposes a penalty to the logistic model for having too many variables"
    },
    {
      "question": "Why is z score normalized",
      "answer": "The z score enables a data administrator to compare two different scores that are from different normal distributions of the data"
    },
    {
      "question": "Should I scale target variable",
      "answer": "Yes you do need to scale the target variable I will quote this reference A target variable with a large spread of values in turn may result in large error gradient values causing weight values to change dramatically making the learning process unstable"
    },
    {
      "question": "Explain what you need to interpret and report to carry out  ordinal regression",
      "answer": "So more generally this indicates that a scores increase on an independent variable Theres an increased probability of falling at a higher level on the dependent"
    },
    {
      "question": "How to carry out ordinal regression using SPSS Statistics",
      "answer": "In SPSS Statistics an ordinal regression can be carried out using one of two procedures PLUM and GENLIN Whilst GENLIN has a number of advantages over PLUM including being easier and quicker to carry out it is only available if you have SPSS Statistics Advanced Module"
    },
    {
      "question": "How should be measured at the ordinal level",
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them"
    },
    {
      "question": "what if multicollinearity occurs in ordinal regression",
      "answer": "Multicollinearity occurs when you have two or more independent variables that are highly correlated with each other"
    },
    {
      "question": "how to use the OMS in ordinal regression",
      "answer": "The Output Management System OMS provides the ability to automatically write selected categories of output to different output files in different formats"
    },
    {
      "question": "what if PLUM procedure in ordinal regression",
      "answer": "Ordinal Regression allows you to model the dependence of a polytomous ordinal response on a set of predictors which can be factors or covariates The design of Ordinal Regression is based on the methodology of McCullagh 1980 1998 and the procedure is referred to as PLUM in the syntax"
    },
    {
      "question": "what is parameter estimates tables information in ordinal regression",
      "answer": "The Parameter estimates table is the core of the output telling us specifically about the relationship between our explanatory variables and the outcome"
    }
  ]
}