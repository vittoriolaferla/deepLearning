	input_text	target_text	indexes
4613	Bayesian learning uses Bayes' theorem to determine the conditional probability of a hypotheses given some evidence or observations.	What is Bayesian learning in machine learning	4613
7729	Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable.	What does linear regression tell you	7729
4991	Mentor: Well, if the line is a good fit for the data then the residual plot will be random. However, if the line is a bad fit for the data then the plot of the residuals will have a pattern.	How do you know if a residual plot is good	4991
7577	"Build the model on the training set and then use the test set as a holdout sample to test your trained model using the test data. Compare the predicted values with the actual values by calculating the error using measures such as the ""Mean Absolute Percent Error"" (MAPE) for example."	How can you tell if the predictive model is accurate	7577
9601	The Implicit Association Test (IAT) measures the strength of associations between concepts (e.g., black people, gay people) and evaluations (e.g., good, bad) or stereotypes (e.g., athletic, clumsy). The main idea is that making a response is easier when closely related items share the same response key.	How does the implicit bias test work	9601
5533	The key to interpreting a hierarchical cluster analysis is to look at the point at which any given pair of cards “join together” in the tree diagram. Cards that join together sooner are more similar to each other than those that join together later.	How do you interpret a hierarchical cluster analysis	5533
100	Most data can be categorized into 4 basic types from a Machine Learning perspective: numerical data, categorical data, time-series data, and text.	What are the different types of data sets used in ML	100
9534	Two types of statistical methods are used in analyzing data: descriptive statistics and inferential statistics. Descriptive statistics are used to synopsize data from a sample exercising the mean or standard deviation. Inferential statistics are used when data is viewed as a subclass of a specific population.	What are the different types of statistics used in research	9534
8577	A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem. — Practical recommendations for gradient-based training of deep architectures, 2012.	What should be the learning rate	8577
1507	Key Differences between AI, ML, and NLP ML is an application of AI. Machine Learning is basically the ability of a system to learn by itself without being explicitly programmed. Deep Learning is a part of Machine Learning which is applied to larger data-sets and based on ANN (Artificial Neural Networks).	What is the difference between AI machine learning NLP and deep learning	1507
2675	The relative frequencies add up to 1.	Aside in a relative frequency distribution what should the relative frequencies add up to	2675
5981	Quartiles let us quickly divide a set of data into four groups, making it easy to see which of the four groups a particular data point is in. For example, a professor has graded an exam from 0-100 points.	How are quartiles used in real life	5981
2577	The exponential distribution is a continuous probability distribution used to model the time we need to wait before a given event occurs. It is the continuous counterpart of the geometric distribution, which is instead discrete.	Why do we use exponential distribution	2577
5413	Hyperparameter optimization is a big part of deep learning. The reason is that neural networks are notoriously difficult to configure and there are a lot of parameters that need to be set. On top of that, individual models can be very slow to train.	Why do we need to do Hyperparameter tuning in neural networks	5413
9591	A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.  The rows represent the predicted values of the target variable.	What is confusion matrix in machine learning	9591
1585	A learning algorithm is a method used to process data to extract patterns appropriate for application in a new situation. In particular, the goal is to adapt a system to a specific input-output transformation task.	What is a learning algorithm	1585
8021	Basically, the test compares the fit of two models. The null hypothesis is that the smaller model is the “best” model; It is rejected when the test statistic is large. In other words, if the null hypothesis is rejected, then the larger model is a significant improvement over the smaller one.	What is the null hypothesis for likelihood ratio test	8021
6061	In computational linguistics, second-order co-occurrence pointwise mutual information is a semantic similarity measure. To assess the degree of association between two given words, it uses pointwise mutual information (PMI) to sort lists of important neighbor words of the two target words from a large corpus.	How does second order pointwise mutual information information retrieval work	6061
1732	In cryptography, padding is any of a number of distinct practices which all include adding data to the beginning, middle, or end of a message prior to encryption.	What is padding in encryption	1732
3799	Matrix factorization using the alternating least squares algorithm for collaborative filtering. Alternating least squares (ALS) is an optimization technique to solve the matrix factorization problem. This technique achieves good performance and has proven relatively easy to implement.	What is the significance of alternating least squares in collaborative filtering	3799
9617	"Predictive modeling is the process of using known results to create, process, and validate a model that can be used to forecast future outcomes. It is a tool used in predictive analytics, a data mining technique that attempts to answer the question ""what might possibly happen in the future?"""	How does predictive modeling work	9617
5990	So the probability that the sample mean will be >22 is the probability that Z is > 1.6 We use the Z table to determine this: P( > 22) = P(Z > 1.6) = 0.0548.	How do you find the probability of a sample mean	5990
9265	The gradients carry information used in the RNN parameter update and when the gradient becomes smaller and smaller, the parameter updates become insignificant which means no real learning is done. Let's have a short reminder of how RNNs look like.	What is gradient RNN	9265
221	The probability that a random variable X X X takes a value in the (open or closed) interval [ a , b ] [a,b] [a,b] is given by the integral of a function called the probability density function f X ( x ) f_X(x) fX​(x): P ( a ≤ X ≤ b ) = ∫ a b f X ( x ) d x .	How do you find the probability density function of a random variable	221
4594	1:2611:18Suggested clip · 118 secondsMultiple Logistic Regression in SPSS - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you do a multiple logistic regression in SPSS	4594
5887	In short, it ensures each subgroup within the population receives proper representation within the sample. As a result, stratified random sampling provides better coverage of the population since the researchers have control over the subgroups to ensure all of them are represented in the sampling.	Why is stratified sampling used	5887
5844	How to Use GA for Optimization Problems?Generate the initial population randomly.Select the initial solution with the best fitness values.Recombine the selected solutions using mutation and crossover operators.Insert offspring into the population.More items	How is genetic algorithm used in neural networks	5844
4025	Correlation analysis explores the association between two or more variables and makes inferences about the strength of the relationship.  Technically, association refers to any relationship between two variables, whereas correlation is often used to refer only to a linear relationship between two variables.	What is Association and correlation in data mining	4025
601	Under the batch processing model, a set of data is collected over time, then fed into an analytics system. In other words, you collect a batch of information, then send it in for processing. Under the streaming model, data is fed into analytics tools piece-by-piece. The processing is usually done in real time.	What are the differences between batch processing and stream processing systems	601
5060	"In systematic sampling, the list of elements is ""counted off"". That is, every kth element is taken.  Stratified sampling also divides the population into groups called strata. However, this time it is by some characteristic, not geographically."	What is the difference between stratified sampling and systematic sampling	5060
10467	Vector autoregression (VAR) is a statistical model used to capture the relationship between multiple quantities as they change over time.  VAR models generalize the single-variable (univariate) autoregressive model by allowing for multivariate time series. VAR models are often used in economics and the natural sciences.	What is VAR model in econometrics	10467
6451	Topic modelling refers to the task of identifying topics that best describes a set of documents.  And the goal of LDA is to map all the documents to the topics in a way, such that the words in each document are mostly captured by those imaginary topics.	How does LDA topic modeling work	6451
1565	Deep learning (sometimes known as deep structured learning) is a subset of machine learning, where machines employ artificial neural networks to process information. Inspired by biological nodes in the human body, deep learning helps computers to quickly recognize and process images and speech.	What is deep learning and how is it useful	1565
7633	Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.	What is the use of gradient descent in machine learning	7633
9345	A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.	What is ResNet in deep learning	9345
9802	7 Answers. Gradient is covariant!  The components of a vector contravariant because they transform in the inverse (i.e. contra) way of the vector basis. It is customary to denote these components with an upper index.	Why is gradient covariant	9802
4670	OCR converts images of typed or handwritten text into machine-encoded text. The major steps in image recognition process are gather and organize data, build a predictive model and use it to recognize images.	How does image recognition AI work	4670
8169	more  A symbol for a value we don't know yet. It is usually a letter like x or y. Example: in x + 2 = 6, x is the variable.	What is variable and example	8169
4481	The general algorithm is The Backpropagation algorithm is suitable for the feed forward neural network on fixed sized input-output pairs. The Backpropagation Through Time is the application of Backpropagation training algorithm which is applied to the sequence data like the time series.	What is the difference between backpropagation algorithm and Backpropagation through time Bptt algorithm	4481
10327	The range is influenced too much by extreme values.	Which difficulty of range as a measure of variability is overcome by interquartile range	10327
2536	Stochastic processes appear in many different fields, including the physical sciences such as biology, chemistry, ecology, neuroscience, and physics as well as technology and engineering fields such as image processing, signal processing, information theory, computer science,, cryptography and telecommunications.	Where is stochastic processes used	2536
10842	Define Population Distribution; and sketch a graph: The population distribution gives the values of the variable for all the individuals in the population.  The sampling distribution shows the statistic values from all the possible samples of the same size from the population. It is a distribution of the statistic.	What is the difference between a sampling distribution and a population distribution	10842
3538	Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.  But if we instead take steps proportional to the positive of the gradient, we approach a local maximum of that function; the procedure is then known as gradient ascent.	Is gradient descent an optimization algorithm	3538
8926	Iterable is an object, which one can iterate over. It generates an Iterator when passed to iter() method. Iterator is an object, which is used to iterate over an iterable object using __next__() method.  Note that every iterator is also an iterable, but not every iterable is an iterator.	What are iterators and Iterables in Python	8926
8782	Gibbs Sampling is based on sampling from condi- tional distributions of the variables of the posterior.  For LDA, we are interested in the latent document-topic portions θd, the topic-word distributions φ(z), and the topic index assignments for each word zi.	What is Gibbs sampling in LDA	8782
10222	This cross-sectional sample provides us with a snapshot of that population, at that one point in time.  Panel data differs from pooled cross-sectional data across time, because it deals with the observations on the same subjects in different times whereas the latter observes different subjects in different time periods.	What is the difference between cross sectional data and panel data	10222
6204	Popular algorithms that can be used for binary classification include:Logistic Regression.k-Nearest Neighbors.Decision Trees.Support Vector Machine.Naive Bayes.	Which algorithms are used to do a binary classification	6204
3497	Textual entailment (TE) in natural language processing is a directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. In the TE framework, the entailing and entailed texts are termed text (t) and hypothesis (h), respectively.	How can you explain the concept of Recognizing Textual Entailment in NLP	3497
1794	An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled.	What is the purpose of an F test	1794
3977	Example: One nanogram of Plutonium-239 will have an average of 2.3 radioactive decays per second, and the number of decays will follow a Poisson distribution.	What is the real life example of Poisson distribution	3977
2551	Dimensionality Reduction and PCA. Dimensionality reduction refers to reducing the number of input variables for a dataset. If your data is represented using rows and columns, such as in a spreadsheet, then the input variables are the columns that are fed as input to a model to predict the target variable.	What is PCA dimensionality reduction	2551
4030	While a P value can inform the reader whether an effect exists, the P value will not reveal the size of the effect. In reporting and interpreting studies, both the substantive significance (effect size) and statistical significance (P value) are essential results to be reported.	Is AP value an effect size	4030
9294	In probability theory, an event is an outcome or defined collection of outcomes of a random experiment. Since the collection of all possible outcomes to a random experiment is called the sample space, another definiton of event is any subset of a sample space.	What is the definition of an event in statistics	9294
4005	Linear filters process time-varying input signals to produce output signals, subject to the constraint of linearity.  Since linear time-invariant filters can be completely characterized by their response to sinusoids of different frequencies (their frequency response), they are sometimes known as frequency filters.	What makes a filter linear	4005
10629	Stationarity. A common assumption in many time series techniques is that the data are stationary. A stationary process has the property that the mean, variance and autocorrelation structure do not change over time.	What is stationarity in time series analysis	10629
1114	The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population. In the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.	What does the law of large numbers say	1114
10921	The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes. The ID3 algorithm builds decision trees using a top-down greedy search approach through the space of possible branches with no backtracking.	Which method is used in decision tree algorithm	10921
3469	A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”. A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes.	What are classification problems in machine learning	3469
4627	To review, the Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.	Which of the following gates in Lstm decides on keeping relevant features from the current input	4627
4531	A mean can be determined for grouped data, or data that is placed in intervals.  The sum of the products divided by the total number of values will be the value of the mean.	What is the mean for grouped data	4531
3592	Recurrent Neural Networks (RNNs) are a form of machine learning algorithm that are ideal for sequential data such as text, time series, financial data, speech, audio, video among others.	Does recurrent neural networks are best suited for text processing	3592
6265	Robust regression is an alternative to least squares regression when data is contaminated with outliers or influential observations and it can also be used for the purpose of detecting influential observations. Please note: The purpose of this page is to show how to use various data analysis commands.	When should I use robust regression	9231
8188	Meta-learning, also known as “learning to learn”, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples.  Humans, in contrast, learn new concepts and skills much faster and more efficiently.	How does meta learning work	8188
9573	Inductive Learning is where we are given examples of a function in the form of data (x) and the output of the function (f(x)). The goal of inductive learning is to learn the function for new data (x). Classification: when the function being learned is discrete. Regression: when the function being learned is continuous.	What is inductive learning in machine learning	9573
1454	An activation function is defined by and defines the output of a neuron in terms of its input (aka induced local field) . There are three types of activation functions. Threshhold function an example of which is. This function is also termed the Heaviside function. Piecewise Linear.	What is activation function and its types	1454
51	How to Detect Omitted Variable Bias and Identify Confounding Variables. You saw one method of detecting omitted variable bias in this post. If you include different combinations of independent variables in the model, and you see the coefficients changing, you're watching omitted variable bias in action!	How do you identify omitted variable bias	51
1682	It can be seen that the function of the loss of quality is a U-shaped curve, which is determined by the following simple quadratic function: L(x)= Quality loss function. x = Value of the quality characteristic (observed). N = Nominal value of the quality characteristic (Target value – target).	How is the target value of a Taguchi loss function identified	1682
1971	Anything central is in the middle of something — or essential to it. Central things are fundamental and important. Think about the center of a circle: it's right in the middle, equidistant from all sides. Similarly, anything central is in the middle of something.	What does the word central mean	1971
3069	In contrast to the non-stationary process that has a variable variance and a mean that does not remain near, or returns to a long-run mean over time, the stationary process reverts around a constant long-term mean and has a constant variance independent of time.	What is the difference between stationary and non stationary time series	3069
9889	The Google Goggles app is an image-recognition mobile app that uses visual search technology to identify objects through a mobile device's camera. Users can take a photo of a physical object, and Google searches and retrieves information about the image.	How can I identify an object in a picture	9889
4343	"The kurtosis of any univariate normal distribution is 3. It is common to compare the kurtosis of a distribution to this value. Distributions with kurtosis less than 3 are said to be platykurtic, although this does not imply the distribution is ""flat-topped"" as is sometimes stated."	What is the kurtosis of a normal distribution	4343
541	Rule-based systems process data and output information, but they also process rules and make decisions.  Knowledge-based systems also process data and rules to output information and make decisions. In addition, they also process expert knowledge to output answers, recommendations, and expert advice.	What is the difference between a rule based system and a knowledge based system	541
101	It's a method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.	What is loss function in machine learning	101
5132	How to train your Deep Neural NetworkTraining data.  Choose appropriate activation functions.  Number of Hidden Units and Layers.  Weight Initialization.  Learning Rates.  Hyperparameter Tuning: Shun Grid Search - Embrace Random Search.  Learning Methods.  Keep dimensions of weights in the exponential power of 2.More items•	How do I train deep neural networks	5132
10452	Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable. Feature selection is primarily focused on removing non-informative or redundant predictors from the model.	What are feature selection techniques in machine learning	10452
3102	In Regression Clustering (RC), K (>1) regression functions are applied to the dataset simultaneously which guide the clustering of the dataset into K subsets each with a simpler distribution matching its guiding function. Each function is regressed on its own subset of data with a much smaller residue error.	What is clustering in regression	3102
5611	17. Deep Convolutional Network (DCN): Convolutional Neural Networks are neural networks used primarily for classification of images, clustering of images and object recognition.	What is neural network classification	5611
3149	The function scipy. linalg. eig computes eigenvalues and eigenvectors of a square matrix .	What is the function to get both eigenvalues and eigenvectors of a matrix	3149
2770	The confidence of an association rule is a percentage value that shows how frequently the rule head occurs among all the groups containing the rule body.  Thus, the confidence of a rule is the percentage equivalent of m/n, where the values are: m. The number of groups containing the joined rule head and rule body.	What is confidence in association rule	2770
3449	A simple random sample is used to represent the entire data population and. randomly selects individuals from the population without any other consideration. A stratified random sample, on the other hand, first divides the population into smaller groups, or strata, based on shared characteristics.	What is the difference between random sampling and stratified sampling	3449
9393	Parametric tests assume a normal distribution of values, or a “bell-shaped curve.” For example, height is roughly a normal distribution in that if you were to graph height from a group of people, one would see a typical bell-shaped curve.	What is an example of parametric statistics	9393
5013	Overfitting can be identified by checking validation metrics such as accuracy and loss. The validation metrics usually increase until a point where they stagnate or start declining when the model is affected by overfitting.	How do we know whether a model is overfitting	5013
8113	Morpheus: If real is what you can feel, smell, taste and see, then 'real' is simply electrical signals interpreted by your brain.	What is the Matrix Morpheus quote	8113
8752	A squashing function is essentially defined as a function that squashes the input to one of the ends of a small interval. In Neural Networks, these can be used at nodes in a hidden layer to squash the input. This introduces non-linearity to the NN and allows the NN to be effective.	Why squashing function is important in neural network	8752
5211	Definition 1. A statistic d is called an unbiased estimator for a function of the parameter g(θ) provided that for every choice of θ, Eθd(X) = g(θ). Any estimator that not unbiased is called biased.  Note that the mean square error for an unbiased estimator is its variance.	What is an unbiased estimator of variance	5211
7300	Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. That is, data sets with high kurtosis tend to have heavy tails, or outliers. Data sets with low kurtosis tend to have light tails, or lack of outliers. A uniform distribution would be the extreme case.	What does kurtosis indicate	7300
4668	In neural networks, a hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output. In short, the hidden layers perform nonlinear transformations of the inputs entered into the network.	What is the purpose of hidden layer in neural network	4668
5527	AI means getting a computer to mimic human behavior in some way.  Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems.	How are the terms artificial intelligence machine learning and deep learning related	5527
7939	Loss is the penalty for a bad prediction. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater.	What is the loss in machine learning	7939
8668	Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.	How can algorithms be biased	8668
9004	Description. VGG-19 is a convolutional neural network that is 19 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database [1]. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals.	What is Vgg in deep learning	9004
10687	The SD is usually more useful to describe the variability of the data while the variance is usually much more useful mathematically. For example, the sum of uncorrelated distributions (random variables) also has a variance that is the sum of the variances of those distributions.	Which is better variance or standard deviation	10687
1828	K-fold cross-validationRandomly split the data set into k-subsets (or k-fold) (for example 5 subsets)Reserve one subset and train the model on all other subsets.Test the model on the reserved subset and record the prediction error.Repeat this process until each of the k subsets has served as the test set.More items•	How do you do k fold cross validation in R	1828
2888	- YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the median for continuous data	2888
8428	How to calculate percentileRank the values in the data set in order from smallest to largest.Multiply k (percent) by n (total number of values in the data set).  If the index is not a round number, round it up (or down, if it's closer to the lower number) to the nearest whole number.Use your ranked data set to find your percentile.	How is percentile calculated	8428
4210	The general linear model requires that the response variable follows the normal distribution whilst the generalized linear model is an extension of the general linear model that allows the specification of models whose response variable follows different distributions.	What is the difference between linear model and generalized linear model	4210
5553	If there are c or less defective items in the sample, the lot is accepted. If there are more than c defective items in the sample, the lot is rejected. In other words, the acceptance or rejection of the lot depends on the inspection results of a single sample.	Under what conditions is lot for lot acceptance sampling not accepted	5553
10703	The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.	How does neural network determine the number of hidden layers	10703
10726	Gaussian processes are useful in statistical modelling, benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly.	What are Gaussian processes used for	10726
6954	August 2017) (Learn how and when to remove this template message) In natural language processing, the latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.	What is Latent Dirichlet Allocation in machine learning	6954
8269	Six quick tips to improve your regression modelingA.1. Fit many models.  A.2. Do a little work to make your computations faster and more reliable.  A.3. Graphing the relevant and not the irrelevant.  A.4. Transformations.  A.5. Consider all coefficients as potentially varying.  A.6. Estimate causal inferences in a targeted way, not as a byproduct of a large regression.	How can statistical models be improved	8269
332	The Binomial Theorem is a quick way (okay, it's a less slow way) of expanding (or multiplying out) a binomial expression that has been raised to some (generally inconveniently large) power. For instance, the expression (3x – 2)10 would be very painful to multiply out by hand.	How do you use the binomial theorem	332
4145	Use of AI in Following Things/Fields/Areas:Virtual Assistant or Chatbots.Agriculture and Farming.Autonomous Flying.Retail, Shopping and Fashion.Security and Surveillance.Sports Analytics and Activities.Manufacturing and Production.Live Stock and Inventory Management.More items•	Where is artificial intelligence used	4145
3340	In statistics, the t-statistic is the ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.  For example, the T-statistic is used in estimating the population mean from a sampling distribution of sample means if the population standard deviation is unknown.	What does the t statistic mean	3340
2054	To solve the problem using logistic regression we take two parameters w, which is n dimensional vector and b which is a real number. The logistic regression model to solve this is : Equation for Logistic Regression. We apply sigmoid function so that we contain the result of ŷ between 0 and 1 (probability value).	What is W and B in logistic regression	2054
9305	1.1 The Role of Logic in Artificial Intelligence Logic, for instance, can provide a specification for a programming language by characterizing a mapping from programs to the computations that they license.	What is the role of logic in artificial intelligence	9305
5116	Every probability pi is a number between 0 and 1, and the sum of all the probabilities is equal to 1. Examples of discrete random variables include: The number of eggs that a hen lays in a given day (it can't be 2.3) The number of people going to a given soccer match.	What is a discrete random variable What are some examples	5116
3077	The mean is also to the left of the peak. A right-skewed distribution has a long right tail.  Next, you'll see a fair amount of negatively skewed distributions. For example, household income in the U.S. is negatively skewed with a very long left tail.	What is an example of skewed data	3077
6434	A linear threshold unit is a simple artificial neuron whose output is its thresholded total net input. That is, an LTU with threshold T calculates the weighted sum of its inputs, and then outputs 0 if this sum is less than T, and 1 if the sum is greater than T.	What is linear threshold unit	6434
7641	The Pearson's correlation coefficient is calculated as the covariance of the two variables divided by the product of the standard deviation of each data sample. It is the normalization of the covariance between the two variables to give an interpretable score.	How do you find the correlation between many variables	7641
1398	Among the learning algorithms, one of the most popular and easiest to understand is the decision tree induction. The popularity of this method is related to three nice characteristics: interpretability, efficiency, and flexibility. Decision tree can be used for both classification and regression kind of problem.	What are the important characteristics of decision tree induction algorithm	1398
3915	RBMs were invented by Geoffrey Hinton and can be used for dimensionality reduction, classification, regression, collaborative filtering, feature learning, and topic modeling. RBMs are a special class of Boltzmann Machines and they are restricted in terms of the connections between the visible and the hidden units.	What are restricted Boltzmann machines used for	3915
10985	In the context of neural networks, a perceptron is an artificial neuron using the Heaviside step function as the activation function. The perceptron algorithm is also termed the single-layer perceptron, to distinguish it from a multilayer perceptron, which is a misnomer for a more complicated neural network.	What is Perceptron in neural network	10985
2082	Image processing is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.	What do you mean by image processing	2082
9650	Regression analysis is a powerful statistical method that allows you to examine the relationship between two or more variables of interest. While there are many types of regression analysis, at their core they all examine the influence of one or more independent variables on a dependent variable.	What is regression effect in data collection	9650
9890	You description is confusing, but it is totally possible to have test error both lower and higher than training error. A lower training error is expected when a method easily overfits to the training data, yet, poorly generalizes.	Is it possible to have a higher train error than a test error in machine learning	9890
6898	Aspin-Welch t-test	What test should you use to determine the equality of the two sample means when the population standard deviation is unknown	6898
5147	Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay.  It is often used in signal processing for analyzing functions or series of values, such as time domain signals.	What is autocorrelation in signal and system	5147
10283	Variance (σ2) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.	How do you explain variance	10283
286	There are 3 main ways of describing the intensity of an activity – vigorous, moderate, and gentle. Vigorous activities tend to make you “huff and puff”.	How do you describe your activity level	286
10832	If X and Y are normed vector spaces (a special type of TVS), then L is bounded if and only if there exists some M ≥ 0 such that for all x in X, ||Lx||Y ≤ M ||x||X. The smallest such M, denoted by ||L||, is called the operator norm of L.	How do you show an operator is bounded	10832
6306	"A bell curve is a common type of distribution for a variable, also known as the normal distribution. The term ""bell curve"" originates from the fact that the graph used to depict a normal distribution consists of a symmetrical bell-shaped curve."	What is the distribution of a bell curve	6306
5755	The terms cost and loss functions almost refer to the same meaning. But, loss function mainly applies for a single training set as compared to the cost function which deals with a penalty for a number of training sets or the complete batch.  The cost function is calculated as an average of loss functions.	What is the difference between a cost function and a loss function in machine learning	5755
1831	Max pooling is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.	What is the purpose of Max pooling	1831
7727	Properties. Unlike the classical conditional entropy, the conditional quantum entropy can be negative.  Positive conditional entropy of a state thus means the state cannot reach even the classical limit, while the negative conditional entropy provides for additional information.	Can conditional entropy negative	7727
4433	A quartile is a statistical term that describes a division of observations into four defined intervals based on the values of the data and how they compare to the entire set of observations.	What is the definition of quartile in statistics	4433
10280	The nominator is the joint probability and the denominator is the probability of the given outcome.  This is the conditional probability: P(A∣B)=P(A∩B)P(B) This is the Bayes' rule: P(A∣B)=P(B|A)∗P(A)P(B).	What is the difference between conditional probability and Bayes Theorem	10280
10160	The mean (average) of a data set is found by adding all numbers in the data set and then dividing by the number of values in the set. The median is the middle value when a data set is ordered from least to greatest. The mode is the number that occurs most often in a data set.	What is the mean value in statistics	10160
1822	Word embeddings are created using a neural network with one input layer, one hidden layer and one output layer. The computer does not understand that the words king, prince and man are closer together in a semantic sense than the words queen, princess, and daughter. All it sees are encoded characters to binary.	How are word Embeddings generated	1822
2964	These are the steps we are going to do:Make a stupid model as an example, train and store it.Fetch the variables you need from your stored model.Build the tensor info from them.Create the model signature.Create and save a model builder.Download a Docker image with TensorFlow serving already compile on it.More items•	How do you deploy TensorFlow in production	2964
3702	Face recognition systems use computer algorithms to pick out specific, distinctive details about a person's face. These details, such as distance between the eyes or shape of the chin, are then converted into a mathematical representation and compared to data on other faces collected in a face recognition database.	How does the facial recognition technology work	3702
5005	Logarithmic scales reduce wide-ranging quantities to tiny scopes. For example, the decibel (dB) is a unit used to express ratio as logarithms, mostly for signal power and amplitude (of which sound pressure is a common example). In chemistry, pH is a logarithmic measure for the acidity of an aqueous solution.	What are logarithms used for	5005
8289	While the previous study (Wu et al., 2015) suggests that ingroup derogation is a specialized mechanism which disregards explicit disease-relevant information mediated by outgroup members, a different pattern was observed in Experiment 2.	What is ingroup derogation	8289
8622	2:1422:33Suggested clip · 114 secondsRegression Trees, Clearly Explained!!! - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you interpret a regression tree	8622
3476	Definition. A study design that randomly assigns participants into an experimental group or a control group. As the study is conducted, the only expected difference between the control and experimental groups in a randomized controlled trial (RCT) is the outcome variable being studied.	Is a randomized controlled trial an experimental design	3476
3969	P ∧ Q means P and Q. P ∨ Q means P or Q. An argument is valid if the following conditional holds: If all the premises are true, the conclusion must be true.  So, when you attempt to write a valid argument, you should try to write out what the logical structure of the argument is by symbolizing it.	What does P ∧ Q mean	3969
9933	Regularization is a set of techniques that can prevent overfitting in neural networks and thus improve the accuracy of a Deep Learning model when facing completely new data from the problem domain.	What is regularization in deep learning	9933
9538	The 'd' means a Δ in the limit approaching zero. Basically the slope is approximately Δy/Δx but if you let Δx approach zero, you reach the exactly slope which is then dy/dx.	What does the D stand for in differentiation	9538
2009	A statistical hypothesis is an explanation about the relationship between data populations that is interpreted probabilistically.  A machine learning hypothesis is a candidate model that approximates a target function for mapping inputs to outputs.	What is specific hypothesis in machine learning	2009
1229	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.	What is bootstrap in machine learning	5158
3895	Moments About the MeanFirst, calculate the mean of the values.Next, subtract this mean from each value.Then raise each of these differences to the sth power.Now add the numbers from step #3 together.Finally, divide this sum by the number of values we started with.	How do you calculate moments in statistics	3895
1699	Covariance indicates the relationship of two variables whenever one variable changes. If an increase in one variable results in an increase in the other variable, both variables are said to have a positive covariance.  Both variables move together in the same direction when they change.	What does Covariance indicate	1699
4803	Clustering is considered unsupervised learning, because there's no labeled target variable in clustering. Clustering algorithms try to, well, cluster data points into similar groups (or… clusters) based on different characteristics of the data.	Is clustering supervised or unsupervised How do you classify it	4803
2833	As in classification, support vector regression (SVR) is characterized by the use of kernels, sparse solution, and VC control of the margin and the number of support vectors. Although less popular than SVM, SVR has been proven to be an effective tool in real-value function estimation.	What is SVR regression	2833
2850	The linear Discriminant analysis estimates the probability that a new set of inputs belongs to every class.  LDA uses Bayes' Theorem to estimate the probabilities. If the output class is (k) and the input is (x), here is how Bayes' theorem works to estimate the probability that the data belongs to each class.	How does linear discriminant analysis work	2850
7002	In neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from every element of the previous layer. In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer.	What is the difference between a neural network and a convolutional network	7002
6595	A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function. SLP is the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target (1 , 0).	What is a single layer Perceptron	6595
831	Multicollinearity occurs when independent variables in a regression model are correlated. This correlation is a problem because independent variables should be independent. If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.	Why is Multicollinearity a problem in linear regression select the correct option	831
9481	Question: 1. When A Value Of Y Is Calculated Using The Regression Equation (Y_hat), It Is Called: -the Fitted Value -the Estimated Value -the Predicted Value -all Of The Above 2.	When a value of y is calculated using the regression equation it is called	9481
7374	The fact is almost all big data sets, generated by systems powered by ML/AI based models, are known to be biased. However, most ML modelers are not aware of these biases and even if they are, they do not know what to do about it.  Most (almost all) big datasets generated by ML powered systems are biased.	Is all data biased	7374
105	Q-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It's considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn't needed.	How does Q learning work	105
6481	Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement.	How do you interpret Cohen's kappa	6481
6262	Accuracy is well defined for any number of classes, so if you use this, a single plot should suffice. Precision and recall, however, are defined only for binary problems.	How many learning curves should I plot for a multi class logistic regression classifier	6262
834	In order to calculate the sample size needed for your survey or experiment, you will need to follow these steps: Determine the total population size.Complete the calculation.Determine the total population size.  Decide on a margin of error.  Choose a confidence level.  Pick a standard of deviation.  Complete the calculation.	How do you calculate sample size needed	834
238	The main advantage of CNN compared to its predecessors is that it automatically detects the important features without any human supervision. For example, given many pictures of cats and dogs, it can learn the key features for each class by itself.	What is the advantage of CNN	238
928	When you reject the null hypothesis with a t-test, you are saying that the means are statistically different. The difference is meaningful. Chi Square:  When you reject the null hypothesis with a Chi-Square, you are saying that there is a relationship between the two variables.	What is the difference between at test and a chi square	928
7416	Classification SVM Type 1 (also known as C-SVM classification); Classification SVM Type 2 (also known as nu-SVM classification); Regression SVM Type 1 (also known as epsilon-SVM regression); Regression SVM Type 2 (also known as nu-SVM regression).	What are the two classification methods that SVM can handle	7416
10165	For values of x > 0, the gamma function is defined using an integral formula as Γ(x) = Integral on the interval [0, ∞ ] of ∫ 0∞t x −1 e−t dt. The probability density function for the gamma distribution is given by. The mean of the gamma distribution is αβ and the variance (square of the standard deviation) is αβ2.	What is the mean of gamma distribution	10165
6812	The most effective tool found for the task for image recognition is a deep neural network, specifically a Convolutional Neural Network (CNN).	Which algorithm is best for image processing	6812
3113	A Sampling unit is one of the units selected for the purpose of sampling. Each unit being regarded as individual and indivisible when the selection is made. CONTEXT: Many times the Sampling frame and the Sampling unit are derived from Administrative data.	What is sampling unit and sampling frame	3113
9618	Probability limits are used when the parameter is considered as the realization of a random variable with given prior distribution.	What is a probability limit	9618
2243	Naive Bayes algorithm works on Bayes theorem and takes a probabilistic approach, unlike other classification algorithms. The algorithm has a set of prior probabilities for each class. Once data is fed, the algorithm updates these probabilities to form something known as posterior probability.	Which algorithm is used in artificial intelligence	2243
625	The general application of the matrix norm is the derivative form of finding proof in terms of interplay and tandem of vectorial normalized formats to whom are extended.. It can be used in tandem with Graphical processing, image processing, all kinds of algorithmics in terms of calculations and derivatives..	What is the application of matrix norm	625
10192	Software Testing MethodologiesFunctional vs. Non-functional Testing.  Unit Testing. Unit testing is the first level of testing and is often performed by the developers themselves.  Integration Testing.  System Testing.  Acceptance Testing.  Performance Testing.  Security Testing.  Usability Testing.More items	What are different testing techniques	10192
8163	A machine learning task is the type of prediction or inference being made, based on the problem or question that is being asked, and the available data. For example, the classification task assigns data to categories, and the clustering task groups data according to similarity.	What are the tasks in machine learning	8163
8890	The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting). The variance is an error from sensitivity to small fluctuations in the training set.	What is bias in machine learning algorithms	8890
1231	hamming distance	Which distance metric do we use in Knn for categorical variables	1231
1298	"The modern mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the ""problem of points"")."	Who developed the theory of probability	1298
8430	. Thus logit regression is simply the GLM when describing it in terms of its link function, and logistic regression describes the GLM in terms of its activation function.	Whats the difference between logit and logistic regression 1	8430
10810	A boxplot is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”).  It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.	What do box plots tell you	10810
4993	: one half of the difference obtained by subtracting the first quartile from the third quartile in a frequency distribution.	What is quartile deviation	4993
4043	A conditional probability estimate is a probability estimate that we make given or assuming the occurrence of some other event. In this case we might start with an estimate that the probability of rain is 30% and then make a conditional probability estimate that the probability of rain given a cloudy sky is 65%.	Is a conditional probability estimate	4043
10300	Accuracy is the percentage of correctly classifies instances out of all instances.  Kappa or Cohen's Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset.	What is accuracy and Kappa	10300
3987	Hyperparameter optimization in machine learning intends to find the hyperparameters of a given machine learning algorithm that deliver the best performance as measured on a validation set. Hyperparameters, in contrast to model parameters, are set by the machine learning engineer before training.	What is Hyperparameter optimization in deep learning	3987
4556	Standard deviation looks at how spread out a group of numbers is from the mean, by looking at the square root of the variance. The variance measures the average degree to which each point differs from the mean—the average of all data points.	Why do we use standard deviation over variance	4556
9767	Nonparametric tests have the following limitations: Nonparametric tests are usually less powerful than corresponding parametric test when the normality assumption holds. Thus, you are less likely to reject the null hypothesis when it is false if the data comes from the normal distribution.	What are the main limitations of non parametric test	9767
6320	Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.	How do you explain logistic regression model	6320
6937	You can tell if two random variables are independent by looking at their individual probabilities. If those probabilities don't change when the events meet, then those variables are independent. Another way of saying this is that if the two variables are correlated, then they are not independent.	How do you prove a random variable is independent	6937
3037	"To recap the differences between the two: Machine learning uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned. Deep learning structures algorithms in layers to create an ""artificial neural network” that can learn and make intelligent decisions on its own."	What is the relationship between machine learning and deep learning	3037
10286	Mean of General discrete uniform distribution The expected value of discrete uniform random variable is E ( X ) = a + b 2 .	What are the expected moments of a uniform discrete distribution	10286
54	Moments help in finding AM, standard deviation and variance of the population directly, and they help in knowing the graphic shapes of the population. We can call moments as the constants used in finding the graphic shape, as the graphic shape of the population also help a lot in characterizing a population.	What is the use of moments in statistics	54
7768	Ensemble methods are learning models that achieve performance by combining the opinions of multiple learners.  Ensemble methods are learning models that achieve performance by combining the opinions of multiple learners.	How do ensemble methods work and why are they superior to individual models	7768
1352	Markov Chain Monte Carlo (MCMC) methods are a class of algorithms for sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution.	How does MCMC sampling work	1352
10959	Artificial intelligence has close connections with philosophy because both use concepts that have the same names and these include intelligence, action, consciousness, epistemology, and even free will.  These factors contributed to the emergence of the philosophy of artificial intelligence.	Is artificial intelligence possible philosophy	10959
8511	Summary. The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems. It's easy to implement and understand, but has a major drawback of becoming significantly slows as the size of that data in use grows.	What is K Nearest Neighbor machine learning	8511
8096	Cross correlation and autocorrelation are very similar, but they involve different types of correlation: Cross correlation happens when two different sequences are correlated. Autocorrelation is the correlation between two of the same sequences. In other words, you correlate a signal with itself.	What is the difference between correlation and autocorrelation	8096
1448	Establish face validity.Conduct a pilot test.Enter the pilot test in a spreadsheet.Use principal component analysis (PCA)Check the internal consistency of questions loading onto the same factors.Revise the questionnaire based on information from your PCA and CA.	How do you establish reliability and validity of a questionnaire	1448
9114	The regression slope intercept formula, b0 = y – b1 * x is really just an algebraic variation of the regression equation, y' = b0 + b1x where “b0” is the y-intercept and b1x is the slope. Once you've found the linear regression equation, all that's required is a little algebra to find the y-intercept (or the slope).	How do you find the Y intercept of a least squares regression line	9114
3267	Neural network momentum is a simple technique that often improves both training speed and accuracy. Training a neural network is the process of finding values for the weights and biases so that for a given set of input values, the computed output values closely match the known, correct, target values.	What is momentum in neural network	3267
2424	In natural language processing, the latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.	What is a good explanation of Latent Dirichlet Allocation	2424
4547	"The decision rule is: Reject H0 if Z < 1.645. The decision rule is: Reject H0 if Z < -1.960 or if Z > 1.960. The complete table of critical values of Z for upper, lower and two-tailed tests can be found in the table of Z values to the right in ""Other Resources."""	How do you find the decision rule	4547
3323	When a data set has a negative value, the axis will be shifted upward by –MIN(R) where R is the data range containing the data. Thus if R ranges from -10 to 20, the range in the chart will range from 0 to 30.	How can the box plot chart have negative values	3323
6782	0:008:06Suggested clip · 106 secondsSPSS - Correspondence Analysis - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you do correspondence analysis in SPSS	6782
9581	Do you know how to choose the right machine learning algorithm among 7 different types?1-Categorize the problem.  2-Understand Your Data.  Analyze the Data.  Process the data.  Transform the data.  3-Find the available algorithms.  4-Implement machine learning algorithms.  5-Optimize hyperparameters.More items	How do I know which ML model to use	9581
8761	Recursive neural network models	Which model is best suited for recursive data	8761
6241	Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.	What is machine learning and its applications	6241
6598	Communalities – This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.	What is communality in factor analysis	6598
3257	If X takes values in [a, b] and Y takes values in [c, d] then the pair (X, Y ) takes values in the product [a, b] × [c, d]. The joint probability density function (joint pdf) of X and Y is a function f(x, y) giving the probability density at (x, y).	How do you find the density of a joint function	3257
3264	A standard deviation is a measure of variability for a distribution of scores in a single sample or in a population of scores. A standard error is the standard deviation in a distribution of means of all possible samples of a given size from a particular population of individual scores.	What is the difference between standard deviation and standard error quizlet	3264
1201	Naive Bayes is a Supervised Machine Learning algorithm based on the Bayes Theorem that is used to solve classification problems by following a probabilistic approach. It is based on the idea that the predictor variables in a Machine Learning model are independent of each other.	What is naive Bayes in R	1201
4599	Image processing is often viewed as arbitrarily manipulating an image to achieve an aesthetic standard or to support a preferred reality. However, image processing is more accurately defined as a means of translation between the human visual system and digital imaging devices.	What is the importance of image processing	4599
9117	7 Top Linear Algebra Resources For Machine Learning BeginnersEssence Of Linear Algebra By 3Blue1Brown.Linear Algebra By Khan Academy.Basic Linear Algebra for Deep Learning By Niklas Donges.Computational Linear Algebra for Coders By fast.ai.Deep Learning Book By Ian Goodfellow and Yoshua Bengio and Aaron Courville.Linear Algebra for Machine Learning By AppliedAICourse.More items•	How do I learn linear algebra for machine learning	9117
6454	Discrete data involves round, concrete numbers that are determined by counting. Continuous data involves complex numbers that are measured across a specific time interval.	How can you tell the difference between continuous and discrete data	6454
10342	Deep Reinforcement Learning: From Toys to Enteprise When paired with simulations, reinforcement learning is a powerful tool for training AI models that can help increase automation or optimize operational efficiency of sophisticated systems such as robotics, manufacturing, and supply chain logistics.	What is reinforcement learning good for	10342
3652	Summing up, a more precise statement of the universality theorem is that neural networks with a single hidden layer can be used to approximate any continuous function to any desired precision.	Can neural networks approximate any function	3652
8745	A t-test tests a null hypothesis about two means; most often, it tests the hypothesis that two means are equal, or that the difference between them is zero.  A chi-square test tests a null hypothesis about the relationship between two variables.	What is the difference between T distribution and chi square distribution	8745
6776	This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting.	Why is pooling used in convolutional neural network	6776
8873	Classic linear regression is one form of general linear model. But with a general linear model you can have any number of continuous or nominal independent variables and their interactions.	Can nominal variables be used in regression analysis	8873
9858	Unlike humans, artificial neural networks are fed with massive amount of data to learn.  Also, real neurons do not stay on until the inputs change and the outputs may encode information using complex pulse arrangements.	Is there a difference between how humans and artificial neural networks learn	9858
616	One of the most widely used predictive analytics models, the forecast model deals in metric value prediction, estimating numeric value for new data based on learnings from historical data. This model can be applied wherever historical numerical data is available.	Which model is used for prediction	616
5262	Offline evaluations test the effectiveness of recommender system algorithms on a certain dataset. Online evaluation attempts to evaluate recommender systems by a method called A/B testing where a part of users are served by recommender system A and the another part of users by recommender system B.	What is offline evaluation	5262
6748	This is why it is important to distinguish between the statistical significance of a result and the practical significance of that result.  Null hypothesis testing is a formal approach to deciding whether a statistical relationship in a sample reflects a real relationship in the population or is just due to chance.	What is the difference between statistical significance testing and null hypothesis testing	6748
253	Bag of Words just creates a set of vectors containing the count of word occurrences in the document (reviews), while the TF-IDF model contains information on the more important words and the less important ones as well.	What is difference between Bag of Words and TF IDF	253
9559	Multiple regression models forecast a variable using a linear combination of predictors, whereas autoregressive models use a combination of past values of the variable.  These concepts and techniques are used by technical analysts to forecast security prices.	What is difference between linear regression and autoregressive model in time series analysis	9559
5912	When working with box plots, the IQR is computed by subtracting the first quartile from the third quartile. In a standard normal distribution (with mean 0 and standard deviation 1), the first and third quartiles are located at -0.67448 and +0.67448 respectively. Thus the interquartile range (IQR) is 1.34896.	How do you find the Iqr with the mean and standard deviation	5912
47	To develop or improve your inductive reasoning, focus on the following skills: Paying attention to detail: No one can draw conclusions based on details without first noticing those details; paying attention is crucial to inductive reasoning.	How does one improve his or her inductive reasoning skills	47
4486	Regression is the statistical model that you use to predict a continuous outcome on the basis of one or more continuous predictor variables. In contrast, ANOVA is the statistical model that you use to predict a continuous outcome on the basis of one or more categorical predictor variables.	When do you apply regression analysis and analysis of variance	4486
3093	It is one of several methods statisticians and researchers use to extract a sample from a larger population; other methods include stratified random sampling and probability sampling. The advantages of a simple random sample include its ease of use and its accurate representation of the larger population.	What are the advantages of simple random sampling	3093
9701	Let's return to our example comparing the mean of a sample to a given value x using a t-test. Our null hypothesis is that the mean is equal to x. A one-tailed test will test either if the mean is significantly greater than x or if the mean is significantly less than x, but not both.	What is the difference between null hypothesis and alternative hypothesis one tailed tests and two tailed test	9701
7213	Stochastic effects have been defined as those for which the probability increases with dose, without a threshold. Nonstochastic effects are those for which incidence and severity depends on dose, but for which there is a threshold dose. These definitions suggest that the two types of effects are not related.	What is the difference between stochastic and non stochastic	7213
5848	A statistical project is the process of answering a research question using statistical techniques and presenting the work in a written report. The research question may arise from any field of scientific endeavor, such as athletics, advertising, aerodynamics, or nutrition.	What is a statistical project	5848
2607	K-nearest neighbor (KNN) decision boundary K-nearest neighbor is an algorithm based on the local geometry of the distribution of the data on the feature hyperplane (and their relative distance measures). The decision boundary, therefore, comes up as nonlinear and non-smooth.	What is decision boundary in Knn	2607
3680	Deep learning requires large amounts of labeled data. For example, driverless car development requires millions of images and thousands of hours of video. Deep learning requires substantial computing power. High-performance GPUs have a parallel architecture that is efficient for deep learning.	What is needed for deep learning	3680
10456	There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.	How can we choose a good K for K means clustering	10456
4321	Selectors are the names given to styles in internal and external style sheets. In this CSS Beginner Tutorial we will be concentrating on HTML selectors, which are simply the names of HTML tags and are used to change the style of a specific type of element.	What are selectors	4321
10897	Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them. Bivariate analysis can be helpful in testing simple hypotheses of association.	What is the purpose of bivariate analysis	10897
4130	k-Means Clustering is an unsupervised learning algorithm that is used for clustering whereas KNN is a supervised learning algorithm used for classification.	Can Knn be used for clustering	4130
6658	Linear regression is used for predicting the continuous dependent variable using a given set of independent features whereas Logistic Regression is used to predict the categorical. Linear regression is used to solve regression problems whereas logistic regression is used to solve classification problems.	Why we use logistic regression instead of linear regression	6658
8687	You can use the ArffViewer:(Tools -> ArffViewer or Ctrl+A). Then open your CSV file.Next go to File -> Save as and select Arff data files (should be selected by default.	How do I convert text files to arff format weka	8687
796	FFTs are great at analyzing vibration when there are a finite number of dominant frequency components; but power spectral densities (PSD) are used to characterize random vibration signals.	What is the difference between FFT and PSD	796
5461	Explanation: Asynchronous update ensures that the next state is at most unit hamming distance from current state. 5. If pattern is to be stored, then what does stable state should have updated value of?	What is asynchronous update in Hopfield model	5461
3888	Object recognition is a computer vision technique for identifying objects in images or videos. Object recognition is a key output of deep learning and machine learning algorithms.  The goal is to teach a computer to do what comes naturally to humans: to gain a level of understanding of what an image contains.	What is object recognition in image processing	3888
5438	The reason dividing by n-1 corrects the bias is because we are using the sample mean, instead of the population mean, to calculate the variance. Since the sample mean is based on the data, it will get drawn toward the center of mass for the data.	Why does dividing by n 1 instead of n remove the bias when calculating sample variance	5438
630	Some of the main drawbacks of association rule algorithms in e-learning are: the used algorithms have too many parameters for somebody non expert in data mining and the obtained rules are far too many, most of them non-interesting and with low comprehensibility.	What is the limitations behind rule generation in association rule mining	630
2603	Backtracking is a technique based on algorithm to solve problem. It uses recursive calling to find the solution by building a solution step by step increasing values with time. It removes the solutions that doesn't give rise to the solution of the problem based on the constraints given to solve the problem.	What is backtracking algorithm in data structure	2603
3094	Definition. Univariate analyses are used extensively in quality of life research. Univariate analysis is defined as analysis carried out on only one (“uni”) variable (“variate”) to summarize or describe the variable (Babbie, 2007; Trochim, 2006).	What do you mean by univariate analysis	3094
5015	The SD line goes through the point of averages, and has slope equal to SDY/SDX if the correlation coefficient r is greater than or equal to zero. The SD line has slope −SDY/SDX if r is negative.  The line slopes up to the right, because r is positive (0.5 at first).	Does the regression line go through the point of averages	5015
4243	Yes, the vectors from a word2vec model can be used as input in the learning of a new task, and in some (not all) cases, may yield better performance in the new model.	Does word2vec transfer learning	4243
8614	Binomial counts successes in a fixed number of trials, while Negative binomial counts failures until a fixed number successes. The Bernoulli and Geometric distributions are the simplest cases of the Binomial and Negative Binomial distributions.	What is the difference between binomial and negative binomial distribution	8614
3354	Step 1: Learn the fundamental data structures and algorithms. First, pick a favorite language to focus on and stick with it.  Step 2: Learn advanced concepts, data structures, and algorithms.  Step 1+2: Practice.  Step 3: Lots of reading + writing.  Step 4: Contribute to open-source projects.  Step 5: Take a break.	How do I start learning algorithms	3354
2253	The natural logarithm function is negative for values less than one and positive for values greater than one. So yes, it is possible that you end up with a negative value for log-likelihood (for discrete variables it will always be so).	Can the likelihood be negative	2253
8475	You will need to know the standard deviation of the population in order to calculate the sampling distribution. Add all of the observations together and then divide by the total number of observations in the sample.	How do you find the sampling distribution	8475
8560	Cluster sampling is typically used in market research. It's used when a researcher can't get information about the population as a whole, but they can get information about the clusters. For example, a researcher may be interested in data about city taxes in Florida.	What is the purpose of cluster sampling	8560
3979	Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron.	Why activation function is used in neural network	3979
4152	Approximately Normal Distributions with Discrete Data. If a random variable is actually discrete, but is being approximated by a continuous distribution, a continuity correction is needed.	Can discrete random variables be normally distributed	4152
3491	In mathematics, a nonnegative matrix, written. is a matrix in which all the elements are equal to or greater than zero, that is, A positive matrix is a matrix in which all the elements are strictly greater than zero.	What is non negative matrix	3491
7810	Explanation: The objective of perceptron learning is to adjust weight along with class identification.	What is the objective of Perceptron learning *	7810
794	It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.  The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.	Why is rectified linear unit a good activation function	794
8833	The major difference between using a Z score and a T statistic is that you have to estimate the population standard deviation. The T test is also used if you have a small sample size (less than 30).	What is Z statistics and t statistics	8833
7828	An ROC curve shows the relationship between clinical sensitivity and specificity for every possible cut-off. The ROC curve is a graph with: The x-axis showing 1 – specificity (= false positive fraction = FP/(FP+TN)) The y-axis showing sensitivity (= true positive fraction = TP/(TP+FN))	What does a ROC curve tell you	7828
9048	4:551:11:29Suggested clip · 112 secondsRodrigo Agundez: Building a live face recognition system | Pydata YouTubeStart of suggested clipEnd of suggested clip	How do you create a face recognition system	9048
6996	One such step is eliminating duplicate data as discussed above. Another step is resolving any conflicting data. Sometimes, datasets will have information that conflicts with each other, so data normalization is meant to address this conflicting issue and solve it before continuing. A third step is formatting the data.	When and why do we need data normalization	6996
8236	Markov models are useful to model environments and problems involving sequential, stochastic decisions over time. Representing such environments with decision trees would be confusing or intractable, if at all possible, and would require major simplifying assumptions [2].	Why Markov model is useful	8236
403	To understand potential interaction effects, compare the lines from the interaction plot: If the lines are parallel, there is no interaction. If the lines are not parallel, there is an interaction.	How do you know if there is an interaction effect	403
365	A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.  See Get ONNX models for Windows ML for more information.	What is ML model	365
10927	With cluster sampling, the researcher divides the population into separate groups, called clusters. Then, a simple random sample of clusters is selected from the population.  For example, given equal sample sizes, cluster sampling usually provides less precision than either simple random sampling or stratified sampling.	What is the difference between simple random sampling and cluster sampling	10927
3591	The short answer is yes—because most regression models will not perfectly fit the data at hand. If you need a more complex model, applying a neural network to the problem can provide much more prediction power compared to a traditional regression.	Are neural networks good for regression	3591
3540	Random forest will reduce variance part of error rather than bias part, so on a given training data set decision tree may be more accurate than a random forest. But on an unexpected validation data set, Random forest always wins in terms of accuracy.	How is random forest better than decision tree	3540
3247	Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and what the corresponding output is in the training data) where the data is continuously split according to a certain parameter.  An example of a decision tree can be explained using above binary tree.	What is decision trees in machine learning	3247
8274	Decision tree is unstable because training a tree with a slightly different sub-sample causes the structure of the tree to change drastically. It overfits by learning from noise data as well and optimises for that particular sample, which causes its variable importance order to change significantly.	Why are decision trees unstable	8274
4979	Types of machine learning AlgorithmsSupervised learning.Unsupervised Learning.Semi-supervised Learning.Reinforcement Learning.	What are the different types of learning that algorithms use	4979
9972	Here are five ways to identify segments.Cross-Tab. Cross-tabbing is the process of examining more than one variable in the same table or chart (“crossing” them).  Cluster Analysis.  Factor Analysis.  Latent Class Analysis (LCA)  Multidimensional Scaling (MDS)	How do you find clusters in data	9972
1098	The k-modes algorithm tries to minimize the sum of within-cluster Hamming distance from the mode of that cluster, summed over all clusters.  The procedure is similar to k-means: a number of clusters (k) is chosen, and k cluster-mode vectors are chosen at random (or according to accepted heuristics).	How does K modes work	1098
10491	• h is the Vapnik Chervonenkis (VC) dimension and is a measure of the capacity or complexity of the machine.	What is VC dimension in SVM	10491
10745	Neural network ensemble is a learning paradigm where many neural networks are jointly used to solve a problem.  Then it assigns random weights to those networks and employs genetic algorithm to evolve the weights so that they can characterize to some extent the fitness of the neural networks in constituting an ensemble.	What is ensemble neural network	10745
10523	So, if you are constrained either by the size of the data or the number of trials you want to try, you may have to go with random forests. There is one fundamental difference in performance between the two that may force you to choose Random Forests over Gradient Boosted Machines (GBMs).	When would one use Random Forests over Gradient Boosted Machines GBMs	10523
8118	In statistics, the method of moments is a method of estimation of population parameters. It starts by expressing the population moments (i.e., the expected values of powers of the random variable under consideration) as functions of the parameters of interest.  The solutions are estimates of those parameters.	What is the method of moments estimator	8118
1368	Using the Interquartile Rule to Find Outliers Multiply the interquartile range (IQR) by 1.5 (a constant used to discern outliers). Add 1.5 x (IQR) to the third quartile. Any number greater than this is a suspected outlier. Subtract 1.5 x (IQR) from the first quartile.	How do you use interquartile range to find outliers	1368
5752	The GRU is like a long short-term memory (LSTM) with a forget gate, but has fewer parameters than LSTM, as it lacks an output gate.  GRU's performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM.	Are GRU Gated Recurrent Unit a special case of LSTM	5752
3138	The low-pass filter has a gain response with a frequency range from zero frequency (DC) to ωC. Any input that has a frequency below the cutoff frequency ωC gets a pass, and anything above it gets attenuated or rejected. The gain approaches zero as frequency increases to infinity.	What is the frequency response of low pass filter	3138
4865	A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.	What is Markov chain in probability	4865
2125	"Another strategy OTs typically recommend is something called “backward chaining."" Backward chaining is working backward from the goal. For example, the goal is put on a T-shirt.  Pull shirt over head. Push right arm up through right sleeve."	What is an example of backward chaining	2125
4700	Differential calculus is usually taught first. I think most students find it more intuitive because they deal with rates of change in real life. Integral calculus is more abstract, and indefinite integrals are much easier to evaluate if you understand differentiation.	Which comes first differential or integral calculus	4700
1315	Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.	What is Dimension reduction in machine learning	1315
1581	1. A Multi-Agent System (MAS) is a loosely coupled network of software agents that interact to solve problems that are beyond the individual capacities or knowledge of each software agent. Learn more in: Using Multi-Agent Systems to Support e-Health Services. A system composed of multiple interacting intelligent agents	What are multi agent systems 1	1581
7160	Theorem 1.2 Suppose that ψ is a simple random point process that has both stationary and independent increments. Then in fact, ψ is a Poisson process. Thus the Poisson process is the only simple point process with stationary and independent increments.	Is Poisson process stationary	7160
3561	Some of the most popular methods for outlier detection are:Z-Score or Extreme Value Analysis (parametric)Probabilistic and Statistical Modeling (parametric)Linear Regression Models (PCA, LMS)Proximity Based Models (non-parametric)Information Theory Models.More items	What methods do you use to identify outliers within a data set	3561
3644	Reduce Variance of an Estimate If we want to reduce the amount of variance in a prediction, we must add bias. Consider the case of a simple statistical estimate of a population parameter, such as estimating the mean from a small random sample of data. A single estimate of the mean will have high variance and low bias.	How do you reduce the variance of data	3644
2628	The lognormal distribution is a probability distribution whose logarithm has a normal distribution. The mean m and variance v of a lognormal random variable are functions of the lognormal distribution parameters µ and σ: m = exp ( μ + σ 2 / 2 ) v = exp ( 2 μ + σ 2 ) ( exp ( σ 2 ) − 1 )	What is the mean and variance of lognormal distribution	2628
5279	2. Exponential Moving Average (EMA) The other type of moving average is the exponential moving average (EMA), which gives more weight to the most recent price points to make it more responsive to recent data points.	Which moving average is more responsive	5279
3303	A batch size of 32 means that 32 samples from the training dataset will be used to estimate the error gradient before the model weights are updated.	Why is batch size 32	3303
4099	Epsilon is used when we are selecting specific actions base on the Q values we already have. As an example if we select pure greedy method ( epsilon = 0 ) then we are always selecting the highest q value among the all the q values for a specific state.	What is Epsilon in Q learning	4099
433	Variance	Which gives the measure of randomness of the random variable	433
7053	The technological singularity—also, simply, the singularity—is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.	What is it called when AI becomes self aware	7053
2936	Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning.  LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.	What is Lstm in neural network	2936
858	Feature Selection.  The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones.	What is the difference between feature selection and feature extraction	858
1717	Digital image processing, as a computer-based technology, carries out automatic processing, manipulation and interpretation of such visual information, and it plays an increasingly important role in many aspects of our daily life, as well as in a wide variety of disciplines and fields in science and technology, with	What are the application of image processing	1717
2618	1. Agglomerative approach: This method is also called a bottom-up approach shown in Figure 6.7. In this method, each node represents a single cluster at the beginning; eventually, nodes start merging based on their similarities and all nodes belong to the same cluster.	Which of clustering algorithms is called bottom up approach	2618
9874	Introduction. The standard deviation is a measure of the spread of scores within a set of data. Usually, we are interested in the standard deviation of a population. However, as we are often presented with data from a sample only, we can estimate the population standard deviation from a sample standard deviation.	Do you use sample or population standard deviation	9874
3942	The mean of a discrete random variable X is a weighted average of the possible values that the random variable can take. Unlike the sample mean of a group of observations, which gives each observation equal weight, the mean of a random variable weights each outcome xi according to its probability, pi.	What is the mean of a discrete random variable	3942
6459	There are often only a handful of possible classes or results. For a given classification, one tries to measure the probability of getting different evidence or patterns.  Using Bayes rule, we use this to get what is desired, the conditional probability of the classification given the evidence.	Why do you think you need conditional probability	6459
5497	The essential difference between these two is that Logistic regression is used when the dependent variable is binary in nature. In contrast, Linear regression is used when the dependent variable is continuous and nature of the regression line is linear.	What are the two main differences between logistic regression and linear regression	5497
4963	The p-value is calculated using the sampling distribution of the test statistic under the null hypothesis, the sample data, and the type of test being done (lower-tailed test, upper-tailed test, or two-sided test).  a lower-tailed test is specified by: p-value = P(TS ts | H 0 is true) = cdf(ts)	How is P value calculated	4963
5295	Nonresponse bias occurs when some respondents included in the sample do not respond. The key difference here is that the error comes from an absence of respondents instead of the collection of erroneous data.  Most often, this form of bias is created by refusals to participate or the inability to reach some respondents.	How does non response cause bias	5295
3967	The survival function is a function that gives the probability that a patient, device, or other object of interest will survive beyond any specified time. The survival function is also known as the survivor function or reliability function.	What does survival function mean	3967
1975	The test statistic used in ANOVA is Student's t. One characteristic of the F distribution is that F cannot be negative. One characteristic of the F distribution is that the computed F can only range between -1 and +1.	What is a characteristic of the F distribution that is used in Anova	1975
8881	A good maximum sample size is usually 10% as long as it does not exceed 1000. A good maximum sample size is usually around 10% of the population, as long as this does not exceed 1000. For example, in a population of 5000, 10% would be 500. In a population of 200,000, 10% would be 20,000.	What is a good representative sample size	8881
4336	Use systematic sampling when there's low risk of data manipulation. Systematic sampling is the preferred method over simple random sampling when a study maintains a low risk of data manipulation.	When would you use systematic sampling	4336
2657	When Longitudinal data looks like a time series is when we measure the same thing over time. The big difference is that in a time series we can measure the overall change in the measurement over time (or by group) while in a longitudinal analysis you actually have the measurement of change at the individual level.	What is the difference between time series and longitudinal data	2657
8798	Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.	What does transfer learning mean	8798
9459	Compare r to the appropriate critical value in the table. If r is not between the positive and negative critical values, then the correlation coefficient is significant. If r is significant, then you may want to use the line for prediction. Suppose you computed r=0.801 using n=10 data points.	How do you know if a correlation coefficient is statistically significant	9459
5003	A factorial ANOVA compares means across two or more independent variables. Again, a one-way ANOVA has one independent variable that splits the sample into two or more groups, whereas the factorial ANOVA has two or more independent variables that split the sample in four or more groups.	What is the difference between one way Anova and factorial Anova	5003
4178	If you want to process the gradients before applying them you can instead use the optimizer in three steps:Compute the gradients with compute_gradients().Process the gradients as you wish.Apply the processed gradients with apply_gradients().	How does one do gradient clipping in TensorFlow	4178
7689	A disadvantage is when researchers can't classify every member of the population into a subgroup. Stratified random sampling is different from simple random sampling, which involves the random selection of data from the entire population so that each possible sample is equally likely to occur.	What are the drawbacks disadvantage of stratified sampling	7689
6985	Once you have generated a prediction model (also called training a model), you can put it to use making predictions.  The scoring process examines a dataset and predicts results for each record based on similarities to records analyzed during model training.	What is the predictive score model	6985
4962	Squaring the residuals, averaging the squares, and taking the square root gives us the r.m.s error. You then use the r.m.s. error as a measure of the spread of the y values about the predicted y value.	How do you find the root mean square error	4962
2662	A support vector machine is a machine learning model that is able to generalise between two different classes if the set of labelled data is provided in the training set to the algorithm. The main function of the SVM is to check for that hyperplane that is able to distinguish between the two classes.	How do support vector machines work	2662
1738	Hidden Markov model (HMM) has been successfully used for sequential data modeling problems.  In the proposed GenHMM, each HMM hidden state is associated with a neural network based generative model that has tractability of exact likelihood and provides efficient likelihood computation.	Is a hidden Markov model a neural network	1738
4029	Softmax is a non-linear activation function, and is arguably the simplest of the set. In this expression, zi is the current value. The denominator in the expression is the sum across every value passed to a node in the layer.	Is Softmax a linear function	4029
3192	A Classification and Regression Tree(CART) is a predictive algorithm used in machine learning. It explains how a target variable's values can be predicted based on other values. It is a decision tree where each fork is a split in a predictor variable and each node at the end has a prediction for the target variable.	What is a classification and regression tree CART	3192
1942	The sign of a regression coefficient tells you whether there is a positive or negative correlation between each independent variable the dependent variable. A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase.	How do you interpret regression results	1942
479	The square of the correlation coefficient, r², is a useful value in linear regression. This value represents the fraction of the variation in one variable that may be explained by the other variable.  The correlation coefficient also relates directly to the regression line Y = a + bX for any two variables, where .	How is the regression line related to the correlation coefficient	479
3802	A sampling frame is a list or other device used to define a researcher's population of interest. The sampling frame defines a set of elements from which a researcher can select a sample of the target population.  Comprehensiveness refers to the degree to which a sampling frame covers the entire target population.	What do you mean by sampling frame	3802
7795	Abstract: The generalized likelihood ratio test (GLRT), which is commonly used in composite hypothesis testing problems, is investigated. Conditions for asymptotic optimality of the GLRT in the Neyman-Pearson sense are studied and discussed.	What is GLRT	7795
8610	Multimodal machine learning is a vibrant multi-disciplinary research field which addresses some of the original goals of artificial intelligence by integrating and modeling multiple communicative modalities, including linguistic, acoustic and visual messages.	What is multimodal machine learning	8610
2580	You do not need to learn linear algebra before you get started in machine learning, but at some time you may wish to dive deeper.  It will give you the tools to help you with the other areas of mathematics required to understand and build better intuitions for machine learning algorithms.	Do you need to know Linear Algebra for machine learning	2580
2947	The margin of error increases as the level of confidence increases because the larger the expected proportion of intervals that will contain the​ parameter, the larger the margin of error.  The larger the level of confidence​ is, the larger number of intervals that will contain the parameter.	What increases the margin of error	2947
1772	It is often used as a gauge of economic inequality, measuring income distribution or, less commonly, wealth distribution among a population. The coefficient ranges from 0 (or 0%) to 1 (or 100%), with 0 representing perfect equality and 1 representing perfect inequality.	What does a lower Gini coefficient mean	1772
6692	"""The difference between discrete choice models and conjoint models is that discrete choice models present experimental replications of the market with the focus on making accurate predictions regarding the market, while conjoint models do not, using product profiles to estimate underlying utilities (or partworths)"	What is the difference between a discrete choice and a conjoint analysis	6692
4177	The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 – FPR). Classifiers that give curves closer to the top-left corner indicate a better performance. As a baseline, a random classifier is expected to give points lying along the diagonal (FPR = TPR).	How do you read a ROC curve	4177
5260	Variational Bayesian methods are primarily used for two purposes: To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.	Why do variational inferences occur	5260
7639	A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data.	What is Gaussian process in machine learning	7639
860	It depends. If the message you want to carry is about the spread and variability of the data, then standard deviation is the metric to use. If you are interested in the precision of the means or in comparing and testing differences between means then standard error is your metric.	Can you use standard error instead of standard deviation	860
4117	Active learning engages students in learning, using activities such as reading, writing, discussion, or problem solving, which promote analysis, synthesis, and evaluation of class content. Active in-class learning also provides students with informal opportunities for feedback on how well they understood the material.	What are active learning strategies	4117
3125	Joint probability is calculated by multiplying the probability of event A, expressed as P(A), by the probability of event B, expressed as P(B). For example, suppose a statistician wishes to know the probability that the number five will occur twice when two dice are rolled at the same time.	How do you calculate joint probability	3125
8068	In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation.  The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.	Why is vanishing gradient a problem	8068
6109	Box plots are useful as they show outliers within a data set. An outlier is an observation that is numerically distant from the rest of the data. When reviewing a box plot, an outlier is defined as a data point that is located outside the whiskers of the box plot.	Can a Boxplot be used to detect outliers	6109
4180	Weights control the signal (or the strength of the connection) between two neurons. In other words, a weight decides how much influence the input will have on the output. Biases, which are constant, are an additional input into the next layer that will always have the value of 1.	What are weights in machine learning	4180
10593	Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.	How does Adam Optimizer work	10593
10945	To find the mean absolute deviation of the data, start by finding the mean of the data set. Find the sum of the data values, and divide the sum by the number of data values. Find the absolute value of the difference between each data value and the mean: |data value – mean|.	How do you get the mean absolute deviation	10945
3427	Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.	What is the exact meaning of artificial intelligence	3427
2389	In statistics and control theory, Kalman filtering, also known as linear quadratic estimation (LQE), is an algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a	What is Kalman filter used for	2389
9828	A (non-mathematical) definition I like by Miller (2017)3 is: Interpretability is the degree to which a human can understand the cause of a decision.  The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made.	What is model interpretability	9828
9531	In a histogram, the total range of data set (i.e from minimum value to maximum value) is divided into 8 to 15 equal parts. These equal parts are known as bins or class intervals. Each and every observation (or value) in the data set is placed in the appropriate bin.	What is binning in histogram	9531
10256	Sampling is used any time data is to be gathered. Data cannot be collected until the sample size (how much) and sample frequency (how often) have been determined. Sampling should be periodically reviewed.	Under what circumstances sampling is used	10256
7454	TensorFlow applications can be run on most any target that's convenient: a local machine, a cluster in the cloud, iOS and Android devices, CPUs or GPUs. If you use Google's own cloud, you can run TensorFlow on Google's custom TensorFlow Processing Unit (TPU) silicon for further acceleration.	Where can I use TensorFlow	7454
10408	A one-tailed test is also known as a directional hypothesis or directional test. A two-tailed test, on the other hand, is designed to examine both sides of a specified data range to test whether a sample is greater than or less than the range of values.	What is the differences between marginal distribution and the two tailed test	10408
1335	Note the difference between parameters and arguments: Function parameters are the names listed in the function's definition. Function arguments are the real values passed to the function. Parameters are initialized to the values of the arguments supplied.	What is the difference between an argument and a parameter	1335
1316	The output of the network is a single vector (also with 10,000 components) containing, for every word in our vocabulary, the probability that a randomly selected nearby word is that vocabulary word. In word2vec, a distributed representation of a word is used.	What is the output of Word2Vec	1316
3166	Creating A Target VariableFrom the menu: Click View > User Variables. The Variables dialog box appears. Click Add Target.From the Target pane: Right-click a linked field and select Edit Lookup Criteria. The Edit Lookup Criteria for the selected field appears. Click Edit Lookup Formula. The Edit Formula for the selected field appears.	How do you create a target variable	3166
6906	This occurs when the line-of-best-fit for describing the relationship between x and y is a straight line. The linear relationship between two variables is positive when both increase together; in other words, as values of x get larger values of y get larger. This is also known as a direct relationship.	How do you tell if there is a linear relationship between two variables	6906
1060	Root Mean Squared Error or RMSE RMSE is the standard deviation of the errors which occur when a prediction is made on a dataset. This is the same as MSE (Mean Squared Error) but the root of the value is considered while determining the accuracy of the model. from sklearn.	What is root mean square error in machine learning	1060
2673	In statistics and regression analysis, moderation occurs when the relationship between two variables depends on a third variable. The third variable is referred to as the moderator variable or simply the moderator.	If you control for a variable and examine the relationship between two others is this moderation	2673
8653	Continuous probability distribution: A probability distribution in which the random variable X can take on any value (is continuous). Because there are infinite values that X could assume, the probability of X taking on any one specific value is zero.  The normal distribution is one example of a continuous distribution.	What is continuous probability distribution	8653
3498	In the real world, knowledge plays a vital role in intelligence as well as creating artificial intelligence. It demonstrates the intelligent behavior in AI agents or systems. It is possible for an agent or system to act accurately on some input only when it has the knowledge or experience about the input.	What is the role of knowledge in AI	3498
4171	The lognormal distribution is a distribution skewed to the right. The pdf starts at zero, increases to its mode, and decreases thereafter. The degree of skewness increases as increases, for a given . For the same , the pdf's skewness increases as increases.	What properties do a log normal distribution have	4171
9244	A stratified sample is one that ensures that subgroups (strata) of a given population are each adequately represented within the whole sample population of a research study. For example, one might divide a sample of adults into subgroups by age, like 18–29, 30–39, 40–49, 50–59, and 60 and above.	What is an example of a stratified sample	9244
9993	Under the hood, these RDDs are stored in partitions on different cluster nodes. Partition basically is a logical chunk of a large distributed data set. It provides the possibility to distribute the work across the cluster, divide the task into smaller parts, and reduce memory requirements for each node.	How is RDD partitioned	9993
10263	Multinomial logistic regression is used when you have a categorical dependent variable with two or more unordered levels (i.e. two or more discrete outcomes).  One level of the dependent variable is chosen as the reference category. This is typically the most common or the most frequent category.	What is a multinomial variable	10263
5463	Random errors in experimental measurements are caused by unknown and unpredictable changes in the experiment. These changes may occur in the measuring instruments or in the environmental conditions.	What is random error	5463
4402	If the correlation between education and unobserved ability is positive, omitted variables bias will occur in an upward direction. Conversely, if the correlation between an explanatory variable and an unobserved relevant variable is negative, omitted variables bias will occur in a downward direction.	How do you determine the direction of omitted variable bias	4402
3430	Len Gould. Answered November 6, 2016 · Author has 6.4K answers and 3M answer views. Outgroups are simply the people who are not members of your ingroup. Obvious examples of bases for forming ingroups are according to their race, culture, gender, age or religion.	What is ingroup and outgroup examples	3430
3608	The difference between true random number generators(TRNGs) and pseudo-random number generators(PRNGs) is that TRNGs use an unpredictable physical means to generate numbers (like atmospheric noise), and PRNGs use mathematical algorithms (completely computer-generated).	What is the difference between random number and pseudo random number	3608
5649	Nonparametric tests are also called distribution-free tests because they don't assume that your data follow a specific distribution. You may have heard that you should use nonparametric tests when your data don't meet the assumptions of the parametric test, especially the assumption about normally distributed data.	In the field of statistics when are nonparametric tests preferred over parametric tests	5649
3339	Stratified random sampling is a method of sampling that involves the division of a population into smaller sub-groups known as strata. In stratified random sampling, or stratification, the strata are formed based on members' shared attributes or characteristics such as income or educational attainment.	What is a stratified random sample	3339
4140	Systematic random samplingCalculate the sampling interval (the number of households in the population divided by the number of households needed for the sample)Select a random start between 1 and sampling interval.Repeatedly add sampling interval to select subsequent households.	How do you do systematic sampling	4140
3060	Bivariate analysis means the analysis of bivariate data. It is one of the simplest forms of statistical analysis, used to find out if there is a relationship between two sets of values. It usually involves the variables X and Y. Univariate analysis is the analysis of one (“uni”) variable.	When will we use bivariate analysis	3060
9282	In deep multilayer Perceptron networks, exploding gradients can result in an unstable network that at best cannot learn from the training data and at worst results in NaN weight values that can no longer be updated. … exploding gradients can make learning unstable.	Do ReLU networks suffer from the exploding gradient problem	9282
7073	Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost.	Why is deep learning needed	7073
4060	Data science is an umbrella term for a group of fields that are used to mine large datasets. Data analytics software is a more focused version of this and can even be considered part of the larger process. Analytics is devoted to realizing actionable insights that can be applied immediately based on existing queries.	What is the difference between working in analytics and data science	4060
4921	Definition. Stimulus generalization is the tendency of a new stimulus to evoke responses or behaviors similar to those elicited by another stimulus. For example, Ivan Pavlov conditioned dogs to salivate using the sound of a bell and food powder.	What is an example of stimulus generalization	4921
17	4.3 The method: evolutionary computation. EC is a computational intelligence technique inspired from natural evolution. An EC algorithm starts with creating a population consisting of individuals that represent solutions to the problem. The first population could be created randomly or fed into the algorithm.	What is evolutionary computation in AI	17
165	In unsupervised learning, an AI system is presented with unlabeled, uncategorized data and the system's algorithms act on the data without prior training. The output is dependent upon the coded algorithms. Subjecting a system to unsupervised learning is an established way of testing the capabilities of that system.	How does unsupervised machine learning work	165
10380	ReLu bounded negative outputs to 0 & above. This works well in hidden layers than the final output layer.  It is not typical, since in this case, the ouput value is not bounded in a range.	Why ReLU is not used in output layer	10380
3828	four outcomes	How many outcomes are in the sample space	3828
6926	Bias can damage research, if the researcher chooses to allow his bias to distort the measurements and observations or their interpretation. When faculty are biased about individual students in their courses, they may grade some students more or less favorably than others, which is not fair to any of the students.	What is the problem with bias	6926
1378	Big data analytics as the name suggest is the analysis of big data by discovering hidden patterns or extracting information from it.  Big data has got more to do with High-Performance Computing, while Machine Learning is a part of Data Science. Machine learning performs tasks where human interaction doesn't matter.	Is Big Data Machine Learning	1378
9712	Step 1: Learn the fundamental data structures and algorithms. First, pick a favorite language to focus on and stick with it.  Step 2: Learn advanced concepts, data structures, and algorithms.  Step 1+2: Practice.  Step 3: Lots of reading + writing.  Step 4: Contribute to open-source projects.  Step 5: Take a break.	What is the best way to learn algorithms	9712
313	The key assumption in ordinal regression is that the effects of any explanatory variables are consistent or proportional across the different thresholds, hence this is usually termed the assumption of proportional odds (SPSS calls this the assumption of parallel lines but it's the same thing).	What are the assumptions of ordinal logistic regression	313
1994	– Validation set: A set of examples used to tune the parameters of a classifier, for example to choose the number of hidden units in a neural network. – Test set: A set of examples used only to assess the performance of a fully-specified classifier.	What is the difference between test set and validation set	1994
9366	When all the points on a scatterplot lie on a straight line, you have what is called a perfect correlation between the two variables (see below). A scatterplot in which the points do not have a linear trend (either positive or negative) is called a zero correlation or a near-zero correlation (see below).	Is it possible for a scatter plot to have a positive or negative association that is not linear	9366
1615	A generative model includes the distribution of the data itself, and tells you how likely a given example is. For example, models that predict the next word in a sequence are typically generative models (usually much simpler than GANs) because they can assign a probability to a sequence of words.	What are generative models used for	1615
4393	A random variable is a numerical description of the outcome of a statistical experiment. A random variable that may assume only a finite number or an infinite sequence of values is said to be discrete; one that may assume any value in some interval on the real number line is said to be continuous.	What is a random variable in statistics	4393
10171	Intuitively, two random variables X and Y are independent if knowing the value of one of them does not change the probabilities for the other one. In other words, if X and Y are independent, we can write P(Y=y|X=x)=P(Y=y), for all x,y.	Does random variables imply independence	10171
4033	Explanation: The two types of Fourier series are- Trigonometric and exponential.	What are the two types of Fourier series	4033
257	The SVM classifier is a frontier which best segregates the two classes (hyper-plane/ line). You can look at support vector machines and a few examples of its working here.	What are the two classification methods that SVM support vector machine can handle	257
1735	The main difference between the two, is that a Perceptron takes that binary response (like a classification result) and computes an error used to update the weights, whereas an Adaline uses a continous response value to update the weights (so before the binarized output is produced).	What is the difference between a Perceptron Adaline and neural network model	1735
5091	Hierarchical regression is a way to show if variables of your interest explain a statistically significant amount of variance in your Dependent Variable (DV) after accounting for all other variables. This is a framework for model comparison rather than a statistical method.	What is hierarchical regression used for	5091
3559	The Non-Linear Decision Boundary SVM works well when the data points are linearly separable. If the decision boundary is non-liner then SVM may struggle to classify. Observe the below examples, the classes are not linearly separable. SVM has no direct theory to set the non-liner decision boundary models.	What is non linear decision boundary	3559
1071	In the statistical analysis of time series, autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression (AR) and the second for the moving average (MA).	What is ARMA model used for	1071
4468	The parameters of LDA model have the prior distribution, and are estimated by Bayesian method. LDA model has attracted many scholars' attention since its start, but its mathematical theory is too complex to understand quickly.	Is LDA a Bayesian	4468
9141	Example 1: Fair Dice Roll The number of desired outcomes is 3 (rolling a 2, 4, or 6), and there are 6 outcomes in total. The a priori probability for this example is calculated as follows: A priori probability = 3 / 6 = 50%. Therefore, the a priori probability of rolling a 2, 4, or 6 is 50%.	How do you calculate a priori probability	9499
839	The SVM in particular defines the criterion to be looking for a decision surface that is maximally far away from any data point. This distance from the decision surface to the closest data point determines the margin of the classifier.  Figure 15.1 shows the margin and support vectors for a sample problem.	What is a margin in SVM	839
10785	Interpret the key results for Fit Mixed Effects ModelStep 1: Determine whether the random terms significantly affect the response.Step 2: Determine whether the fixed effect terms significantly affect the response.Step 3: Determine how well the model fits your data.Step 4: Evaluate how each level of a fixed effect term affects the response.More items	How do you read mixed model results	10785
8371	EXAMPLES OF DATA MINING APPLICATIONS Marketing. Data mining is used to explore increasingly large databases and to improve market segmentation.  It is commonly applied to credit ratings and to intelligent anti-fraud systems to analyse transactions, card transactions, purchasing patterns and customer financial data.	What is data mining and example	8371
6050	E(Y | Xi) = f (Xi) is known as conditional expectation function(CEF) or population regression function (PRF) or population regression (PR) for short. In simple terms, it tells how the mean or average of response of Y varies with X.	What is the conditional expectation function or the population regression function	6050
10947	NAT (Network Address Translation) is a feature of the Firewall Software Blade and replaces IPv4 and IPv6 addresses to add more security. You can enable NAT for all SmartDashboard objects to help manage network traffic. NAT protects the identity of a network and does not show internal IP addresses to the Internet.	What is a NAT policy	10947
3337	Epsilon is used when we are selecting specific actions base on the Q values we already have.  In conclusion learning rate is associated with how big you take a leap and epsilon is associated with how random you take an action.	What is Epsilon in reinforcement learning	3337
518	A psychometric and capability test aims to provide measurable, objective data that can give you a better versatile view of a candidate's skills and suitability for a position. Assessments offer scientific, valid reliable and objectivity to the process of recruiting.	What is psychometric and skills testing	518
4143	Statistical classification helps in determining the set to which a particular observation belongs. Multiple methods can be used for the classification process, namely, Frequentest procedure and Bayesian procedure among others. It helps in quicker arranging and collection of data,as well as more efficient work rate.	What is statistical classification What is the importance of such a classification	4143
6833	A sampling frame is a list of all the items in your population. It's a complete list of everyone or everything you want to study. The difference between a population and a sampling frame is that the population is general and the frame is specific.	Is sampling frame the same as population	6833
914	Because a researcher rarely has direct access to the entire population of interest in social science research, a researcher must rely upon a sampling frame to represent all of the elements of the population of interest. Generally, sampling frames can be divided into two types, list and nonlist.	What is the importance of a sample frame	914
5419	The random (or precision) error for this data point is defined as the reading minus the average of readings, or -1.20 - (-1.42) = 0.22oC. Thus, the maximum absolute value of random error is 0.22oC. You can verify that the magnitude of the random error for any of the other data points is less than this.	How do you find the maximum random error	5419
2891	Gladwell's purpose for writing The Outliers was to inform reader's on how successful people achieve success through the help of others, practice, and opportunity. He also wanted to get rid of our society's crude perspective on how outliers become successful.	What is Gladwell's purpose in outliers	2891
1309	Well, if you break down the words, forward implies moving ahead and propagation is a term for saying spreading of anything. forward propagation means we are moving in only one direction, from input to the output, in a neural network.	What is forward propagation in machine learning	1309
8980	Normal distributions are symmetric, unimodal, and asymptotic, and the mean, median, and mode are all equal. A normal distribution is perfectly symmetrical around its center. That is, the right side of the center is a mirror image of the left side. There is also only one mode, or peak, in a normal distribution.	What are the characteristics of a normal distribution	8980
4012	Machine learning has a limited scope. AI is working to create an intelligent system which can perform various complex tasks. Machine learning is working to create machines that can perform only those specific tasks for which they are trained. AI system is concerned about maximizing the chances of success.	What is the distinction between artificial intelligence AI and machine learning from your perspective what are some of the legitimate concerns about the future of AI	4012
10562	The reason why Convolutional Neural Networks (CNNs) do so much better than classic neural networks on images and videos is that the convolutional layers take advantage of inherent properties of images. Simple feedforward neural networks don't see any order in their inputs.	Why convolutional neural networks are better suited for image recognition than fully connected networks	10562
8822	To convert this distance metric into the similarity metric, we can divide the distances of objects with the max distance, and then subtract it by 1 to score the similarity between 0 and 1. We will look at the example after discussing the cosine metric.	How do you measure similarity	8822
3678	The Euclidean distance corresponds to the L2-norm of a difference between vectors. The cosine similarity is proportional to the dot product of two vectors and inversely proportional to the product of their magnitudes.	Why cosine similarity is better than Euclidean distance	3678
380	It will be easier to learn and use. If you are in the industry where you need to deploy models in production, Tensorflow is your best choice. You can use Keras/Pytorch for prototyping if you want. But you don't need to switch as Tensorflow is here to stay.	Should I use PyTorch or TensorFlow	380
10459	"In statistical hypothesis testing, a type I error is the rejection of a true null hypothesis (also known as a ""false positive"" finding or conclusion; example: ""an innocent person is convicted""), while a type II error is the non-rejection of a false null hypothesis (also known as a ""false negative"" finding or conclusion"	What is the difference between Type 1 and Type 2 error in statistics	10459
9429	Systematic random sampling is the random sampling method that requires selecting samples based on a system of intervals in a numbered population. For example, Lucas can give a survey to every fourth customer that comes in to the movie theater.	What is systematic random sampling with example	9429
9753	Within an artificial neural network, a neuron is a mathematical function that model the functioning of a biological neuron. Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.	What does a neuron compute in neural network	9753
5311	If you are studying one group, use a paired t-test to compare the group mean over time or after an intervention, or use a one-sample t-test to compare the group mean to a standard value. If you are studying two groups, use a two-sample t-test. If you want to know only whether a difference exists, use a two-tailed test.	How do you know what t test to use	5311
7024	Deep learning techniques do not perform well when dealing with data with complex hierarchical structures. Deep learning identifies correlations between sets of features that are themselves “flat” or non-hierarchical, as in a simple, unstructured list, but much human and linguistic knowledge is more structured.	What deep learning Cannot do	7024
2737	Below are the steps to implement the handwritten digit recognition project:Import the libraries and load the dataset. First, we are going to import all the modules that we are going to need for training our model.  Preprocess the data.  Create the model.  Train the model.  Evaluate the model.  Create GUI to predict digits.	How do you make a digit recognizer	2737
2413	The first benefit of time series analysis is that it can help to clean data. This makes it possible to find the true “signal” in a data set, by filtering out the noise. This can mean removing outliers, or applying various averages so as to gain an overall perspective of the meaning of the data.	What are the advantages of time series analysis	2413
8411	Our Big Data Hadoop certification training course lets you master the concepts of the Hadoop framework, Big Data tools, and methodologies to prepare you for success in your role as a Big Data Developer. Learn how various components of the Hadoop ecosystem fit into the Big Data processing lifecycle.	What is big data Course	8411
7968	Very expensive voltmeters are often made to measure “true RMS”, because that is what is desired. Low-cost voltmeters approximate the RMS value. To approximate the RMS value for a sine wave, one could simply find the peak value of the sine wave and multiply it by .	Do voltmeters measure RMS or peak	7968
7185	Sometimes we are given a chart showing frequencies of certain groups instead of the actual values.  If we multiply each midpoint by its frequency, and then divide by the total number of values in the frequency distribution, we have an estimate of the mean.	What does frequency distribution mean	7185
9234	The discriminator in a GAN is simply a classifier. It tries to distinguish real data from the data created by the generator. It could use any network architecture appropriate to the type of data it's classifying. Figure 1: Backpropagation in discriminator training.	What is discriminator in Gan	9234
8168	We will use the RAND() function to generate a random value between 0 and 1 on our Y-axis and then get the inverse of it with the NORM. INV function which will result in our random normal value on the X-axis. Mean – This is the mean of the normal distribution.	How do you generate a random number from a normal distribution	8168
2600	The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information.	Which algorithms are used in recommendation system	2600
9892	Qualitative Variables - Variables that are not measurement variables. Their values do not result from measuring or counting. Examples: hair color, religion, political party, profession. Designator - Values that are used to identify individuals in a table.	What is qualitative variable	9892
2617	The skip-gram model. Both the input vector x and the output y are one-hot encoded word representations. The hidden layer is the word embedding of size N.	Which layer of the skip gram model has an actual word embedding representation	2617
68	Values range from 0 to 1, where 0 is perfect disagreement and 1 is perfect agreement. Krippendorff suggests: “[I]t is customary to require α ≥ . 800. Where tentative conclusions are still acceptable, α ≥ .	What is a good krippendorff's Alpha	68
8467	load_model functionv2. 0. Load a model from a shortcut link, package or data path. If called with a shortcut link or package name, spaCy will assume the model is a Python package and import and call its load() method.	Which function is used to load a model in spaCy	8467
9287	All Answers (8) A matrix is a two dimensional array of numbers (or values from some field or ring). A 2-rank tensor is a linear map from two vector spaces, over some field such as the real numbers, to that field.	What is the difference between a matrix and a tensor	9287
6277	The higher the threshold, or closer to (0, 0), the higher the specificity and the lower the sensitivity. The lower the threshold, or closer to (1,1), the higher the sensitivity and lower the specificity. So which threshold value one should pick?	How do you choose the threshold in logistic regression	6277
6290	Multiclass classification with logistic regression can be done either through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.  By default, multi_class is set to 'ovr'.	Can we use logistic regression for multi class classification	6290
18	Cluster Analysis and Factor Analysis. Latent Class Analysis is similar to cluster analysis. Observed data is analyzed, connections are found, and the data is grouped into clusters.  Another difference is that LCA includes discrete latent categorical variables that have a multinomial distribution.	What is the difference between cluster analysis and latent class analysis	18
3203	AI is a bigger concept to create intelligent machines that can simulate human thinking capability and behavior, whereas, machine learning is an application or subset of AI that allows machines to learn from data without being programmed explicitly.	What is the difference between machine learning	3203
7525	Log-loss is an appropriate performance measure when you're model output is the probability of a binary outcome. The log-loss measure considers confidence of the prediction when assessing how to penalize incorrect classification.	What is log loss and how it helps to improve performance	7525
3191	OLS (linear regression, linear model) assumes normally distributed residuals.  Ordinary least squares assumes things like equal variance of the noise at every x location. Generalized least squares does not assume a diagonal co-variance matrix.	Regression statistics What is the difference between Ordinary least square and generalized least squares	3191
2916	First, make a list of the possible outcomes for each flip. Next, count the number of the possible outcomes for each flip. There are two outcomes for each flip of a coin: heads or tails. Then, multiply the number of outcomes by the number of flips.	How do you find the outcome of a sample space	2916
3962	To say it informally, the filter size is how many neighbor information you can see when processing the current layer. When the filter size is 3*3, that means each neuron can see its left, right, upper, down, upper left, upper right, lower left, lower right, as a total of 8 neighbor information.	What is filter size in CNN	3962
7824	Use In Exponential Distributions It is defined as the reciprocal of the scale parameter and indicates how quickly decay of the exponential function occurs. When the rate parameter = 1, there is no decay. Values close to 1 (e.g. 0.8 or 0.9) indicate a slow decay.	What is exponential distribution rate	7824
10777	A rank-2 tensor gets two rotation matrices. This pattern generalizes to tensors of arbitrary rank. In a particular coordinate system, a rank-2 tensor can be expressed as a square matrix, but one should not marry the concepts of tensors and matrices, just like one should think of vectors simply as arrays of numbers.	What is a rank 2 tensor	10777
2823	Intelligence Quotient	What does IQ mean	2823
3178	1 Answer. In word2vec, you train to find word vectors and then run similarity queries between words. In doc2vec, you tag your text and you also get tag vectors.  If two authors generally use the same words then their vector will be closer.	What is the difference between word2vec and Doc2Vec	3178
690	"A ""single-layer"" perceptron can't implement XOR. The reason is because the classes in XOR are not linearly separable. You cannot draw a straight line to separate the points (0,0),(1,1) from the points (0,1),(1,0). Led to invention of multi-layer networks."	Why can t Perceptron learn XOR	690
8489	To convert a frequency distribution to a probability distribution, divide area of the bar or interval of x by the total area of all the Bars. A simpler formula is: , N is the total Frequency and w is the interval of x.	How do you construct a probability distribution from a frequency distribution	8489
1627	A lazy learner delays abstracting from the data until it is asked to make a prediction while an eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset.	What is the main difference between lazy and eager learning methods in nearest neighbor clustering	1627
863	1950s	When did artificial intelligence start	863
7668	Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters).	How does Lasso regression work	7668
3917	One tool they can use to do so is a decision tree. Decision trees are flowchart graphs or diagrams that help explore all of the decision alternatives and their possible outcomes.  Decision tree software helps businesses draw out their trees, assigns value and probabilities to each branch and analyzes each option.	How do decision trees help business decision making	3917
2658	Negentropy is reverse entropy. It means things becoming more in order. By 'order' is meant organisation, structure and function: the opposite of randomness or chaos. One example of negentropy is a star system such as the Solar System.  The opposite of entropy is negentropy.	What is the opposite of entropy	2658
5458	You can convert measures from discrete to continuous or from continuous to discrete. Click the field and choose Discrete or Continuous. The field is green when it is continuous, and blue when it is discrete. For measures in the Data pane, right-click the field and choose Convert to Discrete or Convert to Continuous.	How do you convert discrete data to continuous data	5458
4806	A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis. If the points in a residual plot are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a nonlinear model is more appropriate.	How do you explain a residual plot	4806
3804	If you are working on a classification problem, the best score is 100% accuracy. If you are working on a regression problem, the best score is 0.0 error. These scores are an impossible to achieve upper/lower bound. All predictive modeling problems have prediction error.	What is a good accuracy for machine learning model	3804
8314	You can regularize your network by introducing a dropout layer soon after the convolution layer. So a typical layer of Conv->Relu becomes Conv->Dropout->Relu. You may play around with the architecture rather than simply use pre-defined ones like VGG or AlexNet.	How is regularization implemented in the VGGNet 16 network	8314
1281	Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.	What is a logistic regression used for	1281
4173	On-policy methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, off-policy methods evaluate or improve a policy different from that used to generate the data.	What is on policy and off policy	4173
1878	The converse of Theorem 1 is the following: Given vector field F = Pi + Qj on D with C1 coefficients, if Py = Qx, then F is the gradient of some function.	How do you tell if a vector field is a gradient field	1878
2502	Equality of result- making certain that people achieve the same result. An example is making sure that all students get the same grade no matter the race. Equality of opportunity- giving people an equal chance to succeed.	What is the difference between equality of opportunity and equality of results quizlet	2502
8558	FDR is a very simple concept. It is the number of false discoveries in an experiment divided by total number of discoveries in that experiment.  (You calculate one P-value for each sample or test in your experiment.)	How is FDR calculated	8558
9116	The first postulate of statistical mechanics � This postulate is often called the principle of equal a priori probabilities. It says that if the microstates have the same energy, volume, and number of particles, then they occur with equal frequency in the ensemble.	What is equal a priori probability	9116
907	The first thing you need to do is learn a programming language. Though there are a lot of languages that you can start with, Python is what many prefer to start with because its libraries are better suited to Machine Learning. Here are some good resources for Python: CodeAcademy.	Where do I start with artificial intelligence	907
1050	Since most natural phenomena are complex and have many factors, the same logic as above applies and distribution of measures of such phenomena tend to have most values near the mean (normal distibution has a desirable property of mean and mode being the same - i.e. the mean is the same as the most frequent value).	Why does the normal distribution show up so often in nature	1050
6332	Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.	How do you organize data for machine learning	6332
2619	One way to par- allelize neural network training is to use a technique called Network Parallel Training (NPT). In this approach the neu- rons of the ANN are divided across machines in the cluster, so that each machine holds a portion of the neural network.	How do you parallelize neural network training	2619
5415	SummaryWeighted Mean: A mean where some values contribute more than others.When the weights add to 1: just multiply each weight by the matching value and sum it all up.Otherwise, multiply each weight w by its matching value x, sum that all up, and divide by the sum of weights: Weighted Mean = ΣwxΣw.	How do you work out the weighted mean	5415
4133	In the statistical theory of design of experiments, randomization involves randomly allocating the experimental units across the treatment groups.  Randomization reduces bias by equalising other factors that have not been explicitly accounted for in the experimental design (according to the law of large numbers).	What is randomization experiment	4133
8802	An interpolated string is a string literal that might contain interpolation expressions. When an interpolated string is resolved to a result string, items with interpolation expressions are replaced by the string representations of the expression results.	What does string interpolation mean	8802
382	The correlation coefficient is a statistical measure of the strength of the relationship between the relative movements of two variables. The values range between -1.0 and 1.0. A calculated number greater than 1.0 or less than -1.0 means that there was an error in the correlation measurement.	What is a correlation coefficient in simple words	382
10826	The work efficiency formula is efficiency = output / input, and you can multiply the result by 100 to get work efficiency as a percentage. This is used across different methods of measuring energy and work, whether it's energy production or machine efficiency.	How do we calculate efficiency	10826
1296	The 95% confidence interval (CI) is a range of values calculated from our data, that most likely, includes the true value of what we're estimating about the population.	What is confidence interval in machine learning	1296
571	Linear Regression Is Limited to Linear Relationships By its nature, linear regression only looks at linear relationships between dependent and independent variables. That is, it assumes there is a straight-line relationship between them. Sometimes this is incorrect.	What is the common problem with linear regression	571
5366	SYNONYMS FOR outlier 2 nonconformist, maverick; original, eccentric, bohemian; dissident, dissenter, iconoclast, heretic; outsider.	What is another word for outlier	5366
2206	The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image.	What is hog computer vision	2206
2289	To get a p-value we compare our observed test- statistic to the randomization distribution of test- statistics obtained by assuming the null is true. The p-value will be the proportion of test- statistics in the randomization distribution that are as or more extreme than the observed test- statistic.	How do you find the p value for a randomization test	2289
9582	5 Techniques to Prevent Overfitting in Neural NetworksSimplifying The Model. The first step when dealing with overfitting is to decrease the complexity of the model.  Early Stopping. Early stopping is a form of regularization while training a model with an iterative method, such as gradient descent.  Use Data Augmentation.  Use Regularization.  Use Dropouts.	What steps can we take to prevent Overfitting in a neural network	9582
3266	"The questionable cause—also known as causal fallacy, false cause, or non causa pro causa (""non-cause for cause"" in Latin)—is a category of informal fallacies in which a cause is incorrectly identified. For example: ""Every time I go to sleep, the sun goes down."	What is an example of a false cause fallacy	3266
8316	So year is a discretized measure of a continuous interval variable, so quantitative.	Is year a quantitative variable	8316
9495	Usually a pattern recognition system uses training samples from known categories to form a decision rule for unknown patterns.  Clustering methods simply try to group similar patterns into clusters whose members are more similar to each other (according to some distance measure) than to members of other clusters.	What is clustering in pattern recognition	9495
753	Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).  Stemming is also a part of queries and Internet search engines.	What is stemming in NLP	753
7658	S-Curves are used to visualize the progress of a project over time. They plot either cumulative work, based on person-hours, or costs over time. The name is derived from the fact that the data usually takes on an S-shape, with slower progress at the beginning and end of a project.	What is S curve used for	7658
1181	The Cox proportional-hazards model (Cox, 1972) is essentially a regression model commonly used statistical in medical research for investigating the association between the survival time of patients and one or more predictor variables.	What is Cox regression survival analysis	1181
312	Qualitative Differences The population standard deviation is a parameter, which is a fixed value calculated from every individual in the population. A sample standard deviation is a statistic. This means that it is calculated from only some of the individuals in a population.	Is population standard deviation the same as standard deviation	312
5534	In statistics, bivariate data is data on each of two variables, where each value of one of the variables is paired with a value of the other variable.  For example, bivariate data on a scatter plot could be used to study the relationship between stride length and length of legs.	What is bivariate variable	5534
8186	The correlation structure between the dependent variables provides additional information to the model which gives MANOVA the following enhanced capabilities: Greater statistical power: When the dependent variables are correlated, MANOVA can identify effects that are smaller than those that regular ANOVA can find.	Why use a Manova instead of Anova	8186
7855	Regression attempts to establish how X causes Y to change and the results of the analysis will change if X and Y are swapped. With correlation, the X and Y variables are interchangeable.  Correlation is a single statistic, whereas regression produces an entire equation.	What is the univariate correlation matrix Is it different from the Pearson correlation analysis	7855
8895	A variable xj is said to be endogenous within the causal model M if its value is determined or influenced by one or more of the independent variables X (excluding itself). A purely endogenous variable is a factor that is entirely determined by the states of other variables in the system.	How do you identify endogenous variables	8895
3159	We propose that especially in the context of introducing automated decision aids to explicitly reduce human error, people become primed to use decision aids in biased ways. Rather than necessarily leading to fewer errors, automated decision aids may simply lead to di!erent kinds or classes of errors.	Does automation bias decision making	3159
8288	Ridge regression has two main benefits. First, adding a penalty term reduces overfitting. Second, the penalty term guarantees that we can find a solution. I think the second part is easier to explain.	What are the benefits of using ridge regression over ordinary linear regression	8288
1349	A recurrent neural network is shown one input each timestep and predicts one output. Conceptually, BPTT works by unrolling all input timesteps. Each timestep has one input timestep, one copy of the network, and one output. Errors are then calculated and accumulated for each timestep.	How does backpropagation work in RNN	1349
10751	Word embeddings are widely used nowadays in Distributional Semantics and for a variety of tasks in NLP. Embeddings can be evaluated using ex- trinsic evaluation methods, i.e. the trained em- beddings are evaluated on a specific task such as part-of-speech tagging or named-entity recogni- tion (Schnabel et al., 2015).	How are word Embeddings usually evaluated	10751
5035	A negative binomial distribution is concerned with the number of trials X that must occur until we have r successes. The number r is a whole number that we choose before we start performing our trials. The random variable X is still discrete. However, now the random variable can take on values of X = r, r+1, r+2,	How do you know if a binomial distribution is negative	5035
3610	Put simply, batch processing is the process by which a computer completes batches of jobs, often simultaneously, in non-stop, sequential order. It's also a command that ensures large jobs are computed in small parts for efficiency during the debugging process.	What is the meaning of batch processing	3610
6326	Convolution has applications that include probability, statistics, computer vision, natural language processing, image and signal processing, engineering, and differential equations.	What are the applications of convolution	6326
9680	For example, medical diagnosis, image processing, prediction, classification, learning association, regression etc. The intelligent systems built on machine learning algorithms have the capability to learn from past experience or historical data.	What is machine learning examples	9680
3698	Verify that the partial derivative Fxy is correct by calculating its equivalent, Fyx, taking the derivatives in the opposite order (d/dy first, then d/dx). In the above example, the derivative d/dy of the function f(x,y) = 3x^2*y - 2xy is 3x^2 - 2x.	How do you find the partial derivative of fxy	3698
10540	We can reduce the size of a Tensorflow Model using the below mentioned methods: Freezing: Convert the variables stored in a checkpoint file of the SavedModel into constants stored directly in the model graph. This reduces the overall size of the model.	How do I reduce the size of a TensorFlow model	10540
1406	"In information theory, the information content, self-information, surprisal, or Shannon information is a basic quantity derived from the probability of a particular event occurring from a random variable.  The Shannon information can be interpreted as quantifying the level of ""surprise"" of a particular outcome."	What does information content mean	1406
7348	AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.	What is a B testing and how does it work	7348
8335	An odds ratio is a measure of association between the presence or absence of two properties.  The value of the odds ratio tells you how much more likely someone under 25 might be to make a claim, for example, and the associated confidence interval indicates the degree of uncertainty associated with that ratio.	What is odds ratio and confidence interval	8335
1402	Deep Neural Networks (DNN) have greater capabilities for image pattern recognition and are widely used in Computer Vision algorithms. And, Convolutional Neural Network (CNN, or ConvNet) is a class of DNN which is most commonly applied to analyzing visual imagery.	Why convolutional neural networks are preferred for computer vision applications	1402
7985	In statistics, a Poisson distribution is a statistical distribution that shows how many times an event is likely to occur within a specified period of time. It is used for independent events which occur at a constant rate within a given interval of time.	What is the Poisson distribution used for	7985
7314	Quota sampling means to take a very tailored sample that's in proportion to some characteristic or trait of a population.  For example, if your population consists of 45% female and 55% male, your sample should reflect those percentages.	What is quota sampling and example	7314
8283	In general, K-means is a heuristic algorithm that partitions a data set into K clusters by minimizing the sum of squared distance in each cluster.  In this paper, the simulation of basic k-means algorithm is done, which is implemented using Euclidian distance metric.	What is the distance metric used in the standard implementation of K means to calculate the cluster assignments	8283
526	Divide the total by the number of members of the cluster. In the example above, 283 divided by four is 70.75, and 213 divided by four is 53.25, so the centroid of the cluster is (70.75, 53.25).	How do you find the centroid in statistics	526
8318	The Binomial Theorem: Formulas. The Binomial Theorem is a quick way (okay, it's a less slow way) of expanding (or multiplying out) a binomial expression that has been raised to some (generally inconveniently large) power. For instance, the expression (3x – 2)10 would be very painful to multiply out by hand.	How does the binomial theorem work	8318
6966	There are several approaches to avoiding overfitting in building decision trees.Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set.Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree.	How do you solve overfitting in decision tree	6966
3548	n_estimators : This is the number of trees you want to build before taking the maximum voting or averages of predictions. Higher number of trees give you better performance but makes your code slower.	What is N_estimators in random forest	3548
9285	The item response theory (IRT), also known as the latent response theory refers to a family of mathematical models that attempt to explain the relationship between latent traits (unobservable characteristic or attribute) and their manifestations (i.e. observed outcomes, responses or performance).	What is IRT model	9285
5926	The hazard function is not a density or a probability. However, we can think of it as the probability of failure in an infinitesimally small time period between y and y + ∂y given that the subject has survived up till time y.	Is the hazard function a probability	5926
3454	A rule-based system (e.g., production system, expert system) uses rules as the knowledge representation. These rules are coded into the system in the form of if-then-else statements.  So, let's regard rule-based systems as the simplest form of AI.	How does rule based AI model work	3454
9865	0:002:44Suggested clip · 118 secondsGeometric Distribution: Mean - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the mean of a geometric distribution	9865
9033	Augmented reality holds the promise of creating direct, automatic, and actionable links between the physical world and electronic information. It provides a simple and immediate user interface to an electronically enhanced physical world.	What is the scope of augmented reality	9033
1353	Alternate-form reliability is the consistency of test results between two different – but equivalent – forms of a test. Alternate-form reliability is used when it is necessary to have two forms of the same tests.  – Alternative-form reliability is needed whenever two test forms are being used to measure the same thing.	What is alternate form of reliability	1353
7349	Recall quantifies the number of positive class predictions made out of all positive examples in the dataset. F-Measure provides a single score that balances both the concerns of precision and recall in one number.	What is the recall score for the machine learning model	7349
4676	While precision refers to the percentage of your results which are relevant, recall refers to the percentage of total relevant results correctly classified by your algorithm. Unfortunately, it is not possible to maximize both these metrics at the same time, as one comes at the cost of another.	How do you interpret precision and recall	4676
2002	According to Bezdek (1994), Computational Intelligence is a subset of Artificial Intelligence. There are two types of machine intelligence: the artificial one based on hard computing techniques and the computational one based on soft computing methods, which enable adaptation to many situations.	What is the difference between computational intelligence and artificial intelligence	2002
570	The accuracy is a measure of the degree of closeness of a measured or calculated value to its actual value. The percent error is the ratio of the error to the actual value multiplied by 100. The precision of a measurement is a measure of the reproducibility of a set of measurements.  A systematic error is human error.	Does percent error measure accuracy or precision explain	570
9498	Predictive modeling is a form of artificial intelligence that uses data mining and probability to forecast or estimate more granular, specific outcomes. For example, predictive modeling could help identify customers who are likely to purchase our new One AI software over the next 90 days.	Is predictive modeling AI	9498
2729	Computer vision, however, is more than machine learning applied. It involves tasks as 3D scene modeling, multi-view camera geometry, structure-from-motion, stereo correspondence, point cloud processing, motion estimation and more, where machine learning is not a key element.	Is computer vision part of machine learning	2729
821	A false positive is an outcome where the model incorrectly predicts the positive class. And a false negative is an outcome where the model incorrectly predicts the negative class. In the following sections, we'll look at how to evaluate classification models using metrics derived from these four outcomes.	What is false negative in a classification table	821
4895	Use Regression to Analyze a Wide Variety of Relationships Include continuous and categorical variables. Use polynomial terms to model curvature. Assess interaction terms to determine whether the effect of one independent variable depends on the value of another variable.	When should regression analysis be performed	4895
10104	The sample mean is a consistent estimator for the population mean. A consistent estimate has insignificant errors (variations) as sample sizes grow larger.  In other words, the more data you collect, a consistent estimator will be close to the real population parameter you're trying to measure.	Why is the definition of a consistent estimator the way it is	10104
8539	A Correlation of 0 means that there is no linear relationship between the two variables. We already know that if two random variables are independent, the Covariance is 0. We can see that if we plug in 0 for the Covariance to the equation for Correlation, we will get a 0 for the Correlation.	What does a covariance of 0 mean	8539
637	At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional to the square of the β values, while the L1 norm is proportional the absolute value of the values in β.	What is the difference between l1 and l2 norms	637
7069	The Rabin-Karp algorithm makes use of hash functions and the rolling hash technique. A hash function is essentially a function that maps one thing to a value. In particular, hashing can map data of arbitrary size to a value of fixed size.	Which technique is used in Rabin Karp algorithm	7069
10177	“Candidate Sampling” training methods involve constructing a training task in which for each. training example. , we only need to evaluate. for a small set of candidate classes.	What is candidate sampling in machine learning	10177
2760	Static final variables 2) The variable MY_VAR is public which means any class can use it. It is a static variable so you won't need any object of class in order to access it. It's final so the value of this variable can never be changed in the current or in any class.	Can we change the value of static variable	2760
1393	The Poisson distribution is used to model the number of events occurring within a given time interval. λ is the shape parameter which indicates the average number of events in the given time interval. The following is the plot of the Poisson probability density function for four values of λ.	What is the parameter of the Poisson distribution	1393
10164	Use the hypergeometric distribution with populations that are so small that the outcome of a trial has a large effect on the probability that the next outcome is an event or non-event. For example, in a population of 10 people, 7 people have O+ blood.	When would you use a hypergeometric distribution	10164
4582	A training dataset is a dataset of examples used during the learning process and is used to fit the parameters (e.g., weights) of, for example, a classifier.	What is training set in machine learning	4582
2446	Just as correlation measures the extent of a linear relationship between two variables, autocorrelation measures the linear relationship between lagged values of a time series. There are several autocorrelation coefficients, corresponding to each panel in the lag plot.	What is the autocorrelation for a time series	2446
2346	Association Rule Mining, as the name suggests, association rules are simple If/Then statements that help discover relationships between seemingly independent relational databases or other data repositories. Most machine learning algorithms work with numeric datasets and hence tend to be mathematical.	What are association rules in data mining	2346
7190	Generally, you're evidently not an AI, if we are talking about the computers and algorithms and codes. You cannot prove this topic unless you definitely define what is artificial intelligence and what you are. Generally, you're evidently not an AI, if we are talking about the computers and algorithms and codes.	How do you prove that you are not an artificial intelligence	7190
6524	As far as i read in the manual, stream length is simply the number (n) of the sequent number of the random number sample. The bitstream is likely a number of sample size.	What does Stream length in NIST randomness test mean	6524
6571	The Central limit Theorem states that when sample size tends to infinity, the sample mean will be normally distributed. The Law of Large Number states that when sample size tends to infinity, the sample mean equals to population mean.	What is the difference between law of large numbers and central limit theorem	6571
2449	TL; DR: The naive Bayes classifier is an approximation to the Bayes classifier, in which we assume that the features are conditionally independent given the class instead of modeling their full conditional distribution given the class. A Bayes classifier is best interpreted as a decision rule.	What is the difference between the Naive Bayes Classifier and the Bayes classifier	2449
1452	A histogram is drawn like a bar chart, but often has bars of unequal width. It is the area of the bar that tells us the frequency in a histogram, not its height. Instead of plotting frequency on the y-axis, we plot the frequency density. To calculate this, you divide the frequency of a group by the width of it.	What does density mean in histogram	1452
4750	Plot a symbol at the median and draw a box between the lower and upper quartiles. Calculate the interquartile range (the difference between the upper and lower quartile) and call it IQ. The line from the lower quartile to the minimum is now drawn from the lower quartile to the smallest point that is greater than L1.	How do you calculate a box plot	4750
1290	We shall look at 5 popular clustering algorithms that every data scientist should be aware of.K-means Clustering Algorithm.  Mean-Shift Clustering Algorithm.  DBSCAN – Density-Based Spatial Clustering of Applications with Noise.  EM using GMM – Expectation-Maximization (EM) Clustering using Gaussian Mixture Models (GMM)More items•	What are the most popular clustering algorithms	1290
8940	According to this link LDA is a generative classifier. Also, the motto of LDA is to model a discriminant function to classify.	Is linear discriminant analysis a generative model	8940
5472	Supervised Learning deals with two main tasks Regression and Classification. Unsupervised Learning deals with clustering and associative rule mining problems. Whereas Reinforcement Learning deals with exploitation or exploration, Markov's decision processes, Policy Learning, Deep Learning and value learning.	What is the difference between supervised unsupervised and reinforcement learning	5472
10631	A finite population is a collection of objects or individuals that are objects of research that occupy a certain area. It clear boundaries that distinguish these population groups from other populations.	What is a finite population in statistics	10631
1857	Overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data.  Specifically, underfitting occurs if the model or algorithm shows low variance but high bias. Underfitting is often a result of an excessively simple model.	What is Overfitting and Underfitting in learning	1857
3844	A simple random sample is a subset of a statistical population in which each member of the subset has an equal probability of being chosen. A simple random sample is meant to be an unbiased representation of a group.	What is a simple random sample in statistics	3844
5380	This variance represents what the regression line cannot predict. It's equal to the sum of squared deviations of data points around predicted points, divided by N minus two. N is the number of data points in the scatterplot. Regression variance is based on differences between predicted data points and the mean of Y.	How do you find the variance of a regression model	5380
4880	Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data.	What is data science and where it is used	4880
6401	Common examples of algorithms with coefficients that can be optimized using gradient descent are Linear Regression and Logistic Regression.	What algorithms use gradient descent	6401
6909	It is acknowledged that current tests do not measure IQ to a level of accuracy of one point: there is a margin of error, usually considered to be about five points either side of the obtained IQ, which should be taken into account when making a diagnosis of ID (The American Association on Mental Retardation 2002).	What is the margin of error of IQ tests	6909
2709	Appropriate Problems for Decision Tree LearningInstances are represented by attribute-value pairs.  The target function has discrete output values.  Disjunctive descriptions may be required.  The training data may contain errors.  The training data may contain missing attribute values.	What are the issues in decision tree learning	2709
2801	Testing approach: The answers lie in the data set. In order to test a machine learning algorithm, tester defines three different datasets viz. Training dataset, validation dataset and a test dataset (a subset of training dataset).	How do you test machine learning models	2801
10976	The standard deviation formula may look confusing, but it will make sense after we break it down.  Step 1: Find the mean.Step 2: For each data point, find the square of its distance to the mean.Step 3: Sum the values from Step 2.Step 4: Divide by the number of data points.Step 5: Take the square root.	How do you find the standard deviation between two sets of data	10976
9687	One way that we calculate the predicted probability of such binary events (drop out or not drop out) is using logistic regression. Unlike regular regression, the outcome calculates the predicted probability of mutually exclusive event occuring based on multiple external factors.	What is predicted probability in logistic regression	9687
6912	Cluster cohesion: Measures the closeness of the objects within the same cluster. A “lower within-cluster” variation indicates good compactness or good clustering. The separation method is implied to measure how well a cluster is separated from other clusters.	Which measures the goodness of a cluster	6912
5816	Artificial intelligence can dramatically improve the efficiencies of our workplaces and can augment the work humans can do. When AI takes over repetitive or dangerous tasks, it frees up the human workforce to do work they are better equipped for—tasks that involve creativity and empathy among others.	What is the impact of AI	5816
211	An Expert system shell is a software development environment. It contains the basic components of expert systems. A shell is associated with a prescribed method for building applications by configuring and instantiating these components.	What is Expert System Shell in artificial intelligence	211
2668	In probability theory and statistics, a collection of random variables is independent and identically distributed if each random variable has the same probability distribution as the others and all are mutually independent. This property is usually abbreviated as i.i.d. or iid or IID.	What does independently and identically distributed mean	2668
6185	In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge.	What is convolutional filter	6185
7166	The value of a dependent variable depends on an independent variable, so a variable cannot be both independent and dependent at the same time. It must be either the cause or the effect, not both!	Can the same variable be used as the dependent and Independent variable after a time lapse	7166
9399	As mentioned in the context of the gradient theorem, a vector field F is conservative if and only if it has a potential function f with F=∇f. Therefore, if you are given a potential function f or if you can find one, and that potential function is defined everywhere, then there is nothing more to do.	How do you know if F is conservative vector field	9399
9905	How to Calculate VarianceFind the mean of the data set. Add all data values and divide by the sample size n.Find the squared difference from the mean for each data value. Subtract the mean from each data value and square the result.Find the sum of all the squared differences.  Calculate the variance.	How do I calculate the variance	9905
9656	To recap, Logistic regression is a binary classification method. It can be modelled as a function that can take in any number of inputs and constrain the output to be between 0 and 1. This means, we can think of Logistic Regression as a one-layer neural network.	Is logistic regression a neural network	9656
5411	Multiple regression formula is used in the analysis of relationship between dependent and multiple independent variables and formula is represented by the equation Y is equal to a plus bX1 plus cX2 plus dX3 plus E where Y is dependent variable, X1, X2, X3 are independent variables, a is intercept, b, c, d are slopes,	What is the formula for multiple regression	5411
10997	Quantum fields are matter.  The simplest “practical” quantum field theory is quantum electromagnetism. In it, two fields exist: the electromagnetic field and the “electron field”. These two fields continuously interact with each other, energy and momentum are transferred, and excitations are created or destroyed.	What is a field in QFT	10997
9058	For example, if the distribution of raw scores if normally distributed, so is the distribution of z-scores. The mean of any SND always = 0. The standard deviation of any SND always = 1. Therefore, one standard deviation of the raw score (whatever raw value this is) converts into 1 z-score unit.	Why does az score have a mean of 0 and standard deviation of 1	9058
6794	In this case, convergence in distribution implies convergence in probability. We can state the following theorem: Theorem If Xn d→ c, where c is a constant, then Xn p→ c. Since Xn d→ c, we conclude that for any ϵ>0, we have limn→∞FXn(c−ϵ)=0,limn→∞FXn(c+ϵ2)=1.	How do you prove probability convergence	6794
1173	Visualping is the newest, easiest and most convenient tool to monitor websites changes. Our Chrome app allows to monitor pages with only 1 click directly from the page you wish to monitor. Users receive an email when changes are detected but can also set up a Slack integration for team notifications.	What is Visualping	1173
10430	Word vectors are simply vectors of numbers that represent the meaning of a word.  In simpler terms, a word vector is a row of real-valued numbers (as opposed to dummy numbers) where each point captures a dimension of the word's meaning and where semantically similar words have similar vectors.	What is vector representation of words	10430
10716	When the two options are available, lemmatization will always be a better option than stemming.  But if you can apply a lemmatizer, it will always give you a better result, because lemmatizers rely on correct language data (dictionaries) to identify a word with its lemma.	Is it advisable to choose lemmatization over stemming in NLP	10716
4361	If a confusion matrix threshold is at disposal, instead, we recommend the usage of the Matthews correlation coefficient over F1 score, and accuracy.  We decided to focus on accuracy and F1 score because they are the most common metrics used for binary classification in machine learning.	Is the Matthews correlation coefficient widely used in binary classifier quality assessment	4361
588	Calculate bias by finding the difference between an estimate and the actual value. To find the bias of a method, perform many estimates, and add up the errors in each estimate compared to the real value. Dividing by the number of estimates gives the bias of the method.	How do you calculate bias	588
7835	The probability of committing a type II error is equal to one minus the power of the test, also known as beta. The power of the test could be increased by increasing the sample size, which decreases the risk of committing a type II error.	What is the probability of a Type II error	7835
5158	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.	What is bootstrap in machine learning	5158
5823	To take your first steps down the artificial intelligence career path, hiring managers will likely require that you hold at least a bachelor's degree in mathematics and basic computer technology. However, for the most part, bachelor's degrees will only get you into entry-level positions.	What degree do I need to work with artificial intelligence	5823
8568	Experimental probability is the actual result of an experiment, which may be different from the theoretical probability. Example: you conduct an experiment where you flip a coin 100 times. The theoretical probability is 50% heads, 50% tails. The actual outcome of your experiment may be 47 heads, 53 tails.	What are some examples of experimental probability	8568
7793	Train Generative Adversarial Network (GAN)Load Training Data.Define Generator Network.Define Discriminator Network.Define Model Gradients, Loss Functions and Scores.Specify Training Options.Train Model.Generate New Images.More items	How do you train a generative adversarial network	7793
9563	Gradient descent is an optimization algorithm that finds the optimal weights (a,b) that reduces prediction error. Step 2: Calculate the gradient i.e. change in SSE when the weights (a & b) are changed by a very small value from their original randomly initialized value.	What are the steps for using a gradient descent algorithm	9563
8765	The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.	What is attention mechanism in NLP	8765
4057	A Bernouilli distribution is a discrete probability distribution for a Bernouilli trial — a random experiment that has only two outcomes (usually called a “Success” or a “Failure”).  The expected value for a random variable, X, from a Bernoulli distribution is: E[X] = p. For example, if p = . 04, then E[X] = 0.4.	What is the mean of a Bernoulli distribution	4057
3161	In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function ( ) that expresses how the shape of one is modified by the other. The term convolution refers to both the result function and to the process of computing it.	What is the convolution of two functions	3161
6813	Tensorflow is the most used library used in development of Deep Learning models.  Keras, on the other end, is a high-level API that is built on top of TensorFlow. It is extremely user-friendly and comparatively easier than TensorFlow.	What is the difference between keras and tensorflow	6813
7257	Gaussian random variables and Gaussian random vectors (vectors whose components are jointly Gaussian, as defined later) play a central role in detection and estimation.  Jointly Gaussian random variables are completely described by their means and covariances, which is part of the simplicity of working with them.	What is a Gaussian vector	7257
7507	Order Statistics Definition Order statistics are sample values placed in ascending order. The study of order statistics deals with the applications of these ordered values and their functions. Let's say you had three weights: X1 = 22 kg, X2 = 44 kg, and X3 = 12 kg.	What is order statistics and why do we use it	7507
726	1:085:00Suggested clip · 93 secondsInterpreting Hazard Ratios - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you interpret hazard ratios	726
9392	An estimator of a given parameter is said to be unbiased if its expected value is equal to the true value of the parameter. In other words, an estimator is unbiased if it produces parameter estimates that are on average correct.	How do you show an estimator is unbiased	9392
9706	Returns the inverse, or critical value, of the cumulative standard normal distribution. This function computes the critical value so that the cumulative distribution is greater than or equal to a pre-specified value.	What is the inverse of the standard normal cumulative distribution	9706
8243	This term is used in statistics in its ordinary sense, but most frequently occurs in connection with samples from different populations which may or may not be identical. If the populations are identical they are said to be homogeneous, and by extension, the sample data are also said to be homogeneous.	What is a homogeneous group in statistics	8243
200	Bayesian analysis, a method of statistical inference (named for English mathematician Thomas Bayes) that allows one to combine prior information about a population parameter with evidence from information contained in a sample to guide the statistical inference process.	What is Bayesian analysis used for	200
9719	Ordinal YouTubeStart of suggested clipEnd of suggested clip	How do you do regression on Likert scale data	9719
8276	A spectrum is simply a chart or a graph that shows the intensity of light being emitted over a range of energies.  Spectra can be produced for any energy of light, from low-energy radio waves to very high-energy gamma rays. Each spectrum holds a wide variety of information.	What is a spectral	8276
3570	Alternatively, general dimensionality reduction techniques are used such as:Independent component analysis.Isomap.Kernel PCA.Latent semantic analysis.Partial least squares.Principal component analysis.Multifactor dimensionality reduction.Nonlinear dimensionality reduction.More items	What are the different feature extraction techniques	3570
737	In the context of CNN, a filter is a set of learnable weights which are learned using the backpropagation algorithm. You can think of each filter as storing a single template/pattern.  Filter is referred to as a set of shared weights on the input.	What is a filter in a CNN	737
7685	Pros: It is easy and fast to predict class of test data set. It also perform well in multi class prediction. When assumption of independence holds, a Naive Bayes classifier performs better compare to other models like logistic regression and you need less training data.	Can naive Bayes be used for multiclass classification	7685
9280	Filters typically are applied to data in the data processing stage or the preprocessing stage. Filters enhance the clarity of the signal that's used for machine learning.	What is filtering in machine learning	9280
812	The difference between the hypergeometric and the binomial distributions.  For the binomial distribution, the probability is the same for every trial. For the hypergeometric distribution, each trial changes the probability for each subsequent trial because there is no replacement.	What is the difference between binomial and hypergeometric distribution	812
6005	Inverse transform sampling is a method for generating random numbers from any probability distribution by using its inverse cumulative distribution F−1(x). Recall that the cumulative distribution for a random variable X is FX(x)=P(X≤x).	How do you do inverse transformation	6005
4253	From Wikipedia, the free encyclopedia. In mathematical optimization, constrained optimization (in some contexts called constraint optimization) is the process of optimizing an objective function with respect to some variables in the presence of constraints on those variables.	What is meant by constrained optimization	4253
2900	You calculate the mean, say it's 10. You calculate the standard deviation: it's 12. That means that any number from 10 to 22 is within one standard deviation away from the mean. Now if your data are symmetric (say normal), any number from -2 to 10 is also within a standard deviation from the mean.	How do you find how many standard deviations away from the mean	2900
8740	A moving average is a technique that calculates the overall trend in a data set. In operations management, the data set is sales volume from historical data of the company. This technique is very useful for forecasting short-term trends. It is simply the average of a select set of time periods.	What is moving average method of forecasting	8740
2115	The normal distribution can be used as an approximation to the binomial distribution, under certain circumstances, namely: If X ~ B(n, p) and if n is large and/or p is close to ½, then X is approximately N(np, npq)	Can the binomial distribution be approximated by a normal distribution	2115
3896	Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors.	What are tensors used for	3896
3787	1. A pattern recognition technique that is used to categorize a huge number of data into different classes.	What is feature classification	3787
394	One assumption of Poisson Models is that the mean and the variance are equal, but this assumption is often violated. This can be dealt with by using a dispersion parameter if the difference is small or a negative binomial regression model if the difference is large.	What can we do if our modelling assumption are violated in Poisson Regression Modelling	394
2369	There are a number of equations that can generate an S curve, the most common is logistics function with the equation (in Excel notation): S(x) = (1/(1+exp(-kx))^a is the simple form of the equation, where the minimum value is 0 and the maximum value is 1, k and a both >0 and control the shape.	How do you calculate S curve	2369
10885	Now, every textbook on linear algebra gives the following definition of a linear operator: an operator T: V—> W between two vector spaces V and W over the same field ! F is said to be linear if it satisfies the conditions of additivity, viz. T(u + v)=T(u)+T(v)	What makes an operator linear	10885
3811	The binomial is a type of distribution that has two possible outcomes (the prefix “bi” means two, or twice). For example, a coin toss has only two possible outcomes: heads or tails and taking a test could have two possible outcomes: pass or fail. A Binomial Distribution shows either (S)uccess or (F)ailure.	What is binomial distribution with example	3811
2778	Detection accuracy as discussed in this section refers to the agreement between the emotional states detected by different sets of emotion measurement equipment (e.g., multiple modalities), one of which is being used as the “grounded truth” (i.e., standard) for determining the correct emotion.	What is detection accuracy	2778
7914	The basic strength of inductive reasoning is its use in predicting what might happen in the future or in establishing the possibility of what you will encounter. The main weakness of inductive reasoning is that it is incomplete, and you may reach false conclusions even with accurate observations.	What are the advantages and disadvantages of using inductive reasoning	7914
9352	Discriminant analysis is statistical technique used to classify observations into non-overlapping groups, based on scores on one or more quantitative predictor variables. For example, a doctor could perform a discriminant analysis to identify patients at high or low risk for stroke.	What is discriminant analysis example	9352
9644	Now, for the differences… The Mann-Whitney U is a very simple test that makes almost no assumptions about any underlying distribution.  Because the K-S test can assume interval or higher level data, it is a more powerful statistical test than the MW-U, assuming that assumption is valid.	What are the differences between the Kolmogorov Smirnov test and the Mann Whitney U test	9644
63	(mathematics) A symbol representing a product over a set of terms.	What does ∏ mean	63
5738	The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems.	Is artificial intelligence a technology	5738
8551	A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process).	What is a null hypothesis in laymans terms	8551
272	In a 2-by-2 table with cells a, b, c, and d (see figure), the odds ratio is odds of the event in the exposure group (a/b) divided by the odds of the event in the control or non-exposure group (c/d). Thus the odds ratio is (a/b) / (c/d) which simplifies to ad/bc.	How do you calculate odds ratio	272
809	Action words, or action verbs, simply express an action. The action is something the subject of the sentence or clause is doing and includes sleeping, sitting, and napping-so even though there is no movement, there is still an action.	What are the action words	809
10802	Decision trees use multiple algorithms to decide to split a node in two or more sub-nodes.  Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes. The algorithm selection is also based on type of target variables.	How does a tree decide where to split	10802
4713	There are two possible objectives in a discriminant analysis: finding a predictive equation for classifying new individuals or interpreting the predictive equation to better understand the relationships that may exist among the variables. In many ways, discriminant analysis parallels multiple regression analysis.	What are the objectives of discriminant analysis	4713
9966	Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the	Is Random Forest ensemble learning	9966
1868	Here are some important considerations while choosing an algorithm.Size of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.	How do I find the best machine learning algorithm	1868
2624	For a good regression model, you want to include the variables that you are specifically testing along with other variables that affect the response in order to avoid biased results.  Cross-validation determines how well your model generalizes to other data sets by partitioning your data.	What makes a good regression model	2624
5979	Artificial Intelligence enhances the speed, precision and effectiveness of human efforts. In financial institutions, AI techniques can be used to identify which transactions are likely to be fraudulent, adopt fast and accurate credit scoring, as well as automate manually intense data management tasks.	Why do we use AI	5979
10059	If you have outliers, the best way is to use a clustering algorithm that can handle them. For example DBSCAN clustering is robust against outliers when you choose minpts large enough. Don't use k-means: the squared error approach is sensitive to outliers. But there are variants such as k-means-- for handling outliers.	How do clusters deal with outliers	10059
4490	T = (X – μ) / [ σ/√(n) ]. This makes the equation identical to the one for the z-score; the only difference is you're looking up the result in the T table, not the Z-table. For sample sizes over 30, you'll get the same result.	What is the similarity between a Z score and a T score	4490
6956	The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X ≤ x, Y ≤ y),where X and Y are continuous or discrete. For example, the probability.  P(x1 ≤ X ≤ x2,y1 ≤ Y ≤ y2) = F(x2,y2) − F(x2,y1) − F(x1,y2) + F(x1,y1).	How do you find the joint pdf of two random variables	6956
2422	Machine Learning is a set of algorithms that parse data and learns from the parsed data and use those learnings to discover patterns of interest. Neural Network or Artificial Neural Network is one set of algorithms used in machine learning for modeling the data using graphs of Neurons.	What is the difference between machine learning and neural networks	2422
10383	Use imputation for the missing values. When the response is missing, we can use a predictive model to predict the missing response, then create a new fully-observed dataset containing the predictions instead of the missing values, and finally re-estimate the predictive model in this expanded dataset.	How can I deal with missing values in a predictive model	10383
10684	Particle filtering uses a set of particles (also called samples) to represent the posterior distribution of some stochastic process given noisy and/or partial observations.  The state-space model can be nonlinear and the initial state and noise distributions can take any form required.	What is filtered in particle filtering	10684
604	Pooled data occur when we have a “time series of cross sections,” but the observations in each cross section do not necessarily refer to the same unit. Panel data refers to samples of the same cross-sectional units observed at multiple points in time.	How is panel data different from cross sectional data	604
5690	Alpha sets the standard for how extreme the data must be before we can reject the null hypothesis. The p-value indicates how extreme the data are.  If the p-value is greater than alpha (p > . 05), then we fail to reject the null hypothesis, and we say that the result is statistically nonsignificant (n.s.).	Are alpha level and P value the same	5690
7627	Compressed sensing addresses the issue of high scan time by enabling faster acquisition by measuring fewer Fourier coefficients. This produces a high-quality image with relatively lower scan time.	How does compressed sensing work	7627
5804	Post-pruning (or just pruning) is the most common way of simplifying trees. Here, nodes and subtrees are replaced with leaves to improve complexity. Pruning can not only significantly reduce the size but also improve the classification accuracy of unseen objects.	What is pruning in decision trees Why is it important	5804
754	The latent space is simply a representation of compressed data in which similar data points are closer together in space. Latent space is useful for learning data features and for finding simpler representations of data for analysis.	What are latent spaces in representation learning	754
10889	Log-loss measures the accuracy of a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class. Log-loss measures the accuracy of a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class.	Why do we use log loss	10889
427	The Bayesian approach permits the use of objective data or subjective opinion in specifying a prior distribution. With the Bayesian approach, different individuals might specify different prior distributions.  Bayesian methods have been used extensively in statistical decision theory (see statistics: Decision analysis).	How is Bayesian analysis used	427
3016	Most recent answer One way to compare the two different size data sets is to divide the large set into an N number of equal size sets. The comparison can be based on absolute sum of of difference. THis will measure how many sets from the Nset are in close match with the single 4 sample set.	How do you compare data with different sample sizes	3016
9178	14:3826:41Suggested clip · 115 secondsCanonical correlation using SPSS - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you interpret canonical correlation in SPSS	9178
10960	Conclusion. Cross-Validation is a very powerful tool. It helps us better use our data, and it gives us much more information about our algorithm performance. In complex machine learning models, it's sometimes easy not pay enough attention and use the same data in different steps of the pipeline.	Why is validation important in machine learning	10960
336	Learning statistics means learning to communicate using the statistical language, solving statistical problems, drawing conclusions, and supporting conclusions by explaining the reasoning behind them. There are often different ways to solve a statistical problem.	What is the goal of learning statistics	336
686	Mean Absolute Error (MAE) The MAE is a simple way to measure error magnitude. It consists on the average of the absolute differences between the predictions and the observed values. Th measure goes from 0 to infinite, being 0 the best value you can get.	What is the error measure used in reinforcement learning	686
6797	One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.	How do you address a vanishing gradient problem	6797
2319	In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard error.	Is RMSE the same as standard error	2319
1226	The marks for a group of students before (pre) and after (post) a teaching intervention are recorded below: Marks are continuous (scale) data. Continuous data are often summarised by giving their average and standard deviation (SD), and the paired t-test is used to compare the means of the two samples of related data.	What statistical test to use to compare pre and post tests	1226
6270	A feature detector is also referred to as a kernel or a filter. Intuitively, the matrix representation of the input image is multiplied element-wise with the feature detector to produce a feature map, also known as a convolved feature or an activation map.	What is feature detector in CNN	6270
10257	A sequence of random variables X1, X2, X3, ⋯ converges in probability to a random variable X, shown by Xn p→ X, if limn→∞P(|Xn−X|≥ϵ)=0, for all ϵ>0.	How do you show convergence in probability	10257
10876	The Kalman filter uses a system's dynamic model (e.g., physical laws of motion), known control inputs to that system, and multiple sequential measurements (such as from sensors) to form an estimate of the system's varying quantities (its state) that is better than the estimate obtained by using only one measurement	How does Kalman filter work	10876
3651	Fourier Methods in Signal Processing The Fourier transform and discrete-time Fourier transform are mathematical analysis tools and cannot be evaluated exactly in a computer. The Fourier transform is used to analyze problems involving continuous-time signals or mixtures of continuous- and discrete-time signals.	What is the use of Fourier transform in signal processing	3651
8649	The classic machine learning procedure follows the scientific paradigm of induction and deduction. In the inductive step we learn the model from raw data (so called training set), and in the deductive step the model is applied to predict the behaviour of new data.	Is machine learning inductive or deductive	8649
9577	Syllabus:Basic Data Structures: Arrays, Strings, Stacks, Queues.Asymptotic analysis (Big-O notation)Basic math operations (addition, subtraction, multiplication, division, exponentiation)Sqrt(n) primality testing.Euclid's GCD Algorithm.Basic Recursion.Greedy Algorithms.Basic Dynamic Programming.More items	What are the topics to be covered in algorithms and data structures	9577
6019	"The power of a hypothesis test is affected by three factors. Sample size (n). Other things being equal, the greater the sample size, the greater the power of the test.  The greater the difference between the ""true"" value of a parameter and the value specified in the null hypothesis, the greater the power of the test."	How does power affect sample size	6019
5227	Abstract. Network representation learning aims to embed the vertexes in a network into low-dimensional dense representations, in which similar vertices in the network should have “close” representations (usually measured by cosine similarity or Euclidean distance of their representations).	What are network representations	5227
816	Ridge regression does not really select variables in the many predictors situation.  Both ridge regression and the LASSO can outperform OLS regression in some predictive situations – exploiting the tradeoff between variance and bias in the mean square error.	Can ridge regression be used for variable selection	816
1919	The difference is a matter of design. In the test of independence, observational units are collected at random from a population and two categorical variables are observed for each unit.  In the goodness-of-fit test there is only one observed variable.	What is the difference between the chi square goodness of fit and independence tests	1919
8256	Population variance (σ2) tells us how data points in a specific population are spread out.  Here N is the population size and the xi are data points. μ is the population mean.	What is N in population variance	8256
731	Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data.	How do you ensemble a model	731
9313	Each feature, or column, represents a measurable piece of data that can be used for analysis: Name, Age, Sex, Fare, and so on. Features are also sometimes referred to as “variables” or “attributes.” Depending on what you're trying to analyze, the features you include in your dataset can vary widely.	What are feature variables	9313
8404	The function fX(x) gives us the probability density at point x. It is the limit of the probability of the interval (x,x+Δ] divided by the length of the interval as the length of the interval goes to 0. Remember that P(x<X≤x+Δ)=FX(x+Δ)−FX(x).	How do you find probability density	8404
3935	This list of requirements prioritization techniques provides an overview of common techniques that can be used in prioritizing requirements.Ranking.  Numerical Assignment (Grouping)  MoScoW Technique.  Bubble Sort Technique.  Hundred Dollar Method.  Analytic Hierarchy Process (AHP)  Five Whys.	What techniques can be used to prioritize changes	3935
1407	5 years	How long until AI is smarter than humans	1407
3142	Given two random variables X and Y, the correlation is scale and location invariant in the sense that cor(X,Y)=cor(XT,YT), if XT=a+bX, and YT=c+dY, and b and d have the same sign (either both positive or both negative).	Are correlation scales invariant	3142
6704	Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.	What is dimensionality reduction in machine learning	6704
5529	In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.	What is fixed effect in panel data regression	5529
5079	The Generative Adversarial Network, or GAN, is an architecture that makes effective use of large, unlabeled datasets to train an image generator model via an image discriminator model. The discriminator model can be used as a starting point for developing a classifier model in some cases.	Can Gan be used for classification	5079
8124	Generally, a machine learning pipeline describes or models your ML process: writing code, releasing it to production, performing data extractions, creating training models, and tuning the algorithm. An ML pipeline should be a continuous process as a team works on their ML platform.	What is pipeline in machine learning	8124
2921	Stochastic (from from Greek στόχος (stókhos) 'aim, guess'.) is any randomly determined process. In mathematics the terms stochastic process and random process are interchangeable.	What is meant by stochastic	2921
10110	The sum of a square matrix and its conjugate transpose. is Hermitian. The difference of a square matrix and its conjugate transpose. is skew-Hermitian.	What are Hermitian and skew Hermitian matrix	10110
72	A random variable is a variable whose value is unknown or a function that assigns values to each of an experiment's outcomes.  Random variables are often used in econometric or regression analysis to determine statistical relationships among one another.	What exactly is a random variable	72
2604	Dimensionality reduction refers to techniques for reducing the number of input variables in training data. When dealing with high dimensional data, it is often useful to reduce the dimensionality by projecting the data to a lower dimensional subspace which captures the “essence” of the data.	What is dimensionality reduction and explain why it is required	2604
3082	When the standard deviation or the mean change, something unusual is happening. To detect such changes, for each upcoming point “p” we create of window from “p” to “p-100″. Then, we calculate the standard deviation and mean of this window. If it changes too much, an anomaly has been detected.	How would you find an anomaly in a distribution	3082
8812	Pure serial correlation: occurs when the error terms are correlated and the regression equation is correctly specified. The most commonly assumed form of serial correlation is first-order serial correlation, in which one error term is a function of a previous error term.	What is pure serial correlation	8812
6424	Correlated vs. A correlated subquery can be thought of as a filter on the table that it refers to, as if the subquery were evaluated on each row of the table in the outer query. An uncorrelated subquery has no such external column references.	What is the difference between correlated and uncorrelated subquery	6424
1778	By Jim Frost 45 Comments. Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.	What is homoscedasticity in linear regression	1778
1916	2:266:36Suggested clip · 120 secondsAn Easy Rule to Setting Up the Null & Alternate Hypotheses YouTubeStart of suggested clipEnd of suggested clip	How do you create a null and alternative hypothesis	1916
4638	To convert a logit ( glm output) to probability, follow these 3 steps:Take glm output coefficient (logit)compute e-function on the logit using exp() “de-logarithimize” (you'll get odds then)convert odds to probability using this formula prob = odds / (1 + odds) .	How do you convert logit to probability	4638
1595	The distribution function , also called the cumulative distribution function (CDF) or cumulative frequency function, describes the probability that a variate takes on a value less than or equal to a number . The distribution function is sometimes also denoted. (Evans et al. 2000, p.	What does distribution function mean	1595
851	(There are two red fours in a deck of 52, the 4 of hearts and the 4 of diamonds). Conditional probability: p(A|B) is the probability of event A occurring, given that event B occurs.  Joint probability is the probability of two events occurring simultaneously. The probability of event A and event B occurring together.	Can you point out the difference between joint probability and conditional probability	851
4437	The normal distribution is a continuous probability distribution that is symmetrical on both sides of the mean, so the right side of the center is a mirror image of the left side.  The normal distribution is often called the bell curve because the graph of its probability density looks like a bell.	What is a normal curve in statistics	4437
9864	Characteristics of a Poisson Distribution The probability that an event occurs in a given time, distance, area, or volume is the same. Each event is independent of all other events. For example, the number of people who arrive in the first hour is independent of the number who arrive in any other hour.	What are the properties of Poisson distribution	9864
5449	One of the stages that SIFT uses is to create a pyramid of scales of the image.  The feature detector then works by finding features that have a peak response not only in the image space, but in scale space too. This means that it finds the scale of the image which the feature will produce the highest response.	Why are SIFT descriptors scale invariant	5449
2942	The difference between multi-task learning and meta-learning is: in multitask learning, your goal would be to try to solve all of the training tasks shown in the gray box (on the left picture); whereas in meta-learning your goal is to use these training tasks in order to solve new tasks with a small amount of data, so	What is the difference between meta learning and multi task learning	2942
4434	Events A and B are independent if the equation P(A∩B) = P(A) · P(B) holds true. You can use the equation to check if events are independent; multiply the probabilities of the two events together to see if they equal the probability of them both happening together.	How do you know if an event is independent	4434
9786	Running the ProcedureClick Transform > Recode into Different Variables.Double-click on variable CommuteTime to move it to the Input Variable -> Output Variable box. In the Output Variable area, give the new variable the name CommuteLength, then click Change.Click the Old and New Values button.  Click OK.	How do you convert continuous variables to categorical in SPSS	9786
10295	The Q-Q plot, or quantile-quantile plot, is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential.  If both sets of quantiles came from the same distribution, we should see the points forming a line that's roughly straight.	What does a QQ plot help you to test	10295
5237	Big Data is defined as data that is huge in size. Bigdata is a term used to describe a collection of data that is huge in size and yet growing exponentially with time. Examples of Big Data generation includes stock exchanges, social media sites, jet engines, etc.	What is big data with examples	5237
2091	The median is a measure of center (location) of a list of numbers.  This will be the median. If there are an even number on the list then average the n/2 and the (N + 2)/2 numbers. In general, the median is at position (n + 1)/2. If this position is a whole number then you have the median at that position in the list.	What is N 2 in median	2091
109	Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. (	What are gradient boosting models	109
6752	"The outcome variable is also called the response or dependent variable, and the risk factors and confounders are called the predictors, or explanatory or independent variables. In regression analysis, the dependent variable is denoted ""Y"" and the independent variables are denoted by ""X""."	Is the explanatory variable The dependent variable	6752
2296	When p is greater than 0.5, the distribution will be positively skewed (the peak will be on the left side of the distribution, with relatively fewer observations on the right).	When binomial distribution is positively skewed	2296
9343	As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.	How do you calculate a standard score	9343
7117	RL is an increasingly popular technique for organizations that deal regularly with large complex problem spaces. Because RL models learn by a continuous process of receiving rewards and punishments on every action taken, it is able to train systems to respond to unforeseen environments .	Why is reinforcement important in learning	7117
5112	There are four basic sequence learning problems: sequence prediction, sequence generation, sequence recognition, and sequential decision making. These “problems” show how sequences are formulated.	Which of the following is part of the sequence learning problem	5112
8756	Two events are said to be mutually exclusive when the two events cannot occur at the same time. For instance, when you throw a coin the event that a head appears and the event that a tail appears are mutually exclusive because they cannot occur at the same time, it's either a head appears or a tail appears.	How do you determine if an event is mutually exclusive	8756
5778	The Spearman correlation is the same as the Pearson correlation, but it is used on data from an ordinal scale. Which situation would be appropriate for obtaining a phi-coefficient with a Pearson test?	What is the difference between the Pearson correlation and the Spearman correlation quizlet	5778
8015	Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Intuitively, underfitting occurs when the model or the algorithm does not fit the data well enough. Specifically, underfitting occurs if the model or algorithm shows low variance but high bias.	What is underfitting in machine learning	8015
1943	7 steps to improve your data structure and algorithm skillsStep 1: Understand Depth vs. Breadth.Step 2: Start the Depth-First Approach—make a list of core questions.Step 3: Master each data structure.Step 4: Spaced Repetition.Step 5: Isolate techniques that are reused. Isolate actual code blocks.Step 6: Now, it's time for Breadth.Step 7: Practice on paper.	How do you get really good at algorithms	1943
1589	The receptive field size of a unit can be increased in a number of ways. One option is to stack more layers to make the network deeper, which increases the receptive field size linearly by theory, as each extra layer increases the receptive field size by the kernel size.	How do you increase receptive fields	1589
9924	A Neural Network has got non linear activation layers which is what gives the Neural Network a non linear element. The function for relating the input and the output is decided by the neural network and the amount of training it gets.  Similarly, a complex enough neural network can learn any function.	Which gives nonlinearity to a neural network	9924
8378	Center: The center is not affected by sample size. The mean of the sample means is always approximately the same as the population mean µ = 3,500. Spread: The spread is smaller for larger samples, so the standard deviation of the sample means decreases as sample size increases.	What effect does the sample size have on the standard deviation of all possible sample means	8378
4094	After a performing a test, scientists can: Reject the null hypothesis (meaning there is a definite, consequential relationship between the two phenomena), or. Fail to reject the null hypothesis (meaning the test has not identified a consequential relationship between the two phenomena)	What is the meaning of a null hypothesis being rejected	4094
2350	The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(∗). Both functions will take any number and rescale it to fall between 0 and 1.	What is the difference between probit and logistic regression	2350
3391	There is a layer of input nodes, a layer of output nodes, and one or more intermediate layers. The interior layers are sometimes called “hidden layers” because they are not directly observable from the systems inputs and outputs.	Why is it called hidden layer	3391
1752	Model calibration is the process of adjustment of the model parameters and forcing within the margins of the uncertainties (in model parameters and / or model forcing) to obtain a model representation of the processes of interest that satisfies pre-agreed criteria (Goodness-of-Fit or Cost Function).	What is model calibration	1752
8366	A GLM consists of three components: A random component, A systematic component, and. A link function.	What are the three components of a generalized linear model	8366
4662	A p-value that is calculated using an approximation to the true distribution is called an asymptotic p-value.  A p-value calculated using the true distribution is called an exact p-value. For large sample sizes, the exact and asymptotic p-values are very similar.	What is an exact p value	4662
4113	Empirical Relationship between Mean, Median and Mode In case of a moderately skewed distribution, the difference between mean and mode is almost equal to three times the difference between the mean and median. Thus, the empirical mean median mode relation is given as: Mean – Mode = 3 (Mean – Median)	What is the relation between mean mode median	4113
4738	Correlation is a statistical measure that expresses the extent to which two variables are linearly related (meaning they change together at a constant rate).	What correlation means statistics	4738
9278	Definition: Stratified sampling is a type of sampling method in which the total population is divided into smaller groups or strata to complete the sampling process. The strata is formed based on some common characteristics in the population data.	What is a stratified sampling method	9278
9283	ReLU is important because it does not saturate; the gradient is always high (equal to 1) if the neuron activates. As long as it is not a dead neuron, successive updates are fairly effective. ReLU is also very quick to evaluate.	Why do we use ReLU in CNN	9283
10268	The confidence interval (CI) is a range of values that's likely to include a population value with a certain degree of confidence. It is often expressed a % whereby a population means lies between an upper and lower interval.	What is a confidence interval in statistics	10268
10698	As a rule of thumb, I'd say that SVMs are great for relatively small data sets with fewer outliers.  Also, deep learning algorithms require much more experience: Setting up a neural network using deep learning algorithms is much more tedious than using an off-the-shelf classifiers such as random forests and SVMs.	Is SVM deep learning	10698
4872	To minimize or avoid performance bias, investigators can consider cluster stratification of patients, in which all patients having an operation by one surgeon or at one hospital are placed into the same study group, as opposed to placing individual patients into groups.	How can we prevent investigators bias	4872
9649	Regression is a statistical method used in finance, investing, and other disciplines that attempts to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables).	What does regression explain	9649
5597	Events A and B are independent if: knowing whether A occured does not change the probability of B. Mathematically, can say in tw. Page 1. Events A and B are independent if: knowing whether A occured does not change the probability of B.	What does it mean for two events A and B to be statistically independent	5597
5513	An independent random variable is a random variable that doesn't have an effect on the other random variables in your experiment. In other words, it doesn't affect the probability of another event happening.	What does it mean for random variables to be independent	5513
6136	For example, a collaborative filtering recommendation system for television tastes could make predictions about which television show a user should like given a partial list of that user's tastes (likes or dislikes). Note that these predictions are specific to the user, but use information gleaned from many users.	What are some examples of user information required by recommendation engines that use collaborative filtering	6136
33	Selection Sort in CExample of Selection Sort.Algorithm for Selection Sort:Step 1 − Set min to the first location.Step 2 − Search the minimum element in the array.Step 3 – swap the first location with the minimum value in the array.Step 4 – assign the second element as min.Step 5 − Repeat the process until we get a sorted array.More items•	How do you write an algorithm for a selection sort	33
1048	Activation functions cannot be linear because neural networks with a linear activation function are effective only one layer deep, regardless of how complex their architecture is.  Therefore, nonlinear functions must be continuous and differentiable between this range.	Why activation functions are nonlinear in deep learning	1048
8246	Precision refers to how close estimates from different samples are to each other. For example, the standard error is a measure of precision. When the standard error is small, estimates from different samples will be close in value; and vice versa.	What is sample precision	8246
4291	0:3910:15Suggested clip · 118 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip	How do you run a regression with multiple variables	4291
4842	For the alternative formulation, where X is the number of trials up to and including the first success, the expected value is E(X) = 1/p = 1/0.1 = 10. For example 1 above, with p = 0.6, the mean number of failures before the first success is E(Y) = (1 − p)/p = (1 − 0.6)/0.6 = 0.67.	What is the expected value of a geometric random variable	4842
7909	Solve each equation to get a solution to the binomial. For x^2 - 9 = 0, for example, x - 3 = 0 and x + 3 = 0. Solve each equation to get x = 3, -3. If one of the equations is a trinomial, such as x^2 + 2x + 4 = 0, solve it using the quadratic formula, which will result in two solutions (Resource).	How do you solve a binomial equation	7909
6244	Two classes of digital filters are Finite Impulse Response (FIR) and Infinite Impulse Response (IIR). The term 'Impulse Response' refers to the appearance of the filter in the time domain.  The mathematical difference between the IIR and FIR implementation is that the IIR filter uses some of the filter output as input.	What is FIR and IIR filter	6244
7079	Discriminant function analysis (DFA) is a statistical procedure that classifies unknown individuals and the probability of their classification into a certain group (such as sex or ancestry group). Discriminant function analysis makes the assumption that the sample is normally distributed for the trait.	What is a discriminant function analysis	7079
1338	Mentor: Well, if the line is a good fit for the data then the residual plot will be random. However, if the line is a bad fit for the data then the plot of the residuals will have a pattern.	How can you tell if a residual plot is a good fit for the data	1338
5866	The common application of indicators is the detection of end points of titrations. The colour of an indicator alters when the acidity or the oxidizing strength of the solution, or the concentration of a certain chemical species, reaches a critical range of values.	What is the function of the indicator	5866
6293	The number of bootstrap samples can be indicated with B (e.g. if you resample 10 times then B = 10). A star next to a statistic, like s* or x̄* indicates the statistic was calculated by resampling. A bootstrap statistic is sometimes denoted with a T, where T*b would be the Bth bootstrap sample statistic T.	How does bootstrap determine sample size	6293
5238	“The distinction between white label and private label are subtle,” he writes. “That's why these terms are so easily confused. Private label is a brand sold exclusively in one retailer, for example, Equate (WalMart). White label is a generic product, which is sold to multiple retailers like generic ibuprofen (Advil).”	Whats the difference between private label and white label	5238
3260	Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters.	What is maximum likelihood hypothesis in machine learning	3260
9619	Advertisements. Interpolation search is an improved variant of binary search. This search algorithm works on the probing position of the required value. For this algorithm to work properly, the data collection should be in a sorted form and equally distributed.	What is interpolation search in data structure	9619
9952	The hierarchical cluster analysis follows three basic steps: 1) calculate the distances, 2) link the clusters, and 3) choose a solution by selecting the right number of clusters. First, we have to select the variables upon which we base our clusters.	How do you do a cluster analysis	9952
5282	Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function.  You start by defining the initial parameter's values and from there gradient descent uses calculus to iteratively adjust the values so they minimize the given cost-function.	How does gradient descent work	5282
9136	Abnormal BRCA1 and BRCA2 genes are found in 5% to 10% of all breast cancer cases in the United States. A study found that women with an abnormal BRCA1 gene had a worse prognosis than women with an abnormal BRCA2 gene 5 years after diagnosis.	Which is worse brca1 or brca2	9136
10471	Under the batch processing model, a set of data is collected over time, then fed into an analytics system. In other words, you collect a batch of information, then send it in for processing. Under the streaming model, data is fed into analytics tools piece-by-piece. The processing is usually done in real time.	What is the difference between batch processing and stream processing	10471
6579	Let A and G be the Arithmetic Means and Geometric Means respectively of two positive numbers a and b. Then, As, a and b are positive numbers, it is obvious that A > G when G = -√ab.  This proves that the Arithmetic Mean of two positive numbers can never be less than their Geometric Means.	What is the relation between arithmetic mean and geometric mean	6579
10143	A dummy variable (aka, an indicator variable) is a numeric variable that represents categorical data, such as gender, race, political affiliation, etc.  For example, suppose we are interested in political affiliation, a categorical variable that might assume three values - Republican, Democrat, or Independent.	What is dummy variable given an example	10143
596	In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the	What is probability density function in normal distribution	596
10819	The loss given default (LGD) is an important calculation for financial institutions projecting out their expected losses due to borrowers defaulting on loans. The expected loss of a given loan is calculated as the LGD multiplied by both the probability of default and the exposure at default.	What is loss given default formula	10819
6354	There are numerous applications of integrals. Using technology such as computer software, internet sources, graphing calculators and smartphone apps can make solving integral problems easier. Some applications of integrals are: Displacement, which is the integral of velocity with respect to time.	What are the applications of integral calculus in different fields	6354
8228	In a dataset a training set is implemented to build up a model, while a test (or validation) set is to validate the model built. Data points in the training set are excluded from the test (validation) set.	What is the difference between training and test dataset	8228
8244	"When your child sits the eleven plus exam, the number of questions answered correctly decides the ""Raw Score"". If there are more than one tests, the score may be the sum of the raw scores.  A standardized test score is calculated by translating the raw score into a completely different scale."	How is 11+ standardized calculated	8244
1332	Example 1: Draw a box-and-whisker plot for the data set {3, 7, 8, 5, 12, 14, 21, 13, 18}.  The box part represents the interquartile range and represents approximately the middle 50% of all the data. The data is divided into four regions, which each represent approximately 25% of the data.	What is an example of a box plot	1332
2093	The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count.	How do we find average	2093
3341	Univariate analysis, looking at single variables, is typically the first procedure one does when examining first time data.  The SPSS tools for looking at single variables include the following procedures: Frequencies, Descriptives and Explore all located under the Analyze menu.	What is univariate analysis in SPSS	3341
6312	Standardization isn't required for logistic regression. The main goal of standardizing features is to help convergence of the technique used for optimization.  Otherwise, you can run your logistic regression without any standardization treatment on the features.	Does logistic regression require feature scaling	6312
4777	The law of large numbers is a theorem from probability and statistics that suggests that the average result from repeating an experiment multiple times will better approximate the true or expected underlying result. The law of large numbers explains why casinos always make money in the long run.	Why does the law of large numbers work	4777
6640	When observed outcome of dependent variable can have multiple possible types then logistic regression will be multinomial.	When the observed outcome of dependent variable can have multiple possible types Then the logistic regression is	6640
827	The k-means clustering algorithm attempts to split a given anonymous data set (a set containing no information as to class identity) into a fixed number (k) of clusters.  The resulting classifier is used to classify (using k = 1) the data and thereby produce an initial randomized set of clusters.	How K means algorithm works	827
189	This means when calculating the output of a node, the inputs are multiplied by weights, and a bias value is added to the result. The bias value allows the activation function to be shifted to the left or right, to better fit the data.  You can think of the bias as a measure of how easy it is to get a node to fire.	What is bias value why it is used	189
2211	Linear Regression Analysis consists of more than just fitting a linear line through a cloud of data points. It consists of 3 stages – (1) analyzing the correlation and directionality of the data, (2) estimating the model, i.e., fitting the line, and (3) evaluating the validity and usefulness of the model.	What are the steps in regression analysis	2211
10724	There are various ways to modify a study design to actively exclude or control confounding variables (3) including Randomization, Restriction and Matching. In randomization the random assignment of study subjects to exposure categories to breaking any links between exposure and confounders.	How do you control a confounding variable in regression	10724
5766	Analysis of covariance (ANCOVA) is a general linear model which blends ANOVA and regression.  Mathematically, ANCOVA decomposes the variance in the DV into variance explained by the CV(s), variance explained by the categorical IV, and residual variance.	What does analysis of covariance mean	5766
4488	Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items•	How do you choose the best regression model in R	4488
3587	There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.	How do you find K for K means	3587
10641	The normal curve is called Mesokurtic curve. If the curve of a distribution is peaked than a normal or mesokurtic curve then it is referred to as a Leptokurtic curve. If a curve is less peaked than a normal curve, it is called as a Platykurtic curve. That's why kurtosis of normal distribution equal to three.	Why kurtosis of normal distribution is 3	10641
1403	Spatial mining is the extraction of knowledge/spatial relationship and interesting measures that are not explicitly stored in spatial database. Temporal mining is the extraction of knowledge about occurrence of an event whether they follow Cyclic , Random ,Seasonal variations etc.	What is temporal and spatial data mining	1403
1032	In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.	What does a parametric test mean	1032
1631	Ordinary least squares assumes things like equal variance of the noise at every x location. Generalized least squares does not assume a diagonal co-variance matrix.	What is the difference between ordinary least squares and generalized least squares	1631
5313	Agents can be grouped into four classes based on their degree of perceived intelligence and capability :Simple Reflex Agents.Model-Based Reflex Agents.Goal-Based Agents.Utility-Based Agents.Learning Agent.	What are the different types of agents in artificial intelligence	5313
5026	The T distribution is similar to the normal distribution, just with fatter tails. Both assume a normally distributed population. T distributions have higher kurtosis than normal distributions. The probability of getting values very far from the mean is larger with a T distribution than a normal distribution.	How is the t distribution related to the normal distribution	5026
9513	In AI, the study on perception is mostly focused on the reproduction of human perception, especially on the perception of aural and visual signals. However, this is not necessarily the case since the perception mechanism of a computer system does not have to be identical to that of a human being.	What is the perception of AI	9513
1844	There are multiple ways to select a good starting point for the learning rate. A naive approach is to try a few different values and see which one gives you the best loss without sacrificing speed of training. We might start with a large value like 0.1, then try exponentially lower values: 0.01, 0.001, etc.	How do you determine learning rate	1844
971	Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.	What is Overfitting in deep learning	971
3578	The normal distribution is a continuous probability distribution. This has several implications for probability. The total area under the normal curve is equal to 1. The probability that a normal random variable X equals any particular value is 0.	Is normal distribution continuous or discrete	3578
147	The general regression tree building methodology allows input variables to be a mixture of continuous and categorical variables. A decision tree is generated when each decision node in the tree contains a test on some input variable's value. The terminal nodes of the tree contain the predicted output variable values.	What is regression tree in machine learning	147
6114	Improve your model accuracy by Transfer Learning.Loading data using python libraries.Preprocess of data which includes reshaping, one-hot encoding and splitting.Constructing the model layers of CNN followed by model compiling, model training.Evaluating the model on test data.Finally, predicting the correct and incorrect labels.	How can transfer learning improve accuracy	6114
7011	Steps for Making decision treeGet list of rows (dataset) which are taken into consideration for making decision tree (recursively at each nodes).Calculate uncertanity of our dataset or Gini impurity or how much our data is mixed up etc.Generate list of all question which needs to be asked at that node.More items•	How do you use the decision tree in machine learning	7011
246	AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability.  By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.	What is the difference between AUC and ROC	246
6361	Qualities of a Good Sampling FrameInclude all individuals in the target population.Exclude all individuals not in the target population.Includes accurate information that can be used to contact selected individuals.	How do you determine a sampling frame	6361
6891	Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.	What is Adam Optimiser	6891
5927	The joint probability is symmetrical, meaning that P(A and B) is the same as P(B and A). The calculation using the conditional probability is also symmetrical, for example: P(A and B) = P(A given B)	How do you find conditional probability from joint probability	5927
2872	Generally, a machine learning pipeline describes or models your ML process: writing code, releasing it to production, performing data extractions, creating training models, and tuning the algorithm. An ML pipeline should be a continuous process as a team works on their ML platform.	What is a pipeline in machine learning	2872
935	A relative frequency distribution shows the proportion of the total number of observations associated with each value or class of values and is related to a probability distribution, which is extensively used in statistics.	How do you describe the relative frequency distribution	935
8650	In ideal conditions, facial recognition systems can have near-perfect accuracy. Verification algorithms used to match subjects to clear reference images (like a passport photo or mugshot) can achieve accuracy scores as high as 99.97% on standard assessments like NIST's Facial Recognition Vendor Test (FRVT).	How good is facial recognition	8650
6163	Blocks and strata are different. Blocking refers to classifying experimental units into blocks whereas stratification refers to classifying individuals of a population into strata. The samples from the strata in a stratified random sample can be the blocks in an experiment.	In Experimental Design what is the difference between blocking and stratified sampling	6163
6854	People also want to know what professions will be most in demand.  This is known as a reward function that will allow AI platforms to come to conclusions instead of arriving at a prediction. Reward Functions are used for reinforcement learning models. Reward Function Engineering determines the rewards for actions.	What is reward in reinforcement learning	6854
9741	For a random variable yt, the unconditional mean is simply the expected value, E ( y t ) . In contrast, the conditional mean of yt is the expected value of yt given a conditioning set of variables, Ωt. A conditional mean model specifies a functional form for E ( y t | Ω t ) . .	What is a conditional mean in regression	9741
8279	Exponential beta value is interpreted with the reference category, where the probability of the dependent variable will increase or decrease. In continuous variables, it is interpreted with one unit increase in the independent variable, corresponding to the increase or decrease of the units of the dependent variable.	What is beta in logistic regression	8279
4710	The three different ways of feature extraction are horizontal direction, vertical direction and diagonal direction. Recognition rate percentage for vertical, horizontal and diagonal based feature extraction using feed forward back propagation neural network as classification phase are 92.69, 93.68, 97.80 respectively.	What are the feature extraction techniques in image processing	4710
9812	Means and Variances of Random Variables: The mean of a discrete random variable, X, is its weighted average. Each value of X is weighted by its probability. To find the mean of X, multiply each value of X by its probability, then add all the products. The mean of a random variable X is called the expected value of X.	How do you find the discrete random variable	9812
837	Prior probability, in Bayesian statistical inference, is the probability of an event before new data is collected. This is the best rational assessment of the probability of an outcome based on the current knowledge before an experiment is performed.	What is prior probability in statistics	837
3458	Answer. A negative path loading is basically the same as a negative regression coefficient. I.e., For a path loading from X to Y it is the predicted increase in Y for a one unit increase on X holding all other variables constant. So a negative coefficient just means that as X increases, Y is predicted to decrease.	What does a negative path coefficient mean	10418
459	With supervised learning, you have features and labels. The features are the descriptive attributes, and the label is what you're attempting to predict or forecast.  Thus, for training the machine learning classifier, the features are customer attributes, the label is the premium associated with those attributes.	What is feature and label in machine learning	459
593	Get startedPrepare your TensorBoard logs. (or download a sample from here).Upload the logs. Install the latest version of TensorBoard to use the uploader. $ pip install -U tensorboard.  View your experiment on TensorBoard. dev. Follow the link provided to view your experiment, or share it with others.	How do you share a TensorBoard	593
10442	General Properties of Probability Distributions The sum of all probabilities for all possible values must equal 1. Furthermore, the probability for a particular value or range of values must be between 0 and 1. Probability distributions describe the dispersion of the values of a random variable.	What are the two properties of a probability distribution	10442
456	Sequential minimal optimization (SMO) is an algorithm for solving the quadratic programming (QP) problem that arises during the training of support-vector machines (SVM).  SMO is widely used for training support vector machines and is implemented by the popular LIBSVM tool.	What is SMO in machine learning	456
5815	A logarithmic scale (or log scale) is a way of displaying numerical data over a very wide range of values in a compact way—typically the largest numbers in the data are hundreds or even thousands of times larger than the smallest numbers.	What does a logarithmic scale look like	5815
10021	Explainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution can be understood by humans.	What is explainable machine learning	10021
227	is that maximin is in decision theory and game theory etc, a rule to identify the worst outcome of each possible option to find one's best (maximum payoff) play while minimax is in decision theory, game theory, etc a decision rule used for minimizing the maximum possible loss, or maximizing the minimum gain.	What is the difference between Minimax and Maximin	227
7635	"The normal distribution, commonly known as the bell curve, occurs throughout statistics. It is actually imprecise to say ""the"" bell curve in this case, as there are an infinite number of these types of curves. Above is a formula that can be used to express any bell curve as a function of x."	What is the equation of a bell curve	7635
10213	"At a bare minimum, collect around 1000 examples. For most ""average"" problems, you should have 10,000 - 100,000 examples. For “hard” problems like machine translation, high dimensional data generation, or anything requiring deep learning, you should try to get 100,000 - 1,000,000 examples."	How much data do you need for machine learning	10213
4088	In a skewed distribution, the upper half and the lower half of the data have a different amount of spread, so no single number such as the standard deviation could describe the spread very well.	How does skew affect standard deviation	4088
2526	For example, a random variable could be the outcome of the roll of a die or the flip of a coin. A probability distribution is a list of all of the possible outcomes of a random variable along with their corresponding probability values.	What is the difference between random variable and probability distribution	2526
10953	A quantile defines a particular part of a data set, i.e. a quantile determines how many values in a distribution are above or below a certain limit. Special quantiles are the quartile (quarter), the quintile (fifth) and percentiles (hundredth).	What does a quantile mean	10953
10310	A loss function is used to optimize a machine learning algorithm. The loss is calculated on training and validation and its interpretation is based on how well the model is doing in these two sets.  An accuracy metric is used to measure the algorithm's performance in an interpretable way.	What is validation Loss and Validation accuracy	10310
2257	The standard normal or z-distribution assumes that you know the population standard deviation. The t-distribution is based on the sample standard deviation.	How does the t distribution differ from the z distribution	2257
477	"Sanderson points out in her book Social Psychology, confirmation bias also helps form and re-confirm stereotypes we have about people:3﻿ ""We also ignore information that disputes our expectations."	What role does confirmation bias play in stereotyping	477
10890	"Logistic regression can be binomial, ordinal or multinomial. Binomial or binary logistic regression deals with situations in which the observed outcome for a dependent variable can have only two possible types, ""0"" and ""1"" (which may represent, for example, ""dead"" vs. ""alive"" or ""win"" vs. ""loss"")."	What are the types of logistic regression	10890
2977	Mini-Max Algorithm in Artificial Intelligence. Mini-max algorithm is a recursive or backtracking algorithm which is used in decision-making and game theory. It provides an optimal move for the player assuming that opponent is also playing optimally.  This Algorithm computes the minimax decision for the current state.	What is Minimax algorithm in AI	2977
835	6:3017:57Suggested clip · 93 secondsSAS - Logistic Regression - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you run a logistic regression in SAS	835
8572	Loss functions in neural networks The loss function is what SGD is attempting to minimize by iteratively updating the weights in the network. At the end of each epoch during the training process, the loss will be calculated using the network's output predictions and the true labels for the respective input.	What is loss in neural network training	8572
10847	It does this by using a means of representing knowledge called, semantic networks. These use graphical methods to describe relationships between concepts and events to describe common sense activities.	How is common sense knowledge represented	10847
10992	The neuron is the basic working unit of the brain, a specialized cell designed to transmit information to other nerve cells, muscle, or gland cells. Neurons are cells within the nervous system that transmit information to other nerve cells, muscle, or gland cells. Most neurons have a cell body, an axon, and dendrites.	What are the functions of neurons	10992
8987	Association between two variables means the values of one variable relate in some way to the values of the other. Association is usually measured by correlation for two continuous variables and by cross tabulation and a Chi-square test for two categorical variables.	What is an association between two variables	8987
536	The training data is an initial set of data used to help a program understand how to apply technologies like neural networks to learn and produce sophisticated results.  Training data is also known as a training set, training dataset or learning set.	What is a training set in data mining	536
3986	The range is the distance from the highest value to the lowest value. The Inter-Quartile Range is quite literally just the range of the quartiles: the distance from the largest quartile to the smallest quartile, which is IQR=Q3-Q1.	How do you compare the interquartile range and range	3986
7400	The binomial theorem is an algebraic method of expanding a binomial expression. Essentially, it demonstrates what happens when you multiply a binomial by itself (as many times as you want). For example, consider the expression (4x+y)7 ( 4 x + y ) 7 .	What is binomial expansion method	7400
6435	1.96	What is the z value in Wilcoxon signed rank test	6435
9249	A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.	Why Max pooling is used in CNN	9249
6303	Repeating patterns often show serial correlation when the level of a variable affects its future level. In finance, this correlation is used by technical analysts to determine how well the past price of a security predicts the future price. Serial correlation is also known as autocorrelation or lagged correlation.	What does autocorrelation or serial correlation imply	6303
2366	In unsupervised learning, there is no training data set and outcomes are unknown. Essentially the AI goes into the problem blind – with only its faultless logical operations to guide it.	Does unsupervised learning need training data	2366
8358	The normal distribution can be used as an approximation to the binomial distribution, under certain circumstances, namely: If X ~ B(n, p) and if n is large and/or p is close to ½, then X is approximately N(np, npq)	Can the normal distribution be used to approximate this probability	8358
10399	Improving recall involves adding more accurately tagged text data to the tag in question. In this case, you are looking for the texts that should be in this tag but are not, or were incorrectly predicted (False Negatives). The best way to find these kind of texts is to search for them using keywords.	How do you increase recall in machine learning	10399
4512	Top 10 Data Analytics toolsR Programming. R is the leading analytics tool in the industry and widely used for statistics and data modeling.  Tableau Public:  SAS:  Apache Spark.  Excel.  RapidMiner:KNIME.  QlikView.More items•	What are the tools used in data analysis	4512
220	It is a rate per unit of time similar in meaning to reading a car speedometer at a particular instant and seeing 45 mph.  The failure rate (or hazard rate) is denoted by h(t) and is calculated from h(t) = \frac{f(t)}{1 - F(t)} = \frac{f(t)}{R(t)} = \mbox{the instantaneous (conditional) failure rate.}	How are hazard rates calculated	220
6979	The main difference is obviously that, in a first order reaction, the order of reaction is one by nature. A pseudo first-order reaction is second order reaction by nature but has been altered to make it a first order reaction.	What is the difference between first order and pseudo first order reactions	6979
241	8:3514:50Suggested clip · 95 secondsLecture 6.3 — Logistic Regression | Decision Boundary — [ Machine YouTubeStart of suggested clipEnd of suggested clip	How do you determine the decision boundary in logistic regression	241
8198	Some of the methods commonly used for binary classification are:Decision trees.Random forests.Bayesian networks.Support vector machines.Neural networks.Logistic regression.Probit model.	What are some binary classification algorithms	8198
2052	As the name implies, multivariate regression is a technique that estimates a single regression model with more than one outcome variable. When there is more than one predictor variable in a multivariate regression model, the model is a multivariate multiple regression.	What is meant by multivariate regression analysis	2052
3623	A statistic is biased if it is calculated in such a way that it is systematically different from the population parameter being estimated. The following lists some types of biases, which can overlap. Selection bias involves individuals being more likely to be selected for study than others, biasing the sample.	What does it mean if a statistic is biased	3623
5736	Cross Entropy is definitely a good loss function for Classification Problems, because it minimizes the distance between two probability distributions - predicted and actual.  So cross entropy make sure we are minimizing the difference between the two probability. This is the reason.	Why do we use cross entropy loss	5736
6008	SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.	Why is SVM used for image classification	6008
6180	Neural style transfer is trained as a supervised learning task in which the goal is to input two images (x), and train a network to output a new, synthesized image (y).	Is neural style transfer supervised learning	6180
9780	"At a bare minimum, collect around 1000 examples. For most ""average"" problems, you should have 10,000 - 100,000 examples. For “hard” problems like machine translation, high dimensional data generation, or anything requiring deep learning, you should try to get 100,000 - 1,000,000 examples."	How many observations do you need for machine learning	9780
3691	Both skew and kurtosis can be analyzed through descriptive statistics. Acceptable values of skewness fall between − 3 and + 3, and kurtosis is appropriate from a range of − 10 to + 10 when utilizing SEM (Brown, 2006).	What kurtosis is acceptable	3691
9252	At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional to the square of the β values, while the L1 norm is proportional the absolute value of the values in β.	What is the difference between l1 and l2 norm	9252
85	While there are a number of different methods for measuring intelligence, the standard and most widely accepted method is by measuring a person's 'intelligence quotient' or IQ. Based on a series of tests which assess various types of abilities such a mathematical, spatial, verbal, logic and memory.	How do you assess your own level of intelligence	85
9855	If a and b are two non-zero numbers, then the harmonic mean of a and b is a number H such that the numbers a, H, b are in H.P. We have H = 1/H = 1/2 (1/a + 1/b) ⇒ H = 2ab/a+b.	What is harmonic mean of A and B	9855
10648	A control group is a set of experimental samples or subjects that are kept separate and aren't exposed to the independent variable.  A controlled experiment is one in which every parameter is held constant except for the experimental (independent) variable.	What is the difference between a control variable and a control group	10648
2784	In behavioral finance, base rate fallacy is the tendency for people to erroneously judge the likelihood of a situation by not taking into account all relevant data. Instead, investors might focus more heavily on new information without acknowledging how this impacts original assumptions.	What is the base rate fallacy and why is it important to avoid it	2784
448	"The obvious difference between ANOVA and ANCOVA is the the letter ""C"", which stands for 'covariance'. Like ANOVA, ""Analysis of Covariance"" (ANCOVA) has a single continuous response variable. ANCOVA is also commonly used to describe analyses with a single response variable, continuous IVs, and no factors."	What is the difference between Anova and Ancova tests	448
8453	1 Answer. In word2vec, you train to find word vectors and then run similarity queries between words. In doc2vec, you tag your text and you also get tag vectors.  If two authors generally use the same words then their vector will be closer.	How is Doc2Vec different from word2vec	8453
6228	The base rate fallacy occurs when prototypical or stereotypical factors are used for analysis rather than actual data. Because the student is volunteering in a hospital with a stroke center, he sees more patients who have experienced a stroke than would be expected in a hospital without a stroke center.	What is base rate fallacy MCAT	6228
9921	6 Steps To Write Any Machine Learning Algorithm From Scratch: Perceptron Case StudyGet a basic understanding of the algorithm.Find some different learning sources.Break the algorithm into chunks.Start with a simple example.Validate with a trusted implementation.Write up your process.	How do you create a learning algorithm	9921
2164	OLS cannot be used because the regression function is not a linear function of the regression coefficients (the coefficients appear inside the nonlinear functions Φ or Λ).	Why are the coefficients of probit and logit models estimated by maximum likelihood instead of OLS	2164
689	0:008:33Suggested clip · 112 secondsHow to read a log scale. - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you read a log scale	689
1177	The Poisson distribution has the following characteristics: It is a discrete distribution. Each occurrence is independent of the other occurrences. It describes discrete occurrences over an interval. The occurrences in each interval can range from zero to infinity.	What is Poisson distribution and its characteristics	1177
9877	SVM Kernel Functions SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel is to take data as input and transform it into the required form.  For example linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid.	What are SVM kernels	9877
3384	Parametric tests assume underlying statistical distributions in the data. Nonparametric tests do not rely on any distribution.  They can thus be applied even if parametric conditions of validity are not met.	What is the difference between parametric and nonparametric tests	3384
781	In probability theory and statistics, a categorical distribution (also called a generalized Bernoulli distribution, multinoulli distribution) is a discrete probability distribution that describes the possible results of a random variable that can take on one of K possible categories, with the probability of each	How do you describe a categorical distribution	781
2017	In addition every algorithm must satisfy the following criteria:input: there are zero or more quantities which are externally supplied;output: at least one quantity is produced;definiteness: each instruction must be clear and unambiguous;More items	What are two important criteria for algorithms	2017
7671	Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.	What is the use of tokenization in NLP	7671
6089	Yes, although 'linear regression' refers to any approach to model the relationship between one or more variables, OLS is the method used to find the simple linear regression of a set of data.	Is OLS the same as linear regression	6089
2437	The Boruta algorithm is a wrapper built around the random forest classification algorithm. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. First, it duplicates the dataset, and shuffle the values in each column.	How does Boruta algorithm work	2437
8421	Introduction[edit] Shift Invariance simply refers to the 'invariance' that a CNN has to recognising images. It allows the CNN to detect features/objects even if it does not look exactly like the images in it's training period. Shift invariance covers 'small' differences, such as movements shifts of a couple of pixels.	What is spatial invariance in CNN	8421
4549	fastText is a library for efficient learning of word representations and sentence classification. In this document we present how to use fastText in python.	What is fastText in Python	4549
1118	The SMD is preferable when the studies in a meta-analysis measure a given outcome using different scales or instruments.	What is the main advantage of the standardized mean difference SMD over the mean difference MD )	1118
7102	A histogram is a graphical display of data using bars of different heights. In a histogram, each bar groups numbers into ranges. Taller bars show that more data falls in that range. A histogram displays the shape and spread of continuous sample data.	How does a histogram work	7102
952	Unsupervised learning is very useful in exploratory analysis because it can automatically identify structure in data.  Dimensionality reduction, which refers to the methods used to represent data using less columns or features, can be accomplished through unsupervised methods.	Why unsupervised learning is important	952
5092	1. A numerical value that defines the learning capability of a neural network during training. Learn more in: Voltage Instability Detection Using Neural Networks.	What is learning coefficient	5092
2882	Output is defined as the act of producing something, the amount of something that is produced or the process in which something is delivered. An example of output is the electricity produced by a power plant. An example of output is producing 1,000 cases of a product.	What output means	2882
4240	To calculate the learnable parameters here, all we have to do is just multiply the by the shape of width m, height n, previous layer's filters d and account for all such filters k in the current layer. Don't forget the bias term for each of the filter.	How are learnable parameters calculated CNN	4240
7397	"ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a ""failure"" (0) or a ""success"" (1).  Your observed outcome in logistic regression can ONLY be 0 or 1. The predicted probabilities from the model can take on all possible values between 0 and 1."	What is ROC in logistic regression	7397
3892	Image processing is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.	What is image processing used for	3892
3806	Bayesian neural networks differ from plain neural networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions.	What are Bayesian neural networks	3806
2121	Precision is a metric that quantifies the number of correct positive predictions made. Precision, therefore, calculates the accuracy for the minority class. It is calculated as the ratio of correctly predicted positive examples divided by the total number of positive examples that were predicted.	How do you find the accuracy of a precision and recall	2121
8504	In an economic model, an exogenous variable is one whose value is determined outside the model and is imposed on the model, and an exogenous change is a change in an exogenous variable. In contrast, an endogenous variable is a variable whose value is determined by the model.	What is the difference between an exogenous variable and an endogenous variable	8504
8472	The slope of a least squares regression can be calculated by m = r(SDy/SDx). In this case (where the line is given) you can find the slope by dividing delta y by delta x. So a score difference of 15 (dy) would be divided by a study time of 1 hour (dx), which gives a slope of 15/1 = 15.	How do you interpret the slope of the least squares regression line	8472
3209	A hierarchical linear regression is a special form of a multiple linear regression analysis in which more variables are added to the model in separate steps called “blocks.” This is often done to statistically “control” for certain variables, to see whether adding variables significantly improves a model's ability to	What is a hierarchical regression analysis	3209
10322	A non-convex optimization problem is any problem where the objective or any of the constraints are non-convex, as pictured below. Such a problem may have multiple feasible regions and multiple locally optimal points within each region.	What is Nonconvex optimization	10322
3029	Enneagram test results are very accurate for determining your enneagram type and the MBTI test results are quite accurate for determining your MBTI type. Neither is in competition with the other. That being said, it can be very interesting to have the results for both of these uniquely different typologies.	Which is more accurate MBTI and Enneagram	3029
3188	The odds ratio tells us how much higher the odds of exposure are among case-patients than among controls. An odds ratio of • 1.0 (or close to 1.0) indicates that the odds of exposure among case-patients are the same as, or similar to, the odds of exposure among controls. The exposure is not associated with the disease.	What does an odds ratio of 1.0 mean	3188
9831	A statistic is a number that represents a property of the sample. For example, if we consider one math class to be a sample of the population of all math classes, then the average number of points earned by students in that one math class at the end of the term is an example of a statistic.	What is an example of an statistic	9831
546	1 Answer. 1. 8. Without math: The delta rule uses gradient descent to minimize the error from a perceptron network's weights. Gradient descent is a general algorithm that gradually changes a vector of parameters in order to minimize an objective function.	What is gradient descent and Delta Rule	546
7818	Types of predictive modelsForecast models. A forecast model is one of the most common predictive analytics models.  Classification models.  Outliers Models.  Time series model.  Clustering Model.  The need for massive training datasets.  Properly categorising data.	What are the types of predictive models	7818
5327	"The correct interpretation of a 95% confidence interval is that ""we are 95% confident that the population parameter is between X and X."""	How do you interpret a confidence interval	5327
8273	Logarithmic Loss, or simply Log Loss, is a classification loss function often used as an evaluation metric in Kaggle competitions.  Log Loss quantifies the accuracy of a classifier by penalising false classifications.	What is log loss function	8273
5153	In review, beta-endorphins are proteins that are primarily synthesized by the pituitary gland in response to physiologic stressors such as pain. They function through various mechanisms in both the central and peripheral nervous system to relieve pain when bound to their mu-opioid receptors.	What releases beta endorphins	5153
8525	Q17. Which of the following is true about “Ridge” or “Lasso” regression methods in case of feature selection? “Ridge regression” will use all predictors in final model whereas “Lasso regression” can be used for feature selection because coefficient values can be zero.	Which of the following is true about Ridge or lasso regression methods in case of feature selection	8525
2881	The optimal number of clusters can be defined as follow: Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters. For each k, calculate the total within-cluster sum of square (wss). Plot the curve of wss according to the number of clusters k.	How do you define K in K means clustering	2881
2109	5 Most Important Methods For Statistical Data AnalysisMean. The arithmetic mean, more commonly known as “the average,” is the sum of a list of numbers divided by the number of items on the list.  Standard Deviation.  Regression.  Sample Size Determination.  Hypothesis Testing.	What are some of the statistical methods that are useful for data analyst	2109
4234	Binary cross-entropy is for multi-label classifications, whereas categorical cross entropy is for multi-class classification where each example belongs to a single class.	What is the difference between binary cross entropy and categorical cross entropy	4234
8458	The critical value is a factor used to compute the margin of error, as shown in the equations below. When the sampling distribution of the statistic is normal or nearly normal, the critical value can be expressed as a t score or as a z-score.	Is critical value the same as Z score	8458
9981	Examples of such greedy algorithms are Kruskal's algorithm and Prim's algorithm for finding minimum spanning trees, and the algorithm for finding optimum Huffman trees. Greedy algorithms appear in network routing as well.	What is greedy algorithm example	9981
5229	False positive rate (FPR) is a measure of accuracy for a test: be it a medical diagnostic test, a machine learning model, or something else. In technical terms, the false positive rate is defined as the probability of falsely rejecting the null hypothesis.	What does false positive rate mean	5229
5582	The sample variance is an estimator for the population variance. When applied to sample data, the population variance formula is a biased estimator of the population variance: it tends to underestimate the amount of variability.  We are using one fitted value (sample mean) in our estimate of the variance.	Why is the formula for sample variance different from the formula for population variance	5582
2783	The variance is the average of the squared differences from the mean. Standard deviation is the square root of the variance so that the standard deviation would be about 3.03.  Because of this squaring, the variance is no longer in the same unit of measurement as the original data.	Is sample variance and standard deviation the same	2783
10600	Unlike the independent-samples t-test, the Mann-Whitney U test allows you to draw different conclusions about your data depending on the assumptions you make about your data's distribution.  These different conclusions hinge on the shape of the distributions of your data, which we explain more about later.	Why use Mann Whitney U test instead of t test	10600
9211	The cumulative distribution function (CDF) of random variable X is defined as FX(x)=P(X≤x), for all x∈R.SolutionTo find the CDF, note that.  To find P(2<X≤5), we can write P(2<X≤5)=FX(5)−FX(2)=3132−34=732.  To find P(X>4), we can write P(X>4)=1−P(X≤4)=1−FX(4)=1−1516=116.	How do you find the CDF of a random variable	9211
649	The central limit theorem applies to almost all types of probability distributions, but there are exceptions. For example, the population must have a finite variance. That restriction rules out the Cauchy distribution because it has infinite variance.	Does the central limit theorem apply to variance	649
9488	"The range containing values that are consistent with the null hypothesis is the ""acceptance region""; the other range, in which the null hypothesis is rejected, is the rejection region (or critical region)."	What is the difference between critical region and acceptance region	9488
3013	Data Augmentation in play. A convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, a CNN can be invariant to translation, viewpoint, size or illumination (Or a combination of the above).	What is data augmentation in CNN	3013
9094	A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.	What does a convolutional neural network do	9094
10624	In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training.  Given these hyperparameters, the training algorithm learns the parameters from the data.	What are hyperparameters in machine learning	10624
3124	There are two stages to prediction. The first stage is training the model—this is where the tree is built, tested, and optimized by using an existing collection of data. In the second stage, you actually use the model to predict an unknown outcome.	How do you make predictions in decision trees	3124
8928	In two-dimensional signals like digital images, frequencies are rate of change of grey scale value (intensity of pixel) with respect to space. This is also called Spatial frequency .  Convert the cosine values represented by the red dots into greyscale (0-255), such that -1 maps to 0 and 1 maps to 255.	What is frequency of an image	8928
7244	If p is a probability, then p/(1 − p) is the corresponding odds; the logit of the probability is the logarithm of the odds, i.e.  For each choice of base, the logit function takes values between negative and positive infinity.	What is the logit function when P refers to probability of occurrence of an event	7244
5043	Artificial intelligence is probably the most widely-known for its application in the etail/retail industry. Conversation intelligence software helps companies interact with customers and follow up leads by analyzing and segmenting sales calls using speech recognition and natural language processing.	In which field is artificial intelligence used	5043
5959	Classification and regression tree (CART) analysis recursively partitions observations in a matched data set, consisting of a categorical (for classification trees) or continuous (for regression trees) dependent (response) variable and one or more independent (explanatory) variables, into progressively smaller groups (	What is classification and regression tree analysis	5959
4076	Systematic sampling involves selecting fixed intervals from the larger population to create the sample. Cluster sampling divides the population into groups, then takes a random sample from each cluster.	What are the differences between systematic random sampling and cluster sampling	4076
3057	Prior probability, in Bayesian statistical inference, is the probability of an event before new data is collected.	What is prior probability in machine learning	3057
1908	8 Common Data Structures every Programmer must know. A quick introduction to 8 commonly used data structures.  Arrays. An array is a structure of fixed-size, which can hold items of the same data type.  Linked Lists.  Stacks.  Queues.  Hash Tables.  Trees.  Heaps.More items	What are the topics in data structures	1908
1623	Technically, all interpreters do the same thing and follow the same basic principles. But since sign languages are visual-manual while spoken languages are based on speaking, hearing and writing/reading, the difference entails several special requirements for interpreting.	In what ways are spoken languages and signed languages the same different	1623
6980	It is a criterion under which a hypothesis tester decides whether a given hypothesis must be accepted or rejected. The general rule of thumb is that if the value of test statics is greater than the critical value then the null hypothesis is rejected in the favor of the alternate hypothesis.	What is the rejection rule	6980
3071	The basic premise of transfer learning is simple: take a model trained on a large dataset and transfer its knowledge to a smaller dataset. For object recognition with a CNN, we freeze the early convolutional layers of the network and only train the last few layers which make a prediction.	What is transfer learning in CNN	3071
3829	A significant advantage of a decision tree is that it forces the consideration of all possible outcomes of a decision and traces each path to a conclusion. It creates a comprehensive analysis of the consequences along each branch and identifies decision nodes that need further analysis.	What are the advantages of decision tree	3829
2324	Data science is the field of study that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract meaningful insights from data.	What is data science in simple words	2324
8726	While a frequency distribution gives the exact frequency or the number of times a data point occurs, a probability distribution gives the probability of occurrence of the given data point.	What is the difference between probability distribution and relative frequency distribution	8726
2782	A feature vector is a vector containing multiple elements about an object. Putting feature vectors for objects together can make up a feature space. The features may represent, as a whole, one mere pixel or an entire image. The granularity depends on what someone is trying to learn or represent about the object.	What features do vectors have	2782
10000	Based on recent research, we hypothesize that there is a neural network of consciousness in which the paraventricular nucleus formally serves as the control nucleus of arousal, which is closely related to the maintenance of consciousness, and the neurons in the posterior cerebral cortex.	Are neural networks conscious	10000
2897	Use systematic sampling when there's low risk of data manipulation. Systematic sampling is the preferred method over simple random sampling when a study maintains a low risk of data manipulation.	What is systematic sampling used for	2897
6577	mAP (mean Average Precision) for Object DetectionPrecision & recall.Precision measures how accurate is your predictions.  Recall measures how good you find all the positives.  IoU (Intersection over union)Precision is the proportion of TP = 2/3 = 0.67.Recall is the proportion of TP out of the possible positives = 2/5 = 0.4.	How do you find the accuracy of an object detection	6577
2433	Note: a Markov chain (of any order) is a stochastic recursive sequence of finite order, or equivalently an auto-regressive process of finite order (possibly nonlinear). In contrast, the martingale property does not put constraints on the order of recursion, while imposing a linear projection condition.	Is a martingale a Markov process	2433
8842	"Variables that can only take on a finite number of values are called ""discrete variables."" All qualitative variables are discrete. Some quantitative variables are discrete, such as performance rated as 1,2,3,4, or 5, or temperature rounded to the nearest degree."	Is a discrete variable	8842
3517	There are several situation in which the variable we want to explain can take only two possible values. This is typically the case when we want to model the choice of an individual.  This is why these models are called binary choice models, because they explain a (0/1) dependent variable.	What is a binary choice model	3517
7928	"The SVM typically tries to use a ""kernel function"" to project the sample points to high dimension space to make them linearly separable, while the perceptron assumes the sample points are linearly separable."	What is the difference between the perceptron learning algorithm and SVM	7928
8227	Gradient is a vector that is tangent of a function and points in the direction of greatest increase of this function. Gradient is zero at a local maximum or minimum because there is no single direction of increase. In mathematics, gradient is defined as partial derivative for every input variable of function.	What is gradient in data science	8227
408	Assuming a double-blind test is not possible, here are some techniques that can help:Standardize everything: the research protocol, the moderator script, the questions etc.  Have a second researcher monitor the first researcher.  Stay out of the participant's line of sight.  Practice.More items•	How do you remove experimenter bias	408
8959	Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. It is also widely used in meta-analysis. Cohen's d is an appropriate effect size for the comparison between two means.	What is Cohen's d in statistics	8959
531	Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.	What exactly is Artificial Intelligence	531
6655	The Poisson parameter Lambda (λ) is the total number of events (k) divided by the number of units (n) in the data (λ = k/n).  In between, or when events are infrequent, the Poisson distribution is used.	What is lambda in Poisson distribution	6655
1285	Imbalanced data typically refers to a classification problem where the number of observations per class is not equally distributed; often you'll have a large amount of data/observations for one class (referred to as the majority class), and much fewer observations for one or more other classes (referred to as the	What is the problem with imbalanced data	1285
10914	This implies that bias and variance of an estimator are complementary to each other i.e. an estimator with high bias will vary less(have low variance) and an estimator with high variance will have less bias(as it can vary more to fit/explain/estimate the data points).	What is the difference between the bias and variance of an estimator	10914
8505	Chisquare Test, Different Types and its Application using RChi-Square Test.Chi-square test of independence.2 x 2 Contingency Table.Chi-square test of significance.Chi-square Test in R.Chi Square Goodness of Fit (One Sample Test)Chi-square Goodness of Test in R.Fisher's exact test.More items•	What are the two types of chi square tests	8505
6651	The generator is a convolutional neural network and the discriminator is a deconvolutional neural network. The goal of the generator is to artificially manufacture outputs that could easily be mistaken for real data. The goal of the discriminator is to identify which outputs it receives have been artificially created.	What is the goal of a generative adversarial network Gan	6651
6245	Abstract: The k-Nearest Neighbors (kNN) classifier is one of the most effective methods in supervised learning problems. It classifies unseen cases comparing their similarity with the training data.  Fuzzy-kNN computes a fuzzy degree of membership of each instance to the classes of the problem.	What is fuzzy KNN	6245
10393	Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items•	How do you know which regression is the best	10393
7992	Correlation is the concept of linear relationship between two variables.  It is linear relationship nor any other relationship. Whereas correlation coefficient is a measure that measures linear relationship between two variables.	Is there any difference between correlation and correlation coefficient	7992
4674	RECALL is the ratio of the number of relevant records retrieved to the total number of relevant records in the database. It is usually expressed as a percentage. ──────b•d────── Page 2 PRECISION is the ratio of the number of relevant records retrieved to the total number of irrelevant and relevant records retrieved.	What is the relationship between precision and recall	4674
3236	Under simple random sampling, a sample of items is chosen randomly from a population, and each item has an equal probability of being chosen. Meanwhile, systematic sampling involves selecting items from an ordered population using a skip or sampling interval.	What is the difference between simple random sampling and systematic sampling	3236
9718	Sets can be used in calculated fields Sets can be used in calculated fields as if they were a field.  Or you can have the calculation return a specific value, or return another field instead, the main point is that they are not very different than normal dimensions in this respect.	Can we use sets in calculated fields	9718
3446	Concepts in Feature Space Given a set of features for a concept learning problem, we can interpret the feature set as a feature space. Given some data, a feature space is just the set of all possible values for a chosen set of features from that data.	What is concept space in machine learning	3446
10232	Scales effectively with data: Deep networks scale much better with more data than classical ML algorithms.  With classical ML algorithms this quick and easy fix doesn't work even nearly as well and more complex methods are often required to improve accuracy.	Can deep learning scale better	10232
5370	In addition, another reason to not initialize everything to zero is so that you get different answers. Some optimization techniques are deterministic, so if you initialize randomly, you'll get different answers each time you run it. This helps you explore the space better and avoid (other) local optima.	Why is zero initialization not a recommended weight initialization technique	5370
3221	Machine learning is more than neural networks and deep learning. It is a field with a legion of smart algorithms that deduce complex patterns and make predictions about the unknown. The robustness of Random forests is contributed to its collection of distinct decision trees, each trying to solve part of the problem.	What have you learned about machine learning	3221
3181	Probability RulesEvery probability is between zero and one. In other words, if A is an event, then 0≤P(A)≤1.The sum of the probabilities of all of the outcomes is one. In other words, if all of the outcomes in the sample space are denoted by Ai, then ∑Ai=1.Impossible events have probability zero.  Certain events have probability one.	What are the probability rules	3181
9444	A pooling or subsampling layer often immediately follows a convolution layer in CNN. Its role is to downsample the output of a convolution layer along both the spatial dimensions of height and width.	What is subsampling in CNN	9444
167	Linear Regression is a machine learning algorithm based on supervised learning. Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).  So, this regression technique finds out a linear relationship between x (input) and y(output).	How does regression algorithm work	167
3918	(retrogress) Opposite of to develop gradually. retrogress. diminish. regress.	What is the opposite of evolve	3918
8922	YOUR preferred learning style is the way in which YOU learn best. Three learning styles that are often identified in students are the Auditory Learning Style, the Visual Learning Style, and theTactile/Kinesthetic Learning Style. Read about each of these learning styles to identify YOUR preferred learning style.	What is your preferred way of learning	8922
1816	Not usually. SGD tends to perform better than using line search.	Is line search used commonly with SGD while learning the parameters for a deep neural networks	1816
1996	If r is not between the positive and negative critical values, then the correlation coefficient is significant. If r is significant, then you may want to use the line for prediction. Suppose you computed r=0.801 using n=10 data points. df=n−2=10−2=8.	Is it possible to determine the statistical significance of a correlation coefficient	1996
7670	Correlation coefficients are indicators of the strength of the relationship between two different variables. A correlation coefficient that is greater than zero indicates a positive relationship between two variables. A value that is less than zero signifies a negative relationship between two variables.	What do different correlation coefficients mean	7670
4901	"Classification is a supervised machine learning approach, in which the algorithm learns from the data input provided to it — and then uses this learning to classify new observations.  The name (""Naive"") derives from the fact that the algorithm assumes that attributes are conditionally independent."	What is classification techniques in machine learning	4901
600	Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on. If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)	How does neural network reduce loss	600
2039	This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method.	What statistics does cross validation reduce	2039
5259	High Pass RL Filter An inductor, like a capacitor, is a reactive device.  And this is why this circuit is a high-pass filter circuit. Low frequency signals, however, will go through the inductor, because inductors offer very low resistance to low-frequency, or Dc, signals.	Is inductor high pass filter	5259
7410	Clustering and Association are two types of Unsupervised learning.  Important clustering types are: 1)Hierarchical clustering 2) K-means clustering 3) K-NN 4) Principal Component Analysis 5) Singular Value Decomposition 6) Independent Component Analysis.	Which of the following is an unsupervised learning algorithm	7410
8835	Canonical correlation analysis (CCA) is very important in MVL, whose main idea is to map data from different views onto a common space with the maximum correlation. The traditional CCA can only be used to calculate the linear correlation between two views.	What is CCA in machine learning	8835
1037	In mathematics, a tensor is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors.	How do you define a tensor	1037
2621	With two-way ANOVA, you have one continuous dependent variable and two categorical grouping variables for the independent variables. MANOVA models several dependent variables simultaneously and you can include a variety of independent variables.	What is the difference between a 2 way ANOVA and a MANOVA	2621
8306	by Tim Bock. Hierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other.	What is hierarchical clustering algorithm	8306
8141	In the mathematical field of numerical analysis, interpolation is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points.  It is often required to interpolate, i.e., estimate the value of that function for an intermediate value of the independent variable.	What is interpolation algorithm	8141
7502	To find “q” or the studentized range statistic, refer to your table on page A-32 of your text. On the table 'k' or the number of groups is found along the top, and degrees of freedom within is down the side.	How do you find q in Tukey's HSD	7502
7361	Such algorithms are called greedy because while the optimal solution to each smaller instance will provide an immediate output, the algorithm doesn't consider the larger problem as a whole.  Greedy algorithms work by recursively constructing a set of objects from the smallest possible constituent parts.	Why is it called greedy algorithm	7361
7877	Multi-view data is common in real-world datasets, where different views describe distinct perspec- tives.  Multi-view data is prevalent in many real-world applications. For instance, the same news can be obtained from various language sources; an image can be described by different low level visual features.	What is multi view data	7877
7027	Perceptron networks have several limitations. First, the output values of a perceptron can take on only one of two values (0 or 1) due to the hard-limit transfer function. Second, perceptrons can only classify linearly separable sets of vectors.	What are the limitations of Perceptron	7027
6916	A vector space is a space of vectors, ie. each element is a vector. A vector field is, at its core, a function between some space and some vector space, so every point in our base space has a vector assigned to it. A good example would be wind direction maps you see on weather reports.	What is the difference between a vector field and a vector space	6916
3035	Structural equation models are often used to assess unobservable 'latent' constructs. They often invoke a measurement model that defines latent variables using one or more observed variables, and a structural model that imputes relationships between latent variables.	When would you use a structural equation model	3035
4797	AREA UNDER THE ROC CURVE In general, an AUC of 0.5 suggests no discrimination (i.e., ability to diagnose patients with and without the disease or condition based on the test), 0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding.	What is a good area under ROC curve	4797
6888	Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.	What is a grid search and why do we use it in machine learning	6888
2748	Classification and regression trees are machine-learning methods for constructing. prediction models from data. The models are obtained by recursively partitioning. the data space and fitting a simple prediction model within each partition.	What is classification and regression tree	2748
8792	A correlation close to -1 or 1 tells us that there is a strong relationship between the variables. It is useful to know this. Strictly speaking, it applies to a linear relationship, but the correlation can be high even for an obviously curvilinear relationship.	What is the advantage of a correlation coefficient	8792
4850	Step 1: Divide your confidence level by 2: .95/2 = 0.475. Step 2: Look up the value you calculated in Step 1 in the z-table and find the corresponding z-value. The z-value that has an area of .475 is 1.96. Step 3: Divide the number of events by the number of trials to get the “P-hat” value: 24/160 = 0.15.	How do you find confidence intervals	4850
5968	Computer Vision. Image processing is mainly focused on processing the raw input images to enhance them or preparing them to do other tasks. Computer vision is focused on extracting information from the input images or videos to have a proper understanding of them to predict the visual input like human brain.	What is computer vision and image processing	5968
3791	Variance plays a major role in interpreting data in statistics. The most common application of variance is in polls. For opinion polls, the data gathering agencies cannot invest in collecting data from the entire population.	How is variance used in real life	3791
8401	Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters.	What is maximum likelihood estimation in machine learning	8401
4467	In mathematics, specifically in functional analysis, each bounded linear operator on a complex Hilbert space has a corresponding Hermitian adjoint (or adjoint operator). Adjoints of operators generalize conjugate transposes of square matrices to (possibly) infinite-dimensional situations.	What is the adjoint of a linear operator	4467
3371	Adding Noise into Neural Network Neural networks are capable of learning output functions that can change wildly with small changes in input. Adding noise to inputs randomly is like telling the network to not change the output in a ball around your exact input.	What is noise in neural network	3371
1575	They have too few levels of structure: Neurons, Layers, and Whole Nets. We need to group neurons in each layer in 'capsules' that do a lot of internal computation and then output a compact result.”	What is wrong with convolutional neural nets	1575
8925	Qualities of a Good Sampling Frame Include all individuals in the target population. Exclude all individuals not in the target population. Includes accurate information that can be used to contact selected individuals.	What is a good sampling frame	8925
2382	The resulting image after applying Canny operator (b). The primary advantages of the Sobel operator lie in its simplicity. The Sobel method provides a approximation to the gradient magnitude. Another advantage of the Sobel operator is it can detect edges and their orientations.	What is the advantage of Sobel operator over Prewitt operator	2382
6847	We present a freely available open-source toolkit for training recurrent neural network based language models. It can be easily used to improve existing speech recognition and machine translation systems.	Is there a recurrent neural networks toolkit	6847
7870	Definition. The class intervals are the subsets into which the data is grouped. The width of the class intervals will be a compromise between having intervals short enough so that not all of the observations fall in the same interval, but long enough so that you do not end up with only one observation per interval.	What is class interval in statistics with example	7870
10402	A feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly.  If you accept most classes of problems can be reduced to functions, this statement implies a neural network can, in theory, solve any problem.	Can neural networks solve any problem	10402
6297	"The dissimilarity matrix, using the euclidean metric, can be calculated with the command: daisy(agriculture, metric = ""euclidean""). The result the of calculation will be displayed directly in the screen, and if you wanna reuse it you can simply assign it to an object: x <- daisy(agriculture, metric = ""euclidean"")."	How do you find the dissimilarity of a matrix	6297
5656	Face validity: Does the content of the test appear to be suitable to its aims? Criterion validity: Do the results correspond to a different test of the same thing?	What is the difference between content and criterion validity	5656
6238	In computer science, specifically in algorithms related to pathfinding, a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.	What is admissible heuristic in AI	6238
10240	In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.  Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex.	What is meant by convolution neural network	10240
8026	Average (or mean) filtering is a method of 'smoothing' images by reducing the amount of intensity variation between neighbouring pixels. The average filter works by moving through the image pixel by pixel, replacing each value with the average value of neighbouring pixels, including itself.	What is average filtering	8026
4586	The Elbow Method is more of a decision rule, while the Silhouette is a metric used for validation while clustering. Thus, it can be used in combination with the Elbow Method. Therefore, the Elbow Method and the Silhouette Method are not alternatives to each other for finding the optimal K.	Which method is not used for finding the best K in K means technique	4586
889	Normalization: Similarly, the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.  So we normalize the data to bring all the variables to the same range.	Why do we normalize data	889
9935	Naive bayes is a Generative model whereas Logistic Regression is a Discriminative model . Generative model is based on the joint probability, p( x, y), of the inputs x and the label y, and make their predictions by using Bayes rules to calculate p(y | x), and then picking the most likely label y.	Is naive Bayes generative or discriminative	9935
7055	In probability theory and statistics, the multivariate normal distribution, multivariate Gaussian distribution, or joint normal distribution is a generalization of the one-dimensional (univariate) normal distribution to higher dimensions.	What is the multivariate Gaussian distribution	7055
2086	Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.	Why does normalization work in batch	2086
6687	Summary: “OLS” stands for “ordinary least squares” while “MLE” stands for “maximum likelihood estimation.”  Maximum likelihood estimation, or MLE, is a method used in estimating the parameters of a statistical model and for fitting a statistical model to data.	What is the difference between OLS and Maximum Likelihood	6687
3575	Ensemble learning helps improve machine learning results by combining several models.  Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).	How does ensemble method work	3575
4052	Data Preprocessing is a technique that is used to convert the raw data into a clean data set.  In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis.	What is data preprocessing in ML	4052
3968	In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables.	What is the difference between linear regression and multiple linear regression	3968
6475	The principal advantage of linear regression is its simplicity, interpretability, scientific acceptance, and widespread availability. Linear regression is the first method to use for many problems. Analysts can use linear regression together with techniques such as variable recoding, transformation, or segmentation.	What is the main advantage of using linear regression	6475
10357	Consider the normal distribution N(100, 10). To find the percentage of data below 105.3, that is P(x < 105.3), standartize first: P(x < 105.3) = P ( z < 105.3 − 100 10 ) = P(z < 0.53). Then find the proportion corresponding to 0.53 in Table A: look for the intersection of the row labeled 0.5 and the column labeled .	How do you find the standard normal distribution percentage	10357
1441	ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x). Visually, it looks like the following: ReLU is the most commonly used activation function in neural networks, especially in CNNs.	What is ReLU in machine learning	1441
1700	You can use regression equations to make predictions. Regression equations are a crucial part of the statistical output after you fit a model.  However, you can also enter values for the independent variables into the equation to predict the mean value of the dependent variable.	Is it appropriate to use the linear regression equation to make predictions	1700
8699	Explanation: Weight adjustment is proportional to negative gradient of error with respect to weight. 10.	Does backpropagation learning is based on gradient descent along error surface	8699
3612	Binomial is defined as a math term meaning two expressions connected by a plus or minus sign. An example of a binomial is x – y.  An example of a binomial is Canis familiaris, the scientific name for dog.	What is binomial example	3612
799	Data Collection & Analysis Tools Related TopicsBox & Whisker Plot.Check Sheet.Control Chart.Design of Experiments (DOE)Histogram.Scatter Diagram.Stratification.Survey.	What are the tools for analysis	799
1165	In data science, association rules are used to find correlations and co-occurrences between data sets. They are ideally used to explain patterns in data from seemingly independent information repositories, such as relational databases and transactional databases.	What is the applicability of association rules	1165
10835	Linear Regression, intuitively is a regression algorithm with a Linear approach. We try to predict a continuous value of a given data point by generalizing on the data that we have in hand. The linear part indicates that we are using a linear approach in generalizing over the data.	What is the intuition behind linear regression	10835
8492	Metrics like accuracy, precision, recall are good ways to evaluate classification models for balanced datasets, but if the data is imbalanced and there's class disparity, then other methods like ROC/AUC perform better in evaluating the model performance.	What are the metrics chosen to evaluate model performance	8492
7758	The two are different. Stoichiometry looks at balancing equations whereas dimensional analysis is looking at the units particular equations take and allowing you to make a determination of final units (and possibly the correctness of your derivation of units for any equations).	Is dimensional analysis the same thing as stoichiometry	7758
2798	Examples of sampling bias include self-selection, pre-screening of trial participants, discounting trial subjects/tests that did not run to completion and migration bias by excluding subjects who have recently moved into or out of the study area.	What is selection bias example	2798
10566	Gradient Boosting Machines vs. XGBoost.  While regular gradient boosting uses the loss function of our base model (e.g. decision tree) as a proxy for minimizing the error of the overall model, XGBoost uses the 2nd order derivative as an approximation.	What's the difference between gradient boosting and XGBoost	10566
8493	Introduction to K-Means ClusteringStep 1: Choose the number of clusters k.  Step 2: Select k random points from the data as centroids.  Step 3: Assign all the points to the closest cluster centroid.  Step 4: Recompute the centroids of newly formed clusters.  Step 5: Repeat steps 3 and 4.	How do you use K means clustering	8493
7569	In statistics, a confounder (also confounding variable, confounding factor, or lurking variable) is a variable that influences both the dependent variable and independent variable, causing a spurious association. Confounding is a causal concept, and as such, cannot be described in terms of correlations or associations.	What is meant by confounding in statistics	7569
735	Initializers define the way to set the initial random weights of Keras layers. The keyword arguments used for passing initializers to layers depends on the layer. Usually, it is simply kernel_initializer and bias_initializer : from tensorflow.keras import layers from tensorflow.keras import initializers layer = layers.	What is kernel initializer in keras	735
8575	The 1×1 filter can be used to create a linear projection of a stack of feature maps. The projection created by a 1×1 can act like channel-wise pooling and be used for dimensionality reduction. The projection created by a 1×1 can also be used directly or be used to increase the number of feature maps in a model.	How are 1x1 convolutions used for dimensionality reduction	8575
4332	The null hypothesis (H0) for a one tailed test is that the mean is greater (or less) than or equal to µ, and the alternative hypothesis is that the mean is < (or >, respectively) µ.	What is the null hypothesis for a one tailed test	4332
1798	It's greedy because you always mark the closest vertex. It's dynamic because distances are updated using previously calculated values. I would say it's definitely closer to dynamic programming than to a greedy algorithm. To find the shortest distance from A to B, it does not decide which way to go step by step.	Why is Dijkstra A greedy algorithm	1798
2564	all provides a way to leverage binary classification. -all solution consists of N separate binary classifiers—one binary classifier for each possible outcome.  During training, the model runs through a sequence of binary classifiers, training each to answer a separate classification question.	What is one vs all classification	2564
3058	By reversing the words in the source sentence, the average distance between corresponding words in the source and target language is unchanged. However, the first few words in the source language are now very close to the first few words in the target language, so the problem's minimal time lag is greatly reduced.	In the paper Sequence to Sequence Learning with Neural Networks why does reversing the source sentence allow better performance on longer sentences	3058
6024	The main difference is that ABM typically implement low numbers of highly complex agents, and the main feature they consider are their individual capabilities to face the task. On the opposite, MAS consider (very) large numbers of simpler agents, focusing on the emergence of new phenomena from social interactions.	What is the difference between agent based simulation ABS and multi agent system MAS )	6024
4541	A box and whisker plot—also called a box plot—displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum.	What values are in a box plot	4541
5651	Establish face validity.Conduct a pilot test.Enter the pilot test in a spreadsheet.Use principal component analysis (PCA)Check the internal consistency of questions loading onto the same factors.Revise the questionnaire based on information from your PCA and CA.	How do you check for the validity and reliability of a questionnaire	5651
4749	"""A Bayesian network is a probabilistic graphical model which represents a set of variables and their conditional dependencies using a directed acyclic graph.""  It is also called a Bayes network, belief network, decision network, or Bayesian model."	What is Bayesian network in AI	4749
2804	They are basically equivalent: the linear time invariant systems refers to an analog system and shift-invariant system refers to a discrete-time system.  The shift-invariant is the same as time invariant: if we delay the input, the output that we get is the original input to the signal that wasn't delayed.	What is difference between Linear time invariant system and Linear shift invariant system 1	2804
6090	Java, Python, Lisp, Prolog, and C++ are major AI programming language used for artificial intelligence capable of satisfying different needs in the development and designing of different software.	Which program is used for artificial intelligence	6090
461	A random variable is a variable whose value is a numerical outcome of a random phenomenon. A discrete random variable X has a countable number of possible values. Example: Let X represent the sum of two dice.  A continuous random variable X takes all values in a given interval of numbers.	What is the difference between a random variable and a discrete random variable	461
1135	Linear Shift-Invariant systems, called LSI systems for short, form a very important class of practical systems, and hence are of interest to us. They are also referred to as Linear Time-Invariant systems, in case the independent variable for the input and output signals is time.	What is linear shift invariant system	1135
10238	Now we'll check out the proven way to improve the accuracy of a model:Add more data. Having more data is always a good idea.  Treat missing and Outlier values.  Feature Engineering.  Feature Selection.  Multiple algorithms.  Algorithm Tuning.  Ensemble methods.	How can the accuracy of a linear regression model be improved	10238
5127	Inductive probability refers to the likelihood that an inductive argument with true premises will give a true conclusion.  An argument with low inductive probability is less likely to have a true conclusion even if its premises are true.	What is a probability argument	5127
6869	The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.	How does Softmax regression work	6869
7583	Autocorrelation can cause problems in conventional analyses (such as ordinary least squares regression) that assume independence of observations. In a regression analysis, autocorrelation of the regression residuals can also occur if the model is incorrectly specified.	Why is autocorrelation a problem for times series analysis	7583
4026	First, after looking around on the web, it seems that there is no way to compute a (discrete) Fourier transform through a neural network. You can hack it by hard-coding the thing to include the Fourier constants for the transform and then get a decent result.	Can neural networks learn Fourier Transform	4026
7743	Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation.	What does tokenization mean in NLP	7743
9754	A sample survey can be broadly defined as an exercise that involves collecting standardised data from a sample of study units (e.g., persons, households, businesses) designed to represent a larger population of units, in order to make quantitative inferences about the population.	What is sample survey method	9754
27	(e.g. if P=1/256, that's 8 bits.) Entropy is just the average of that information bit length, over all the outcomes. The purpose of log(pi) appearing in Shannon's Entropy is that log(pi) is the only function satisfying the basic set of properties that the entropy function, H(p1,…,pN), is held to embody.	Why log is used in entropy	27
7469	Regularization is a technique which makes slight modifications to the learning algorithm such that the model generalizes better. This in turn improves the model's performance on the unseen data as well.	What are regularization techniques	7469
8924	In machine learning, scoring is the process of applying an algorithmic model built from a historical dataset to a new dataset in order to uncover practical insights that will help solve a business problem.  The second stage is scoring, in which you apply the trained model to a new dataset.	What is model scoring in machine learning	8924
2165	The Matrix represents a system of control that operates completely in the mind. As a complex, machine-driven program, it appropriates any personal, political, or ideological leanings and renders them wholly false. It allows illusions but no action.	What is the Matrix and what does it represent	2165
3500	Two main statistical methods are used in data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from data that are subject to random variation (e.g., observational errors, sampling variation).	What are statistical methods used for analysis	3500
8986	"The beginnings of modern AI can be traced to classical philosophers' attempts to describe human thinking as a symbolic system. But the field of AI wasn't formally founded until 1956, at a conference at Dartmouth College, in Hanover, New Hampshire, where the term ""artificial intelligence"" was coined."	What is the history of artificial intelligence	8986
1582	Causation is the relationship between cause and effect. So, when a cause results in an effect, that's a causation.  When we say that correlation does not imply cause, we mean that just because you can see a connection or a mutual relationship between two variables, it doesn't necessarily mean that one causes the other.	Does correlation imply causation Why or why not	1582
594	more  A symbol for a value we don't know yet. It is usually a letter like x or y. Example: in x + 2 = 6, x is the variable.	What is variable example	594
5948	1. If having conditional independence will highly negative affect classification, you'll want to choose K-NN over Naive Bayes. Naive Bayes can suffer from the zero probability problem; when a particular attribute's conditional probability equals zero, Naive Bayes will completely fail to produce a valid prediction.	Classification machine learning When should I use a K NN classifier over a Naive Bayes classifier	5948
8991	A time series is a dataset whose unit of analysis is a time period, rather than a person. Regression is an analytic tool that attempts to predict one variable, y as a function of one or more x variables. It can be used to analyze both time-series and static data.	What is the difference between regression and time series	8991
7931	Inverted Dropout is how Dropout is implemented in practice in the various deep learning frameworks because it helps to define the model once and just change a parameter (the keep/drop probability) to run train and test on the same model.	Why is the dropout inverted	7931
3949	If exploding gradients are still occurring, you can check for and limit the size of gradients during the training of your network. This is called gradient clipping. Dealing with the exploding gradients has a simple but very effective solution: clipping gradients if their norm exceeds a given threshold.	What technique is followed to deal with the problem of exploding gradients in recurrent neural net works RNN )	3949
7960	Statistics is generally considered a prerequisite to the field of applied machine learning. We need statistics to help transform observations into information and to answer questions about samples of observations.	How is statistics related to machine learning	7960
4184	Thus, the SMC counts both mutual presences (when an attribute is present in both sets) and mutual absence (when an attribute is absent in both sets) as matches and compares it to the total number of attributes in the universe, whereas the Jaccard index only counts mutual presence as matches and compares it to the	What is the main difference between simple matching coefficient SMC similarity and Jaccard similarity	4184
10041	If you use import numpy , all sub-modules and functions in the numpy module can only be accesses in the numpy.  If you use from numpy import * , all functions will be loaded into the local namespace. For example array([1,2,3]) can then be used.	What is the difference between import numpy and from numpy import *	10041
8278	For independent random variables X and Y, the variance of their sum or difference is the sum of their variances: Variances are added for both the sum and difference of two independent random variables because the variation in each variable contributes to the variation in each case.	How do you find the variance of an independent variable	8278
4760	The t-value measures the size of the difference relative to the variation in your sample data. Put another way, T is simply the calculated difference represented in units of standard error. The greater the magnitude of T, the greater the evidence against the null hypothesis.	What does the T score tell you	4760
3107	Loss curves are a standard actuarial technique for helping insurance companies assess the amount of reserve capital they need to keep on hand to cover claims from a line of business. Claims made and reported for a given accounting period are tracked seperately over time.	What is a loss curve	3107
7626	0:007:21Suggested clip · 102 secondsBayesian posterior sampling - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you sample a posterior distribution	7626
1946	This is referred to as the joint probability of X = x and Y = y. If X and Y are discrete random variables, the function given by f (x, y) = P(X = x, Y = y) for each pair of values (x, y) within the range of X is called the joint probability distribution of X and Y .	What is the joint distribution of X and Y	1946
1455	In addition, scales can be constructed from categorical variables. This is covered in a later section. The Count property returns the number of levels in the scale. The IsOrdered property indicates whether the scale is ordered or unordered.	Can Scaling be applied to categorical variables	1455
7092	KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression).	How does KNN classification work	7092
418	A mutually exclusive pair of events are complements to each other. For example: If the desired outcome is heads on a flipped coin, the complement is tails. The Complement Rule states that the sum of the probabilities of an event and its complement must equal 1, or for the event A, P(A) + P(A') = 1.	How is the rule of complement used to calculate probability	418
258	(8) The moment generating function corresponding to the normal probability density function N(x;µ, σ2) is the function Mx(t) = exp{µt + σ2t2/2}.	What is the moment generating function of normal distribution	258
9012	Step 1 — Deciding on the network topology (not really considered optimization but is obviously very important)  Step 2 — Adjusting the learning rate.  Step 3 — Choosing an optimizer and a loss function.  Step 4 — Deciding on the batch size and number of epochs.  Step 5 — Random restarts.	How do I tune Hyperparameters in neural network	9012
2877	"To work out the probability that a discrete random variable X takes a particular value x, we need to identify the event (the set of possible outcomes) that corresponds to ""X=x"". pX(x)=Pr(X=x). In general, the probability function pX(x) may be specified in a variety of ways."	What is the function of probability	2877
7711	12 Common Logical Fallacies and How to Debunk Them12 Common Logical Fallacies and How to Debunk Them.  Ad Hominem.  Appeal to Authority.  Bandwagon Argument, or ad populum.  The Strawman.  Circular Reasoning.  The Genetic Fallacy.  Anecdotal Evidence.More items•	What are the 12 fallacies	7711
1457	Five main Component of Natural Language processing are:Morphological and Lexical Analysis.Syntactic Analysis.Semantic Analysis.Discourse Integration.Pragmatic Analysis.	What are the components of NLP	1457
8369	x̄ = ( Σ xi ) / nAdd up the sample items.Divide sum by the number of samples.The result is the mean.Use the mean to find the variance.Use the variance to find the standard deviation.	How do you find the mean of a random sample	8369
1065	Generalized Linear Models let you express the relation between covariates X and response y in a linear, additive manner.	What is the practical purpose of generalized linear models	1065
4736	We can use the regression line to predict values of Y given values of X. For any given value of X, we go straight up to the line, and then move horizontally to the left to find the value of Y. The predicted value of Y is called the predicted value of Y, and is denoted Y'.	How do you find the predicted value in a regression equation	4736
3346	Just as ordinary least square regression is the method used to estimate coefficients for the best fit line in linear regression, logistic regression uses maximum likelihood estimation (MLE) to obtain the model coefficients that relate predictors to the target.	Which method gives the best fit for logistic regression model	3346
5082	2 Answers. Boosting is based on weak learners (high bias, low variance).  Boosting reduces error mainly by reducing bias (and also to some extent variance, by aggregating the output from many models). On the other hand, Random Forest uses as you said fully grown decision trees (low bias, high variance).	What is the difference in bias and variance in 1 Random Forest 2 gradient boosting Why is there this difference	5082
8743	Some applications of unsupervised machine learning techniques include: Clustering allows you to automatically split the dataset into groups according to similarity. Often, however, cluster analysis overestimates the similarity between groups and doesn't treat data points as individuals.	What are the application of unsupervised learning	8743
2776	Because our sample size is greater than 30, the Central Limit Theorem tells us that the sampling distribution will approximate a normal distribution.  Because we know the population standard deviation and the sample size is large, we'll use the normal distribution to find probability.	Why is normal distribution used in sampling distribution	2776
7497	We find the robust standard deviation estimate by multiplying the MAD by a factor that happens to have a value close to 1.5. This gives us a robust value ('sigma- hat') of B . . If we use this method on data without outliers, it provides estimates that are close to x and s, so no harm is done.	How is robust standard deviation calculated	7497
173	"A statistical test provides a mechanism for making quantitative decisions about a process or processes. The intent is to determine whether there is enough evidence to ""reject"" a conjecture or hypothesis about the process.  A classic use of a statistical test occurs in process control studies."	What are statistical tests in research	173
7667	13. What is the difference between unimodal, bimodal, and multimodal data? Unimodal data has a distribution that is single-peaked (one mode). Bimodal data has two peaks (2 modes) and multimodal data refer to distributions with more than two clear peaks.	What is the difference between unimodal and multimodal	7667
10552	In project management terms, an s-curve is a mathematical graph that depicts relevant cumulative data for a project—such as cost or man-hours—plotted against time.  An s-curve in project management is typically used to track the progress of a project.	What does an S curve represent	10552
3884	K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.	What is K nearest Knn data mining algorithm	3884
9173	Spark is capable of handling large-scale batch and streaming data to figure out when to cache data in memory and processing them up to 100 times faster than Hadoop-based MapReduce.  First, you will learn how to install Spark with all new features from the latest Spark 2.0 release.	Why is Spark efficient for large scale machine learning	9173
1935	Hello every one, We know that Pearson linear correlation coefficient gives the strength of linear relationship, while Spearman rank correlation coefficient gives the strength of monotonic relationship between two variables.	Is rank correlation coefficient different from Pearson correlation coefficient explain with reason	1935
4782	It is able to do this by using a novel form of reinforcement learning, in which AlphaGo Zero becomes its own teacher. The system starts off with a neural network that knows nothing about the game of Go. It then plays games against itself, by combining this neural network with a powerful search algorithm.	Does AlphaGo use reinforcement learning	4782
9484	Classification is a data mining function that assigns items in a collection to target categories or classes. The goal of classification is to accurately predict the target class for each case in the data. For example, a classification model could be used to identify loan applicants as low, medium, or high credit risks.	What is data mining classification	9484
1415	Matrix Inventory allows you to add and manage product lists that consist of similar items that are available in a variety of attributes, such as size or color.  Each product is defined by a combination of attributes is a unique product with its own price, inventory and/or recipe.	What is Matrix inventory	1415
8425	Since a Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.	Why is naive Bayes used for text classification	8425
10891	Standard interpretation of the ordered logit coefficient is that for a one unit increase in the predictor, the response variable level is expected to change by its respective regression coefficient in the ordered log-odds scale while the other variables in the model are held constant.	How do you interpret ordered logit coefficients	10891
3425	The formula is:P(A|B) = P(A) P(B|A)P(B)P(Man|Pink) = P(Man) P(Pink|Man)P(Pink)P(Man|Pink) = 0.4 × 0.1250.25 = 0.2.Both ways get the same result of ss+t+u+v.P(A|B) = P(A) P(B|A)P(B)P(Allergy|Yes) = P(Allergy) P(Yes|Allergy)P(Yes)P(Allergy|Yes) = 1% × 80%10.7% = 7.48%More items	How do you calculate Bayesian probability	3425
468	Difference between Z score vs T score. Z score is a conversion of raw data to a standard score, when the conversion is based on the population mean and population standard deviation.  T score is a conversion of raw data to the standard score when the conversion is based on the sample mean and sample standard deviation.	What is the difference between T score and Z score	468
8005	He doesn't explicitly betray Kaneki, but it seems like it because someone who seemed like such a nice guy, giving advice to Kaneki and helping retrieve him from Aogiri, ended up being a sadistic and manipulative person.	Did Uta betray kaneki	8005
10396	Variance (σ2) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.	What is a variance in statistics	10396
7706	Put simply: random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction. Random forest has nearly the same hyperparameters as a decision tree or a bagging classifier.  Random forest adds additional randomness to the model, while growing the trees.	How does a Random Forest model work	7706
1146	We can say that, when we move from RNN to LSTM, we are introducing more & more controlling knobs, which control the flow and mixing of Inputs as per trained Weights. And thus, bringing in more flexibility in controlling the outputs. So, LSTM gives us the most Control-ability and thus, Better Results.	Why is Lstm better than RNN	1146
636	When examining the distribution of a quantitative variable, one should describe the overall pattern of the data (shape, center, spread), and any deviations from the pattern (outliers).	How do you describe the distribution	636
10432	To find the interquartile range (IQR), ​first find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.	How do you determine the interquartile range	10432
2155	Cluster analysis, or clustering, is an unsupervised machine learning task. It involves automatically discovering natural grouping in data. Unlike supervised learning (like predictive modeling), clustering algorithms only interpret the input data and find natural groups or clusters in feature space.	What is a clustering algorithm	2155
9829	A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input.	What are convolutional neural networks used for	9829
7382	Entropy is the measure of disorder in a thermodynamic system.Difference Between Enthalpy and EntropyEnthalpy is a kind of energyEntropy is a propertyIt is the sum of internal energy and flows energyIt is the measurement of the randomness of moleculesIt is denoted by symbol HIt is denoted by symbol S5 more rows	What is the difference between entropy and entropy	7382
2195	The logistic function is the inverse of the natural logit function and so can be used to convert the logarithm of odds into a probability. In mathematical notation the logistic function is sometimes written as expit in the same form as logit.	What is the logistic function used for	2195
1642	If you want to ingest DynamoDB data into Redshift you have a few options.The Redshift Copy command.Build a Data Pipeline that copies the data using an EMR job to S3.Export the DynamoDB data to a file using the AWS CLI and load the flat file into Redshift.More items	How do I transfer data from DynamoDB to redshift	1642
3887	An endogenous variable is a variable in a statistical model that's changed or determined by its relationship with other variables within the model.  Therefore, its values may be determined by other variables. Endogenous variables are the opposite of exogenous variables, which are independent variables or outside forces.	What is an endogenous variable in regression	3887
1481	A continuous random variable takes a range of values, which may be finite or infinite in extent. Here are a few examples of ranges: [0, 1], [0, ∞), (−∞, ∞), [a, b]. The function f(x) is called the probability density function (pdf).	What is range where X is a continuous random variable	1481
7191	A mixed model, mixed-effects model or mixed error-component model is a statistical model containing both fixed effects and random effects.  Because of their advantage in dealing with missing values, mixed effects models are often preferred over more traditional approaches such as repeated measures ANOVA.	What is a mixed model in statistics	7191
10061	ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network. The network uses memistors.  It is based on the McCulloch–Pitts neuron. It consists of a weight, a bias and a summation function.	What is Adaline in neural network	10061
10231	LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution. Given a dataset of documents, LDA backtracks and tries to figure out what topics would create those documents in the first place. LDA is a matrix factorization technique.	How does LDA modeling work	10231
4274	Ridge regression is a term used to refer to a linear regression model whose coefficients are not estimated by ordinary least squares (OLS), but by an estimator, called ridge estimator, that is biased but has lower variance than the OLS estimator.	What is the difference between OLS and ridge regression	4274
4011	The classic approach to the multiple comparison problem is to control the familywise error rate. Instead of setting the critical P level for significance, or alpha, to 0.05, you use a lower critical value.	How do you control multiple comparisons	4011
358	Conditional probability is defined as the likelihood of an event or outcome occurring, based on the occurrence of a previous event or outcome. Conditional probability is calculated by multiplying the probability of the preceding event by the updated probability of the succeeding, or conditional, event.	What do you mean by conditional probability	358
4271	They are often confused with each other. The 'K' in K-Means Clustering has nothing to do with the 'K' in KNN algorithm. k-Means Clustering is an unsupervised learning algorithm that is used for clustering whereas KNN is a supervised learning algorithm used for classification.	What is the difference between Knn and K means clustering	4271
4225	Support Vector Machine algorithms are supervised learning models that analyse data used for classification and regression analysis. They essentially filter data into categories, which is achieved by providing a set of training examples, each set marked as belonging to one or the other of the two categories.	What is an algorithm in machine learning	4225
7537	Boosting differs somewhat from bagging as it does not involve bootstrap sampling. Instead models are generated sequentially and iteratively, meaning that it is necessary to have information about model before iteration is produced. Boosting was motivated by Kearns and Valiant (1989).	Does boosting use bootstrapping	7537
1664	Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.	What is transfer learning in ML	1664
5900	Below are the methods to convert a categorical (string) input to numerical nature:Label Encoder: It is used to transform non-numerical labels to numerical labels (or nominal categorical variables).  Convert numeric bins to number: Let's say, bins of a continuous variable are available in the data set (shown below).	How do you deal with categorical variables in machine learning	5900
7218	There are two types of sampling methods: Probability sampling involves random selection, allowing you to make statistical inferences about the whole group. Non-probability sampling involves non-random selection based on convenience or other criteria, allowing you to easily collect initial data.	What are the types of probability and non probability sampling	7218
4888	The purpose of statistical inference is to estimate this sample to sample variation or uncertainty.	What is the purpose of statistical inference	4888
10365	The first component is the definition: Two variables are independent when the distribution of one does not depend on the the other.  If the probabilities of one variable remains fixed, regardless of whether we condition on another variable, then the two variables are independent.	What does it mean if two variables are independent	10365
9120	Deep Learning is a part of Machine Learning which is applied to larger data-sets and based on ANN (Artificial Neural Networks). The main technology used in NLP (Natural Language Processing) which mainly focuses on teaching natural/human language to computers.  NLP is a part of AI which overlaps with ML & DL.	Does NLP come under deep learning	9120
3110	CRF is a discriminant model. MEMM is not a generative model, but a model with finite states based on state classification. HMM and MEMM are a directed graph, while CRF is an undirected graph. HMM directly models the transition probability and the phenotype probability, and calculates the probability of co-occurrence.	What is the major difference between CRF Conditional Random Field and HMM hidden Markov model	3110
259	5 Answers. The Fourier series is used to represent a periodic function by a discrete sum of complex exponentials, while the Fourier transform is then used to represent a general, nonperiodic function by a continuous superposition or integral of complex exponentials.	What is the relationship between the Fourier transform and Fourier series representation of a continuous function	259
244	A correlation coefficient that is greater than zero indicates a positive relationship between two variables. A value that is less than zero signifies a negative relationship between two variables. Finally, a value of zero indicates no relationship between the two variables that are being compared.	What should the correlation of variable when compared with itself *	244
273	In marketing terms, a multi-armed bandit solution is a 'smarter' or more complex version of A/B testing that uses machine learning algorithms to dynamically allocate traffic to variations that are performing well, while allocating less traffic to variations that are underperforming.	What is a bandit algorithm	273
3606	Spatiotemporal data mining refers to the process of discovering patterns and knowledge from spatiotemporal data.  Other examples of moving-object data mining include mining periodic patterns for one or a set of moving objects, and mining trajectory patterns, clusters, models, and outliers.	What is spatio temporal data mining	3606
1950	ASUS EZ Flash 3 allows you to download and update to the latest BIOS through the Internet without having to use a bootable disk or an OS-based utility.	What is EZ flash	1950
10545	Hickam's dictum	What's the opposite of Occam's razor	10545
966	Random utility theory is based on the hypothesis that every individual is a rational decision-maker, maximizing utility relative to his or her choices. Specifically, the theory is based on the following assumptions.	What is random utility model	966
5474	"In probability, an outcome is in event ""A and B"" only when the outcome is in both event A and event B. (Intersection) In a Venn Diagram, an element is in the intersection of ""A and B"" only when the element is in BOTH sets. Rule (for AND):"	What is the and rule in probability	5474
2949	Algorithms consist of instructions that are carried out (performed) one after another. Sequencing is the specific order in which instructions are performed in an algorithm. For example, a very simple algorithm for brushing teeth might consist of these steps: put toothpaste on toothbrush.	What is the difference between sequence and algorithm	2949
873	XFL teams will have two timeouts per half, one fewer than in the NFL. Halftime is 10 minutes, two minutes less than the NFL. Another attempt to shorten the game is not allowing coaches to challenge an official's ruling. All plays are subject to review by the replay official.	What rules are different in the XFL	873
9870	2 Key Challenges of Streaming Data and How to Solve ThemStreaming Data is Very Complex. Streaming data is particularly challenging to handle because it is continuously generated by an array of sources and devices and is delivered in a wide variety of formats.  Business Wants Data, But IT Can't Keep Up.	What are the challenges of data stream processing	9870
9271	Linear regression is used to find the best fitting line between all the points of your dataset (by computing the minimum of a given distance), it does not, in itself, reduce the dimensionality of your data.	Is dimensionality reduction applicable in simple linear regression	9271
1842	A paired t-test is used when we are interested in the difference between two variables for the same subject. Often the two variables are separated by time. For example, in the Dixon and Massey data set we have cholesterol levels in 1952 and cholesterol levels in 1962 for each subject.	Why would you use a paired t test	1842
8105	General linear modeling in SPSS for Windows The general linear model (GLM) is a flexible statistical model that incorporates normally distributed dependent variables and categorical or continuous independent variables.	What is general linear model in SPSS	8105
3756	The Basics of a One-Tailed Test Hypothesis testing is run to determine whether a claim is true or not, given a population parameter. A test that is conducted to show whether the mean of the sample is significantly greater than and significantly less than the mean of a population is considered a two-tailed test.	What do you mean by one tailed test and two tailed test	3756
10294	An artificial neural network's learning rule or learning process is a method, mathematical logic or algorithm which improves the network's performance and/or training time.  Depending upon the process to develop the network there are three main models of machine learning: Unsupervised learning. Supervised learning.	What is learning in neural networks	10294
9598	A moving average term in a time series model is a past error (multiplied by a coefficient). Let w t ∼ i i d N ( 0 , σ w 2 ) , meaning that the wt are identically, independently distributed, each with a normal distribution having mean 0 and the same variance.	What is moving average model in time series	9598
9341	A factorial distribution happens when a set of variables are independent events. In other words, the variables don't interact at all; Given two events x and y, the probability of x doesn't change when you factor in y.	What is factorial distribution	9341
10071	For many continuous random variables, we can define an extremely useful function with which to calculate probabilities of events associated to the random variable. In short, the PDF of a continuous random variable is the derivative of its CDF.	Is the derivative of the probability distribution function PDF just a cumulative distribution function cdf	10071
3912	Global max pooling = ordinary max pooling layer with pool size equals to the size of the input (minus filter size + 1, to be precise). You can see that MaxPooling1D takes a pool_length argument, whereas GlobalMaxPooling1D does not.	What is Global Max pooling	3912
628	Naive Bayes works best when you have small training data set, relatively small features(dimensions). If you have huge feature list, the model may not give you accuracy, because the likelihood would be distributed and may not follow the Gaussian or other distribution.	When should we use naive Bayes	628
4135	Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.  Also known as deep neural learning or deep neural network.	What is deep learning in simple words	4135
4864	At the point of non-differentiability, you can assign the derivative of the function at the point “right next” to the singularity and the algorithm will work fine. For example, in ReLU we can give the derivative of the function at zero as 0.	How do deep learning algorithms use ReLU if it is not differentiable at 0	4864
7061	In mathematics, a Fourier transform (FT) is a mathematical transform that decomposes a function (often a function of time, or a signal) into its constituent frequencies, such as the expression of a musical chord in terms of the volumes and frequencies of its constituent notes.	What is Fourier transform in signals and systems	7061
567	User-Based Collaborative Filtering is a technique used to predict the items that a user might like on the basis of ratings given to that item by the other users who have similar taste with that of the target user. Many websites use collaborative filtering for building their recommendation system.	What is user based collaborative filtering	567
872	In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers.  It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.	What is Perceptron in machine learning	872
721	linear threshold unit (LTU) A linear threshold unit is a simple artificial neuron whose output is its thresholded total net input. That is, an LTU with threshold T calculates the weighted sum of its inputs, and then outputs 0 if this sum is less than T, and 1 if the sum is greater than T.	What is a linear threshold unit	721
4460	Communalities – This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.  They are the reproduced variances from the factors that you have extracted.	What is the meaning of communality in factor analysis	4460
2902	An autocorrelation plot is designed to show whether the elements of a time series are positively correlated, negatively correlated, or independent of each other. (The prefix auto means “self”— autocorrelation specifically refers to correlation among the elements of a time series.)	What is an autocorrelation plot	2902
5004	The main requirements that a clustering algorithm should satisfy are:scalability;dealing with different types of attributes;discovering clusters with arbitrary shape;minimal requirements for domain knowledge to determine input parameters;ability to deal with noise and outliers;More items	What are the requirements of clustering algorithms	5004
3830	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.	What is bootstrapping in machine learning	3830
1499	While many people use the terms interchangeably, data science and big data analytics are unique fields, with the major difference being the scope.  Data science produces broader insights that concentrate on which questions should be asked, while big data analytics emphasizes discovering answers to questions being asked.	What is the difference between data science and data analytics	1499
3817	Backpropagation only works during training the model on a dataset.  You run your model with the learned parameters (from Backpropagation) and best hyperparameters (from validation) once on the Test set and report the accuracy. You never learn anything, be it parameters or hyperparameters on the Test set.	How does backpropagation work between training validation and test sets	3817
5737	Inverted dropout is a variant of the original dropout technique developed by Hinton et al. Just like traditional dropout, inverted dropout randomly keeps some weights and sets others to zero. In contrast, traditional dropout requires scaling to be implemented during the test phase.	What is inverted dropout	5737
7253	Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.	What does a normal distribution tell us	7253
6383	An environment is everything in the world which surrounds the agent, but it is not a part of an agent itself. An environment can be described as a situation in which an agent is present. The environment is where agent lives, operate and provide the agent with something to sense and act upon it.	What is agent and environment in artificial intelligence	6383
7470	Data are rarely randomly distributed in high-dimensions and are highly correlated, often with spurious correlations. The distances between a data point and its nearest and farthest neighbours can become equidistant in high dimensions, potentially compromising the accuracy of some distance-based analysis tools.	What are the implications of using highly dimensional data	7470
5428	Recall that in order for a neural networks to learn, weights associated with neuron connections must be updated after forward passes of data through the network. These weights are adjusted to help reconcile the differences between the actual and predicted outcomes for subsequent forward passes.	How are weights updated in neural network	5428
7834	Generative modeling is an unsupervised learning task in machine learning that involves automatically discovering and learning the regularities or patterns in input data in such a way that the model can be used to generate or output new examples that plausibly could have been drawn from the original dataset.	Are generative models unsupervised	7834
4306	Covariance is when two variables vary with each other, whereas Correlation is when the change in one variable results in the change in another variable.Differences between Covariance and Correlation.CovarianceCorrelationCovariance can vary between -∞ and +∞Correlation ranges between -1 and +17 more rows•	Should I use correlation or covariance	4306
10051	A metric is a function that is used to judge the performance of your model. Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.	What is metrics in neural network	10051
6440	Clustering starts by computing a distance between every pair of units that you want to cluster. A distance matrix will be symmetric (because the distance between x and y is the same as the distance between y and x) and will have zeroes on the diagonal (because every item is distance zero from itself).	What is distance matrix in clustering	6440
3163	load_data function Loads the MNIST dataset. This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the MNIST homepage.	What is Mnist Load_data ()	3163
5898	Dummy variables (sometimes called indicator variables) are used in regression analysis and Latent Class Analysis. As implied by the name, these variables are artificial attributes, and they are used with two or more categories or levels.	Why is it called a dummy variable	5898
2042	Probability density function (PDF) is a statistical expression that defines a probability distribution (the likelihood of an outcome) for a discrete random variable (e.g., a stock or ETF) as opposed to a continuous random variable.	What does probability density function mean	2042
1644	Artificial neural networks are forecasting methods that are based on simple mathematical models of the brain. They allow complex nonlinear relationships between the response variable and its predictors.	What are neural network models	1644
8064	The short answer is yes—because most regression models will not perfectly fit the data at hand. If you need a more complex model, applying a neural network to the problem can provide much more prediction power compared to a traditional regression.	Can neural networks be used for linear regression	8064
10632	To predict a continuous value, you need to adjust your model (regardless whether it is Recurrent or Not) to the following conditions:Use a linear activation function for the final layer.Chose an appropriate cost function (square error loss is typically used to measure the error of predicting real values)	How can we make a neural network to predict a continuous variable	10632
8410	In statistics and probability, quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. There is one fewer quantile than the number of groups created.	What is quantile distribution	8410
1811	Features: The characteristics that define your problem. These are also called attributes. Parameters: The variables your algorithm is trying to tune to build an accurate model.	What are the features and parameters in machine learning	1811
6016	Answer : Algorithm is a noun meaning some special process of solving a certain type of problem.  Whereas logarithm, again a noun, is the exponent of that power of a fixed number, called the base, which equals a given number, called the antilogarithm.	What is the difference between a logarithm and an algorithm	6016
5381	To find the interquartile range (IQR), ​first find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.	How do you find the interquartile range	5381
5587	Once you have calculated the decimal values of each percentage for each given sample size, you then add these decimal values together and divide the total number by the total sum of both sample sizes. You then need to multiply this value by 100 to get the average percentage.5 days ago	How do you calculate the median percentage	5587
4898	Stochastic Gradient Descent (SGD) addresses both of these issues by following the negative gradient of the objective after seeing only a single or a few training examples. The use of SGD In the neural network setting is motivated by the high cost of running back propagation over the full training set.	What is SGD in neural network	4898
4193	Decision tree learning is generally best suited to problems with the following characteristics: Instances are represented by attribute-value pairs. There is a finite list of attributes (e.g. hair colour) and each instance stores a value for that attribute (e.g. blonde).	What type of problems are best suited for decision tree learning	4193
2339	1 Answers found. A recursive filter has a system in which the output is directly dependent on one or more of its past outputs. But in a non recursive filter the system followed is the one in which the output is independent of any of the past outputs like, the feed-forward system where the system is having no feedback.	What is the main difference between recursive and non recursive filters in DSP	2339
345	The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.  Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level.	What is calibrated probability	345
10570	So, assuming a 15% survey response rate, we see that you should send your NPS survey to 1,700 customers. What if you're a smaller company and don't have enough customers to send the recommended number of invitations?	What is a good sample size for NPS	10570
136	Fisher's exact test obtains its two-tailed P value by computing the probabilities associated with all possible tables that have the same row and column totals. Then, it identifies the alternative tables with a probability that is less than that of the observed table.	What is an intuitive explanation of the Fisher exact test	136
2263	The loss function of SVM is very similar to that of Logistic Regression. Looking at it by y = 1 and y = 0 separately in below plot, the black line is the cost function of Logistic Regression, and the red line is for SVM. Please note that the X axis here is the raw model output, θᵀx.	What is the loss function for SVM	2263
2727	This task of identifying the best subset of predictors to include in the model, among all possible subsets of predictors, is referred to as variable selection.	What is variable selection in regression	2727
1160	It's a method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.	What is a loss function machine learning	1160
1186	Standard Deviation: The Difference. The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean.	Is the standard deviation the error	1186
7308	Criteria for CausalityStrength: A relationship is more likely to be causal if the correlation coefficient is large and statistically significant.Consistency: A relationship is more likely to be causal if it can be replicated.More items•	How do you know if correlation is causation	7308
6925	Stride is a parameter of the neural network's filter that modifies the amount of movement over the image or video. For example, if a neural network's stride is set to 1, the filter will move one pixel, or unit, at a time.	What is stride in deep learning	6925
6141	The hazard rate measures the propensity of an item to fail or die depending on the age it has reached. It is part of a wider branch of statistics called survival analysis, a set of methods for predicting the amount of time until a certain event occurs, such as the death or failure of an engineering system or component.	What is hazard rate in survival analysis	6141
7560	Linear discriminant function analysis (i.e., discriminant analysis) performs a multivariate test of differences between groups.  In addition, discriminant analysis is used to determine the minimum number of dimensions needed to describe these differences.	What is discriminant analysis in SPSS	7560
10494	Path analysis is a special case of SEM.  Most of the models that you will see in the literature are SEM rather than path analyses. The main difference between the two types of models is that path analysis assumes that all variables are measured without error. SEM uses latent variables to account for measurement error.	What is the difference between path analysis and SEM	10494
9934	The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.  The C parameter trades off correct classification of training examples against maximization of the decision function's margin.	What is C and gamma in SVM	9934
641	Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.	What is a deep learning model	641
489	Structured data is highly specific and is stored in a predefined format, where unstructured data is a conglomeration of many varied types of data that are stored in their native formats. This means that structured data takes advantage of schema-on-write and unstructured data employs schema-on-read.	What is structured and unstructured data	489
7943	Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression.  A Random Forest operates by constructing several decision trees during training time and outputting the mean of the classes as the prediction of all the trees.	What is a Random Forest Regression	7943
3847	Prior probability represents what is originally believed before new evidence is introduced, and posterior probability takes this new information into account.  A posterior probability can subsequently become a prior for a new updated posterior probability as new information arises and is incorporated into the analysis.	What is the difference between prior and posterior probabilities	3847
2252	It is the sum of the likelihood residuals. At record level, the natural log of the error (residual) is calculated for each record, multiplied by minus one, and those values are totaled.	What is the log likelihood in logistic regression	2252
2772	A bias vector is an additional set of weights in a neural network that require no input, and this it corresponds to the output of an artificial neural network when it has zero input. Bias represents an extra neuron included with each pre-output layer and stores the value of “1,” for each action.	What is bias in convolutional neural network	2772
10008	In information theory, the graph entropy is a measure of the information rate achievable by communicating symbols over a channel in which certain pairs of values may be confused. This measure, first introduced by Körner in the 1970s, has since also proven itself useful in other settings, including combinatorics.	What is an entropy of Graph Is it related to concept of entropy in Information Theory	10008
8140	In spatial analysis, four major problems interfere with an accurate estimation of the statistical parameter: the boundary problem, scale problem, pattern problem (or spatial autocorrelation), and modifiable areal unit problem.  In analysis with area data, statistics should be interpreted based upon the boundary.	What are spatial problems	8140
9090	"The binomial distribution model allows us to compute the probability of observing a specified number of ""successes"" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure."	What are binomial distributions used for	9090
2363	AUC and accuracy are fairly different things.  For a given choice of threshold, you can compute accuracy, which is the proportion of true positives and negatives in the whole data set. AUC measures how true positive rate (recall) and false positive rate trade off, so in that sense it is already measuring something else.	What is the difference between accuracy and AUC	2363
6432	SGD is a variant of gradient descent. Instead of performing computations on the whole dataset — which is redundant and inefficient — SGD only computes on a small subset or random selection of data examples.  Essentially Adam is an algorithm for gradient-based optimization of stochastic objective functions.	What is the difference between SGD and Adam	6432
10871	It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance. In this tutorial, you will discover the rectified linear activation function for deep learning neural networks.	Why is the ReLU activation function used the most often in neural networks for computer vision	10871
4447	"StepsStep 1: For each (x,y) point calculate x2 and xy.Step 2: Sum all x, y, x2 and xy, which gives us Σx, Σy, Σx2 and Σxy (Σ means ""sum up"")Step 3: Calculate Slope m:m = N Σ(xy) − Σx Σy N Σ(x2) − (Σx)2Step 4: Calculate Intercept b:b = Σy − m Σx N.Step 5: Assemble the equation of a line."	What is the least squares regression formula	4447
4255	The most common evaluation metric that is used in object recognition tasks is 'mAP', which stands for 'mean average precision'. It is a number from 0 to 100 and higher values are typically better, but it's value is different from the accuracy metric in classification.	What is mAP object detection	4255
4981	To calculate permutations, we use the equation nPr, where n is the total number of choices and r is the amount of items being selected. To solve this equation, use the equation nPr = n! / (n - r)!.	How do you calculate permutations	4981
1600	Understanding the differences Detection refers to mining insights or information in a data pool when it is being processed.  Prediction or predictive analysis employs probability based on the data analyses and processing.	What is the difference between detection and prediction	1600
5660	Cluster sampling is best used when the clusters occur naturally in a population, when you don't have access to the entire population, and when the clusters are geographically convenient. However, cluster sampling is not as precise as simple random sampling or stratified random sampling.	When should cluster sampling be used	5660
8161	The mean value of x is thus the first moment of its distribution, while the fact that the probability distribution is normalized means that the zeroth moment is always 1.  The variance of x is thus the second central moment of the probability distribution when xo is the mean value or first moment.	What are moments prove that first moment is average and second moment is variance	8161
4441	Here are five ways, but it really all boils down to stretching your brain by learning new things:Become a renaissance man. Or woman.  Play the brain game Dual N-Back. Do this 20 minutes a day.  Do regular high cardio exercise.  Learn an instrument.  Buy the book Boost Your IQ by Carolyn Skitt, and play all the games.	How do you get genius level intelligence	4441
6824	Mean: the average score, calculated by dividing the sum of scores by the number of examinees.  Median: the middle raw score of the distribution; 50 percent of the obtained raw scores are higher and 50 percent are lower than the median.	What does distribution of scores mean	6824
7411	The three main metrics used to evaluate a classification model are accuracy, precision, and recall. Accuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.	How do you evaluate machine learning models	7411
3710	Word sense disambiguation, in natural language processing (NLP), may be defined as the ability to determine which meaning of word is activated by the use of word in a particular context.  Lexical ambiguity, syntactic or semantic, is one of the very first problem that any NLP system faces.	What is word sense disambiguation give example	3710
3494	Many algorithms have been used in measuring user similarity or item similarity in recommender systems. For example, the k-nearest neighbor (k-NN) approach and the Pearson Correlation as first implemented by Allen.	Which algorithm is used in recommendation system	3494
8602	If the weights are zero, complexity of the whole deep net would be the same as that of a single neuron and the predictions would be nothing better than random. Nodes that are side-by-side in a hidden layer connected to the same inputs must have different weights for the learning algorithm to update the weights.	Is random weight assignment better than assigning weights to the units in the hidden layer	8602
2873	Sample variance Concretely, the naive estimator sums the squared deviations and divides by n, which is biased.  The sample mean, on the other hand, is an unbiased estimator of the population mean μ. Note that the usual definition of sample variance is. , and this is an unbiased estimator of the population variance.	Is the sample variance an unbiased estimator	2873
3589	The significance level, also denoted as alpha or α, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference.	What is Alpha in statistics significance level	3589
7339	The main difference between cluster sampling and stratified sampling is that in cluster sampling the cluster is treated as the sampling unit so sampling is done on a population of clusters (at least in the first stage). In stratified sampling, the sampling is done on elements within each stratum.	What is the difference between cluster sampling and stratified sampling	7339
8522	Train and serve a TensorFlow model with TensorFlow ServingTable of contents.Create your model. Import the Fashion MNIST dataset. Train and evaluate your model.Save your model.Examine your saved model.Serve your model with TensorFlow Serving. Add TensorFlow Serving distribution URI as a package source:  Make a request to your model in TensorFlow Serving. Make REST requests.	How do you use TensorFlow serving	8522
6048	Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models.	What is data preprocessing in machine learning	6048
10281	In probability, and statistics, a multivariate random variable or random vector is a list of mathematical variables each of whose value is unknown, either because the value has not yet occurred or because there is imperfect knowledge of its value.  Normally each element of a random vector is a real number.	What is a multivariate variable	10281
1238	To calculate the variance follow these steps:Work out the Mean (the simple average of the numbers)Then for each number: subtract the Mean and square the result (the squared difference).Then work out the average of those squared differences. (Why Square?)	How do you calculate sample variance	1238
9929	Poisson regression assumes the response variable Y has a Poisson distribution, and assumes the logarithm of its expected value can be modeled by a linear combination of unknown parameters. A Poisson regression model is sometimes known as a log-linear model, especially when used to model contingency tables.	How does Poisson regression work	9929
1166	Business Uses The K-means clustering algorithm is used to find groups which have not been explicitly labeled in the data. This can be used to confirm business assumptions about what types of groups exist or to identify unknown groups in complex data sets.	What is K means used for	1166
8816	Semantic similarity is calculated based on two semantic vectors. An order vector is formed for each sentence which considers the syntactic similarity between the sentences. Finally, semantic similarity is calculated based on semantic vectors and order vectors.	How do you find the semantic similarity between two words	8816
3156	Batch normalization is a layer that allows every layer of the network to do learning more independently. It is used to normalize the output of the previous layers. The activations scale the input layer in normalization.	What is batch normalization CNN	3156
10857	SVD, or Singular Value Decomposition, is one of several techniques that can be used to reduce the dimensionality, i.e., the number of columns, of a data set.  SVD is an algorithm that factors an m x n matrix, M, of real or complex values into three component matrices, where the factorization has the form USV*.	How does SVD help in dimensionality reduction	10857
2681	7.2. Radial basis function (RBF) networks are a commonly used type of artificial neural network for function approximation problems. Radial basis function networks are distinguished from other neural networks due to their universal approximation and faster learning speed.	Which function popularly we used in RBF network	2681
4575	Frequency is not quantized, and has a continuous spectrum. As such, a photon can have any energy, as E=ℏω. However, quantum mechanically, if a particle is restricted by a potential, i.e. for V≠0, the energy spectrum is discrete.	Is frequency quantized	4575
9437	- Chad Orzel - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the Uncertainty Principle	9437
10196	The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution.	Why is distribution important in statistics	10196
1091	Random field theory (RFT) is a recent body of mathematics defining theo- retical results for smooth statistical maps.  The way that RFT solves this problem is by using results that give the expected Euler characteristic (EC) for a smooth statistical map that has been thresholded.	What is random field theory	1091
10649	“The benefit to using a one-tailed test is that it requires fewer subjects to reach significance. A two-tailed test splits your significance level and applies it in both directions. Thus, each direction is only half as strong as a one-tailed test, which puts all the significance in one direction.	What is the primary benefit of conducting a one tailed test instead of a two tailed test	10649
3432	Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.	What are GANs in machine learning	3432
6384	Mean, variance, and standard deviation The mean of the sampling distribution of the sample mean will always be the same as the mean of the original non-normal distribution. In other words, the sample mean is equal to the population mean.	Is the sample mean equal to the population mean	6384
10223	Unconscious racial stereotypes are a major example of implicit bias. In other words, having an automatic preference for one race over another without even being aware of this bias.	What is implicit bias example	10223
762	Target Concept Term used in the machine learning literature to denote the Bayes decision rule, or the regression function, depending on the context. The target concept is a member of the concept space. Synonyms: Bayes Decision Rule in classification, Regression Function in regression.	What is the target concept in machine learning	762
1483	N-grams are contiguous sequences of n-items in a sentence. N can be 1, 2 or any other positive integers, although usually we do not consider very large N because those n-grams rarely appears in many different places.  This post describes several different ways to generate n-grams quickly from input sentences in Python.	What is N grams Python	1483
10740	Descriptive studies only describe the current state of a variable, so there are no presumed cause or effects, therefore no independent and dependent variables.  Since neither variable in a correlational design is manipulated, it is impossible to determine which is the cause and which is the effect.	Why are dependent and independent variables not applicable in a descriptive type of research	10740
7228	Dropout is a regularization technique for neural network models proposed by Srivastava, et al. in their 2014 paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting (download the PDF). Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly.	What is dropout rate in deep learning	7228
4134	In computational mathematics, an iterative method is a mathematical procedure that uses an initial value to generate a sequence of improving approximate solutions for a class of problems, in which the n-th approximation is derived from the previous ones.	What is the condition for iterative method	4134
4451	Altman's Z-Score model is a numerical measurement that is used to predict the chances of a business going bankrupt in the next two years. The model was developed by American finance professor Edward Altman in 1968 as a measure of the financial stability of companies.	What is Altman's Z score model	4451
556	A feedforward neural network is a biologically inspired classification algorithm. It consist of a (possibly large) number of simple neuron-like processing units, organized in layers. Every unit in a layer is connected with all the units in the previous layer.  This is why they are called feedforward neural networks.	What is meant by feed forward neural network	556
9765	The chi-square test is a hypothesis test designed to test for a statistically significant relationship between nominal and ordinal variables organized in a bivariate table. In other words, it tells us whether two variables are independent of one another.  The chi-square test is sensitive to sample size.	Is Chi square bivariate analysis	9765
6881	For large samples, the sample proportion is approximately normally distributed, with mean μˆP=p. and standard deviation σˆP=√pqn. A sample is large if the interval [p−3σˆp,p+3σˆp] lies wholly within the interval [0,1].	How do you find a sample proportion	6881
6792	"The ""Fast Fourier Transform"" (FFT) is an important measurement method in the science of audio and acoustics measurement. It converts a signal into individual spectral components and thereby provides frequency information about the signal."	What is the purpose of FFT	6792
8225	The weaknesses of decision tree methods : Decision trees are less appropriate for estimation tasks where the goal is to predict the value of a continuous attribute. Decision trees are prone to errors in classification problems with many class and relatively small number of training examples.	What are the issues in decision tree induction	8225
1929	A one-sided argument (also known as card stacking, stacking the deck, ignoring the counterevidence, slanting, and suppressed evidence) is an informal fallacy that occurs when only the reasons supporting a proposition are supplied, while all reasons opposing it are omitted.	What fallacy involves a deliberate selection of data to support only one side of an issue	1929
8562	The availability heuristic is a mental shortcut that helps us make a decision based on how easy it is to bring something to mind.  The representativeness heuristic is a mental shortcut that helps us make a decision by comparing information to our mental prototypes.	What is the difference between representative and availability heuristics	8562
39	Deep learning neural networks are trained using the stochastic gradient descent optimization algorithm. The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.	Why is learning rate used in gradient descent optimization	39
5189	Variance (σ2) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.	What exactly is variance	5189
7173	Normal Approximation to the Binomialn is your sample size,p is your given probability.q is just 1 – p. For example, let's say your probability p is . You would find q by subtracting this probability from 1: q = 1 – . 6 = .	How do you find the probability of normal approximation	7173
355	In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of successes (random draws for which the object drawn has a specified feature) in draws, without replacement, from a finite population of size that contains exactly objects with	What is hypergeometric distribution in statistics	355
161	With binary data the variance is a function of the mean, and in particular is not constant as the mean changes. This violates one of the standard linear regression assumptions that the variance of the residual errors is constant.	Why linear regression is not suitable for modeling binary responses	161
9218	Quota sampling is different from stratified sampling, because in a stratified sample individuals within each stratum are selected at random. Quota sampling achieves a representative age distribution, but it isn't a random sample, because the sampling frame is unknown.	Is quota sampling random	9218
9432	To see the accuracy of clustering process by using K-Means clustering method then calculated the square error value (SE) of each data in cluster 2. The value of square error is calculated by squaring the difference of the quality score or GPA of each student with the value of centroid cluster 2.	How do you find the accuracy of K means clustering	9432
7628	A disadvantage is when researchers can't classify every member of the population into a subgroup. Stratified random sampling is different from simple random sampling, which involves the random selection of data from the entire population so that each possible sample is equally likely to occur.	What are the disadvantages of stratified sampling	7628
656	Bias allows you to shift the activation function by adding a constant (i.e. the given bias) to the input. Bias in Neural Networks can be thought of as analogous to the role of a constant in a linear function, whereby the line is effectively transposed by the constant value.	What are biases in neural network	656
10313	"Ridge and lasso regression allow you to regularize (""shrink"") coefficients. This means that the estimated coefficients are pushed towards 0, to make them work better on new data-sets (""optimized for prediction""). This allows you to use complex models and avoid over-fitting at the same time."	Why do we use Ridge and lasso regression	10313
3916	Endogenous variables are used in econometrics and sometimes in linear regression. They are similar to (but not exactly the same as) dependent variables. Endogenous variables have values that are determined by other variables in the system (these “other” variables are called exogenous variables).	How do you find endogenous variables	3916
9541	The purpose of an inverted index is to allow fast full-text searches, at a cost of increased processing when a document is added to the database. The inverted file may be the database file itself, rather than its index.	What are the uses of an inverted index	9541
3288	Because it arises from consistency between parts of a test, split-half reliability is an “internal consistency” approach to estimating reliability. This result is an estimate of the reliability of the test scores, and it provides some support for the quality of the test scores.	Why is split half reliability important	3288
9738	The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(∗). Both functions will take any number and rescale it to fall between 0 and 1.	What is the difference between logit and probit regression	9738
7415	Here are 11 tips for making the most of your large data sets.Cherish your data. “Keep your raw data raw: don't manipulate it without having a copy,” says Teal.  Visualize the information.Show your workflow.  Use version control.  Record metadata.  Automate, automate, automate.  Make computing time count.  Capture your environment.More items•	How do you handle large datasets	7415
1748	We call vectorization the general process of turning a collection of text documents into numerical feature vectors.  Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.	What is feature vectorization	1748
5010	Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel. This is related to a form of mathematical convolution. The matrix operation being performed—convolution—is not traditional matrix multiplication, despite being similarly denoted by *.	What is convolution in an image	5010
5790	R is a very dynamic and versatile programming language for data science. This article deals with classification in R. Generally classifiers in R are used to predict specific category related information like reviews or ratings such as good, best or worst. Various Classifiers are: Decision Trees.	What is R classification	5790
563	Leaky ReLU & Parametric ReLU (PReLU) Leaky ReLU has two benefits: It fixes the “dying ReLU” problem, as it doesn't have zero-slope parts. It speeds up training. There is evidence that having the “mean activation” be close to 0 makes training faster.	What are the advantages of using Leaky Rectified Linear Units Leaky ReLU over normal ReLU in deep learning	563
9662	7 Practical Guidelines for Accurate Statistical Model BuildingRemember that regression coefficients are marginal results.  Start with univariate descriptives and graphs.  Next, run bivariate descriptives, again including graphs.  Think about predictors in sets.  Model building and interpreting results go hand-in-hand.More items	How do you develop a statistical model	9662
5156	A population is called multinomial if its data is categorical and belongs to a collection of discrete non-overlapping classes. The null hypothesis for goodness of fit test for multinomial distribution is that the observed frequency fi is equal to an expected count ei in each category.	What is multinomial population	5156
4808	The coefficient of variation (CV) is the ratio of the standard deviation to the mean. The higher the coefficient of variation, the greater the level of dispersion around the mean.  The lower the value of the coefficient of variation, the more precise the estimate.	Is it better to have a higher or lower coefficient of variation	4808
5269	Two determine if two images are rotated versions of each other, one can either exhaustively rotate them in order to find out if the two match up at some angle, or alternatively extract features from the images that can then be compared to make the same decision.	What is rotation invariant in image processing	5269
826	Linear models describe a continuous response variable as a function of one or more predictor variables. They can help you understand and predict the behavior of complex systems or analyze experimental, financial, and biological data.	What do you mean by linear model	826
6994	Three reasons that you should NOT use deep learning(1) It doesn't work so well with small data. To achieve high performance, deep networks require extremely large datasets.  (2) Deep Learning in practice is hard and expensive. Deep learning is still a very cutting edge technique.  (3) Deep networks are not easily interpreted.	When should you not use deep learning	6994
4734	Batch processing requires separate programs for input, process and output.  In contrast, real time data processing involves a continual input, process and output of data. Data must be processed in a small time period (or near real time). Radar systems, customer services and bank ATMs are examples.	What is the difference between batch processing and real time processing	4734
4252	Step 1: Load Python packages.  Step 2: Pre-Process the data.  Step 3: Subset the data.  Step 4: Split the data into train and test sets.  Step 5: Build a Random Forest Classifier.  Step 6: Predict.  Step 7: Check the Accuracy of the Model.  Step 8: Check Feature Importance.	How do you create a classification model	4252
1541	The “trick” is that kernel methods represent the data only through a set of pairwise similarity comparisons between the original data observations x (with the original coordinates in the lower dimensional space), instead of explicitly applying the transformations ϕ(x) and representing the data by these transformed	What is the kernel trick SVM	1541
2952	If I know a programming language, where is a great place to start practicing algorithms?  Become proficient at written communication.  Learn Functional Programming.  Learn Object Oriented Analysis and Design.  Free Code Camp.More items•	How can I begin to learn algorithms	2952
2796	For an idea we are all familiar with, randomness is surprisingly hard to formally define. We think of a random process as something that evolves over time but in a way we can't predict.	Can we predict randomness	2796
782	The difference between the two norms is that the standard deviation is calculating the square of the difference whereas the mean absolute deviation is only looking at the absolute difference. Hence large outliers will create a higher dispersion when using the standard deviation instead of the other method.	What is the logical difference between mean deviation and standard deviation	782
8418	Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks.  Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents.	What does spreading activation mean	8418
6263	Convolution is used in the mathematics of many fields, such as probability and statistics. In linear systems, convolution is used to describe the relationship between three signals of interest: the input signal, the impulse response, and the output signal.	What is the use of convolution	6263
8485	In image processing, thresholding is used to split an image into smaller segments, or junks, using at least one color or gray scale value to define their boundary. The advantage of obtaining first a binary image is that it reduces the complexityof the data and simplifies the process of recognition and classification.	Why thresholding is used in image processing	8485
5955	The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.	What is canny edge detection in image processing	5955
5542	The geometric distribution would represent the number of people who you had to poll before you found someone who voted independent. You would need to get a certain number of failures before you got your first success. If you had to ask 3 people, then X=3; if you had to ask 4 people, then X=4 and so on.	What does a geometric distribution look like	5542
8100	Measurement uncertainty is critical to risk assessment and decision making. Organizations make decisions every day based on reports containing quantitative measurement data. If measurement results are not accurate, then decision risks increase. Selecting the wrong suppliers, could result in poor product quality.	Why do statistics and uncertainties matter	8100
4386	In practical terms, deep learning is just a subset of machine learning. In fact, deep learning technically is machine learning and functions in a similar way (hence why the terms are sometimes loosely interchanged).	Is deep learning a part of machine learning	4386
3636	Time Series Forecast in RStep 1: Reading data and calculating basic summary.  Step 2: Checking the cycle of Time Series Data and Plotting the Raw Data.  Step 3: Decomposing the time series data.  Step 4: Test the stationarity of data.  Step 5: Fitting the model.  Step 6: Forecasting.	How do you forecast time series data	3636
2665	Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.	How does machine learning collect data	2665
1207	The hazard rate refers to the rate of death for an item of a given age (x). It is part of a larger equation called the hazard function, which analyzes the likelihood that an item will survive to a certain point in time based on its survival to an earlier time (t).	What is the hazard rate function	1207
8981	The normal distribution is a probability function that describes how the values of a variable are distributed. It is a symmetric distribution where most of the observations cluster around the central peak and the probabilities for values further away from the mean taper off equally in both directions.	Which distribution is a normal distribution	8981
6540	On the other hand, when the normal approximation is used to approximate a discrete distribution, a continuity correction can be employed so that we can approximate the probability of a specific value of the discrete distribution. The continuity correction requires adding or subtracting .	Why is the correction for continuity used when using the normal approximation to the binomial distribution	6540
8075	It is a particular Monte Carlo method that numerically computes a definite integral. While other algorithms usually evaluate the integrand at a regular grid, Monte Carlo randomly chooses points at which the integrand is evaluated. This method is particularly useful for higher-dimensional integrals.	How does Monte Carlo integration work	8075
2528	Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor. For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms.	Why is there a Bayesian network	2528
7493	Although side effects believed to be caused by statins can be annoying, consider the benefits of taking a statin before you decide to stop taking your medication. Remember that statin medications can reduce your risk of a heart attack or stroke, and the risk of life-threatening side effects from statins is very low.	Are statins really worth taking	7493
8382	2. Why is it important to examine a residual plot even if a scatterplot appears to be linear? An examination of the of the residuals often leads us to discover groups of observations that are different from the rest.	Why is it important to examine a residual plot	8382
3301	"Prediction bias is a quantity that measures how far apart those two averages are. That is: prediction bias = average of predictions − average of labels in data set. Note: ""Prediction bias"" is a different quantity than bias (the b in wx + b)."	What is bias in classification	3301
5668	The sample proportion, P is an unbiased estimator of the population proportion, . Unbiased estimators determines the tendency , on the average, for the statistics to assume values closed to the parameter of interest.	Is proportion a biased estimator	5668
363	Jakob Bernoulli	Who discovered the law of large numbers	363
1805	The top 5 AI developments as chosen by our team are as follows:The increased speed of AI-enabled medical research.  Computer vision, image, and video analysis technology is evolving.  Powerful AI-based tools become mainstream.  AI learns increasingly higher-level human functions.More items•	What are the recent developments in AI	1805
2985	Sampling is done because you usually cannot gather data from the entire population. Even in relatively small populations, the data may be needed urgently, and including everyone in the population in your data collection may take too long.	Why is sample survey done	2985
3720	Association rule mining is a procedure which aims to observe frequently occurring patterns, correlations, or associations from datasets found in various kinds of databases such as relational databases, transactional databases, and other forms of repositories.	What is an association rule in data mining	3720
7893	From Wikipedia, the free encyclopedia. Cohen's kappa coefficient (κ) is a statistic that is used to measure inter-rater reliability (and also Intra-rater reliability) for qualitative (categorical) items.	What does Kappa mean in statistics	7893
6632	Concepts in Machine Learning can be thought of as a boolean-valued function defined over a large set of training data.  We have some attributes/features of the day like, Sky, Air Temperature, Humidity, Wind, Water, Forecast and based on this we have a target Concept named EnjoySport.	What is ML concept	6632
5746	It is one of the more common descriptive statistics functions used to calculate uncertainty.How to CalculateSubtract each value from the mean.Square each value in step 1.Add all of the values from step 2.Count the number of values and Subtract it by 1.Divide step 3 by step 4.Calculate the Square Root of step 5.	How do you calculate uncertainty in statistics	5746
3965	One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.	Which of the following were introduced to overcome the vanishing gradient problem	3965
6999	K-nearest neighbor is also used in retail to detect patterns in credit card usage. Many new transaction-scrutinizing software applications use kNN algorithms to analyze register data and spot unusual patterns that indicate suspicious activity.	What are industry applications of the K nearest neighbor algorithm	6999
5182	One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.	What is the vanishing gradient problem and how do we overcome that	5182
10617	"Symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high-level ""symbolic"" (human-readable) representations of problems, logic and search.  Production rules connect symbols in a relationship similar to an If-Then statement."	What is symbolic machine learning	10617
3639	Definition: The trend is the component of a time series that represents variations of low frequency in a time series, the high and medium frequency fluctuations having been filtered out.	What is trend in time series data	3639
381	Machine learning can be described in many ways. Perhaps the most useful is as type of optimization.  This is done via what is known as an objective function, with “objective” used in the sense of a goal. This function, taking data and model parameters as arguments, can be evaluated to return a number.	What is an objective function in machine learning	381
7592	However, it is not necessary for you to learn the machine learning algorithms that are not a part of machine learning in order to learn deep learning. Instead, if you want to learn deep learning then you can go straight to learning the deep learning models if you want to.	Can I directly learn deep learning	7592
8018	Cohen's kappa coefficient (κ) is a statistic that is used to measure inter-rater reliability (and also Intra-rater reliability) for qualitative (categorical) items.	What is Cohen's kappa used for	8018
3147	Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set.  Based on historical data about earlier outcomes involving the same input criteria, it then scores new cases on their probability of falling into a particular outcome category.	What is logistic regression in data science	3147
880	Analysis of variance (ANOVA) is an analysis tool used in statistics that splits an observed aggregate variability found inside a data set into two parts: systematic factors and random factors.  1﻿﻿2﻿ ANOVA is also called the Fisher analysis of variance, and it is the extension of the t- and z-tests.	What is the concept of analysis of variance ANOVA in statistics	880
3463	The aim of distributional semantics is to learn the meanings of linguistic expressions from a corpus of text. The core idea, known as the distributional hy- pothesis, is that the contexts in which an expression appears give us information about its meaning.	What are the goals of distributional semantics	3463
8664	Midrange determines the number that is halfway between the minimum and maximum numbers of a data set. It is a statistical tool that identifies a measure of center like median, mean or mode.	What is the mid range in statistics	8664
8719	Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.	What is Adam algorithm	8719
10422	The least squares approach limits the distance between a function and the data points that the function explains. It is used in regression analysis, often in nonlinear regression modeling in which a curve is fit into a set of data. Mathematicians use the least squares method to arrive at a maximum-likelihood estimate.	Why do we use least square method	10422
10605	"Heuristics are the ""shortcuts"" that humans use to reduce task complexity in judgment and choice, and biases are the resulting gaps between normative behavior and the heuristically determined behavior (Kahneman et al., 1982)."	What is the difference between a heuristic and a bias	10605
5916	The coefficient of determination can also be found with the following formula: R2 = MSS/TSS = (TSS − RSS)/TSS, where MSS is the model sum of squares (also known as ESS, or explained sum of squares), which is the sum of the squares of the prediction from the linear regression minus the mean for that variable; TSS is the	What is the formula for calculating the coefficient of determination	5916
4244	Mutual information is a quantity that measures a relationship between two random variables that are sampled simultaneously. In particular, it measures how much information is communicated, on average, in one random variable about another.	How does mutual information work	4244
1225	The three main methods to perform linear regression analysis in Excel are: Regression tool included with Analysis ToolPak. Scatter chart with a trendline.	What method does Excel use for linear regression	1225
509	The Hidden layer of the neural network is the intermediate layer between Input and Output layer. Activation function applies on hidden layer if it is available.  Hidden nodes or hidden neurons are the neurons that are neither in the input layer nor the output layer [3].	What are hidden nodes in neural network	509
5923	Linear regression attempts to model the relationship between two variables by fitting a linear equation (= a straight line) to the observed data. One variable is considered to be an explanatory variable (e.g. your income), and the other is considered to be a dependent variable (e.g. your expenses).	How would linear regression be described and explained in laymans terms	5923
10246	The independent variable is the variable the experimenter changes or controls and is assumed to have a direct effect on the dependent variable.  The dependent variable is the variable being tested and measured in an experiment, and is 'dependent' on the independent variable.	What is the independent variable in an experiment	10246
3671	"A Gaussian filter is a linear filter. It's usually used to blur the image or to reduce noise. If you use two of them and subtract, you can use them for ""unsharp masking"" (edge detection). The Gaussian filter alone will blur edges and reduce contrast."	What does a Gaussian filter do	3671
10292	If you don't know your population mean (μ) but you do know the standard deviation (σ), you can find a confidence interval for the population mean, with the formula: x̄ ± z* σ / (√n),  Step 1: Subtract the confidence level (Given as 95 percent in the question) from 1 and then divide the result by two.	How are confidence intervals calculated	10292
9941	"""A discrete variable is one that can take on finitely many, or countably infinitely many values"", whereas a continuous random variable is one that is not discrete, i.e. ""can take on uncountably infinitely many values"", such as a spectrum of real numbers."	What is the difference between discrete and continuous variables	9941
3080	The sensitivity of the test reflects the probability that the screening test will be positive among those who are diseased. In contrast, the specificity of the test reflects the probability that the screening test will be negative among those who, in fact, do not have the disease.	How do you interpret sensitivity and specificity	3080
5067	Reinforcement Learning (RL) refers to a kind of Machine Learning method in which the agent receives a delayed reward in the next time step to evaluate its previous action. It was mostly used in games (e.g. Atari, Mario), with performance on par with or even exceeding humans.	What is reinforcement learning algorithms	5067
3444	For a discrete random variable, the expected value, usually denoted as or , is calculated using: μ = E ( X ) = ∑ x i f ( x i )	How do you find the expected value of a random variable	3444
9540	The notation for the uniform distribution is X ~ U(a, b) where a = the lowest value of x and b = the highest value of x. The probability density function is f(x)=1b−a f ( x ) = 1 b − a for a ≤ x ≤ b. For this example, X ~ U(0, 23) and f(x)=123−0 f ( x ) = 1 23 − 0 for 0 ≤ X ≤ 23.	How do you calculate uniform distribution	9540
6753	A decision boundary is the region of a problem space in which the output label of a classifier is ambiguous. If the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable. Decision boundaries are not always clear cut.	What is decision boundary in SVM	6753
5708	Propositional Logic converts a complete sentence into a symbol and makes it logical whereas in First-Order Logic relation of a particular sentence will be made that involves relations, constants, functions, and constants.	What is the difference between first order logic and propositional logic	5708
1451	The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence.	What data is used to train vector space models of words such as word2vec	1451
5164	4:1213:02Suggested clip · 101 secondsThe Transition Matrix - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you read a transition matrix	5164
1286	Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. Improving operations. Many companies use predictive models to forecast inventory and manage resources.	What is predictive analytics used for	1286
5183	Wilcoxon – The Wilcoxon signed rank test has the null hypothesis that both samples are from the same population.  Sign – The sign test has the null hypothesis that both samples are from the same population. The sign test compares the two dependent observations and counts the number of negative and positive differences.	What is the difference between sign test and Wilcoxon signed rank test	5183
5850	Lasso regression performs L1 regularization, which adds a penalty equal to the absolute value of the magnitude of coefficients.  On the other hand, L2 regularization (e.g. Ridge regression) doesn't result in elimination of coefficients or sparse models. This makes the Lasso far easier to interpret than the Ridge.	How are Lasso and ridge regressions used for regularization	5850
7610	The degree of freedom is not a property of the distribution, it's the name of the distribution. It refers to the number of degrees of freedom of some variable that has the distribution.	Statistics academic discipline What is an intuitive explanation of degrees of freedom	7610
7149	Mathematically speaking, a decision tree has low bias and high variance. Averaging the result of many decision trees reduces the variance while maintaining that low bias. Combining trees is known as an 'ensemble method'.	Is decision tree an ensemble method	7149
7809	Feature Selection. Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones.	What is feature selection and feature extraction	7809
20	In neural networks, Convolutional neural network (ConvNets or CNNs) is one of the main categories to do images recognition, images classifications. Objects detections, recognition faces etc., are some of the areas where CNNs are widely used.	What is convolutional neural network in image processing	20
2678	Any object, function, or statistic that doesn't change when scales are multiplied by a common factor is scale invariant. In statistics, it can also mean a statistic that tends not to change (i.e. 99% of the time, it will stay the same). Some specific statistics are scale invariant.	What is invariance in statistics	2678
4875	Linear models describe a continuous response variable as a function of one or more predictor variables. They can help you understand and predict the behavior of complex systems or analyze experimental, financial, and biological data.	What is a linear model used for	4875
10708	Each class will have a “lower class limit” and an “upper class limit” which are the lowest and highest numbers in each class. The “class width” is the distance between the lower limits of consecutive classes.	What is the difference between class size and class width	10708
3021	A Binomial Regression model can be used to predict the odds of an event.  The Logistic Regression model is a special case of the Binomial Regression model in the situation where the size of each group of explanatory variables in the data set is one.	Is binomial regression the same as logistic regression	3021
4367	Any good analysis of survey data from a stratified sample includes the same seven steps:Estimate a population parameter.Compute sample variance within each stratum.Compute standard error.Specify a confidence level.Find the critical value (often a z-score or a t-score).Compute margin of error.More items	How do you analyze stratified random sampling	4367
544	In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own Boolean-valued outcome: success/yes/true/one (with probability p)	What are the parameters of binomial distribution	544
8473	The name 'exponential smoothing' is attributed to the use of the exponential window function during convolution. It is no longer attributed to Holt, Winters & Brown. , and the weights assigned to previous observations are proportional to the terms of the geometric progression. .	Why is it called exponential smoothing	8473
8732	The biggest flaw in this machine learning technique, according to Mittu, is that there is a large amount of art to building these networks, which means there are few scientific methods to help understand when they will fail.	What's wrong with deep learning	8732
7785	This lesson explains how to conduct a chi-square goodness of fit test. The test is applied when you have one categorical variable from a single population. It is used to determine whether sample data are consistent with a hypothesized distribution.	What does the chi square goodness of fit test actually test	7785
8647	Examples of Discrete Distribution The most common discrete probability distributions include binomial, Poisson, Bernoulli, and multinomial.	Which is an example of a discrete distribution	8647
296	Entropy is simply a measure of disorder and affects all aspects of our daily lives. In fact, you can think of it as nature's tax. Left unchecked disorder increases over time. Energy disperses, and systems dissolve into chaos.	What is entropy and why is it important	296
2876	In Computer science (especially Machine learning) Pruning means simplifying/compressing and optimizing a Decision tree by removing sections of the tree that are uncritical and redundant to classify instances.	How does pruning work in decision trees	2876
8759	In such a sequence of trials, the geometric distribution is useful to model the number of failures before the first success. The distribution gives the probability that there are zero failures before the first success, one failure before the first success, two failures before the first success, and so on.	What is geometric distribution used for	8759
4147	An ordinal variable is a categorical variable for which the possible values are ordered. Ordinal variables can be considered “in between” categorical and quantitative variables. Thus it does not make sense to take a mean of the values.	What type of variable is ordinal	4147
5346	One of the key methodologies to improve efficiency in computational intensive tasks is to reduce the dimensions after ensuring most of the key information is maintained. It also eliminates features with strong correlation between them and reduces over-fitting.	When would you reduce dimensions in your data in machine learning	5346
560	The Antardasha of Mercury with Ketu Mahadasha can be evil and good depending on the placement of both Mercury and Ketu in the birth chart.  The antardasha of Mercury with Mahadasha of Ketu brings very bad results if the planet Mercury is weak, afflicted, aspect by Rahu, Saturn and Mars.	Is Ketu Mahadasha bad	560
7081	In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.	What is the mean of exponential distribution	7081
255	The main difference between the t-test and f-test is, that t-test is used to test the hypothesis whether the given mean is significantly different from the sample mean or not. On the other hand, an F-test is used to compare the two standard deviations of two samples and check the variability.	What is the difference between F and T test	255
3629	The range can also be used to estimate another measure of spread, the standard deviation. Rather than go through a fairly complicated formula to find the standard deviation, we can instead use what is called the range rule. The range is fundamental in this calculation.	What are the uses of the range in statistics and what are the areas that we use range for calculations in statistics	3629
143	Grid-searching is the process of scanning the data to configure optimal parameters for a given model.  Grid-searching can be applied across machine learning to calculate the best parameters to use for any given model.	What is grid search in machine learning	143
1624	The P-value is the probability that a chi-square statistic having 2 degrees of freedom is more extreme than 19.58. We use the Chi-Square Distribution Calculator to find P(Χ2 > 19.58) = 0.0001.	What is the relationship between p value and chi square	1624
3762	Discriminant analysis is a versatile statistical method often used by market researchers to classify observations into two or more groups or categories. In other words, discriminant analysis is used to assign objects to one group among a number of known groups.	What is the purpose of discriminant analysis	3762
3353	Preventing the error gradients from vanishing The presence of the forget gate's activations allows the LSTM to decide, at each time step, that certain information should not be forgotten and to update the model's parameters accordingly. and the gradient doesn't vanish.	How does LSTM help prevent the vanishing and exploding gradient problem in a recurrent neural network	3353
9416	Spatiotemporal, or spatial temporal, is used in data analysis when data is collected across both space and time. It describes a phenomenon in a certain location and time — for example, shipping movements across a geographic area over time (see above example image).	What is spatiotemporal analysis	9416
10980	The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape).	When would you use a Mann Whitney U test	10980
1744	How to optimize your meta tags: A checklistCheck whether all your pages and your content have title tags and meta descriptions.Start paying more attention to your headings and how you structure your content.Don't forget to mark up your images with alt text.More items•	How do you optimize meta tags	5386
9853	In mathematics, the geometric–harmonic mean M(x, y) of two positive real numbers x and y is defined as follows: we form the geometric mean of g0 = x and h0 = y and call it g1, i.e. g1 is the square root of xy.  The geometric–harmonic mean is also designated as the harmonic–geometric mean. (cf. Wolfram MathWorld below.)	What is geometric mean and harmonic mean in statistics	9853
565	 Birst employs caching and aggregate awareness to send queries to the cache first, and then data to the user-ready data store.  If data is not cached, Birst generates one or more queries depending on how the data is sourced.  Birst's in-memory caching includes both exact and fuzzy matching.	What are the matching types that birst employs while searching data in cache	565
2326	The mean used here is referred to as the arithmetic mean – the sum of all values divided by the number of cases. When working with grouped data, this mean is sometimes referred to as the weighted mean or, more properly, the weighted arithmetic mean. Ungrouped and group methods.	Is a weighted mean and a grouped data mean the same	2326
6930	The most used algorithm to train neural networks is gradient descent. We'll define it later, but for now hold on to the following idea: the gradient is a numeric calculation allowing us to know how to adjust the parameters of a network in such a way that its output deviation is minimized.	What is gradient neural network	6930
6948	7:5214:07Suggested clip · 100 secondsHow to Select the Correct Predictive Modeling Technique | Machine YouTubeStart of suggested clipEnd of suggested clip	How do you choose a predictive model	6948
1688	parameter-list is the list of parameters that the function takes separated by commas. If no parameters are given, then the function does not take any and should be defined with an empty set of parenthesis or with the keyword void. If no variable type is in front of a variable in the paramater list, then int is assumed.	What is the difference between a function with parameters and a functions without parameters	1688
2714	Each feature, or column, represents a measurable piece of data that can be used for analysis: Name, Age, Sex, Fare, and so on. Features are also sometimes referred to as “variables” or “attributes.” Depending on what you're trying to analyze, the features you include in your dataset can vary widely.	What is a feature variable	2714
4114	Statistical knowledge helps you use the proper methods to collect the data, employ the correct analyses, and effectively present the results. Statistics is a crucial process behind how we make discoveries in science, make decisions based on data, and make predictions.	What are the uses of statistics	4114
3761	Univariate statistics summarize only one variable at a time. Bivariate statistics compare two variables. Multivariate statistics compare more than two variables.	What is the difference between univariate and multivariate analysis	3761
8405	The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(∗). Both functions will take any number and rescale it to fall between 0 and 1.	What is the difference between logit and probit model	8405
9709	Last Updated on Decem. Cross-entropy is commonly used in machine learning as a loss function. Cross-entropy is a measure from the field of information theory, building upon entropy and generally calculating the difference between two probability distributions.	What is entropy and cross entropy	9709
854	A statistical hypothesis is a formal claim about a state of nature structured within the framework of a statistical model. For example, one could claim that the median time to failure from (acce]erated) electromigration of the chip population described in Section 6.1.	What is hypothesis in statistics with example	854
8220	Euclidean distance	Which distance metric can be used in Knn	8220
9994	TL;DR – The train_test_split function is for splitting a single dataset for two different purposes: training and testing.	Which of the following functions can be used to split the data into train and test	9994
6157	From Wikipedia, the free encyclopedia. An odds ratio (OR) is a statistic that quantifies the strength of the association between two events, A and B.	What is or in statistics	6157
9255	Perceptron Learning Rule The Perceptron receives multiple input signals, and if the sum of the input signals exceeds a certain threshold, it either outputs a signal or does not return an output. In the context of supervised learning and classification, this can then be used to predict the class of a sample.	How does a perceptron algorithm work	9255
5976	A discrete variable is a variable whose value is obtained by counting. A continuous variable is a variable whose value is obtained by measuring.  A discrete random variable X has a countable number of possible values.	What are the differences between continuous and discrete variables	5976
6133	A box plot (also known as box and whisker plot) is a type of chart often used in explanatory data analysis to visually show the distribution of numerical data and skewness through displaying the data quartiles (or percentiles) and averages.	What is Boxplot used for	6133
6038	H is the measurement matrix. This matrix influences the Kalman Gain.  R is the sensor noise matrix. This matrix implies the measurement error covariance, based on the amount of sensor noise. In this simulation, Q and R are constants, but some implementations of the Kalman Filter may adjust them throughout execution.	What is H in Kalman filter	6038
9910	In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment.	What is the purpose of probability distribution functions	9910
7225	An RNNs is essentially a fully connected neural network that contains a refactoring of some of its layers into a loop.  Among the text usages, the following tasks are among those RNNs perform well at: Sequence labelling. Natural Language Processing (NLP) text classification.	Is NLP neural network	7225
10595	Chi-Square goodness of fit test is a non-parametric test that is used to find out how the observed value of a given phenomena is significantly different from the expected value.  In Chi-Square goodness of fit test, sample data is divided into intervals.	What is the chi square goodness of fit test used for	10595
9931	Starting at $99.00 USD per user per month. Single-user, desktop application for Windows and Macs. Includes 12 months of technical support. Pricing information for IBM SPSS Statistics is supplied by the software provider or retrieved from publicly accessible pricing materials.	How much is SPSS for Mac	9931
37	From Wikipedia, the free encyclopedia. The control variates method is a variance reduction technique used in Monte Carlo methods. It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity.	What is control variates in variance reduction	37
4654	An autoencoder accepts input, compresses it, and then recreates the original input.  A variational autoencoder assumes that the source data has some sort of underlying probability distribution (such as Gaussian) and then attempts to find the parameters of the distribution.	What is the difference between traditional Autoencoder and variational Autoencoder	4654
8084	Other examples that may follow a Poisson distribution include the number of phone calls received by a call center per hour and the number of decay events per second from a radioactive source.	What is Poisson distribution example	8084
3076	If a problem is nonlinear and its class boundaries cannot be approximated well with linear hyperplanes, then nonlinear classifiers are often more accurate than linear classifiers. If a problem is linear, it is best to use a simpler linear classifier.	What is linear and nonlinear classifier	3076
5478	How do I run a Z Test?State the null hypothesis and alternate hypothesis.Choose an alpha level.Find the critical value of z in a z table.Calculate the z test statistic (see below).Compare the test statistic to the critical z value and decide if you should support or reject the null hypothesis.	How do you use Z test	5478
8587	Probability is the chance of an event occurring. A probability distribution is a table or an equation that links each outcome of a statistical experiment with its probability of occurrence.	What is the difference between probability and probability distribution	8587
7718	In statistics, the multiple comparisons, multiplicity or multiple testing problem occurs when one considers a set of statistical inferences simultaneously or infers a subset of parameters selected based on the observed values.	What is a multiple hypothesis testing problem in statistics	7718
4286	The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative. Using the original matrix (A), NMF will give you two matrices (W and H).	How does NMF topic modeling work	4286
5932	Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply.	What is rule based learning in AI	5932
10040	It is not rare that the results from a study that uses a convenience sample differ significantly with the results from the entire population.  Since the sample is not representative of the population, the results of the study cannot speak for the entire population. This results to a low external validity of the study.	How does convenience sampling affect results	10040
2370	If we use non - standard units then we may not be able to express our measurement internationally as mainly standard units are used and accepted internationally. The non- standard units do not have the same dimensions all over the world.	What are the disadvantages of using non standard units	2370
3983	Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models.	What is preprocessing in machine learning	3983
6397	Static Rules Approach. The most simple, and maybe the best approach to start with, is using static rules. The Idea is to identify a list of known anomalies and then write rules to detect those anomalies. Rules identification is done by a domain expert, by using pattern mining techniques, or a by combination of both.	How do you do anomaly detection	6397
1986	Log loss, aka logistic loss or cross-entropy loss. This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true .	What is the log loss function	1986
7673	In a normal distribution, the mean and the median are the same number while the mean and median in a skewed distribution become different numbers: A left-skewed, negative distribution will have the mean to the left of the median. A right-skewed distribution will have the mean to the right of the median.	What are some ways to distinguish between a skewed and normal distribution	7673
6670	The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.	What is Z score used for	6670
1336	The expression double standard originally referred to 18th- and 19th-century economic policies of bimetallism. Bimetallism was a monetary system that was based on two metals—a double standard, in its financial “prescribed value” sense, of gold and silver.	Where do double standards come from	1336
5368	matrix: A rectangular arrangement of numbers or terms having various uses such as transforming coordinates in geometry, solving systems of linear equations in linear algebra and representing graphs in graph theory.	What does a matrix represent in linear algebra	5368
6649	Homogeneity of variance is an assumption underlying both t tests and F tests (analyses of variance, ANOVAs) in which the population variances (i.e., the distribution, or “spread,” of scores around the mean) of two or more samples are considered equal.	What is homogeneity of variance in statistics	6649
10448	To convert a logit ( glm output) to probability, follow these 3 steps:Take glm output coefficient (logit)compute e-function on the logit using exp() “de-logarithimize” (you'll get odds then)convert odds to probability using this formula prob = odds / (1 + odds) .	How do you convert odds ratio to logit	10448
742	The recommended reference range of serum TNF-α was from nondetectable to 8.1 pg/mL. Among 147 patients with IgAN, 98 patients were with elevated serum TNF-α and 49 patients were without elevated serum TNF-α.	What is normal range of TNF alpha	742
1192	Multiclass classification: classification task with more than two classes. Each sample can only be labelled as one class. For example, classification using features extracted from a set of images of fruit, where each image may either be of an orange, an apple, or a pear.	What is multi class classification in machine learning	1192
9955	When the image goes through them, the important features are kept in the convolution layers, and thanks to the pooling layers, these features are intensified and kept over the network, while discarding all the information that doesn't make a difference for the task.	What is convolution and pooling	9955
9861	Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.	When should logistic regression be used for data analysis	9861
8883	Second-Order/Pseudo-Second-Order Reaction For a Pseudo-Second-Order Reaction, the reaction rate constant k is replaced by the apparent reaction rate constant k'. If the reaction is not written out specifically to show a value of νA, the value is assumed to be 1 and is not shown in these equations.	What is a pseudo second order reaction	8883
8919	The values of the kernel filters are learned automatically by the neural network through the training process, and the filters kernels which results in the features that are most efficient for the particular classification or the detection are automatically learned.	How are filters chosen in CNN	8919
6896	The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed.  In general, a lower RMSD is better than a higher one.	What is root mean square error used for	6896
4802	A recursive system is a system in which current output depends on previous output(s) and input(s) but in non-recursive system current output does not depend on previous output(s).	What is recursive and nonrecursive system	4802
10858	Fourier analysis is used in electronics, acoustics, and communications. Many waveforms consist of energy at a fundamental frequency and also at harmonic frequencies (multiples of the fundamental). The relative proportions of energy in the fundamental and the harmonics determines the shape of the wave.	What is Fourier analysis used for	10858
683	Q-learning is called off-policy because the updated policy is different from the behavior policy, so Q-Learning is off-policy. In other words, it estimates the reward for future actions and appends a value to the new state without actually following any greedy policy.	How is Q learning off policy	683
3297	K-nearest neighbors K- nearest neighbor (kNN) is a simple supervised machine learning algorithm that can be used to solve both classification and regression problems. kNN stores available inputs and classifies new inputs based on a similar measure i.e. the distance function.	Which algorithm is used for both classification and regression predictive problems	3297
917	The linear, polynomial and RBF or Gaussian kernel are simply different in case of making the hyperplane decision boundary between the classes.  Usually linear and polynomial kernels are less time consuming and provides less accuracy than the rbf or Gaussian kernels.	What is the difference between a Gaussian kernel a polynomial kernel a linear kernel and an RBF based kernel	917
3920	Z Score is free of any scale, hence it is used as a transformation technique while we need to make any variable unit free in various statistical techniques. Also, it is used to identifying outliers in a univarite way.  Z-test is a statistical technique to test the Null Hypothesis against the Alternate Hypothesis.	How is the Z test different from Z score analysis	3920
2626	To help you get started in the field, we've assembled a list of the best Big Data courses available.Simplilearn. Simplilearn's Big Data Course catalogue is known for their large number of courses, in subjects as varied as Hadoop, SAS, Apache Spark, and R.  Cloudera.  Big Data University.  Hortonworks.  Coursera.	How do you learn big data	2626
5818	An -dimensional vector, i.e., a vector ( , , , ) with components. In dimensions greater than or equal to two, vectors are sometimes considered synonymous with points and so n-tuples ( , , , ) are sometimes called points in n-space.	What is an N dimensional vector	5818
6363	Stochastic gradient descent (SGD) computes the gradient for each update using a single training data point x_i (chosen at random). The idea is that the gradient calculated this way is a stochastic approximation to the gradient calculated using the entire training data.	What is an intuitive explanation of stochastic gradient descent	6363
6426	a. it allows us to disregard the size of the sample selected when the population is not normal.  it allows us the disregard the shape of the population when n is large.	Why is the central limit theorem so important to the study of sampling distributions	6426
10033	Whereas multiple regression predicts a single dependent variable from a set of multiple independent variables, canonical correlation simultaneously predicts multiple dependent variables from multiple independent variables.	When would someone use canonical correlation analysis versus multiple multiple regressions	10033
9270	"In artificial intelligence research, commonsense knowledge consists of facts about the everyday world, such as ""Lemons are sour"", that all humans are expected to know.  Common sense knowledge also helps to solve problems in the face of incomplete information."	What is common sense in artificial intelligence	9270
3213	The sample variance is not always smaller than the population variance.	Is sample variance always smaller than population variance	3213
8766	At its core, a loss function is incredibly simple: it's a method of evaluating how well your algorithm models your dataset. If your predictions are totally off, your loss function will output a higher number. If they're pretty good, it'll output a lower number.	What does the equation for the loss function do conceptually	8766
1367	OLS does not require that the error term follows a normal distribution to produce unbiased estimates with the minimum variance. However, satisfying this assumption allows you to perform statistical hypothesis testing and generate reliable confidence intervals and prediction intervals.	Does OLS require normal distribution	1367
10161	The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems.	Can Knn be used for classification	10161
8336	The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases.  Therefore, as a sample size increases, the sample mean and standard deviation will be closer in value to the population mean μ and standard deviation σ .	Does the mean increase with sample size	8336
9911	A parametric model is one where we assume the 'shape' of the data, and therefore only have to estimate the coefficients of the model. A non-parametric model is one where we do not assume the 'shape' of the data, and we have to estimate the most suitable form of the model, along with the coefficients.	What is the difference between parametric and non parametric models	9911
4459	Model calibration is done by adjusting the selected parameters such as growth rates, loss rates in the model to obtain a best fit between the model calculations and the monthly average field data (Set #1) collected during first year (June 18, 2004–June 27, 2005).	How do you calibrate a model	4459
6494	Class limits are the least and greatest numbers that can belong to the class. Class boundaries are the numbers that separate classes without forming gaps between them.	What is the difference between class limits and class boundaries quizlet	6494
9295	The term convolution refers to the mathematical combination of two functions to produce a third function. It merges two sets of information. In the case of a CNN, the convolution is performed on the input data with the use of a filter or kernel (these terms are used interchangeably) to then produce a feature map.	What is CNN convolution operation	9295
981	In this context, a neural network is one of several machine learning algorithms that can help solve classification problems. Its unique strength is its ability to dynamically create complex prediction functions, and emulate human thinking, in a way that no other algorithm can.	Can neural networks be used for classification	981
10707	The problem is we always prefer an output having highest probability or lowest distance from reference as our answer and while we are dealing with it, KNN will always give same output for a given set of input repeatedly tested. That means it is quit deterministic.	Is K nearest neighbors example of deterministic algorithm	10707
10289	According to my POV model accuracy is more important and its all depends on the training data.  Model performance can be improved using distributed computing and parallelizing over the scored assets, whereas accuracy has to be carefully built during the model training process.	Which is more important to you model accuracy or model performance	10289
4126	1a : to divide into parts or shares. b : to divide (a place, such as a country) into two or more territorial units having separate political status. 2 : to separate or divide by a partition (such as a wall) —often used with off. Other Words from partition Synonyms More Example Sentences Learn More about partition.	What does partitioning mean	4126
10364	"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."	What is the role of activation function in neural network	10364
10035	Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks. Tim Salimans, Diederik P. Kingma. Download PDF. We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction.	What is called as weight normalization in machine learning	10035
7585	Normalization is the process of organizing data into a related table; it also eliminates redundancy and increases the integrity which improves performance of the query. To normalize a database, we divide the database into tables and establish relationships between the tables.	What is normalization and its types	7585
2356	Here are 13 ways you can naturally increase your eagerness to learn and keep feeding your curiosity to stay on your learning goals.Just Show Your Eagerness.  Stay Updated.  Don't Stop Developing Your Skills.  Look for Challenges.  Learn Lateral Thinking.  Be Open to New Experiences.  Start to Be Interesting.  Gain Initial Knowledge.More items•	In what ways do I become more eager to learn and improve myself	2356
8582	A z-score measures exactly how many standard deviations above or below the mean a data point is.  A negative z-score says the data point is below average. A z-score close to 0 says the data point is close to average. A data point can be considered unusual if its z-score is above 3 or below −3 .	What is a z score in math	8582
5906	Time series data is data that is collected at different points in time. This is opposed to cross-sectional data which observes individuals, companies, etc. at a single point in time. Because data points in time series are collected at adjacent time periods there is potential for correlation between observations.	How do you collect time series data	5906
388	Stochastic vs. In general, stochastic is a synonym for random. For example, a stochastic variable is a random variable. A stochastic process is a random process. Typically, random is used to refer to a lack of dependence between observations in a sequence.	What is the difference between stochastic and random	388
8848	Entry level positions require at least a bachelor's degree while positions entailing supervision, leadership or administrative roles frequently require master's or doctoral degrees. Typical coursework involves study of: Various level of math, including probability, statistics, algebra, calculus, logic and algorithms.	What should I study to work with artificial intelligence	8848
4788	To find the harmonic mean of a set of n numbers, add the reciprocals of the numbers in the set, divide the sum by n, then take the reciprocal of the result.	How do you calculate harmonic mean	4788
7757	For example, a perfect precision and recall score would result in a perfect F-Measure score:F-Measure = (2 * Precision * Recall) / (Precision + Recall)F-Measure = (2 * 1.0 * 1.0) / (1.0 + 1.0)F-Measure = (2 * 1.0) / 2.0.F-Measure = 1.0.	How do you calculate precision and recall	7757
2230	How to Perform Systematic Sampling: StepsStep 1: Assign a number to every element in your population.  Step 2: Decide how large your sample size should be.  Step 3: Divide the population by your sample size.  Step 1: Assign a number to every element in your population.Step 2: Decide how large your sample size should be.More items•	What are the steps of systematic sampling	2230
3630	Using too large a batch size can have a negative effect on the accuracy of your network during training since it reduces the stochasticity of the gradient descent.	How does a larger batch size affect your training accuracy	3630
4851	Unlike the previous measures of variability, the variance includes all values in the calculation by comparing each value to the mean. To calculate this statistic, you calculate a set of squared differences between the data points and the mean, sum them, and then divide by the number of observations.	How do you compare variability of two data sets	4851
7273	The median is the middle number in a sorted, ascending or descending, list of numbers and can be more descriptive of that data set than the average.  If there is an odd amount of numbers, the median value is the number that is in the middle, with the same amount of numbers below and above.	What is median value in statistics	7273
5135	Random errors often have a Gaussian normal distribution (see Fig. 2). In such cases statistical methods may be used to analyze the data. The mean m of a number of measurements of the same quantity is the best estimate of that quantity, and the standard deviation s of the measurements shows the accuracy of the estimate.	Do random errors always have a Gaussian distribution	5135
2557	Softmax is used for multi-classification in the Logistic Regression model, whereas Sigmoid is used for binary classification in the Logistic Regression model. This is similar to the Sigmoid function. The difference is that, in the denominator, we sum together all of the values.	What is the difference between sigmoid and Softmax	2557
6899	So while L2 regularization does not perform feature selection the same way as L1 does, it is more useful for feature *interpretation*: a predictive feature will get a non-zero coefficient, which is often not the case with L1.	Can we use l2 regularization for feature selection	6899
1313	In general, an LSTM can be used for classification or regression; it is essentially just a standard neural network that takes as input, in addition to input from that time step, a hidden state from the previous time step. So, just as a NN can be used for classification or regression, so can an LSTM.	Can Lstm be used for classification	1313
4867	Multinomial logistic regression is used to predict categorical placement in or the probability of category membership on a dependent variable based on multiple independent variables. The independent variables can be either dichotomous (i.e., binary) or continuous (i.e., interval or ratio in scale).	What is multinomial logistic regression used for	4867
8660	5 | Problems and Issues of Linear RegressionSpecification.Proxy Variables and Measurement Error.Selection Bias.Multicollinearity.Autocorrelation.Heteroskedasticity.Simultaneous Equations.Limited Dependent Variables.More items	What are some problems that are encountered when creating a regression model	8660
5915	Factor Analysis in SPSS To conduct a Factor Analysis, start from the “Analyze” menu.  This dialog allows you to choose a “rotation method” for your factor analysis.  This table shows you the actual factors that were extracted.  E.  Finally, the Rotated Component Matrix shows you the factor loadings for each variable.More items	How do you do factor analysis in SPSS	5915
9691	where Ua is size m × n, Ub is size m × (m - n), and Σa is of size n × n. Then A = UaΣaVH is called the reduced SVD of the matrix A. In this context the SVD defined in Equation (1) is sometimes referred to as the full SVD for contrast. Notice that Ua is not unitary, but it does have orthogonal columns.	What is reduced SVD	9691
9822	The data structure which is being used in DFS is stack. The process is similar to BFS algorithm. In DFS, the edges that leads to an unvisited node are called discovery edges while the edges that leads to an already visited node are called block edges.	Which data structure is used by depth first search algorithm	9822
3834	A supervised learning algorithm takes a known set of input data and known responses to the data (output) and trains a model to generate reasonable predictions for the response to new data.  Supervised learning uses classification and regression techniques to develop predictive models.	How does supervised learning algorithm work	3834
9340	How to Use K-means Cluster Algorithms in Predictive AnalysisPick k random items from the dataset and label them as cluster representatives.Associate each remaining item in the dataset with the nearest cluster representative, using a Euclidean distance calculated by a similarity function.Recalculate the new clusters' representatives.More items	How do you predict using clustering	9340
4338	Hold-out is when you split up your dataset into a 'train' and 'test' set. The training set is what the model is trained on, and the test set is used to see how well that model performs on unseen data.	What is hold out in machine learning	4338
2976	A random process is a time-varying function that assigns the outcome of a random experiment to each time instant: X(t). • For a fixed (sample path): a random process is a time varying function, e.g., a signal.	What does random processes mean	2976
2899	Convenience sampling (also known as grab sampling, accidental sampling, or opportunity sampling) is a type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.	What is a convenience sample in statistics	2899
767	Computing accuracy for clustering can be done by reordering the rows (or columns) of the confusion matrix so that the sum of the diagonal values is maximal. The linear assignment problem can be solved in O(n3) instead of O(n!). Coclust library provides an implementation of the accuracy for clustering results.	How do you find the accuracy of a clustering algorithm	767
5210	The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions. Factor analysis can be used to simplify data, such as reducing the number of variables in regression models.	What is the purpose of factor analysis	8409
7439	The equation of a hyperplane is w · x + b = 0, where w is a vector normal to the hyperplane and b is an offset.	How do you calculate Hyperplane	7439
6914	t-test is used to test if two sample have the same mean. The assumptions are that they are samples from normal distribution. f-test is used to test if two sample have the same variance. Same assumptions hold.	What is the difference between t distribution and F distribution	6914
2781	To analyze this data follow these steps:Open the file KAPPA.SAV.  Select Analyze/Descriptive Statistics/Crosstabs.Select Rater A as Row, Rater B as Col.Click on the Statistics button, select Kappa and Continue.Click OK to display the results for the Kappa test shown here:	How do I report a kappa statistic	2781
8133	Decision Tree Splitting Method #1: Reduction in VarianceFor each split, individually calculate the variance of each child node.Calculate the variance of each split as the weighted average variance of child nodes.Select the split with the lowest variance.Perform steps 1-3 until completely homogeneous nodes are achieved.	How do you determine the best split in decision tree	8133
1924	Bayesian networks encode the dependencies and independencies between variables. Under the causal Markov assumption, each variable in a Bayesian network is independent of its ancestors given the values of its parents.	What is the Markov assumption for a dynamic Bayesian network	1924
208	value of the Shapiro-Wilk Test is greater than 0.05, the data is normal. If it is below 0.05, the data significantly deviate from a normal distribution. If you need to use skewness and kurtosis values to determine normality, rather the Shapiro-Wilk test, you will find these in our enhanced testing for normality guide.	How do you test for normality	208
3880	To overcome this prob- lem, the ResNet incorporates skip-connections between layers (He et al., 2016a,b) and the batch-normalization (BN) normalizes the input of activation functions (Ioffe and Szegedy, 2015). These architectures enable an extreme deep neural network to be trained with high performance.	Does ResNet use batch normalization	3880
6273	Difference Between Temporal and Spatial Databases A spatial database stores and allows queries of data defined by geometric space. Many spatial databases can represent simple coordinates, points, lines and polygons.  A temporal database stores data relating to time whether past, present or future.	What is the difference between spatial temporal data with other type of data	6273
4756	All Answers (6) Indeed a common rule of thumb is 10 outcome events per predictor, but sometimes this rule is too conservative and can be relaxed (see Vittinghoff E, McCulloch CE. 2007. Relaxing the rule of ten events per variable in logistic and Cox regression.	How many variables should be in a regression model	4756
3171	How to Calculate a Confusion MatrixStep 1) First, you need to test dataset with its expected outcome values.Step 2) Predict all the rows in the test dataset.Step 3) Calculate the expected predictions and outcomes:	How do you analyze a confusion matrix	3171
9690	The mean, or average, IQ is 100. Standard deviations, in most cases, are 15 points. The majority of the population, 68.26%, falls within one standard deviation of the mean (IQ 85-115).	What is IQ standard deviation	9690
9959	Advantages of Linear Regression Linear regression has a considerably lower time complexity when compared to some of the other machine learning algorithms. The mathematical equations of Linear regression are also fairly easy to understand and interpret. Hence Linear regression is very easy to master.	What are advantages of different regression algorithms	9959
1297	Parallel analysis is a method for determining the number of components or factors to retain from pca or factor analysis. Essentially, the program works by creating a random dataset with the same numbers of observations and variables as the original data.	What is parallel analysis in factor analysis	1297
8311	Chunking in NLP is Changing a perception by moving a “chunk”, or a group of bits of information, in the direction of a Deductive or Inductive conclusion through the use of language.  you will start to get smaller pieces of information about a car.	What is chunking in NLP	8311
5412	The Dirichlet is the multivariate generalization of the beta distribution.  The Dirichlet equals the uniform distribution when all parameters (α1… αk) are equal. The Dirichlet distribution is a conjugate prior to the categorical distribution and multinomial distributions. A compound variant is the Dirichlet-multinomial.	What does Dirichlet mean	5412
1211	Logistic regression is a powerful machine learning algorithm that utilizes a sigmoid function and works best on binary classification problems, although it can be used on multi-class classification problems through the “one vs. all” method. Logistic regression (despite its name) is not fit for regression tasks.	Is logistic regression only for binary classification	1211
6250	Popular ML algorithms include: linear regression, logistic regression, SVMs, nearest neighbor, decision trees, PCA, naive Bayes classifier, and k-means clustering. Classical machine learning algorithms are used for a wide range of applications.	What are the models in machine learning	6250
4616	A Classification report is used to measure the quality of predictions from a classification algorithm.  The report shows the main classification metrics precision, recall and f1-score on a per-class basis. The metrics are calculated by using true and false positives, true and false negatives.	What is classification report in machine learning	4616
10538	Normality: Data have a normal distribution (or at least is symmetric) Homogeneity of variances: Data from multiple groups have the same variance. Linearity: Data have a linear relationship. Independence: Data are independent.	What are four main assumptions for parametric statistics	10538
5718	If you are working on a classification problem, the best score is 100% accuracy. If you are working on a regression problem, the best score is 0.0 error. These scores are an impossible to achieve upper/lower bound.	What is a good accuracy score in machine learning	5718
2232	0:007:47Suggested clip · 116 seconds[Proof] Sequence is divergent - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you prove divergence	2232
3359	Contrastive Loss: Contrastive refers to the fact that these losses are computed contrasting two or more data points representations. This name is often used for Pairwise Ranking Loss, but I've never seen using it in a setup with triplets. Triplet Loss: Often used as loss name when triplet training pairs are employed.	What is contrastive loss	3359
984	The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X ≤ x, Y ≤ y),where X and Y are continuous or discrete. For example, the probability.  P(x1 ≤ X ≤ x2,y1 ≤ Y ≤ y2) = F(x2,y2) − F(x2,y1) − F(x1,y2) + F(x1,y1).	How do you find the joint distribution of X and Y	984
2838	A P value is also affected by sample size and the magnitude of effect. Generally the larger the sample size, the more likely a study will find a significant relationship if one exists. As the sample size increases the impact of random error is reduced.	Why does P value change with sample size	2838
6023	DEFINITION: Primary sampling unit refers to Sampling units that are selected in the first (primary) stage of a multi-stage sample ultimately aimed at selecting individual elements.	What is a primary sampling unit	6023
2442	Harmonic means are often used in averaging things like rates (e.g., the average travel speed given a duration of several trips). The weighted harmonic mean is used in finance to average multiples like the price-earnings ratio because it gives equal weight to each data point.	When should harmonic mean be used	2442
2227	The null hypothesis is the one to be tested and the alternative is everything else. In our example, The null hypothesis would be: The mean data scientist salary is 113,000 dollars. While the alternative: The mean data scientist salary is not 113,000 dollars.	What is null and alternative hypothesis example	2227
1728	The independent variable is called the Explanatory variable (or better known as the predictor) - the variable which influences or predicts the values. i.e. if the explanatory variable changes then it affects the response variable. Here Y is the Dependent variable or response variable.	Which variable is the explanatory variable	1728
10849	Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.  Tokenization can be done to either separate words or sentences.	Why tokenization is important in NLP	10849
1012	2. What is the area under a conditional Cumulative density function? Explanation: Area under any conditional CDF is 1.	What is the area under the conditional C * * * * * * * * * density function	1012
2497	Each class will have a “lower class limit” and an “upper class limit” which are the lowest and highest numbers in each class. The “class width” is the distance between the lower limits of consecutive classes. The range is the difference between the maximum and minimum data entries.	What is the difference between class interval and class width in statistics	2497
4160	Accuracy reflects how close a measurement is to a known or accepted value, while precision reflects how reproducible measurements are, even if they are far from the accepted value. Measurements that are both precise and accurate are repeatable and very close to true values.	What is difference between precision and accuracy	4160
627	You do need distributional assumptions about the response variable in order to make inferences (e.g, confidence intervals), but it is not necessary that the response variable be normallhy distributed.	Does dependent variable need to be normally distributed	627
1689	Weights are the co-efficients of the equation which you are trying to resolve. Negative weights reduce the value of an output. When a neural network is trained on the training set, it is initialised with a set of weights.  A neuron first computes the weighted sum of the inputs.	How weights are calculated in neural networks	1689
79	Calculating the distance of various points in the scene relative to the position of the camera is one of the important tasks for a computer vision system.	What is depth computer vision	79
1819	Abstract. This work centers on a novel data mining technique we term supervised clustering. Unlike traditional clustering, supervised clustering assumes that the examples are classified. The goal of supervised clustering is to identify class-uniform clusters that have high probability densities.	What is supervised clustering	1819
351	Random forest (RF) missing data algorithms are an attractive approach for imputing missing data. They have the desirable properties of being able to handle mixed types of missing data, they are adaptive to interactions and nonlinearity, and they have the potential to scale to big data settings.	Can random forest handle missing data	351
3899	A mathematical function with symbol εijk defined to switch between the discrete values of +1, 0, and -1, depending on the values of the three indices i, j, and k: It is one of the tools used in Einstein's summation notation to handle operations equivalent to cross products in vector notation.	What is alternating tensor	3899
7551	They are continuous vs discrete distributions. A first difference is that multinomial distribution M(N,p) is discrete (it generalises binomial disrtibution) whereas Dirichlet distribution is continuous (it generalizes Beta distribution).	What makes the Dirichlet distribution different from a multinomial distribution	7551
4289	The convolutional neural networks (CNNs) have proven to be a powerful tool for discriminative learning. Recently researchers have also started to show interest in the generative aspects of CNNs in order to gain a deeper understanding of what they have learned and how to further improve them.	Is CNN generative or discriminative	4289
6728	Statistical Machine Translation. Machine translation (MT) is automated translation. It is the process by which computer software is used to translate a text from one natural language (such as English) to another (such as Spanish).	What is machine translation in AI	6728
6957	The value of the z-score tells you how many standard deviations you are away from the mean.  A positive z-score indicates the raw score is higher than the mean average. For example, if a z-score is equal to +1, it is 1 standard deviation above the mean. A negative z-score reveals the raw score is below the mean average.	What does the Z score represent	6957
2487	Deep-learning software by nameSoftwareCreatorInterfacePlaidMLVertex.AI, IntelPython, C++PyTorchAdam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan (Facebook)Python, C++, JuliaApache SINGAApache Software FoundationPython, C++, JavaTensorFlowGoogle BrainPython (Keras), C/C++, Java, Go, JavaScript, R, Julia, Swift18 riviä lisää	Which software is used for deep learning	2487
2129	Model-based collaborative filtering algorithms provide item recommendation by first developing a model of user ratings. Algorithms in this category take a probabilistic approach and envision the collaborative filtering process as computing the expected value of a user prediction, given his/her ratings on other items.	What is model based collaborative filtering	2129
5009	Any quantity that has both magnitude and direction is called a vector.  The only difference is that tensor is the generalized form of scalars and vectors . Means scalars and vectors are the special cases of tensor quantities. Scalar is a tensor of rank 0 and vector is a tensor of rank 1.	What is difference between tensor and vector	5009
7977	The tensor of inertia gives us an idea about how the mass is distributed in a rigid body. Analogously, we can define the tensor of inertia about point O, by writing equation(4) in matrix form.  It follows from the definition of the products of inertia, that the tensors of inertia are always symmetric.	What do you mean by inertia tensor	7977
2719	We have compiled a list of best practices and strategies that you can use to improve your TensorFlow Lite model performance.Choose the best model for the task.  Profile your model.  Profile and optimize operators in the graph.  Optimize your model.  Tweak the number of threads.  Eliminate redundant copies.More items	How can I improve my TensorFlow performance	2719
5552	In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.	What is meant by the term instance based learning	5552
3275	Hypothesis Tests with the Repeated-Measures t (cont.) In words, the null hypothesis says that there is no consistent or systematic difference between the two treatment conditions. Note that the null hypothesis does not say that each individual will have a difference score equal to zero.	What is the null hypothesis for a repeated measures test	3275
9383	The traditional method of training AI models involves setting up servers where models are trained on data, often through the use of a cloud-based computing platform.  Federated learning brings machine learning models to the data source, rather than bringing the data to the model.	What is Federated AI	9383
4646	Latent semantic indexing (LSI) is a concept used by search engines to discover how a term and content work together to mean the same thing, even if they do not share keywords or synonyms.  Basically, though, you often need specific keywords on your pages to boost your website traffic.	What is latent semantic indexing and where can it be applied	4646
2378	split testing	What does AB testing stand for	2378
2381	Neural networks take input data, train themselves to recognize patterns found in the data, and then predict the output for a new set of similar data. Therefore, a neural network can be thought of as the functional unit of deep learning, which mimics the behavior of the human brain to solve complex data-driven problems.	What is a neural network in programming	2381
3515	Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.  The three steps involved in cross-validation are as follows : Reserve some portion of sample data-set.	What is cross validation set in machine learning	3515
7888	If the hazard ratio is less than 1, then the predictor is protective (i.e., associated with improved survival) and if the hazard ratio is greater than 1, then the predictor is associated with increased risk (or decreased survival).	How do you interpret the hazard ratio in Cox Regression	7888
6224	Collaborative filtering (CF) is a technique used by recommender systems.  In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating).	What is meant by collaborative filtering	6224
2805	1 Answer. Transfer learning is when a model developed for one task is reused to work on a second task. Fine tuning is one approach to transfer learning.	What is the difference between transfer learning and fine tuning	2805
9990	Content validity is different from face validity, which refers not to what the test actually measures, but to what it superficially appears to measure.  In clinical settings, content validity refers to the correspondence between test items and the symptom content of a syndrome.	What is the difference between face and content validity	9990
960	A random variable, usually written X, is a variable whose possible values are numerical outcomes of a random phenomenon. There are two types of random variables, discrete and continuous.	What is a random variable What are the various types of random variables	960
8130	Brownian motion lies in the intersection of several important classes of processes. It is a Gaussian Markov process, it has continuous paths, it is a process with stationary independent increments (a Lévy process), and it is a martingale. Several characterizations are known based on these properties.	Is Brownian motion a Markov process	8130
3249	The anti-Martingale, or reverse Martingale, system is a trading methodology that involves halving a bet each time there is a trade loss and doubling it each time there is a gain. This technique is the opposite of the Martingale system, whereby a trader (or gambler) doubles down on a losing bet and halves a winning bet.	What is reverse Martingale	3249
2723	deep learning - a name for an algorithm in machine learning (just like SVM, Regression etc.) transfer learning - as you may know, in order to train a Neural network it might take long time. So, we use a Neural Network that is already trained and in this way we can extract some features of new sample.	What is the difference between deep learning and transfer learning	2723
8858	Interpreting the ROC curve Classifiers that give curves closer to the top-left corner indicate a better performance. As a baseline, a random classifier is expected to give points lying along the diagonal (FPR = TPR). The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.	How do you read ROC curve results	8858
6835	Sampling Frame Error: A type of nonsampling error in a survey caused by a sampling frame (i.e., a list) that is not a perfect representation of the population or universe. That is, the sample list might contain respondents who do not meet the definition of the population or universe.	What is sample frame error	6835
9185	The Lorenz Curve is a graph that illustrates the distribution of income in the economy. It suggests that the distribution of income in the United States is unequal.	What is the Lorenz curve and what does it suggest	9185
349	The reason that SVMs often outperform ANNs in practice is that they deal with the biggest problem with ANNs, SVMs are less prone to overfitting.	What is one reason we might choose to use support vector machine rather than an artificial neural network	349
2148	In the chapter on Human Development Indicators, there should be a table that includes the Gini coefficient. For example, in the 2004 edition, they are in table number 14. See also the “Get Indicators” portion of their web site, where you can download an Excel table with the Gini index.	Where is the Gini coefficient data	2148
454	Data labeling, in the context of machine learning, is the process of detecting and tagging data samples. The process can be manual but is usually performed or assisted by software.	What is Labelling in machine learning	454
377	Definition: Distribution means to spread the product throughout the marketplace such that a large number of people can buy it. Distribution involves doing the following things: Tracking the places where the product can be placed such that there is a maximum opportunity to buy it.	What is meant by a distribution	377
