{
  "qas": [
    {
      "answer": "Factor analysis is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.  Factor analysis aims to find independent latent variables.",
      "question": "What does a factor analysis tell you"
    },
    {
      "answer": "In qualitative research no hypotheses or relationships of variables are tested. Because variables must be defined numerically in hypothesis-testing research, they cannot reflect subjective experience. This leads to hypothesis-generating research using the grounded theory method to study subjective experience directly.",
      "question": "Does a qualitative study have variables"
    },
    {
      "answer": "Explain the difference between descriptive and inferential statistics. Descriptive statistics describes sets of data. Inferential statistics draws conclusions about the sets of data based on sampling.  A population is a set of units of interest to a study.",
      "question": "What is the difference between descriptive and inferential statistics quizlet"
    },
    {
      "answer": "Exponential Smoothing is one of the more popular smoothing techniques due to its flexibility, ease in calculation, and good performance. Exponential Smoothing uses a simple average calculation to assign exponentially decreasing weights starting with the most recent observations.",
      "question": "Which method is best for smoothing of data"
    },
    {
      "answer": "Basically, there are three methods to solve a multi-label classification problem, namely: Problem Transformation. Adapted Algorithm.1 Binary Relevance. This is the simplest technique, which basically treats each label as a separate single class classification problem.  2 Classifier Chains.  3 Label Powerset.",
      "question": "How do you handle multi label classification"
    },
    {
      "answer": "Five Common Types of Sampling ErrorsPopulation Specification Error\u2014This error occurs when the researcher does not understand who they should survey.  Sample Frame Error\u2014A frame error occurs when the wrong sub-population is used to select a sample.More items",
      "question": "What are the types of sampling errors"
    },
    {
      "answer": "The Word2Vec Model This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity.",
      "question": "Is Word2Vec deep learning"
    },
    {
      "answer": "The law of averages is not a mathematical principle, whereas the law of large numbers is.  According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.",
      "question": "What is the difference between the law of large numbers and the law of averages"
    },
    {
      "answer": "Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.",
      "question": "Why AI algorithms are biased"
    },
    {
      "answer": ": to aim an attack at someone or something. : to direct an action, message, etc., at someone or something.",
      "question": "What does it mean to target someone"
    },
    {
      "answer": "1: The number of observations n is fixed. 2: Each observation is independent. 3: Each observation represents one of two outcomes (\"success\" or \"failure\"). 4: The probability of \"success\" p is the same for each outcome.",
      "question": "What are the 4 characteristics of a binomial distribution"
    },
    {
      "answer": "The number of neurons in the input layer equals the number of input variables in the data being processed. The number of neurons in the output layer equals the number of outputs associated with each input.",
      "question": "How do you determine the number of neurons in the input layer"
    },
    {
      "answer": "If two random variables X and Y are independent, then their covariance Cov(X, Y) = E(XY) \u2212 E(X)E(Y) = 0, that is, they are uncorrelated.",
      "question": "When X and Y are statistically independent then I xy is"
    },
    {
      "answer": "Artificial intelligence is imparting a cognitive ability to a machine.  The idea behind machine learning is that the machine can learn without human intervention. The machine needs to find a way to learn how to solve a task given the data. Deep learning is the breakthrough in the field of artificial intelligence.",
      "question": "What is artificial intelligence machine learning and deep learning"
    },
    {
      "answer": "Counterintuitive as it may be, supervised algorithms (particularly logistic regression and random forest) tend to outperform unsupervised ones on discrete classification and categorization tasks, where data is relatively structured and well-labeled.",
      "question": "Is it possible for unsupervised learning algorithms to outperform supervised ones"
    },
    {
      "answer": "You should put it after the non-linearity (eg. relu layer). If you are using dropout remember to use it before.",
      "question": "Where should I insert batch normalization"
    },
    {
      "answer": "For example, if n = 100 and p = 0.25 then we are justified in using the normal approximation. This is because np = 25 and n(1 - p) = 75. Since both of these numbers are greater than 10, the appropriate normal distribution will do a fairly good job of estimating binomial probabilities.",
      "question": "What is an example of the normal approximation of the binomial distribution"
    },
    {
      "answer": "Hierarchical clustering outputs a hierarchy, ie a structure that is more informa ve than the unstructured set of flat clusters returned by k-\u2010means. Therefore, it is easier to decide on the number of clusters by looking at the dendrogram (see sugges on on how to cut a dendrogram in lab8).",
      "question": "What are the benefits of hierarchical clustering over K means clustering"
    },
    {
      "answer": "The monty hall problem has 3 doors instead of 100. It is still more likely that you pick a goat.  If a person picks door 1 which is wrong the Monty Hall will close door 3 and give you chance to switch to the right answer, so it means they want always people win the prize.",
      "question": "How does the Monty Hall problem work"
    },
    {
      "answer": "To calculate how much weight you need, divide the known population percentage by the percent in the sample. For this example: Known population females (51) / Sample Females (41) = 51/41 = 1.24. Known population males (49) / Sample males (59) = 49/59 = .",
      "question": "How do you do weightage to a variable"
    },
    {
      "answer": "A variable is said to be continuous if it can assume an infinite number of real values. Examples of a continuous variable are distance, age and temperature. The measurement of a continuous variable is restricted by the methods used, or by the accuracy of the measuring instruments.",
      "question": "Is age a continuous variable"
    },
    {
      "answer": "The lower quartile, or first quartile, is denoted as Q1 and is the middle number that falls between the smallest value of the dataset and the median. The second quartile, Q2, is also the median.",
      "question": "Is median the same with second quartile"
    },
    {
      "answer": "Residual analysis is used to assess the appropriateness of a linear regression model by defining residuals and examining the residual plot graphs.",
      "question": "What is residual analysis used for"
    },
    {
      "answer": "If you want a representative sample of a particular population, you need to ensure that:The sample source includes all the target population.The selected data collection method (online, phone, paper, in person) can reach individuals that represent that target population.More items\u2022",
      "question": "How do you know if a sample size is representative"
    },
    {
      "answer": "The main difference between stratified sampling and cluster sampling is that with cluster sampling, you have natural groups separating your population.  With stratified random sampling, these breaks may not exist*, so you divide your target population into groups (more formally called \"strata\").",
      "question": "What is the difference between stratified random sampling and cluster sampling"
    },
    {
      "answer": "The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.",
      "question": "In what setting are z scores useful"
    },
    {
      "answer": "CONCLUSION. There are three primary goals of survival analysis, to estimate and interpret survival and / or hazard functions from the survival data; to compare survival and / or hazard functions, and to assess the relationship of explanatory variables to survival time.",
      "question": "Why is survival analysis used"
    },
    {
      "answer": "Every parametric test has the assumption that the sample means are following a normal distribution. This is the case if the sample itself is normal distributed or if approximately if the sample size is big enough.",
      "question": "Why does data need to be normally distributed in parametric tests"
    },
    {
      "answer": "A Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.  The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence.",
      "question": "What is Seq2Seq model"
    },
    {
      "answer": "Divide the number of subjects by 2, and round down. In the example 5 \u00f7 2 = 2.5 and rounding down gives 2. Find the first-ordered survival time that is greater than this number. This is the median survival time.",
      "question": "How do you find the median in survival time"
    },
    {
      "answer": "While regular gradient boosting uses the loss function of our base model (e.g. decision tree) as a proxy for minimizing the error of the overall model, XGBoost uses the 2nd order derivative as an approximation.",
      "question": "How is XGBoost different from gradient boosting"
    },
    {
      "answer": "The reason n-1 is used is because that is the number of degrees of freedom in the sample. The sum of each value in a sample minus the mean must equal 0, so if you know what all the values except one are, you can calculate the value of the final one.",
      "question": "Why is there a degree of freedom of n 1 for sample standard deviation"
    },
    {
      "answer": "Statistical knowledge helps you use the proper methods to collect the data, employ the correct analyses, and effectively present the results. Statistics is a crucial process behind how we make discoveries in science, make decisions based on data, and make predictions.",
      "question": "What are the advantages of statistics"
    },
    {
      "answer": "Linear regression can only be used when one has two continuous variables\u2014an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.",
      "question": "What data is used for multiple linear regression"
    },
    {
      "answer": "The four elements of a descriptive statistics problem include population/sample, tables/graphs, identifying patterns, and A. data.",
      "question": "What are the four elements of a descriptive statistics problem"
    },
    {
      "answer": "The mass density (\u03c1) of a substance is the mass of one unit volume of the substance.  The relative density is the ratio of the mass of the substance in air at 20 \u00b0C to that of an equal volume of water at the same temperature.",
      "question": "What is density and relative density"
    },
    {
      "answer": "The Paired Samples t Test compares two means that are from the same individual, object, or related units. The two means can represent things like: A measurement taken at two different times (e.g., pre-test and post-test with an intervention administered between the two time points)5 p\u00e4iv\u00e4\u00e4 sitten",
      "question": "What is the comparison mean for a paired sample t test"
    },
    {
      "answer": "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",
      "question": "What is a gradient in deep learning"
    },
    {
      "answer": "The prior distribution is a distribution for the parameters whereas the prior predictive distribution is a distribution for the observations.  The last line is based on the assumption that the upcoming observation is independent of X given \u03b8.",
      "question": "Differences between prior distribution and prior predictive distribution"
    },
    {
      "answer": "Decision trees: Are popular among non-statisticians as they produce a model that is very easy to interpret. Each leaf node is presented as an if/then rule.",
      "question": "Is a decision tree a model"
    },
    {
      "answer": "Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data.  Models and algorithms based on the principle of competitive learning include vector quantization and self-organizing maps (Kohonen maps).",
      "question": "What is competitive learning algorithm in neural network"
    },
    {
      "answer": "Answer. True is the answer of Restricted Boltzmann Machine expect data to be labeled for Training as because there are two process for training one which is called as pre-training and training. In pre-training one don't need labeled data.",
      "question": "Does Restricted Boltzmann Machine expect the data to be labeled for training"
    },
    {
      "answer": "Sampling is a statistical procedure that is concerned with the selection of the individual observation; it helps us to make statistical inferences about the population. In sampling, we assume that samples are drawn from the population and sample means and population means are equal.",
      "question": "What are the importance of sampling in statistics"
    },
    {
      "answer": "AI programs can provide automation for low-value tasks freeing up engineers to perform higher-value tasks. By using machine learning to discover patterns in the data, machines will be incredibly important to help with engineering judgment.",
      "question": "How is AI used in engineering"
    },
    {
      "answer": "Bootstrap aggregating, also called bagging (from bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.",
      "question": "Is bootstrapping the same as bagging"
    },
    {
      "answer": "Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.",
      "question": "What is NLP used for"
    },
    {
      "answer": "Fundamentally, classification is about predicting a label and regression is about predicting a quantity.  That classification is the problem of predicting a discrete class label output for an example. That regression is the problem of predicting a continuous quantity output for an example.",
      "question": "What is regression and classification"
    },
    {
      "answer": "A) (ii) Disadvantages of Mohr Method \uf0a7 Mohr's method is suitable only for titration of chloride, bromide and cyanide alone. \uf0a7 Errors can be introduced due to the need of excess titrant before the endpoint colour is visible.",
      "question": "What are the limitations of Mohr's method"
    },
    {
      "answer": "This article lists out 10 comprehensive data mining tools widely used in the big data industry.Rapid Miner.  Oracle Data Mining.  IBM SPSS Modeler.  KNIME.  Python.  Orange.  Kaggle.  Rattle.More items\u2022",
      "question": "What are the data mining tools"
    },
    {
      "answer": "We can compute the p-value corresponding to the absolute value of the t-test statistics (|t|) for the degrees of freedom (df): df=n\u22121. If the p-value is inferior or equal to 0.05, we can conclude that the difference between the two paired samples are significantly different.",
      "question": "How do you find the degrees of freedom for a t test"
    },
    {
      "answer": "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.  Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks.",
      "question": "What does batch normalization do"
    },
    {
      "answer": "Robust statistics are statistics with good performance for data drawn from a wide range of probability distributions, especially for distributions that are not normal. Robust statistical methods have been developed for many common problems, such as estimating location, scale, and regression parameters.",
      "question": "What does it mean robust in statistics"
    },
    {
      "answer": "So, for 10% error, you need 100 hash functions. For 1% error, you need 10,000 hash functions. Yick. That's friggin expensive, and if that's all there were to MinHash, I'd simply go with the O(n log(n)) algorithm.",
      "question": "How many hash functions are required in a minhash algorithm"
    },
    {
      "answer": "Genetic algorithms are important in machine learning for three reasons. First, they act on discrete spaces, where gradient-based methods cannot be used. They can be used to search rule sets, neural network architectures, cellular automata computers, and so forth.",
      "question": "Are genetic algorithms machine learning"
    },
    {
      "answer": "Given an image or a video stream, an object detection model can identify which of a known set of objects might be present and provide information about their positions within the image.",
      "question": "What is an object detection model"
    },
    {
      "answer": "Here are applications of Reinforcement Learning:Robotics for industrial automation.Business strategy planning.Machine learning and data processing.It helps you to create training systems that provide custom instruction and materials according to the requirement of students.Aircraft control and robot motion control.",
      "question": "What are the applications of reinforcement learning"
    },
    {
      "answer": "Definition: Stratified sampling is a type of sampling method in which the total population is divided into smaller groups or strata to complete the sampling process.  Stratified sampling is used when the researcher wants to understand the existing relationship between two groups.",
      "question": "What is meant by stratified sampling"
    },
    {
      "answer": "Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate (\"backtracks\") as soon as it determines that the candidate cannot possibly be completed to a",
      "question": "What is backtracking algorithm"
    },
    {
      "answer": "Micro-level adaptive instruction: The main feature of this approach is to utilize on-task rather than pre-task measurement to diagnose the students' learning behaviors and performance so as to adapt the instruction at the micro-level. Typical examples include one-on-one tutoring and intelligent tutoring systems.",
      "question": "Which is an example of adaptive instruction"
    },
    {
      "answer": "The distributional hypothesis in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings. The underlying idea that \"a word is characterized by the company it keeps\" was popularized by Firth in the 1950s.",
      "question": "What is distributional information"
    },
    {
      "answer": "The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.",
      "question": "How do you calculate false positives and negatives"
    },
    {
      "answer": "The input() function accepts an optional string argument called prompt and returns a string. Note that the input() function always returns a string even if you entered a number. To convert it to an integer you can use int() or eval() functions.",
      "question": "What is the datatype of the output for the function input ()"
    },
    {
      "answer": "Time series regression is a statistical method for predicting a future response based on the response history (known as autoregressive dynamics) and the transfer of dynamics from relevant predictors.  Time series regression is commonly used for modeling and forecasting of economic, financial, and biological systems.",
      "question": "What are some methods of time series regression analysis"
    },
    {
      "answer": "Bayesian hyperparameter tuning allows us to do so by building a probabilistic model for the objective function we are trying to minimize/maximize in order to train our machine learning model. Examples of such objective functions are not scary - accuracy, root mean squared error and so on.",
      "question": "What is Bayesian Hyperparameter optimization"
    },
    {
      "answer": "Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities.",
      "question": "What is modality in machine learning"
    },
    {
      "answer": "An operating system (OS) is a set of functions or programs that coordinate a user program's access to the computer's resources (i.e. memory and CPU).  These functions are called the MicroStamp11's kernel functions.",
      "question": "How kernel functions are called"
    },
    {
      "answer": "As regards the normality of group data, the one-way ANOVA can tolerate data that is non-normal (skewed or kurtotic distributions) with only a small effect on the Type I error rate. However, platykurtosis can have a profound effect when your group sizes are small.",
      "question": "Can you use Anova if data is not normally distributed"
    },
    {
      "answer": "Sample size refers to the number of participants or observations included in a study. This number is usually represented by n. The size of a sample influences two statistical properties: 1) the precision of our estimates and 2) the power of the study to draw conclusions.",
      "question": "What is sample and sample size"
    },
    {
      "answer": "Analysis of variance (ANOVA) is a statistical technique that is used to check if the means of two or more groups are significantly different from each other. ANOVA checks the impact of one or more factors by comparing the means of different samples.  Another measure to compare the samples is called a t-test.",
      "question": "How does Anova work in statistics"
    },
    {
      "answer": "\u2022 Model capacity is ability to fit variety of functions. \u2013 Model with Low capacity struggles to fit training set. \u2013 A High capacity model can overfit by memorizing. properties of training set not useful on test set. \u2022 When model has higher capacity, it overfits.",
      "question": "What is model capacity in machine learning"
    },
    {
      "answer": "A marginal distribution is the percentages out of totals, and conditional distribution is the percentages out of some column.  Conditional distribution, on the other hand, is the probability distribution of certain values in the table expressed as percentages out of sums (or local totals) of certain rows or columns.",
      "question": "What is marginal and conditional distribution"
    },
    {
      "answer": "communalities is calculated sum of square factor loadings. Generally, an item factor loading is recommended higher than 0.30 or 0.33 cut value. So if an item load only one factor its communality will be 0.30*0.30 = 0.09.",
      "question": "What is the cutoff for loading factors using factor analysis"
    },
    {
      "answer": "5. Image Processing Using Machine LearningFeature mapping using the scale-invariant feature transform (SIFT) algorithm.Image registration using the random sample consensus (RANSAC) algorithm.Image Classification using artificial neural networks.Image classification using convolutional neural networks (CNNs)Image Classification using machine learning.More items",
      "question": "How is image processing used in machine learning"
    },
    {
      "answer": "As the df increase, the chi square distribution approaches a normal distribution. The mean of a chi square distribution is its df. The mode is df - 2 and the median is approximately df - 0 .",
      "question": "How do you find the mode of a chi square distribution"
    },
    {
      "answer": "Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.",
      "question": "Which algorithm falls under unsupervised learning"
    },
    {
      "answer": "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.",
      "question": "Is matrix factorization collaborative filtering"
    },
    {
      "answer": "The theorem and its generalizations can be used to prove results and solve problems in combinatorics, algebra, calculus, and many other areas of mathematics. The binomial theorem also helps explore probability in an organized way: A friend says that she will flip a coin 5 times.",
      "question": "Why is the binomial theorem useful"
    },
    {
      "answer": "Linear least squares regression is by far the most widely used modeling method. It is what most people mean when they say they have used \"regression\", \"linear regression\" or \"least squares\" to fit a model to their data.",
      "question": "Is linear regression A least squares"
    },
    {
      "answer": "0:1110:28\u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u062d \u00b7 110 \u062b\u0627\u0646\u064a\u0629Lambda Measure of Association for Two Nominal Variables in SPSS YouTube\u0628\u062f\u0627\u064a\u0629 \u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u064e\u062d\u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u064e\u062d",
      "question": "How do you interpret lambda in SPSS"
    },
    {
      "answer": "A random variable can be either discrete (having specific values) or continuous (any value in a continuous range). The use of random variables is most common in probability and statistics, where they are used to quantify outcomes of random occurrences.",
      "question": "Why are statistics random variables"
    },
    {
      "answer": "KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.",
      "question": "Why do we use KNN algorithm"
    },
    {
      "answer": "A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process). For example, a gambler may be interested in whether a game of chance is fair.",
      "question": "What is a null hypothesis example"
    },
    {
      "answer": "Non-hierarchical clustering is frequently referred to as k-means clustering. This type of clustering does not require all possible distances to be computed in a large data set. This technique is primarily used for the analysis of clusters in data mining.",
      "question": "Is frequently referred to as K means clustering"
    },
    {
      "answer": "Artificial intelligence is generally divided into two types \u2013 narrow (or weak) AI and general AI, also known as AGI or strong AI.",
      "question": "What are the 2 types of AI"
    },
    {
      "answer": "The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero.",
      "question": "What is the purpose of Lasso regression"
    },
    {
      "answer": "In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.",
      "question": "When should we use hierarchical linear models"
    },
    {
      "answer": "The chief difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias problem, while CRFs are globally renormalized.",
      "question": "How do Conditional Random Fields CRF compare to Maximum Entropy Models and Hidden Markov Models"
    },
    {
      "answer": "Two different learning models were introduced that can be used as part of the word2vec approach to learn the word embedding; they are: Continuous Bag-of-Words, or CBOW model. Continuous Skip-Gram Model.",
      "question": "Which is the best model used in Word2Vec algorithm for word embedding"
    },
    {
      "answer": "Artificial intelligence (AI) is the attempt to let computers perform services for which humans need intelligence. However, this is still not possible today. AI systems are capable of recognizing patterns, learning and making decisions.",
      "question": "Is artificial intelligence intelligent"
    },
    {
      "answer": "A random effect model is a model all of whose factors represent random effects. (See Random Effects.) Such models are also called variance component models. Random effect models are often hierarchical models. A model that contains both fixed and random effects is called a mixed model.",
      "question": "What is random effect in mixed model"
    },
    {
      "answer": "Introduction Statistical discrete processes \u2013 for example, the number of accidents per driver, the number of insects per leaf in an orchard, the number of thunderstorms per year, the number of earthquakes per year, the number of patients visit emergency room in a certain hospital per day - often occur in real life.",
      "question": "What are uses of discrete distributions in real life"
    },
    {
      "answer": "Artificial Intelligence ExamplesManufacturing robots.Smart assistants.Proactive healthcare management.Disease mapping.Automated financial investing.Virtual travel booking agent.Social media monitoring.Inter-team chat tool.More items",
      "question": "What products use artificial intelligence"
    },
    {
      "answer": "The Kruskal-Wallis H test (sometimes also called the \"one-way ANOVA on ranks\") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable.",
      "question": "When Kruskal Wallis test is used"
    },
    {
      "answer": "R-squared is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.  After fitting a linear regression model, you need to determine how well the model fits the data.",
      "question": "What is r squared change in regression"
    },
    {
      "answer": "Perceptron Learning Rule states that the algorithm would automatically learn the optimal weight coefficients. The input features are then multiplied with these weights to determine if a neuron fires or not.",
      "question": "What do you mean by Perceptron and its learning rule"
    },
    {
      "answer": "Unlike the independent-samples t-test, the Mann-Whitney U test allows you to draw different conclusions about your data depending on the assumptions you make about your data's distribution.  These different conclusions hinge on the shape of the distributions of your data, which we explain more about later.",
      "question": "What is the difference between t test and Mann Whitney test"
    },
    {
      "answer": "Two disjoint events can never be independent, except in the case that one of the events is null.  Events are considered disjoint if they never occur at the same time. For example, being a freshman and being a sophomore would be considered disjoint events. Independent events are unrelated events.",
      "question": "Can two events be independent and disjoint"
    },
    {
      "answer": "Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.",
      "question": "What is the difference between interpolation and extrapolation"
    },
    {
      "answer": "The most popular is definitely KMP, if you need fast string matching without any particular usecase in mind it's what you should use. Here are your options(with time complexity): Brute Force O(nm) Knuth\u2013Morris\u2013Pratt algorithm - O(n)",
      "question": "Which is the best algorithm for checking string similarity metric"
    },
    {
      "answer": "To visualize a small data set containing multiple categorical (or qualitative) variables, you can create either a bar plot, a balloon plot or a mosaic plot.  These methods make it possible to analyze and visualize the association (i.e. correlation) between a large number of qualitative variables.",
      "question": "What is a recommended way to visualize categorical data"
    },
    {
      "answer": "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability.  By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",
      "question": "What is ROC AUC score"
    },
    {
      "answer": "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.",
      "question": "What is gradient boosting used for"
    },
    {
      "answer": "Random forest (RF) is a machine-learning method that generally works well with high-dimensional problems and allows for nonlinear relationships between predictors; however, the presence of correlated predictors has been shown to impact its ability to identify strong predictors.",
      "question": "Can random forest handle correlated variables"
    },
    {
      "answer": "So regression performance is measured by how close it fits an expected line/curve, while machine learning is measured by how good it can solve a certain problem, with whatever means necessary. I'll argue that the distinction between machine learning and statistical inference is clear.",
      "question": "What is the difference between machine learning and regression"
    },
    {
      "answer": "Abstract. Markov chain Monte Carlo (MCMC) is a simulation technique that can be used to find the posterior distribution and to sample from it. Thus, it is used to fit a model and to draw samples from the joint posterior distribution of the model parameters.  The software OpenBUGS and Stan are MCMC samplers.",
      "question": "What is Markov Chain Monte Carlo and why it matters"
    },
    {
      "answer": "When comparing two groups, you need to decide whether to use a paired test. When comparing three or more groups, the term paired is not apt and the term repeated measures is used instead. Use an unpaired test to compare groups when the individual values are not paired or matched with one another.",
      "question": "What statistical analysis should I use to compare two groups"
    },
    {
      "answer": "The Cox (proportional hazards or PH) model (Cox, 1972) is the most commonly used multivariate approach for analysing survival time data in medical research. It is a survival analysis regression model, which describes the relation between the event incidence, as expressed by the hazard function and a set of covariates.",
      "question": "What is multivariate Cox regression analysis"
    },
    {
      "answer": "To reduce variability we perform multiple rounds of cross-validation with different subsets from the same data. We combine the validation results from these multiple rounds to come up with an estimate of the model's predictive performance. Cross-validation will give us a more accurate estimate of a model's performance.",
      "question": "What does cross validation reduce"
    },
    {
      "answer": "It is a Markov random field. It was translated from statistical physics for use in cognitive science. The Boltzmann machine is based on stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model that is a stochastic Ising Model and applied to machine learning.",
      "question": "Is there a relation between Boltzmann machines and Markov random fields"
    },
    {
      "answer": "The null hypothesis is a general statement that states that there is no relationship between two phenomenons under consideration or that there is no association between two groups. An alternative hypothesis is a statement that describes that there is a relationship between two selected variables in a study.",
      "question": "What is the difference between null and alternative hypothesis"
    },
    {
      "answer": "In mathematics, a Fourier transform (FT) is a mathematical transform that decomposes a function (often a function of time, or a signal) into its constituent frequencies, such as the expression of a musical chord in terms of the volumes and frequencies of its constituent notes.",
      "question": "What does Fourier mean"
    },
    {
      "answer": "A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.",
      "question": "What is a probability distribution explain your answer"
    },
    {
      "answer": "The t-distribution cannot be calculated without a known standard deviation, while the standard normal distribution can be.",
      "question": "Which of the following is a difference between the T distribution and the standard normal Z distribution group of answer choices"
    },
    {
      "answer": "8:3417:13Suggested clip \u00b7 72 secondsStepwise regression procedures in SPSS (new, 2018) - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you interpret a stepwise regression analysis"
    },
    {
      "answer": "Abstract. Hidden Markov Models (HMMs) provide a simple and effective frame- work for modelling time-varying spectral vector sequences. As a con- sequence, almost all present day large vocabulary continuous speech recognition (LVCSR) systems are based on HMMs.",
      "question": "What is hidden Markov in speech recognition"
    },
    {
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error. The key idea is to set the target outcomes for this next model in order to minimize the error.",
      "question": "What is an intuitive explanation of Gradient Boosting"
    },
    {
      "answer": "k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.",
      "question": "What is the point of K means clustering"
    },
    {
      "answer": "Depending on the skill being taught, backward chaining has a distinct advantage: It directly links the independent completion of a task to the immediate reward or reinforcement. Once the child can complete the last step independently, he or she can work on also completing the next-to-last step independently.",
      "question": "What is an advantage of backward chaining"
    },
    {
      "answer": "For more tips, read 10 Best Practices for Effective Dashboards.Choose the right charts and graphs for the job.  Use predictable patterns for layouts.  Tell data stories quickly with clear color cues.  Incorporate contextual clues with shapes and designs.  Strategically use size to visualize values.More items",
      "question": "How do you visualize data effectively"
    },
    {
      "answer": "By using these midpoints as the categorical response values, the researcher can easily calculate averages. Granted, this average will only be an estimate or a \u201cballpark\u201d value but is still extremely useful for the purpose of data analysis.",
      "question": "Can you average categorical data"
    },
    {
      "answer": "The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.",
      "question": "What is back propagation in machine learning"
    },
    {
      "answer": "In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of successes (random draws for which the object drawn has a specified feature) in draws, without replacement, from a finite population of size that contains exactly objects with",
      "question": "What is a hypergeometric probability distribution"
    },
    {
      "answer": "Definition of outliers. An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.",
      "question": "What defines an outlier"
    },
    {
      "answer": "A statistic d is called an unbiased estimator for a function of the parameter g(\u03b8) provided that for every choice of \u03b8, E\u03b8d(X) = g(\u03b8). Any estimator that not unbiased is called biased. The bias is the difference bd(\u03b8) = E\u03b8d(X) \u2212 g(\u03b8). We can assess the quality of an estimator by computing its mean square error.",
      "question": "How do you calculate an unbiased estimator"
    },
    {
      "answer": "Standardized effect size statistics remove the units of the variables in the effect. The second type is simple. These statistics describe the size of the effect, but remain in the original units of the variables. So for example, say you're comparing the mean temperature of soil under two different conditions.",
      "question": "What is standardized effect"
    },
    {
      "answer": "A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is zero.  Non-square matrices (m-by-n matrices for which m \u2260 n) do not have an inverse. However, in some cases such a matrix may have a left inverse or right inverse.",
      "question": "What is non invertible matrix"
    },
    {
      "answer": "A data set can also be presented by means of a data frequency table, a table in which each distinct value is listed in the first row and its frequency, which is the number of times the value appears in the data set, is listed below it in the second row.",
      "question": "What is data frequency table"
    },
    {
      "answer": "Factor Analysis (FA) is an exploratory technique applied to a set of outcome variables that seeks to find the underlying factors (or subsets of variables) from which the observed variables were generated.",
      "question": "What is factor analysis in multivariate analysis"
    },
    {
      "answer": "There are different types of mean, viz. arithmetic mean, weighted mean, geometric mean (GM) and harmonic mean (HM). If mentioned without an adjective (as mean), it generally refers to the arithmetic mean.",
      "question": "How many types of mean in statistics"
    },
    {
      "answer": "The squared error has some nice properties: It is symmetrical. That means, if the actual value is and you predict or , you get the same error measure.",
      "question": "Why we take SSE sum of square error and RMSE root mean square error"
    },
    {
      "answer": "Low-shot learning deep learning is based on the concept that reliable algorithms can be created to make predictions from minimalist datasets.",
      "question": "What is low shot learning"
    },
    {
      "answer": "Weights(Parameters) \u2014 A weight represent the strength of the connection between units. If the weight from node 1 to node 2 has greater magnitude, it means that neuron 1 has greater influence over neuron 2. A weight brings down the importance of the input value.",
      "question": "Why weight is used in neural network"
    },
    {
      "answer": "Multi-class Classification using Decision Tree, Random Forest and Extra Trees Algorithm in Python: An End-To-End Data Science Recipe \u2014 016. a) Different types of Machine Learning problems.  i) How to implement Decision Tree, Random Forest and Extra Tree Algorithms for Multiclass Classification in Python.",
      "question": "Can random forest be used for multiclass classification"
    },
    {
      "answer": "Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.",
      "question": "What are decision trees commonly used for"
    },
    {
      "answer": "This is the basis of the Breusch\u2013Pagan test. It is a chi-squared test: the test statistic is distributed n\u03c72 with k degrees of freedom. If the test statistic has a p-value below an appropriate threshold (e.g. p < 0.05) then the null hypothesis of homoskedasticity is rejected and heteroskedasticity assumed.",
      "question": "What is the null hypothesis for Heteroskedasticity"
    },
    {
      "answer": "There are various ways to modify a study design to actively exclude or control confounding variables (3) including Randomization, Restriction and Matching. In randomization the random assignment of study subjects to exposure categories to breaking any links between exposure and confounders.",
      "question": "How do you deal with confounders within a statistical study"
    },
    {
      "answer": "In an upper-tailed test the decision rule has investigators reject H0 if the test statistic is larger than the critical value. In a lower-tailed test the decision rule has investigators reject H0 if the test statistic is smaller than the critical value.",
      "question": "How do you know if its a lower or upper tailed test"
    },
    {
      "answer": "The quality loss function as defined by Taguchi is the loss imparted to the society by the product from the time the product is designed to the time it is shipped to the customer. In fact, he defined quality as the conformity around a target value with a lower standard deviation in the outputs.",
      "question": "What is Taguchi quality loss function"
    },
    {
      "answer": "A mode of a continuous probability distribution is often considered to be any value x at which its probability density function has a locally maximum value, so any peak is a mode. In symmetric unimodal distributions, such as the normal distribution, the mean (if defined), median and mode all coincide.",
      "question": "What is the mode of a continuous random variable"
    },
    {
      "answer": "Achieving translation invariance in Convolutional NNs: Then the max pooling layer takes the output from the convolutional layer and reduces its resolution and complexity. It does so by outputting only the max value from a grid.So the information about the exact position of the max value in the grid is discarded.",
      "question": "How exactly does max pooling create translation invariance"
    },
    {
      "answer": "7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.",
      "question": "How do you handle an unbalanced data set"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean.  SD is the dispersion of individual data values.",
      "question": "What does standard deviation of the mean represent"
    },
    {
      "answer": "How to Handle Imbalanced DatasetChange the evaluation matrix. If we apply the wrong evaluation matrix on the imbalanced dataset, it can give us misleading results.  Resample the dataset. Resample means to change the distribution of the imbalance classes in the dataset.  Change the algorithm and approach to the problem.",
      "question": "How do you handle an imbalanced data set"
    },
    {
      "answer": "The cumulative distribution function (CDF) calculates the cumulative probability for a given x-value. Use the CDF to determine the probability that a random observation that is taken from the population will be less than or equal to a certain value.",
      "question": "What is the use of cumulative distribution function"
    },
    {
      "answer": "So, for example, if our random variable were the number obtained by rolling a fair 3-sided die, the expected value would be (1 * 1/3) + (2 * 1/3) + (3 * 1/3) = 2.",
      "question": "How do you find the expected value example"
    },
    {
      "answer": "Decision theory is the science of making optimal decisions in the face of uncertainty. Statistical decision theory is concerned with the making of decisions when in the presence of statistical knowledge (data) which sheds light on some of the uncertainties involved in the decision problem.",
      "question": "What is decision theory in statistics"
    },
    {
      "answer": "The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data.",
      "question": "What does Akaike information criterion mean"
    },
    {
      "answer": "Though the name is a mouthful, the concept behind this is very simple. To tell briefly, LDA imagines a fixed set of topics. Each topic represents a set of words. And the goal of LDA is to map all the documents to the topics in a way, such that the words in each document are mostly captured by those imaginary topics.",
      "question": "How does LDA algorithm work"
    },
    {
      "answer": "Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.",
      "question": "What is validation machine learning"
    },
    {
      "answer": "Cost function(J) of Linear Regression is the Root Mean Squared Error (RMSE) between predicted y value (pred) and true y value (y). Gradient Descent: To update \u03b81 and \u03b82 values in order to reduce Cost function (minimizing RMSE value) and achieving the best fit line the model uses Gradient Descent.",
      "question": "What is a cost function in linear regression"
    },
    {
      "answer": "Vector space model or term vector model is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, such as, for example, index terms.  The model is used to represent documents in an n-dimensional space. But a \u201cdocument\u201d can mean any object you're trying to model.",
      "question": "What is vector space in machine learning"
    },
    {
      "answer": "Decision Tree - Overfitting There are several approaches to avoiding overfitting in building decision trees. Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set. Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree.",
      "question": "What is pre pruning and post pruning in decision tree"
    },
    {
      "answer": "The 7 Steps of Machine Learning1 - Data Collection.2 - Data Preparation.3 - Choose a Model.4 - Train the Model.5 - Evaluate the Model.6 - Parameter Tuning.7 - Make Predictions.More items",
      "question": "What are the correct steps of a machine learning process"
    },
    {
      "answer": "gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set gammas = [0.1, 1, 10, 100]for gamma in gammas: svc = svm.SVC(kernel='rbf', gamma=gamma).fit(X, y)",
      "question": "What is Gamma in SVC"
    },
    {
      "answer": "The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.",
      "question": "When should I use weighted kappa"
    },
    {
      "answer": "Taking the square root of the variance gives us the units used in the original scale and this is the standard deviation. Standard deviation is the measure of spread most commonly used in statistical practice when the mean is used to calculate central tendency. Thus, it measures spread around the mean.",
      "question": "Where do we use standard deviation and variance"
    },
    {
      "answer": "The generator is a convolutional neural network and the discriminator is a deconvolutional neural network. The goal of the generator is to artificially manufacture outputs that could easily be mistaken for real data. The goal of the discriminator is to identify which outputs it receives have been artificially created.",
      "question": "What is the goal of a generative adversarial network GAN )"
    },
    {
      "answer": "If the outcomes are mutually independent, then yes the method is valid. If the outcomes are mutually exclusive, then no, the method is not valid. It's easy to see why this is the case. If you have three binary models, then the sum of the outcomes do not necessarily sum to one.",
      "question": "Can you split a multinomial logistic regression model into separate binary logistic regression models"
    },
    {
      "answer": "Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them.",
      "question": "What is correlation and autocorrelation"
    },
    {
      "answer": "Choosing the right Activation FunctionSigmoid functions and their combinations generally work better in the case of classifiers.Sigmoids and tanh functions are sometimes avoided due to the vanishing gradient problem.ReLU function is a general activation function and is used in most cases these days.More items\u2022",
      "question": "What is the activation function used for"
    },
    {
      "answer": "Information provides a way to quantify the amount of surprise for an event measured in bits. Entropy provides a measure of the average amount of information needed to represent an event drawn from a probability distribution for a random variable.",
      "question": "Why is information entropy"
    },
    {
      "answer": "While the returns for stocks usually have a normal distribution, the stock price itself is often log-normally distributed. This is because extreme moves become less likely as the stock's price approaches zero.",
      "question": "Why do prices and income follow a log normal distribution"
    },
    {
      "answer": "Response bias can be defined as the difference between the true values of variables in a study's net sample group and the values of variables obtained in the results of the same study.  Nonresponse bias occurs when some respondents included in the sample do not respond.",
      "question": "What is the difference between nonresponse and response bias"
    },
    {
      "answer": "Linear means something related to a line.  A non-linear equation is such which does not form a straight line. It looks like a curve in a graph and has a variable slope value. The major difference between linear and nonlinear equations is given here for the students to understand it in a more natural way.",
      "question": "What is the difference between linear and nonlinear association"
    },
    {
      "answer": "The 5 main steps to create word clouds in RStep 1: Create a text file.  Step 2 : Install and load the required packages.  Step 3 : Text mining.  Step 4 : Build a term-document matrix.  Step 5 : Generate the Word cloud.",
      "question": "How do I use text mining in R"
    },
    {
      "answer": "5 Most Important Methods For Statistical Data AnalysisMean. The arithmetic mean, more commonly known as \u201cthe average,\u201d is the sum of a list of numbers divided by the number of items on the list.  Standard Deviation.  Regression.  Sample Size Determination.  Hypothesis Testing.",
      "question": "What is the best statistical analysis technique"
    },
    {
      "answer": "Big data is a big deal. From reducing their costs and making better decisions, to creating products and services that are in demand by customers, businesses will increasingly benefit by using big-data analytics.",
      "question": "What's the big deal about Big Data"
    },
    {
      "answer": "recursion",
      "question": "Which search method is used in Minimax algorithm"
    },
    {
      "answer": "Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels.  A non-linear filtering is one that cannot be done with convolution or Fourier multiplication. A sliding median filter is a simple example of a non-linear filter.",
      "question": "What is the difference between linear and nonlinear filters"
    },
    {
      "answer": "Linear regression quantifies the relationship between one or more predictor variable(s) and one outcome variable.  For example, it can be used to quantify the relative impacts of age, gender, and diet (the predictor variables) on height (the outcome variable).",
      "question": "What is regression example"
    },
    {
      "answer": "For skewed distributions, it is quite common to have one tail of the distribution considerably longer or drawn out relative to the other tail. A \"skewed right\" distribution is one in which the tail is on the right side. A \"skewed left\" distribution is one in which the tail is on the left side.",
      "question": "What does a left skewed distribution mean"
    },
    {
      "answer": "Pearson's product moment correlation coefficient (r) is given as a measure of linear association between the two variables: r\u00b2 is the proportion of the total variance (s\u00b2) of Y that can be explained by the linear regression of Y on x. 1-r\u00b2 is the proportion that is not explained by the regression.",
      "question": "What is the correlation coefficient in a linear regression"
    },
    {
      "answer": "Investment risk is the idea that an investment will not perform as expected, that its actual return will deviate from the expected return. Risk is measured by the amount of volatility, that is, the difference between actual returns and average (expected) returns.",
      "question": "How do you measure risk and return"
    },
    {
      "answer": "The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.",
      "question": "What is an example of probability distribution"
    },
    {
      "answer": "Binary Search: Search a sorted array by repeatedly dividing the search interval in half. Begin with an interval covering the whole array. If the value of the search key is less than the item in the middle of the interval, narrow the interval to the lower half.",
      "question": "How do you perform a binary search"
    },
    {
      "answer": "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.",
      "question": "What s so special about rectified linear units ReLU activation function"
    },
    {
      "answer": "Typically, a regression analysis is done for one of two purposes: In order to predict the value of the dependent variable for individuals for whom some information concerning the explanatory variables is available, or in order to estimate the effect of some explanatory variable on the dependent variable.",
      "question": "What is the purpose of a regression model"
    },
    {
      "answer": "T-test. A t-test is used to compare the mean of two given samples. Like a z-test, a t-test also assumes a normal distribution of the sample. A t-test is used when the population parameters (mean and standard deviation) are not known.",
      "question": "Is at test a statistical test"
    },
    {
      "answer": "Replaces an image by the norm of its gradient, as estimated by discrete filters. The Raw filter of the detail panel designates two filters that correspond to the two components of the gradient in the principal directions.",
      "question": "What is a gradient norm"
    },
    {
      "answer": "The amount that the weights are updated during training is referred to as the step size or the \u201clearning rate.\u201d Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0.",
      "question": "What is step size in machine learning"
    },
    {
      "answer": "Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron.",
      "question": "What is the role of the activation function in a neural network How does this function in a human neural network system"
    },
    {
      "answer": "Dimensionality reduction is the process of reducing the number of random variables or attributes under consideration. High-dimensionality data reduction, as part of a data pre-processing-step, is extremely important in many real-world applications.",
      "question": "What is the need of dimensionality reduction in data mining"
    },
    {
      "answer": "Your classifier would have learned an equal an opposite rule, with the same performance and same AUC / ROC curve.",
      "question": "What will happen to AUC if I switch the positive and negative classes in the test data"
    },
    {
      "answer": "Posterior probability = prior probability + new evidence (called likelihood). For example, historical data suggests that around 60% of students who start college will graduate within 6 years. This is the prior probability. However, you think that figure is actually much lower, so set out to collect new data.",
      "question": "What is posterior probability example"
    },
    {
      "answer": "It depends on the data you want and the project you're doing. You could use even your twitter data for sentiment analysis. Request your archive in twitter -> download -> analyse sentiment through supervised learning techniques.",
      "question": "Where can one find a training set for sentiment analysis"
    },
    {
      "answer": "Random assignment helps reduce the chances of systematic differences between the groups at the start of an experiment and, thereby, mitigates the threats of confounding variables and alternative explanations. However, the process does not always equalize all of the confounding variables.",
      "question": "How does random assignment control for confounding variables"
    },
    {
      "answer": "In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.",
      "question": "What is map in ML"
    },
    {
      "answer": "The size of the sample space is the total number of possible outcomes. For example, when you roll 1 die, the sample space is 1, 2, 3, 4, 5, or 6. So the size of the sample space is 6.",
      "question": "How do you find the sample space"
    },
    {
      "answer": "Some of my suggestions to you would be:Feature Scaling and/or Normalization - Check the scales of your gre and gpa features.  Class Imbalance - Look for class imbalance in your data.  Optimize other scores - You can optimize on other metrics also such as Log Loss and F1-Score.More items",
      "question": "How can you improve the accuracy of a logistic regression model in python"
    },
    {
      "answer": "The k-means problem is finding the least-squares assignment to centroids. There are multiple algorithms for finding a solution. There is an obvious approach to find the global optimum: enumerating all k^n possible assignments - that will yield a global minimum, but in exponential runtime.",
      "question": "How do you get global minima in K means algorithm"
    },
    {
      "answer": "If a p-value is lower than our significance level, we reject the null hypothesis. If not, we fail to reject the null hypothesis.",
      "question": "What happens when the p value is lower than the level of significance"
    },
    {
      "answer": "1:314:30Suggested clip \u00b7 120 secondsCumulative Frequency Distribution (Less than and More than YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you construct a less than cumulative frequency distribution"
    },
    {
      "answer": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.",
      "question": "Is AI all about simulating human intelligence"
    },
    {
      "answer": "For the vanishing gradient problem, the further you go through the network, the lower your gradient is and the harder it is to train the weights, which has a domino effect on all of the further weights throughout the network. That was the main roadblock to using Recurrent Neural Networks.",
      "question": "What is vanishing gradient problem in RNN"
    },
    {
      "answer": "Hypothesis Tests of the Mean and MedianParametric tests (means)Nonparametric tests (medians)1-sample t test1-sample Sign, 1-sample Wilcoxon2-sample t testMann-Whitney testOne-Way ANOVAKruskal-Wallis, Mood's median testFactorial DOE with one factor and one blocking variableFriedman test",
      "question": "What are the different types of parametric tests"
    },
    {
      "answer": "Simple linear regression relates X to Y through an equation of the form Y = a + bX. Both quantify the direction and strength of the relationship between two numeric variables.  The correlation squared (r2 or R2) has special meaning in simple linear regression.",
      "question": "Does linear regression show correlation"
    },
    {
      "answer": "In statistics, the likelihood function (often simply called the likelihood) measures the goodness of fit of a statistical model to a sample of data for given values of the unknown parameters.",
      "question": "What does likelihood mean in statistics"
    },
    {
      "answer": "If you're given the probability (percent) greater than x and you need to find x, you translate this as: Find b where p(X > b) = p (and p is given). Rewrite this as a percentile (less-than) problem: Find b where p(X < b) = 1 \u2013 p. This means find the (1 \u2013 p)th percentile for X.",
      "question": "How do you find the percentile under the normal curve"
    },
    {
      "answer": "Two examples of common independent variables are age and time.  They're independent of everything else. The dependent variable (sometimes known as the responding variable) is what is being studied and measured in the experiment. It's what changes as a result of the changes to the independent variable.",
      "question": "What is an independent variable example"
    },
    {
      "answer": "A decision tree is a flowchart-like diagram that shows the various outcomes from a series of decisions. It can be used as a decision-making tool, for research analysis, or for planning strategy. A primary advantage for using a decision tree is that it is easy to follow and understand.",
      "question": "What is decision tree diagram"
    },
    {
      "answer": "Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.",
      "question": "What is Homoscedasticity in regression analysis"
    },
    {
      "answer": "The universe is considered an isolated system because the energy of the universe is constant. This matches with the definition of an isolated system, which is that energy is not exchanged with the surroundings, thus staying constant.",
      "question": "Is the universe an isolated system"
    },
    {
      "answer": "Simple Linear Regression Math by HandCalculate average of your X variable.Calculate the difference between each X and the average X.Square the differences and add it all up.  Calculate average of your Y variable.Multiply the differences (of X and Y from their respective averages) and add them all together.More items",
      "question": "How do you calculate linear regression by hand"
    },
    {
      "answer": "Bayesian analysis is a statistical paradigm that answers research questions about unknown parameters using probability statements.",
      "question": "What is the purpose of Bayesian analysis"
    },
    {
      "answer": "Reliability refers to the extent that the instrument yields the same results over multiple trials. Validity refers to the extent that the instrument measures what it was designed to measure.  Construct validity uses statistical analyses, such as correlations, to verify the relevance of the questions.",
      "question": "What is validity and reliability in statistics"
    },
    {
      "answer": "1:246:12Suggested clip \u00b7 104 secondsBuilding Statistical Models - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you make a statistical model"
    },
    {
      "answer": "Naive Bayes classifier (Russell, & Norvig, 1995) is another feature-based supervised learning algorithm. It was originally intended to be used for classification tasks, but with some modifications it can be used for regression as well (Frank, Trigg, Holmes, & Witten, 2000) .",
      "question": "Can naive Bayes be used for regression"
    },
    {
      "answer": "As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.",
      "question": "How do you find the standardized score"
    },
    {
      "answer": "12 Tips to boost your multitasking skillsAccept your limits. To better manage task organization, be aware of your limits, especially those you can't control.  Distinguish urgent from important.  Learn to concentrate.  Avoid distractions.  Work in blocks of time.  Work on related tasks together.  Learn to supervise.  Plan ahead.More items\u2022",
      "question": "How can I learn multitasking"
    },
    {
      "answer": "How to conduct a multivariate testIdentify a problem.  Formulate a hypothesis.  Create variations.  Determine your sample size.  Test your tools.  Start driving traffic.  Analyze your results.  Learn from your results.",
      "question": "How do you do a multivariate test"
    },
    {
      "answer": "A subquery is a select statement that is embedded in a clause of another select statement.  A Correlated subquery is a subquery that is evaluated once for each row processed by the outer query or main query.",
      "question": "What is the difference between subquery and correlated query"
    },
    {
      "answer": "Look at normality plots of the data. \u201cNormal Q-Q Plot\u201d provides a graphical way to determine the level of normality. The black line indicates the values your sample should adhere to if the distribution was normal.  If the dots fall exactly on the black line, then your data are normal.",
      "question": "How do you know if your data is normally distributed"
    },
    {
      "answer": "A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.",
      "question": "Why is the pooling layer used in CNN"
    },
    {
      "answer": "How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "How does logistic regression deal with Multicollinearity"
    },
    {
      "answer": "Derivative RulesCommon FunctionsFunctionDerivativeSquarex22xSquare Root\u221ax(\u00bd)x-\u00bdExponentialexexaxln(a) ax24 more rows",
      "question": "What is the derivative of E X"
    },
    {
      "answer": "In exploratory studies, p-values enable the recognition of any statistically noteworthy findings. Confidence intervals provide information about a range in which the true value lies with a certain degree of probability, as well as about the direction and strength of the demonstrated effect.",
      "question": "What is the difference between P value and confidence interval"
    },
    {
      "answer": "In the design of experiments and analysis of variance, a main effect is the effect of an independent variable on a dependent variable averaged across the levels of any other independent variables.  Main effects are essentially the overall effect of a factor.",
      "question": "What do main effects mean in Anova"
    },
    {
      "answer": "A function that represents a discrete probability distribution is called a probability mass function. A function that represents a continuous probability distribution is called a probability density function. Functions that represent probability distributions still have to obey the rules of probability.",
      "question": "What is the difference between probability density function and probability distribution function"
    },
    {
      "answer": "Similar to the distinction in philosophy between a priori and a posteriori, in Bayesian inference a priori denotes general knowledge about the data distribution before making an inference, while a posteriori denotes knowledge that incorporates the results of making an inference.",
      "question": "What is the difference between a priori and a posteriori probability"
    },
    {
      "answer": "This learning process is independent.  During the training of ANN under unsupervised learning, the input vectors of similar type are combined to form clusters. When a new input pattern is applied, then the neural network gives an output response indicating the class to which input pattern belongs.",
      "question": "What is unsupervised learning in neural network"
    },
    {
      "answer": "Critic Loss: D(x) - D(G(z)) The discriminator tries to maximize this function. In other words, it tries to maximize the difference between its output on real instances and its output on fake instances.",
      "question": "What is discriminator loss"
    },
    {
      "answer": "Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.",
      "question": "What do you mean by tensor"
    },
    {
      "answer": "The task of object localization is to predict the object in an image as well as its boundaries.  Simply, object localization aims to locate the main (or most visible) object in an image while object detection tries to find out all the objects and their boundaries.",
      "question": "What is localization in image processing"
    },
    {
      "answer": "Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph. How sent_tokenize works ? The sent_tokenize function uses an instance of PunktSentenceTokenizer from the nltk.",
      "question": "How does NLTK sentence Tokenizer work"
    },
    {
      "answer": "The best fit line is the one that minimises sum of squared differences between actual and estimated results. Taking average of minimum sum of squared difference is known as Mean Squared Error (MSE). Smaller the value, better the regression model.",
      "question": "How do you tell if a regression model is a good fit"
    },
    {
      "answer": "The cross-entropy compares the model's prediction with the label which is the true probability distribution. The cross-entropy goes down as the prediction gets more and more accurate. It becomes zero if the prediction is perfect. As such, the cross-entropy can be a loss function to train a classification model.",
      "question": "How does cross entropy work"
    },
    {
      "answer": "The Machine Learning algorithms that require the feature scaling are mostly KNN (K-Nearest Neighbours), Neural Networks, Linear Regression, and Logistic Regression.",
      "question": "Which machine learning algorithms require feature scaling"
    },
    {
      "answer": "Definition. Inter-rater reliability is the extent to which two or more raters (or observers, coders, examiners) agree. It addresses the issue of consistency of the implementation of a rating system. Inter-rater reliability can be evaluated by using a number of different statistics.",
      "question": "What does Inter rater mean"
    },
    {
      "answer": "Events A and B are independent if the equation P(A\u2229B) = P(A) \u00b7 P(B) holds true. You can use the equation to check if events are independent; multiply the probabilities of the two events together to see if they equal the probability of them both happening together.",
      "question": "How do you know if something is independent in probability"
    },
    {
      "answer": "An indicator random variable is a special kind of random variable associated with the occurence of an event. The indicator random variable IA associated with event A has value 1 if event A occurs and has value 0 otherwise. In other words, IA maps all outcomes in the set A to 1 and all outcomes outside A to 0.",
      "question": "What is an indicator random variable"
    },
    {
      "answer": "The coefficient of variation is a better risk measure than the standard deviation alone because the CV adjusts for the size of the project. The CV measures the standard deviation divided by the mean and therefore puts the standard deviation into context.",
      "question": "Why is the coefficient of variation a better risk measure to"
    },
    {
      "answer": "1 \u2014 Linear Regression.  2 \u2014 Logistic Regression.  3 \u2014 Linear Discriminant Analysis.  4 \u2014 Classification and Regression Trees.  5 \u2014 Naive Bayes.  6 \u2014 K-Nearest Neighbors.  7 \u2014 Learning Vector Quantization.  8 \u2014 Support Vector Machines.More items\u2022",
      "question": "Which classification algorithms is easiest to start with for prediction"
    },
    {
      "answer": "A feature selection method is proposed to select a subset of variables in principal component analysis (PCA) that preserves as much information present in the complete data as possible. The information is measured by means of the percentage of consensus in generalised Procrustes analysis.",
      "question": "How Principal component analysis is used for feature selection"
    },
    {
      "answer": "The task boils down to computing the distance between two face vectors. As such, appropriate distance metrics are essential for face verification accuracy.  The use of cosine similarity in our method leads to an effective learning algorithm which can improve the generalization ability of any given metric.",
      "question": "Why does face verification identification usally use cosine similarity"
    },
    {
      "answer": "When dealing with Machine Learning models, it is usually recommended that you store them somewhere. At the private sector, you oftentimes train them and store them before production, while in research and for future model tuning it is a good idea to store them locally.",
      "question": "Where are machine learning models stored"
    },
    {
      "answer": "Logistic regression is a classification algorithm traditionally limited to only two-class classification problems. If you have more than two classes then Linear Discriminant Analysis is the preferred linear classification technique.",
      "question": "Is linear discriminant analysis machine learning"
    },
    {
      "answer": "A significant result indicates that your data are significantly heteroscedastic, and thus the assumption of homoscedasticity in the regression residuals is violated. In your case the data violate the assumption of homoscedasticity, as your p value is 8.6\u22c510\u221228. The e is standard scientific notation for powers of 10.",
      "question": "What is E in P value"
    },
    {
      "answer": "A latent variable is a variable that cannot be observed. The presence of latent variables, however, can be detected by their effects on variables that are observable. Most constructs in research are latent variables.  Because measurement error is by definition unique variance, it is not captured in the latent variable.",
      "question": "What is the meaning of latent variable"
    },
    {
      "answer": "ANOVA is used to compare and contrast the means of two or more populations. ANCOVA is used to compare one variable in two or more populations while considering other variables.",
      "question": "Why we use Ancova instead of Anova"
    },
    {
      "answer": "The ith order statistic of a set of n elements is the ith smallest element. For example, the minimum of a set of elements is the first order statistic (i = 1), and the maximum is the nth order statistic (i = n). A median, informally, is the \"halfway point\" of the set.",
      "question": "What is the ith order statistic"
    },
    {
      "answer": "Convolution neural network is a type of neural network which has some or all convolution layers. Feed forward neural network is a network which is not recursive. neurons in this layer were only connected to neurons in the next layer.  neurons in this layer were only connected to neurons in the next layer.",
      "question": "What are the differences between a convolutional network and a feedforward neural network"
    },
    {
      "answer": "Markov chains are an important concept in stochastic processes. They can be used to greatly simplify processes that satisfy the Markov property, namely that the future state of a stochastic variable is only dependent on its present state.",
      "question": "What is the use of Markov chain"
    },
    {
      "answer": "Conditional Random Fields (CRF) CRF is a discriminant model for sequences data similar to MEMM. It models the dependency between each state and the entire input sequences. Unlike MEMM, CRF overcomes the label bias issue by using global normalizer.",
      "question": "What is CRF NLP"
    },
    {
      "answer": "68% of the data is within 1 standard deviation (\u03c3) of the mean (\u03bc), 95% of the data is within 2 standard deviations (\u03c3) of the mean (\u03bc), and 99.7% of the data is within 3 standard deviations (\u03c3) of the mean (\u03bc).",
      "question": "What is 2 standard deviations from the mean"
    },
    {
      "answer": "In scikit-learn we can use the CalibratedClassifierCV class to create well calibrated predicted probabilities using k-fold cross-validation.  In CalibratedClassifierCV the training sets are used to train the model and the test sets is used to calibrate the predicted probabilities.",
      "question": "What is CalibratedClassifierCV"
    },
    {
      "answer": "Different classifiers are then added on top of this feature extractor to classify images.Support Vector Machines. It is a supervised machine learning algorithm used for both regression and classification problems.  Decision Trees.  K Nearest Neighbor.  Artificial Neural Networks.  Convolutional Neural Networks.",
      "question": "How do you classify images in machine learning"
    },
    {
      "answer": "The AUC value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an excellent classifier.",
      "question": "What is a good ROC score"
    },
    {
      "answer": "Data for two variables (usually two types of related data). Example: Ice cream sales versus the temperature on that day. The two variables are Ice Cream Sales and Temperature.",
      "question": "What are some examples of bivariate data"
    },
    {
      "answer": "Statement of the Multiplication Rule In order to use the rule, we need to have the probabilities of each of the independent events. Given these events, the multiplication rule states the probability that both events occur is found by multiplying the probabilities of each event.",
      "question": "Do you multiply independent events probability"
    },
    {
      "answer": "Findings. A fundamental problem with stepwise regression is that some real explanatory variables that have causal effects on the dependent variable may happen to not be statistically significant, while nuisance variables may be coincidentally significant.",
      "question": "What is wrong with stepwise regression"
    },
    {
      "answer": "Gradient Boosting or GBM is another ensemble machine learning algorithm that works for both regression and classification problems. GBM uses the boosting technique, combining a number of weak learners to form a strong learner.  We will use a simple example to understand the GBM algorithm.",
      "question": "What are different ensemble learning algorithms"
    },
    {
      "answer": "The mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or overall IoU thresholds, depending on different detection challenges that exist. In PASCAL VOC2007 challenge, AP for one object class is calculated for an IoU threshold of 0.5.",
      "question": "How do you calculate average precision score"
    },
    {
      "answer": "Interpolation is making an educated guess with the information within a certain data set. It is a \u201cbest guess\u201d using the information you have at hand.",
      "question": "What is interpolation in machine learning"
    },
    {
      "answer": "Unsupervised learning uses the entire dataset for the supervised training process. In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.  In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.",
      "question": "What is the difference between self supervised and unsupervised learning"
    },
    {
      "answer": "A matrix A is symmetric if it is equal to its transpose, i.e., A=AT. A matrix A is symmetric if and only if swapping indices doesn't change its components, i.e., aij=aji.",
      "question": "What makes a matrix symmetric"
    },
    {
      "answer": "A kind of average sometimes used in statistics and engineering, often abbreviated as RMS. To find the root mean square of a set of numbers, square all the numbers in the set and then find the arithmetic mean of the squares. Take the square root of the result. This is the root mean square.",
      "question": "How is root mean square calculated"
    },
    {
      "answer": "Probit regression, also called a probit model, is used to model dichotomous or binary outcome variables. In the probit model, the inverse standard normal distribution of the probability is modeled as a linear combination of the predictors.",
      "question": "What is probit regression used for"
    },
    {
      "answer": "4.1 Input Layer Input layer in CNN should contain image data. Image data is represented by three dimensional matrix as we saw earlier. You need to reshape it into a single column.  If you have \u201cm\u201d training examples then dimension of input will be (784, m).",
      "question": "What is input layer in CNN"
    },
    {
      "answer": "Because neural networks work internally with numeric data, binary data (such as sex, which can be male or female) and categorical data (such as a community, which can be suburban, city or rural) must be encoded in numeric form.",
      "question": "Can neural network handle categorical data"
    },
    {
      "answer": "Variance of estimator: Variance is one of the most popularly used measures of spread. It is taken into consideration for quantification of the amount of dispersion with respect to set of data values. Variance is defined as the average of the squared deviation of each observation from its mean.",
      "question": "What is the variance of the estimator"
    },
    {
      "answer": "How It Works. Connected component labeling works by scanning an image, pixel-by-pixel (from top to bottom and left to right) in order to identify connected pixel regions, i.e. regions of adjacent pixels which share the same set of intensity values V.",
      "question": "How does connected component image labeling work on colored images"
    },
    {
      "answer": "The variance is the average of the sum of squares (i.e., the sum of squares divided by the number of observations). The standard deviation is the square root of the variance.",
      "question": "How do you find the variance of a sum of squares"
    },
    {
      "answer": "Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. Improving operations. Many companies use predictive models to forecast inventory and manage resources.",
      "question": "How are predictive analytics commonly used"
    },
    {
      "answer": "Machine learning is perhaps the principal technology behind two emerging domains: data science and artificial intelligence. The rise of machine learning is coming about through the availability of data and computation, but machine learning methdologies are fundamentally dependent on models.",
      "question": "What are the domains of machine learning"
    },
    {
      "answer": "The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.",
      "question": "How do you determine the size of a hidden layer"
    },
    {
      "answer": "Blocking refers to classifying experimental units into blocks whereas stratification refers to classifying individuals of a population into strata. The samples from the strata in a stratified random sample can be the blocks in an experiment.",
      "question": "What is the difference between blocking and stratification"
    },
    {
      "answer": "It is well known that maximum likelihood estimators are often biased, and it is of use to estimate the expected bias so that we can reduce the mean square errors of our parameter estimates.  In both problems, the first-order bias is found to be linear in the parameter and the sample size.",
      "question": "Is maximum likelihood estimator biased"
    },
    {
      "answer": "Rather than trying to define a number, instead define what a field of numbers is; instead of defining what a vector is, consider instead all the vectors that make up a vector space. So to understand tensors of a particular type, instead consider all those tensors of the same type together.",
      "question": "What is a good way to understand tensors"
    },
    {
      "answer": "Bayes Theorem for Modeling Hypotheses. Bayes Theorem is a useful tool in applied machine learning. It provides a way of thinking about the relationship between data and a model. A machine learning algorithm or model is a specific way of thinking about the structured relationships in the data.",
      "question": "How Bayes theorem is applied in machine learning"
    },
    {
      "answer": "The WordNet is a part of Python's Natural Language Toolkit. It is a large word database of English Nouns, Adjectives, Adverbs and Verbs. These are grouped into some set of cognitive synonyms, which are called synsets.  In the wordnet, there are some groups of words, whose meaning are same.",
      "question": "What is NLTK WordNet"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What are the differences between supervised and unsupervised classification"
    },
    {
      "answer": "Hypergeometric Formula.. The hypergeometric distribution has the following properties: The mean of the distribution is equal to n * k / N . The variance is n * k * ( N - k ) * ( N - n ) / [ N2 * ( N - 1 ) ] .",
      "question": "What is the formula for hypergeometric distribution"
    },
    {
      "answer": "Finally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset. If the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.",
      "question": "Why is test data set used"
    },
    {
      "answer": "The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.",
      "question": "What is a probability distribution example"
    },
    {
      "answer": "A statistic is biased if the long-term average value of the statistic is not the parameter it is estimating. More formally, a statistic is biased if the mean of the sampling distribution of the statistic is not equal to the parameter.  Therefore the sample mean is an unbiased estimate of \u03bc.",
      "question": "Is mean a biased estimator"
    },
    {
      "answer": "Many everyday data sets typically follow a normal distribution: for example, the heights of adult humans, the scores on a test given to a large class, errors in measurements. The normal distribution is always symmetrical about the mean.",
      "question": "Does the data follow a normal distribution"
    },
    {
      "answer": "Simple linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line. Both variables should be quantitative.",
      "question": "What is a simple linear regression model"
    },
    {
      "answer": "The second reason you may see validation loss lower than training loss is due to how the loss value are measured and reported: Training loss is measured during each epoch. While validation loss is measured after each epoch.",
      "question": "Why is my validation loss lower than training loss"
    },
    {
      "answer": "In other words, discriminative models are used to specify outputs based on inputs (by models such as Logistic regression, Neural networks and Random forests), while generative models generate both inputs and outputs (for example, by Hidden Markov model, Bayesian Networks and Gaussian mixture model).",
      "question": "Is Random Forest generative or discriminative"
    },
    {
      "answer": "The ability to slide the signal is the what gives Engineers a more accurate representation of the signal and therefore a better resolution in time.  So when you use a Wavelet Transform the signal is deconstructed using the same wavelet at different scales, rather than the same sin() wave at different frequencies.",
      "question": "Why do we use wavelet transform"
    },
    {
      "answer": "To create a stratified random sample, there are seven steps: (a) defining the population; (b) choosing the relevant stratification; (c) listing the population; (d) listing the population according to the chosen stratification; (e) choosing your sample size; (f) calculating a proportionate stratification; and (g) using",
      "question": "How do you do stratified sampling"
    },
    {
      "answer": "A method of computing a kind of arithmetic mean of a set of numbers in which some elements of the set carry more importance (weight) than others. Example: Grades are often computed using a weighted average. Suppose that homework counts 10%, quizzes 20%, and tests 70%.",
      "question": "What is weighted average with example"
    },
    {
      "answer": "In probability theory and statistics, the marginal distribution of a subset of a collection of random variables is the probability distribution of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.",
      "question": "What does marginal distribution mean"
    },
    {
      "answer": "Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).",
      "question": "What is conditional probability explain with an example"
    },
    {
      "answer": "Now we'll check out the proven way to improve the performance(Speed and Accuracy both) of neural network models:Increase hidden Layers.  Change Activation function.  Change Activation function in Output layer.  Increase number of neurons.  Weight initialization.  More data.  Normalizing/Scaling data.More items\u2022",
      "question": "How can neural networks be improved"
    },
    {
      "answer": "In probability theory and related fields, a stochastic or random process is a mathematical object usually defined as a family of random variables.  Stochastic processes are widely used as mathematical models of systems and phenomena that appear to vary in a random manner.",
      "question": "What is probability and random process"
    },
    {
      "answer": "The mn Rule Consider an experiment that is performed in two stages. If the first stage can be accomplished in m different ways and for each of these ways, the second stage can be accomplished in n different ways, then there are to- tal mn different ways to accomplish the experiment.",
      "question": "What is the MN rule in statistics"
    },
    {
      "answer": "Recurrent Neural Networks (RNNs) are a form of machine learning algorithm that are ideal for sequential data such as text, time series, financial data, speech, audio, video among others.",
      "question": "Is recurrent neural networks are best suited for text processing"
    },
    {
      "answer": "3.1 . Each bootstrap distribution is centered at the statistic from the corresponding sample rather than at the population mean \u03bc.",
      "question": "Where is a bootstrap distribution centered"
    },
    {
      "answer": "DeepMind",
      "question": "Who has beaten AlphaGo"
    },
    {
      "answer": "Pierre-Simon Laplace",
      "question": "Who proved the central limit theorem"
    },
    {
      "answer": "The estimation of distribution algorithm (EDA) aims to explicitly model the probability distribution of the quality solutions to the underlying problem. By iterative filtering for quality solution from competing ones, the probability model eventually approximates the distribution of global optimum solutions.",
      "question": "Evolutionary Computation Estimation of Distribution Algorithm EDA"
    },
    {
      "answer": "Artificial intelligence can dramatically improve the efficiencies of our workplaces and can augment the work humans can do. When AI takes over repetitive or dangerous tasks, it frees up the human workforce to do work they are better equipped for\u2014tasks that involve creativity and empathy among others.",
      "question": "What is the role of artificial intelligence in the shaping modern society"
    },
    {
      "answer": "Implementing Deep Learning Methods and Feature Engineering for Text Data: FastText. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub.",
      "question": "Is fastText deep learning"
    },
    {
      "answer": "The exponential distribution is often used to model the longevity of an electrical or mechanical device. In Example, the lifetime of a certain computer part has the exponential distribution with a mean of ten years (X\u223cExp(0.1)).",
      "question": "When would you use an exponential distribution"
    },
    {
      "answer": "The definition is: \"Entropy is a measure of how evenly energy is distributed in a system. In a physical system, entropy provides a measure of the amount of energy that cannot be used to do work.\"",
      "question": "What is entropy in layman's terms"
    },
    {
      "answer": "For this, you aim to maximize the Youden's index, which is Maximum=Sensitivity + Specificity - 1. So you choose those value of the ROC-curve as a cut-off, where the term \"Sensitivity + Specificity - 1\" (parameters taken from the output in the same line as the observed value, see attachments) is maximal.",
      "question": "How cut off value is calculated from ROC curve"
    },
    {
      "answer": "The standard error tells you how accurate the mean of any given sample from that population is likely to be compared to the true population mean. When the standard error increases, i.e. the means are more spread out, it becomes more likely that any given mean is an inaccurate representation of the true population mean.",
      "question": "What standard error tells us"
    },
    {
      "answer": "Validity is important because it can help determine what types of tests to use, and help to make sure researchers are using methods that are not only ethical, and cost-effective, but also a method that truly measures the idea or constructs in question.",
      "question": "What is the purpose of measuring the validity of a test"
    },
    {
      "answer": "Standard deviation tells you how spread out the data is. It is a measure of how far each observed value is from the mean. In any distribution, about 95% of values will be within 2 standard deviations of the mean.",
      "question": "What does the standard deviation tell you"
    },
    {
      "answer": "0:0012:40Suggested clip \u00b7 82 secondsCommon Source Amplifiers - Gain Equation - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you calculate gain of common source amplifier"
    },
    {
      "answer": "Use Augmented Dickey-Fuller Test (adf test). A p-Value of less than 0.05 in adf. test() indicates that it is stationary.",
      "question": "How do I check if a time series is stationary in R"
    },
    {
      "answer": "A CNN LSTM can be defined by adding CNN layers on the front end followed by LSTM layers with a Dense layer on the output. It is helpful to think of this architecture as defining two sub-models: the CNN Model for feature extraction and the LSTM Model for interpreting the features across time steps.",
      "question": "How do I combine CNN and Lstm"
    },
    {
      "answer": "Subject 2. Time-series data is a set of observations collected at usually discrete and equally spaced time intervals.  Cross-sectional data are observations that come from different individuals or groups at a single point in time.",
      "question": "What is the difference between trend time series and cross section analysis"
    },
    {
      "answer": "The pre-attention phase is an automatic process which happens unconsciously. The second stage is focused attention in which an individual takes all of the observed features and combines them to make a complete perception. This second stage process occurs if the object doesn't stand out immediately.",
      "question": "What are the two stages of processing in the feature integration theory"
    },
    {
      "answer": "Data is the currency of applied machine learning.  Resampling is a methodology of economically using a data sample to improve the accuracy and quantify the uncertainty of a population parameter. Resampling methods, in fact, make use of a nested resampling method.",
      "question": "What is resampling in machine learning"
    },
    {
      "answer": "Statistical data binning is a way to group numbers of more or less continuous values into a smaller number of \"bins\". For example, if you have data about a group of people, you might want to arrange their ages into a smaller number of age intervals (for example, grouping every five years together).",
      "question": "What is data binning in statistics"
    },
    {
      "answer": "Temporal Difference is an approach to learning how to predict a quantity that depends on future values of a given signal. It can be used to learn both the V-function and the Q-function, whereas Q-learning is a specific TD algorithm used to learn the Q-function.",
      "question": "Is Q learning temporal difference"
    },
    {
      "answer": "The main difference is the one of focus. Data Engineers are focused on building infrastructure and architecture for data generation. In contrast, data scientists are focused on advanced mathematics and statistical analysis on that generated data.  Simply put, data scientists depend on data engineers.",
      "question": "How data engineering is different from data science"
    },
    {
      "answer": "The product moment correlation coefficient (pmcc) can be used to tell us how strong the correlation between two variables is. A positive value indicates a positive correlation and the higher the value, the stronger the correlation.  If there is a perfect negative correlation, then r = -1.",
      "question": "What does product moment correlation coefficient mean"
    },
    {
      "answer": "Key Takeaways. Standard deviation looks at how spread out a group of numbers is from the mean, by looking at the square root of the variance. The variance measures the average degree to which each point differs from the mean\u2014the average of all data points.",
      "question": "What is standard deviation and variance"
    },
    {
      "answer": "In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class.",
      "question": "What is Perceptron learning algorithm"
    },
    {
      "answer": "What is the F-distribution. A probability distribution, like the normal distribution, is means of determining the probability of a set of events occurring. This is true for the F-distribution as well. The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution.",
      "question": "Is F distribution a normal distribution"
    },
    {
      "answer": "6 Answers. Machine learning algorithms use optimization all the time.  Nonetheless, as mentioned in other answers, convex optimization is faster, simpler and less computationally intensive, so it is often easier to \"convexify\" a problem (make it convex optimization friendly), then use non-convex optimization.",
      "question": "Is convex optimization important for machine learning"
    },
    {
      "answer": "A weak classifier is simply a classifier that performs poorly, but performs better than random guessing.  AdaBoost can be applied to any classification algorithm, so it's really a technique that builds on top of other classifiers as opposed to being a classifier itself.",
      "question": "What is weak classifier in AdaBoost"
    },
    {
      "answer": "K-means clustering algorithm computes the centroids and iterates until we it finds optimal centroid.  In this algorithm, the data points are assigned to a cluster in such a manner that the sum of the squared distance between the data points and centroid would be minimum.",
      "question": "What is K means clustering algorithm explain with an example"
    },
    {
      "answer": "TL;DR: Entropy is not quantized. Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.  Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.",
      "question": "Is entropy quantized"
    },
    {
      "answer": "Confusion matrix not only gives you insight into the errors being made by your classifier but also types of errors that are being made. This breakdown helps you to overcomes the limitation of using classification accuracy alone. Every column of the confusion matrix represents the instances of that predicted class.",
      "question": "Why do we need confusion matrix in data mining"
    },
    {
      "answer": "A simple linear regression plot for amount of rainfall. Regression analysis is used in stats to find trends in data. For example, you might guess that there's a connection between how much you eat and how much you weigh; regression analysis can help you quantify that.",
      "question": "What is regression analysis example"
    },
    {
      "answer": "The coefficient of variation (COV) is a measure of relative event dispersion that's equal to the ratio between the standard deviation and the mean. While it is most commonly used to compare relative risk, the COV may be applied to any type of quantitative likelihood or probability distribution.",
      "question": "Where is coefficient variation used"
    },
    {
      "answer": "Cluster analysis divides data into groups (clusters) that are meaningful, useful, or both. If meaningful groups are the goal, then the clusters should capture the natural structure of the data. In some cases, however, cluster analysis is only a useful starting point for other purposes, such as data summarization.",
      "question": "How do you read cluster analysis"
    },
    {
      "answer": "Test method. Use the one-sample z-test to determine whether the hypothesized population proportion differs significantly from the observed sample proportion.",
      "question": "What test statistic is used to test a population proportion"
    },
    {
      "answer": "In the context of AB testing experiments, statistical significance is how likely it is that the difference between your experiment's control version and test version isn't due to error or random chance.  It's commonly used in business to observe how your experiments affect your business's conversion rates.",
      "question": "What is statistical significance in AB testing"
    },
    {
      "answer": "r text-mining natural-language. According the documentation of the removeSparseTerms function from the tm package, this is what sparsity entails: A term-document matrix where those terms from x are removed which have at least a sparse percentage of empty (i.e., terms occurring 0 times in a document) elements.",
      "question": "What is sparsity in document term matrix"
    },
    {
      "answer": "The ground-truth bounding boxes (i.e., the hand labeled bounding boxes from the testing set that specify where in the image our object is).",
      "question": "What is ground truth box"
    },
    {
      "answer": "Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.",
      "question": "What is sentiment analysis in natural language processing"
    },
    {
      "answer": "Simply put, a random sample is a subset of individuals randomly selected by researchers to represent an entire group as a whole. The goal is to get a sample of people that is representative of the larger population.",
      "question": "What is the main purpose of random sampling"
    },
    {
      "answer": "Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution.",
      "question": "What is the shape of the chi square distribution"
    },
    {
      "answer": "Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. In logistic regression we assumed that the labels were binary: y(i)\u2208{0,1} . We used such a classifier to distinguish between two kinds of hand-written digits.",
      "question": "Is Softmax the same as logistic regression"
    },
    {
      "answer": "Definition: A vector space is a set V on which two operations + and \u00b7 are defined, called vector addition and scalar multiplication. The operation + (vector addition) must satisfy the following conditions: Closure: If u and v are any vectors in V, then the sum u + v belongs to V.",
      "question": "How do you define a vector space"
    },
    {
      "answer": "1 : a branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data. 2 : a collection of quantitative data.",
      "question": "What is the simple definition of statistics"
    },
    {
      "answer": "Multicollinearity causes the following two basic types of problems: The coefficient estimates can swing wildly based on which other independent variables are in the model.  Multicollinearity reduces the precision of the estimate coefficients, which weakens the statistical power of your regression model.",
      "question": "How does Multicollinearity affect the regression model"
    },
    {
      "answer": "Key Takeaways. Standard deviation defines the line along which a particular data point lies. Z-score indicates how much a given value differs from the standard deviation. The Z-score, or standard score, is the number of standard deviations a given data point lies above or below mean.",
      "question": "What is the difference between AZ score and standard deviation"
    },
    {
      "answer": "The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(\u2217). Both functions will take any number and rescale it to fall between 0 and 1.",
      "question": "What is logit probit model"
    },
    {
      "answer": "A probability sampling method is any method of sampling that utilizes some form of random selection. In order to have a random selection method, you must set up some process or procedure that assures that the different units in your population have equal probabilities of being chosen.",
      "question": "What is probability sampling technique"
    },
    {
      "answer": "Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients. Implementations may choose to sum the gradient over the mini-batch which further reduces the variance of the gradient.",
      "question": "What is mini batch stochastic gradient descent"
    },
    {
      "answer": "Character N-grams (of at least 3 characters) that are common to words meaning \u201ctransport\u201d in the same texts sample in French, Spanish and Greek and their respective frequency.",
      "question": "What is character N grams"
    },
    {
      "answer": "The Linear Regression Equation The equation has the form Y= a + bX, where Y is the dependent variable (that's the variable that goes on the Y axis), X is the independent variable (i.e. it is plotted on the X axis), b is the slope of the line and a is the y-intercept.",
      "question": "How do you write a regression model"
    },
    {
      "answer": "A Kalman Filter is an algorithm that can predict future positions based on current position. It can also estimate current position better than what the sensor is telling us. It will be used to have better association.",
      "question": "How can a Kalman filter be used in computer vision"
    },
    {
      "answer": "Developers can make use of NLP to perform tasks like speech recognition, sentiment analysis, translation, auto-correct of grammar while typing, and automated answer generation. NLP is a challenging field since it deals with human language, which is extremely diverse and can be spoken in a lot of ways.",
      "question": "What is the scope of NLP"
    },
    {
      "answer": "A continuous variable is one which can take on a value between any other two values, such as: indoor temperature, time spent waiting, water consumed, color wavelength, and direction of travel. A discrete variable corresponds to a digital quantity, while a continuous variable corresponds to an analog quantity.",
      "question": "Is time a discrete variable"
    },
    {
      "answer": "ProcedureFrom the cluster management console, select Workload > Spark > Deep Learning.Select the Datasets tab.Click New.Create a dataset from Images for Object Classification.Provide a dataset name.Specify a Spark instance group.Specify image storage format, either LMDB for Caffe or TFRecords for TensorFlow.More items",
      "question": "How do you create a dataset of an image"
    },
    {
      "answer": "The different types of regression in machine learning techniques are explained below in detail:Linear Regression. Linear regression is one of the most basic types of regression in machine learning.  Logistic Regression.  Ridge Regression.  Lasso Regression.  Polynomial Regression.  Bayesian Linear Regression.",
      "question": "What are the different types of regression"
    },
    {
      "answer": "How to Use K-means Cluster Algorithms in Predictive AnalysisPick k random items from the dataset and label them as cluster representatives.Associate each remaining item in the dataset with the nearest cluster representative, using a Euclidean distance calculated by a similarity function.Recalculate the new clusters' representatives.More items",
      "question": "How is K means clustering used in prediction"
    },
    {
      "answer": "The p-value for each term tests the null hypothesis that the coefficient is equal to zero (no effect). A low p-value (< 0.05) indicates that you can reject the null hypothesis.",
      "question": "How do I interpret p value in logistic regression"
    },
    {
      "answer": "The Monty Hall problem has confused people for decades. In the game show, Let's Make a Deal, Monty Hall asks you to guess which closed door a prize is behind. The answer is so puzzling that people often refuse to accept it! The problem occurs because our statistical assumptions are incorrect.",
      "question": "Why the Monty Hall problem is wrong"
    },
    {
      "answer": "A major difference is in its shape: the normal distribution is symmetrical, whereas the lognormal distribution is not. Because the values in a lognormal distribution are positive, they create a right-skewed curve.  A further distinction is that the values used to derive a lognormal distribution are normally distributed.",
      "question": "What is the difference between normal and lognormal distribution"
    },
    {
      "answer": "If two random variables X and Y are independent, then they are uncorrelated. Proof. Uncorrelated means that their correlation is 0, or, equivalently, that the covariance between them is 0.",
      "question": "How do you prove two variables are uncorrelated"
    },
    {
      "answer": "Advantages of Dimensionality Reduction It helps in data compression, and hence reduced storage space. It reduces computation time. It also helps remove redundant features, if any.",
      "question": "Why dimensionality reduction is important step in machine learning"
    },
    {
      "answer": "Probability theory is the mathematical study of phenomena characterized by randomness or uncertainty. More precisely, probability is used for modelling situations when the result of an experiment, realized under the same circumstances, produces different results (typically throwing a dice or a coin).",
      "question": "What is probability theory used for"
    },
    {
      "answer": "Discriminant analysis is a versatile statistical method often used by market researchers to classify observations into two or more groups or categories. In other words, discriminant analysis is used to assign objects to one group among a number of known groups.",
      "question": "What is discriminant analysis used for"
    },
    {
      "answer": "The level of statistical significance is often expressed as a p-value between 0 and 1. The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.  A p-value higher than 0.05 (> 0.05) is not statistically significant and indicates strong evidence for the null hypothesis.",
      "question": "Is the level of significance the same as the P value"
    },
    {
      "answer": "Sparse coding is the representation of items by the strong activation of a relatively small set of neurons. For each stimulus, this is a different subset of all available neurons.",
      "question": "What is sparse coding in neural network"
    },
    {
      "answer": "NHST is difficult to describe in one sentence, particularly here.",
      "question": "What does Null Hypothesis significance testing NHST mean"
    },
    {
      "answer": "The performance of deep learning neural networks often improves with the amount of data available. Data augmentation is a technique to artificially create new training data from existing training data. This means, variations of the training set images that are likely to be seen by the model.",
      "question": "What is augmentation in deep learning"
    },
    {
      "answer": "If your data contains both numeric and categorical variables, the best way to carry out clustering on the dataset is to create principal components of the dataset and use the principal component scores as input into the clustering.",
      "question": "Can you use categorical variables in clustering"
    },
    {
      "answer": "If all of the values in the sample are identical, the sample standard deviation will be zero. When discussing the sample mean, we found that the sample mean for diastolic blood pressure was 71.3.",
      "question": "Can a sample mean be zero"
    },
    {
      "answer": "There is a good reason why accuracy is not an appropriate measure for information retrieval problems. In almost all circumstances, the data is extremely skewed: normally over 99.9% of the documents are in the nonrelevant category.",
      "question": "Why accuracy is not used as a preferred method for real world IR system evaluation"
    },
    {
      "answer": "Padding is a term relevant to convolutional neural networks as it refers to the amount of pixels added to an image when it is being processed by the kernel of a CNN. For example, if the padding in a CNN is set to zero, then every pixel value that is added will be of value zero.",
      "question": "What is padding in deep learning"
    },
    {
      "answer": "resample Function One resampling application is the conversion of digitized audio signals from one sample rate to another, such as from 48 kHz (the digital audio tape standard) to 44.1 kHz (the compact disc standard).  resample applies a lowpass filter to the input sequence to prevent aliasing during resampling.",
      "question": "What is resampling in signal processing"
    },
    {
      "answer": "In computer science and engineering, a test vector is a set of inputs provided to a system in order to test that system. In software development, test vectors are a methodology of software testing and software verification and validation.",
      "question": "What is input vector"
    },
    {
      "answer": "An easy guide to choose the right Machine Learning algorithmSize of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.",
      "question": "Which algorithm is right for machine learning"
    },
    {
      "answer": "Just multiply the probability of the first event by the second. For example, if the probability of event A is 2/9 and the probability of event B is 3/9 then the probability of both events happening at the same time is (2/9)*(3/9) = 6/81 = 2/27.",
      "question": "How do you find the probability of multiple events"
    },
    {
      "answer": "To format the size of data points in a scatter plot graph, right click any of the data points and select 'format data series' then select marker options and customize for larger or smaller data points.",
      "question": "How do you make the dots on a scatter plot bigger"
    },
    {
      "answer": "A common problem in machine learning is sparse data, which alters the performance of machine learning algorithms and their ability to calculate accurate predictions. Data is considered sparse when certain expected values in a dataset are missing, which is a common phenomenon in general large scaled data analysis.",
      "question": "What is sparse data in machine learning"
    },
    {
      "answer": "Regression: This is a tool used to evaluate the relationship of a dependent variable in relation to multiple independent variables. A regression will analyze the mean of the dependent variable in relation to changes in the independent variables. Time Series: A time series measures data over a specific period of time.",
      "question": "What is the difference between time series and regression"
    },
    {
      "answer": "Consider statistics as a problem-solving process and examine its four components: asking questions, collecting appropriate data, analyzing the data, and interpreting the results. This session investigates the nature of data and its potential sources of variation. Variables, bias, and random sampling are introduced.",
      "question": "What is the statistical problem solving process"
    },
    {
      "answer": "Eigenanalysis is a mathematical operation on a square, symmetric matrix. A square matrix has the same number of rows as columns. A symmetric matrix is the same if you switch rows and columns. Distance and similarity matrices are nearly always square and symmetric.",
      "question": "What is Eigen analysis"
    },
    {
      "answer": "Simply put, homoscedasticity means \u201chaving the same scatter.\u201d For it to exist in a set of data, the points must be about the same distance from the line, as shown in the picture above. The opposite is heteroscedasticity (\u201cdifferent scatter\u201d), where points are at widely varying distances from the regression line.",
      "question": "What does Homoscedasticity mean in regression"
    },
    {
      "answer": "If you have both a response variable and an explanatory variable, the explanatory variable is always plotted on the x-axis (the horizontal axis). The response variable is always plotted on the y-axis (the vertical axis).",
      "question": "How do you know which is the explanatory variable"
    },
    {
      "answer": "Approach \u2013Load dataset from source.Split the dataset into \u201ctraining\u201d and \u201ctest\u201d data.Train Decision tree, SVM, and KNN classifiers on the training data.Use the above classifiers to predict labels for the test data.Measure accuracy and visualise classification.",
      "question": "How do you do multi class classification"
    },
    {
      "answer": "Here are some important considerations while choosing an algorithm.Size of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.",
      "question": "How can I choose among classification algorithms to work with"
    },
    {
      "answer": "Genetic algorithms are stochastic search algorithms which act on a population of possible solutions.  Genetic algorithms are used in artificial intelligence like other search algorithms are used in artificial intelligence \u2014 to search a space of potential solutions to find one which solves the problem.",
      "question": "Are genetic algorithms artificial intelligence"
    },
    {
      "answer": "Taguchi loss function formulaL is the loss function.y is the value of the characteristic you are measuring (e.g. length of product)m is the value you are aiming for (in our example, perfect length for the product)k is a proportionality constant (i.e. just a number)",
      "question": "How is Taguchi quality loss function calculated"
    },
    {
      "answer": "Exploratory Data Analysis is one of the important steps in the data analysis process.  Exploratory Data Analysis is a crucial step before you jump to machine learning or modeling of your data. It provides the context needed to develop an appropriate model \u2013 and interpret the results correctly.",
      "question": "Why do we need to perform exploratory data analysis"
    },
    {
      "answer": "Fortunately, hinge loss, logistic loss and square loss are all convex functions. Convexity ensures global minimum and it's computationally appleaing.",
      "question": "Is squared loss convex"
    },
    {
      "answer": "The input nodes take in information, in the form which can be numerically expressed. The information is presented as activation values, where each node is given a number, the higher the number, the greater the activation.  The output nodes then reflect the input in a meaningful way to the outside world.",
      "question": "What is an activation value *"
    },
    {
      "answer": "Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks.  Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents.",
      "question": "How does activation spread through a semantic network"
    },
    {
      "answer": "Examples of Artificial Intelligence: Work & School1 \u2013 Google's AI-Powered Predictions.  2 \u2013 Ridesharing Apps Like Uber and Lyft.  3 \u2014 Commercial Flights Use an AI Autopilot.1 \u2013 Spam Filters.2 \u2013 Smart Email Categorization.1 \u2013Plagiarism Checkers.  2 \u2013Robo-readers.  1 \u2013 Mobile Check Deposits.More items\u2022",
      "question": "What are some applications of AI in real life"
    },
    {
      "answer": "There are two main ways to access subsets of the elements in a tensor, either of which should work for your example.Use the indexing operator (based on tf. slice() ) to extract a contiguous slice from the tensor. input = tf.  Use the tf. gather() op to select a non-contiguous slice from the tensor. input = tf.",
      "question": "How do I find the value of Tensor"
    },
    {
      "answer": "The sampling distribution of the sample mean can be thought of as \"For a sample of size n, the sample mean will behave according to this distribution.\" Any random draw from that sampling distribution would be interpreted as the mean of a sample of n observations from the original population.",
      "question": "What does a sampling distribution of sample means represent"
    },
    {
      "answer": "The determinant is related to the volume of the space occupied by the swarm of data points represented by standard scores on the measures involved.  When the measures are correlated, the space occupied becomes an ellipsoid whose volume is less than 1.",
      "question": "What does the determinant of the correlation matrix represent"
    },
    {
      "answer": "0:041:23Suggested clip \u00b7 72 secondsQuick Example - Find the Area to the Right Of a Z-Score - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How is technology used to find the area to the right of Z"
    },
    {
      "answer": "\u2022 A random process is a time-varying function that assigns the outcome of a random experiment to each time instant: X(t). \u2022 For a fixed (sample path): a random process is a time varying function, e.g., a signal.",
      "question": "What is random process in communication"
    },
    {
      "answer": "Basically, it takes between 365 days (1 year) to 1,825 days (5 years) to learn artificial intelligence (assuming you put in 4 \u2013 0.5 learning hours a day). And how fast you learn also affects how long it takes you to be an expert.",
      "question": "How long does it take to learn artificial intelligence"
    },
    {
      "answer": "An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.",
      "question": "What are some applications of the Autoregressive integrated moving average ARIMA model"
    },
    {
      "answer": "All descriptive statistics are either measures of central tendency or measures of variability, also known as measures of dispersion.  Range, quartiles, absolute deviation and variance are all examples of measures of variability. Consider the following data set: 5, 19, 24, 62, 91, 100.",
      "question": "What is an example of a descriptive statistic"
    },
    {
      "answer": "The total number of contravariant and covariant indices of a tensor. The rank of a tensor is independent of the number of dimensions. of the underlying space.",
      "question": "What is tensor rank"
    },
    {
      "answer": "Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.",
      "question": "What is meant by a tensor"
    },
    {
      "answer": "Generative adversarial nets can be applied in many fields from generating images to predicting drugs, so don't be afraid of experimenting with them. We believe they help in building a better future for machine learning.",
      "question": "What are generative adversarial networks used for"
    },
    {
      "answer": "the state of being likely or probable; probability. a probability or chance of something: There is a strong likelihood of his being elected.",
      "question": "What is meant by likelihood"
    },
    {
      "answer": "Canonical discriminant analysis is a dimension-reduction technique related to principal component analysis and canonical correlation.  This maximal multiple correlation is called the first canonical correlation. The coefficients of the linear combination are the canonical coefficients or canonical weights.",
      "question": "What is canonical discriminant analysis"
    },
    {
      "answer": "Entropy can be calculated for a random variable X with k in K discrete states as follows: H(X) = -sum(each k in K p(k) * log(p(k)))",
      "question": "How do you calculate entropy of information"
    },
    {
      "answer": "Word2Vec can be used to get actionable metrics from thousands of customers reviews. Businesses don't have enough time and tools to analyze survey responses and act on them thereon. This leads to loss of ROI and brand value. Word embeddings prove invaluable in such cases.",
      "question": "Where is Word2Vec used"
    },
    {
      "answer": "This is the \u201cq-value.\u201d A p-value of 5% means that 5% of all tests will result in false positives. A q-value of 5% means that 5% of significant results will result in false positives.",
      "question": "How do you interpret Q values"
    },
    {
      "answer": "In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.",
      "question": "What does it mean when data is positively skewed"
    },
    {
      "answer": "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization.",
      "question": "Does normalization improve performance machine learning"
    },
    {
      "answer": "2:316:15Suggested clip \u00b7 118 secondsUnit Conversion the Easy Way (Dimensional Analysis) - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you convert dimensional analysis"
    },
    {
      "answer": "Multi-task learning (MTL) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks.  In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly.",
      "question": "What is multi task learning in machine learning"
    },
    {
      "answer": "The MSE is a measure of the quality of an estimator\u2014it is always non-negative, and values closer to zero are better.  For an unbiased estimator, the MSE is the variance of the estimator. Like the variance, MSE has the same units of measurement as the square of the quantity being estimated.",
      "question": "Is MSE equal to variance"
    },
    {
      "answer": "4:026:15Suggested clip \u00b7 93 secondsFinding the Test Statistic for a Wilcoxon Rank Sum Test in  - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you solve the Wilcoxon rank sum test"
    },
    {
      "answer": "if p is a statement variable, the negation of p is \"not p\", denoted by ~p. If p is true, then ~p is false. Conjunction: if p and q are statement variables, the conjunction of p and q is \"p and q\", denoted p q.(p q) ~(p q) p xor qExclusive Orp ~(~p)Double Negation",
      "question": "What is logically equivalent to P or Q"
    },
    {
      "answer": "The difference between combinations and permutations is ordering. With permutations we care about the order of the elements, whereas with combinations we don't. For example, say your locker \u201ccombo\u201d is 5432. If you enter 4325 into your locker it won't open because it is a different ordering (aka permutation).",
      "question": "How do you know when to use a permutation instead of a combination"
    },
    {
      "answer": "to safeguard against the researcher problem of experimenter bias, researchers employ blind observers, single and double blind study, and placebos. to control for ethnocentrism, they use cross cultural sampling.",
      "question": "What are two methods researchers use to avoid experimenter bias"
    },
    {
      "answer": "In ordinary least squares, the relevant assumption of the classical linear regression model is that the error term is uncorrelated with the regressors. The presence of omitted-variable bias violates this particular assumption. The violation causes the OLS estimator to be biased and inconsistent.",
      "question": "Which assumption does omitted variable bias violate"
    },
    {
      "answer": "0:012:32Suggested clip \u00b7 101 secondsMultiple Logistic Regression - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do multiple logistic regression"
    },
    {
      "answer": "Artificial General Intelligence",
      "question": "What does AGI stand for in artificial intelligence"
    },
    {
      "answer": "Cross tabulationCross tabulations require that the two data columns be adjacent. You can drag columns by selecting them, and moving the cursor so it's immediately between two columns.  Once you have the columns adjacent, select both of them including the variable names all the way to the bottom.",
      "question": "How do you do cross tabulation"
    },
    {
      "answer": "Factor analysis is as much of a \"test\" as multiple regression (or statistical tests in general) in that it is used to reveal hidden or latent relationships/groupings in one's dataset.  Multiple regression takes data points in some n-dimensional space and finds the best fit line.",
      "question": "How is factor analysis different from multiple regression"
    },
    {
      "answer": "When someone talks about AR, they are referring to technology that overlays information and virtual objects on real-world scenes in real-time. It uses the existing environment and adds information to it to make a new artificial environment.",
      "question": "What is augmented reality used for"
    },
    {
      "answer": "They provide a natural way to handle missing data, they allow combination of data with domain knowledge, they facilitate learning about causal relationships between variables, they provide a method for avoiding overfitting of data (Heckerman, 1995), they can show good prediction accuracy even with rather small sample",
      "question": "What are the advantages of Bayesian networks"
    },
    {
      "answer": "Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on. If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)",
      "question": "How do neural networks reduce loss"
    },
    {
      "answer": "To put simply, likelihood is \"the likelihood of \u03b8 having generated D\" and posterior is essentially \"the likelihood of \u03b8 having generated D\" further multiplied by the prior distribution of \u03b8.",
      "question": "What is the difference between likelihood function and posterior probability"
    },
    {
      "answer": "Adding more training data.Reducing parameters. We have too many neurons in our hidden layers or too many layers. Let's remove some layers, or reduce the number of hidden neurons.Increase regularization. Either by increasing our. for L1/L2 weight regularization. We can also use dropout the technique.",
      "question": "Why and what to do when neural networks perform poorly on the training set"
    },
    {
      "answer": "Learning involves far more than thinking: it involves the whole personality - senses, feelings, intuition, beliefs, values and will.  Learning occurs when we are able to: Gain a mental or physical grasp of the subject. Make sense of a subject, event or feeling by interpreting it into our own words or actions.",
      "question": "What is learning and how do we learn"
    },
    {
      "answer": "EM is an iterative method which alternates between two steps, expectation (E) and maximization (M). For clustering, EM makes use of the finite Gaussian mixtures model and estimates a set of parameters iteratively until a desired convergence value is achieved.",
      "question": "What is Expectation Maximization clustering"
    },
    {
      "answer": "Simple logistic regression analysis refers to the regression application with one dichotomous outcome and one independent variable; multiple logistic regression analysis applies when there is a single dichotomous outcome and more than one independent variable.",
      "question": "What does multiple logistic regression mean"
    },
    {
      "answer": "Tokenization is one of the most common tasks when it comes to working with text data.  Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.",
      "question": "What is tokenization NLP"
    },
    {
      "answer": "Click on the triangle-shaped icon located at the top right corner of the panel, and then choose \"Save Path\". Next, select \"Clipping Path\" from the same drop-down menu. A new dialog box will appear with a variety of clipping path settings. Make sure your path is selected, and then click OK.",
      "question": "How do you do a clipping path"
    },
    {
      "answer": "It's a form of machine learning and therefore a branch of artificial intelligence. Depending on the complexity of the problem, reinforcement learning algorithms can keep adapting to the environment over time if necessary in order to maximize the reward in the long-term.",
      "question": "Is reinforcement learning AI"
    },
    {
      "answer": "Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.",
      "question": "How do you know if an event is independent or dependent"
    },
    {
      "answer": "While statistical significance relates to whether an effect exists, practical significance refers to the magnitude of the effect. However, no statistical test can tell you whether the effect is large enough to be important in your field of study.  An effect of 4 points or less is too small to care about.",
      "question": "How might a statistical test be statistically significant but not practical"
    },
    {
      "answer": "When there is lack of domain understanding for feature introspection , Deep Learning techniques outshines others as you have to worry less about feature engineering . Deep Learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition.",
      "question": "Why should I learn deep learning"
    },
    {
      "answer": "Linear discriminant analysis (LDA) is one of commonly used supervised subspace learning methods.  The objective optimization is in both the ratio trace and the trace ratio forms, forming a complete framework of a new approach to jointly clustering and unsupervised subspace learning.",
      "question": "Is linear discriminant analysis supervised or unsupervised"
    },
    {
      "answer": "Communalities \u2013 This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.  They are the reproduced variances from the factors that you have extracted.",
      "question": "What does Communalities mean in factor analysis"
    },
    {
      "answer": "Non-linearity in neural networks simply mean that the output at any unit cannot be reproduced from a linear function of the input.",
      "question": "What is nonlinearity in neural networks"
    },
    {
      "answer": "Stochastic Gradient Descent: you would randomly select one of those training samples at each iteration to update your coefficients. Online Gradient Descent: you would use the \"most recent\" sample at each iteration. There is no stochasticity as you deterministically select your sample.",
      "question": "Difference between stochastic gradient descent and online learning"
    },
    {
      "answer": "The first method involves the conditional distribution of a random variable X2 given X1. Therefore, a bivariate normal distribution can be simulated by drawing a random variable from the marginal normal distribution and then drawing a second random variable from the conditional normal distribution.",
      "question": "How do you create a bivariate normal distribution"
    },
    {
      "answer": "In a crossover network, resistors are usually used in combination with other components to control either impedance magnitudes or the relative levels between different drivers in a system.",
      "question": "What does a resistor do in a crossover"
    },
    {
      "answer": "A regression equation is used in stats to find out what relationship, if any, exists between sets of data. For example, if you measure a child's height every year you might find that they grow about 3 inches a year. That trend (growing three inches a year) can be modeled with a regression equation.",
      "question": "What does a regression equation tell you"
    },
    {
      "answer": "Optimal control focuses on a subset of problems, but solves these problems very well, and has a rich history. RL can be thought of as a way of generalizing or extending ideas from optimal control to non-traditional control problems.",
      "question": "What is the difference between optimal control theory and reinforcement learning"
    },
    {
      "answer": "Random forests perform well for multi-class object detection and bioinformatics, which tends to have a lot of statistical noise. Gradient Boosting performs well when you have unbalanced data such as in real time risk assessment.",
      "question": "Why is gradient boosting better than random forest"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is the difference between supervised and unsupervised learning"
    },
    {
      "answer": "PD analysis is a method used by larger institutions to calculate their expected loss. A PD is assigned to each risk measure and represents as a percentage the likelihood of default.  LGD represents the amount unrecovered by the lender after selling the underlying asset if a borrower defaults on a loan.",
      "question": "What is PD and LGD"
    },
    {
      "answer": "Instance-based methods are sometimes referred to as lazy learning methods because they delay processing until a new instance must be classified. The nearest neighbors of an instance are defined in terms of Euclidean distance.",
      "question": "Why instance based learning is called as lazy learning"
    },
    {
      "answer": "Other ways of avoiding experimenter's bias include standardizing methods and procedures to minimize differences in experimenter-subject interactions; using blinded observers or confederates as assistants, further distancing the experimenter from the subjects; and separating the roles of investigator and experimenter.",
      "question": "How do you get rid of experimenter bias"
    },
    {
      "answer": "The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution. It is also known as the Gaussian distribution and the bell curve.",
      "question": "Why data should be normally distributed"
    },
    {
      "answer": "An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value.  The vertical axis represents the size of the area (total number of pixels) that is captured in each one of these zones.",
      "question": "What is a histogram in image processing"
    },
    {
      "answer": "conditions\u2014Random, Normal, and Independent\u2014is. important when constructing a confidence interval.",
      "question": "What are the three conditions for constructing a confidence interval for the population mean"
    },
    {
      "answer": "Regression trees are used in Statistics, Data Mining and Machine learning. It is a very important and powerful technique when it comes to predictive analysis [5] . The goal is to predict the value of target variable on the basis of several input attributes that act as nodes of the regression tree.",
      "question": "Which type of data is often Modelled using regression trees"
    },
    {
      "answer": "The C parameter trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors.",
      "question": "Which parameter in SVM is responsible for tradeoff between misclassification and simplicity of model"
    },
    {
      "answer": "Average-linkage is where the distance between each pair of observations in each cluster are added up and divided by the number of pairs to get an average inter-cluster distance. Average-linkage and complete-linkage are the two most popular distance metrics in hierarchical clustering.",
      "question": "How does Average Linkage work in Hierarchical Agglomerative clustering"
    },
    {
      "answer": "Each is essentially a component of the prior term. That is, machine learning is a subfield of artificial intelligence. Deep learning is a subfield of machine learning, and neural networks make up the backbone of deep learning algorithms.",
      "question": "Is neural network a part of machine learning"
    },
    {
      "answer": "Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e.g., points, lines or bars) contained in graphics. The goal is to communicate information clearly and efficiently to users. It is one of the steps in data analysis or data science.",
      "question": "What is data visualization and its techniques"
    },
    {
      "answer": "A data distribution is a function or a listing which shows all the possible values (or intervals) of the data. It also (and this is important) tells you how often each value occurs.",
      "question": "What does a distribution tell us about a set of data"
    },
    {
      "answer": "The correlation coefficient is a measure of the degree of linear association between two continuous variables, i.e. when plotted together, how close to a straight line is the scatter of points.  Both x and y must be continuous random variables (and Normally distributed if the hypothesis test is to be valid).",
      "question": "For correlation coefficient between two random variables to be a meaningful measure of their linear association do the variables need to be normally distributed"
    },
    {
      "answer": "A stochastic process is a family of random variables {X\u03b8}, where the parameter \u03b8 is drawn from an index set \u0398. For example, let's say the index set is \u201ctime\u201d.  One example of a stochastic process that evolves over time is the number of customers (X) in a checkout line.",
      "question": "What is a stochastic process provide an example"
    },
    {
      "answer": "The covariance between X and Y is defined as Cov(X,Y)=E[(X\u2212EX)(Y\u2212EY)]=E[XY]\u2212(EX)(EY).The covariance has the following properties:Cov(X,X)=Var(X);if X and Y are independent then Cov(X,Y)=0;Cov(X,Y)=Cov(Y,X);Cov(aX,Y)=aCov(X,Y);Cov(X+c,Y)=Cov(X,Y);Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z);more generally,",
      "question": "How do you find the covariance of a random variable"
    },
    {
      "answer": "The chi-square distribution curve is skewed to the right, and its shape depends on the degrees of freedom df. For df > 90, the curve approximates the normal distribution. Test statistics based on the chi-square distribution are always greater than or equal to zero.",
      "question": "What is the basic shape of the chi square distribution"
    },
    {
      "answer": "The Gini coefficient for the entire world has been estimated by various parties to be between 0.61 and 0.68.",
      "question": "What is the average Gini coefficient"
    },
    {
      "answer": "R-squared should accurately reflect the percentage of the dependent variable variation that the linear model explains. Your R2 should not be any higher or lower than this value.  However, if you analyze a physical process and have very good measurements, you might expect R-squared values over 90%.",
      "question": "What is an acceptable R squared value"
    },
    {
      "answer": "The decision rule is: Reject H0 if Z < 1.645. The decision rule is: Reject H0 if Z < -1.960 or if Z > 1.960. The complete table of critical values of Z for upper, lower and two-tailed tests can be found in the table of Z values to the right in \"Other Resources.\"",
      "question": "What is the rule for rejecting Ho in terms of Z"
    },
    {
      "answer": "Suggest Edits. Support Vector Machines (SVMs) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.",
      "question": "What is a linear SVM"
    },
    {
      "answer": "Unsupervised learning is the Holy Grail of Deep Learning. The goal of unsupervised learning is to create general systems that can be trained with little data.  Today Deep Learning models are trained on large supervised datasets. Meaning that for each data, there is a corresponding label.",
      "question": "Can deep learning be unsupervised"
    },
    {
      "answer": "1:1111:18Suggested clip \u00b7 91 secondsLimits of Functions of Two Variables - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the limit of a function with two variables"
    },
    {
      "answer": "Text classification using word embeddings and deep learning in python \u2014 classifying tweets from twitterSplit the data into text (X) and labels (Y)Preprocess X.Create a word embedding matrix from X.Create a tensor input from X.Train a deep learning model using the tensor inputs and labels (Y)More items\u2022",
      "question": "How do I use Word embeds for text classification"
    },
    {
      "answer": "Gaussian Distribution Function The nature of the gaussian gives a probability of 0.683 of being within one standard deviation of the mean. The mean value is a=np where n is the number of events and p the probability of any integer value of x (this expression carries over from the binomial distribution ).",
      "question": "What is the mean of a Gaussian distribution"
    },
    {
      "answer": "Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.",
      "question": "What is dimensional analysis and how do we use it"
    },
    {
      "answer": "Just so, the Poisson distribution deals with the number of occurrences in a fixed period of time, and the exponential distribution deals with the time between occurrences of successive events as time flows by continuously.",
      "question": "What is the relationship between Poisson and exponential distribution"
    },
    {
      "answer": "Regression analysis is used when you want to predict a continuous dependent variable from a number of independent variables. If the dependent variable is dichotomous, then logistic regression should be used.",
      "question": "Which method is used for predicting continuous dependent variable"
    },
    {
      "answer": "The second derivative may be used to determine local extrema of a function under certain conditions. If a function has a critical point for which f\u2032(x) = 0 and the second derivative is positive at this point, then f has a local minimum here.  This technique is called Second Derivative Test for Local Extrema.",
      "question": "Why do you use the second derivative test"
    },
    {
      "answer": "With cluster sampling, in contrast, the sample includes elements only from sampled clusters. Multistage sampling. With multistage sampling, we select a sample by using combinations of different sampling methods. For example, in Stage 1, we might use cluster sampling to choose clusters from a population.",
      "question": "What is the difference between cluster and multistage sampling"
    },
    {
      "answer": "In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.",
      "question": "What is minimum variance of an estimator"
    },
    {
      "answer": "Do not confuse statistical significance with practical importance.  However, a weak correlation can be statistically significant, if the sample size is large enough.",
      "question": "Can a weak correlation be significant"
    },
    {
      "answer": "In active learning teachers are facilitators rather than one way providers of information.  Other examples of active learning techniques include role-playing, case studies, group projects, think-pair-share, peer teaching, debates, Just-in-Time Teaching, and short demonstrations followed by class discussion.",
      "question": "What is an example of active learning"
    },
    {
      "answer": "Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.  Thus, attempting to make the model conform too closely to slightly inaccurate data can infect the model with substantial errors and reduce its predictive power.",
      "question": "What is meant by Overfitting of data"
    },
    {
      "answer": "ELIZA is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum.  As such, ELIZA was one of the first chatterbots and one of the first programs capable of attempting the Turing test.",
      "question": "What is Eliza in artificial intelligence"
    },
    {
      "answer": "The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image. It finds the direction of the largest increase from light to dark and the rate of change in that direction.",
      "question": "How do Sobel filters work"
    },
    {
      "answer": "A term-document matrix represents the processed text from a text analysis as a table or matrix where the rows represent the text responses, or documents, and the columns represent the words or phrases (the terms).  matrix).",
      "question": "What is text Matrix"
    },
    {
      "answer": "Non-probability sampling is often used because the procedures used to select units for inclusion in a sample are much easier, quicker and cheaper when compared with probability sampling. This is especially the case for convenience sampling.",
      "question": "Why do we use non probability sampling"
    },
    {
      "answer": "R is now used by over 50% of data miners. R, Python, and SQL were the most popular programming languages. Python, Lisp/Clojure, and Unix tools showest the highest growth in 2012, while Java and MATLAB slightly declined in popularity.",
      "question": "What language is used for data mining"
    },
    {
      "answer": "A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts. Stress and strain are both tensor quantities.  A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts.",
      "question": "What is tensor quantity"
    },
    {
      "answer": "Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression.",
      "question": "Is stochastic gradient descent linear"
    },
    {
      "answer": "The CAC ratio is calculated by looking at the quarter over quarter increase in gross margin divided by the total sales and marketing expenses for that quarter. Gross margin is the total revenue minus cost of goods sold.",
      "question": "How is CAC ratio calculated"
    },
    {
      "answer": "The experts predict that AI will outperform humans in the next 10 years in tasks such as translating languages (by 2024), writing high school essays (by 2026), and driving trucks (by 2027). But many other tasks will take much longer for machines to master.",
      "question": "Will artificial intelligence supersede human intelligence"
    },
    {
      "answer": "Whereas AI is preprogrammed to carry out a task that a human can but more efficiently, artificial general intelligence (AGI) expects the machine to be just as smart as a human.  A machine that was able to do this would be considered a fine example of AGI.",
      "question": "What is the difference between general artificial intelligence and artificial intelligence"
    },
    {
      "answer": "Any point directly on the y-axis has an X value of 0. Multiple Choice: In a simple Linear regression problem, r and b1. Explanation: r= correlation coefficient and b1= slope. If we have a downward sloping trend-line then that means we have a negative (or inverse) correlation coefficient.",
      "question": "What is the relationship between the linear correlation coefficient r and the slope b 1 of a regression line"
    },
    {
      "answer": "The name tells you how to calculate it. You subtract the regression-predicted values from the actual values, square them (to get rid of directionality), take their average, then take the square root of the average.",
      "question": "How do you evaluate the accuracy of a regression result"
    },
    {
      "answer": "Gradient Descent is the process of minimizing a function by following the gradients of the cost function. This involves knowing the form of the cost as well as the derivative so that from a given point you know the gradient and can move in that direction, e.g. downhill towards the minimum value.",
      "question": "What is gradient descent in logistic regression"
    },
    {
      "answer": "Poisson Formula. Suppose we conduct a Poisson experiment, in which the average number of successes within a given region is \u03bc. Then, the Poisson probability is: P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828.",
      "question": "How do you find the probability of a Poisson distribution"
    },
    {
      "answer": "Advantages of distributed representations Mapping efficiency: a micro-feature-based distributed representation often allows a simple mapping (that uses few connections or weights) to solve a task. For example, suppose we wish to classify 100 different colored shapes as to whether or not they are yellow.",
      "question": "What are the advantages of distributed representations"
    },
    {
      "answer": "As Justin Rising points out, the order statistics are clearly not independent of each other. . If the observations are independent and identically distributed from a continuous distribution, then any ordering of the samples is equally likely.",
      "question": "Are the order statistics independent"
    },
    {
      "answer": "The value to be gained from taking a decision. Net gain is calculated by adding together the expected value of each outcome and deducting the costs associated with the decision.",
      "question": "How do you calculate decision trees"
    },
    {
      "answer": "How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "How can Multicollinearity be reduced"
    },
    {
      "answer": "Each party in a dispute recognises that its own use of the concept is contested by those of other parties. To use an essentially contested concept means to use it against other users. To use such a concept means to use it aggresssively and defensively.",
      "question": "What is contested concept"
    },
    {
      "answer": "Use. Cluster sampling is typically used in market research. It's used when a researcher can't get information about the population as a whole, but they can get information about the clusters.  Cluster sampling is often more economical or more practical than stratified sampling or simple random sampling.",
      "question": "Why do we use cluster sampling"
    },
    {
      "answer": "0:082:33Suggested clip \u00b7 117 secondsHistogram Finding Frequency - Corbettmaths - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you read a relative frequency density histogram"
    },
    {
      "answer": "It is linear if there exists a function H(x) = \u03b20 + \u03b2T x such that h(x) = I(H(x) > 0). H(x) is also called a linear discriminant function. The decision boundary is therefore defined as the set {x \u2208 Rd : H(x)=0}, which corresponds to a (d \u2212 1)-dimensional hyperplane within the d-dimensional input space X.",
      "question": "What are the decision boundaries for linear discriminant analysis"
    },
    {
      "answer": "A good knowledge representation system must have properties such as: Representational Accuracy: It should represent all kinds of required knowledge. Inferential Adequacy: It should be able to manipulate the representational structures to produce new knowledge corresponding to the existing structure.",
      "question": "What are the properties of good knowledge representation techniques"
    },
    {
      "answer": "The example of reinforcement learning is your cat is an agent that is exposed to the environment. The biggest characteristic of this method is that there is no supervisor, only a real number or reward signal. Two types of reinforcement learning are 1) Positive 2) Negative.",
      "question": "What is reinforcement learning example"
    },
    {
      "answer": "Unsupervised Learning is the second type of machine learning, in which unlabeled data are used to train the algorithm, which means it used against data that has no historical labels.",
      "question": "What category of machine learning algorithm finds patterns in the data when the data is not labeled"
    },
    {
      "answer": "Convolutional Neural Networks (CNNs) is the most popular neural network model being used for image classification problem. The big idea behind CNNs is that a local understanding of an image is good enough.",
      "question": "What type of deep learning models are best suited for image recognition"
    },
    {
      "answer": "Pre-Interview PreparationDevelop a deep knowledge of data structures. You should understand and be able to talk about different data structures and their strengths, weaknesses, and how they compare to each other.  Understand Big O notation.  Know the major sorting algorithms.",
      "question": "How do I start preparing for data structures and algorithms"
    },
    {
      "answer": "The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.",
      "question": "Why do we use sigmoid function"
    },
    {
      "answer": "Streaming Data is data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously, and in small sizes (order of Kilobytes).",
      "question": "What does streaming data mean"
    },
    {
      "answer": "- Mode-The most repetitive number! - Median:The number in the MIDDLE when they are IN ORDER! - Mean- The AVERAGE OF ALL NUMBERS: You add up all the numbers then you divide it by the TOTAL NUMBER of NUMBERS! - Range - THE BIGGEST minus the Smallest!",
      "question": "What is the purpose of mean median mode and range"
    },
    {
      "answer": "The standard deviation of the sample mean \u02c9X that we have just computed is the standard deviation of the population divided by the square root of the sample size: \u221a10=\u221a20/\u221a2.",
      "question": "What is the formula for the standard deviation of the sampling distribution of the sample mean X"
    },
    {
      "answer": "Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B. {/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B\u2014but one event doesn't necessarily cause the other event to happen.",
      "question": "How do you tell the difference between correlation and causation"
    },
    {
      "answer": "Categories with a large difference between observed and expected values make a larger contribution to the overall chi-square statistic. In these results, the contribution values from each category sum to the overall chi-square statistic, which is 0.65.",
      "question": "What is the contribution to the chi square statistic"
    },
    {
      "answer": "A statistical hypothesis is a formal claim about a state of nature structured within the framework of a statistical model. For example, one could claim that the median time to failure from (acce]erated) electromigration of the chip population described in Section 6.1.",
      "question": "What is a statistical hypothesis example"
    },
    {
      "answer": "In this blog we will learn what is calibration and why and when we should use it. We calibrate our model when the probability estimate of a data point belonging to a class is very important. Calibration is comparison of the actual output and the expected output given by a system.",
      "question": "Why do we need calibration in machine learning"
    },
    {
      "answer": "Standard deviation (represented by the symbol sigma, \u03c3 ) shows how much variation or dispersion exists from the average (mean), or expected value. More precisely, it is a measure of the average distance between the values of the data in the set and the mean.",
      "question": "How do you explain standard deviation in statistics"
    },
    {
      "answer": "So the difference is in the way the future reward is found. In Q-learning it's simply the highest possible action that can be taken from state 2, and in SARSA it's the value of the actual action that was taken.",
      "question": "What is the difference between Q learning and Sarsa"
    },
    {
      "answer": "Fixed effects are variables that are constant across individuals; these variables, like age, sex, or ethnicity, don't change or change at a constant rate over time. They have fixed effects; in other words, any change they cause to an individual is the same.",
      "question": "What does fixed effect mean in statistics"
    },
    {
      "answer": "The number of outcomes in non-overlapping intervals are independent.   The probability of two or more outcomes in a sufficiently short interval is virtually zero.   The probability of exactly one outcome in a sufficiently short interval or small region is proportional to the length of the interval or region.",
      "question": "How do I know if my data is Poisson distributed"
    },
    {
      "answer": "A Bayesian network (also known as a Bayes network, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG).  Efficient algorithms can perform inference and learning in Bayesian networks.",
      "question": "What does Bayesian networks mean in Machine Learning"
    },
    {
      "answer": "Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.",
      "question": "What is validation in machine learning"
    },
    {
      "answer": "Edge detection is an image processing technique for finding the boundaries of objects within images. It works by detecting discontinuities in brightness. Edge detection is used for image segmentation and data extraction in areas such as image processing, computer vision, and machine vision.",
      "question": "Why do we need edge detection"
    },
    {
      "answer": "Using P values and Significance Levels Together If your P value is less than or equal to your alpha level, reject the null hypothesis. The P value results are consistent with our graphical representation. The P value of 0.03112 is significant at the alpha level of 0.05 but not 0.01.",
      "question": "Is the P value the same as Alpha"
    },
    {
      "answer": "A GLM is absolutely a statistical model, but statistical models and machine learning techniques are not mutually exclusive. In general, statistics is more concerned with inferring parameters, whereas in machine learning, prediction is the ultimate goal.",
      "question": "Are generalized linear models statistical methods or machine learning methods"
    },
    {
      "answer": "We input the data in the learning algorithm as a set of inputs, which is called as Features, denoted by X along with the corresponding outputs, which is indicated by Y, and the algorithm learns by comparing its actual production with correct outputs to find errors. It then modifies the model accordingly.",
      "question": "What data would be used as input to the machine learning algorithms"
    },
    {
      "answer": "Kappa is widely used on Twitch in chats to signal you are being sarcastic or ironic, are trolling, or otherwise playing around with someone. It is usually typed at the end of a string of text, but, as can often the case on Twitch, it is also often used on its own or repeatedly (to spam someone).",
      "question": "What is Kappa used for"
    },
    {
      "answer": "When q-learning is performed we create what's called a q-table or matrix that follows the shape of [state, action] and we initialize our values to zero. We then update and store our q-values after an episode. This q-table becomes a reference table for our agent to select the best action based on the q-value.",
      "question": "What does the Q table in Q learning algorithm represent"
    },
    {
      "answer": "A commonly used rule says that a data point is an outlier if it is more than 1.5 \u22c5 IQR 1.5\\cdot \\text{IQR} 1. 5\u22c5IQR1, point, 5, dot, start text, I, Q, R, end text above the third quartile or below the first quartile.",
      "question": "How do you determine if there are outliers in a data set"
    },
    {
      "answer": "Randomization as a method of experimental control has been extensively used in human clinical trials and other biological experiments. It prevents the selection bias and insures against the accidental bias. It produces the comparable groups and eliminates the source of bias in treatment assignments.",
      "question": "Why is it important to randomise participants in a study"
    },
    {
      "answer": "Two-sample t-test is used when the data of two samples are statistically independent, while the paired t-test is used when data is in the form of matched pairs.  To use the two-sample t-test, we need to assume that the data from both samples are normally distributed and they have the same variances.",
      "question": "What is the difference between at test and a paired t test"
    },
    {
      "answer": "The formula to calculate the test statistic comparing two population means is, Z= ( x - y )/\u221a(\u03c3x2/n1 + \u03c3y2/n2). In order to calculate the statistic, we must calculate the sample means ( x and y ) and sample standard deviations (\u03c3x and \u03c3y) for each sample separately. n1 and n2 represent the two sample sizes.",
      "question": "How do you find the test statistic"
    },
    {
      "answer": "One reason you should consider when using ReLUs is, that they can produce dead neurons. That means that under certain circumstances your network can produce regions in which the network won't update, and the output is always 0.",
      "question": "Why is ReLu used in hidden layers"
    },
    {
      "answer": "The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the \u201cerrors\u201d) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences.",
      "question": "How do you interpret mean square error"
    },
    {
      "answer": "'Learning to learn' is the ability to pursue and persist in learning, to organise one's own learning, including through effective management of time and information, both individually and in groups.",
      "question": "What is the meaning of learning to learn"
    },
    {
      "answer": "Back-propagation is the process of calculating the derivatives and gradient descent is the process of descending through the gradient, i.e. adjusting the parameters of the model to go down through the loss function.",
      "question": "What is the difference between Backpropagation and gradient descent"
    },
    {
      "answer": "To measure the relationship between numeric variable and categorical variable with > 2 levels you should use eta correlation (square root of the R2 of the multifactorial regression). If the categorical variable has 2 levels, point-biserial correlation is used (equivalent to the Pearson correlation).",
      "question": "How do you find the correlation between categorical variables"
    },
    {
      "answer": "A Z-score is a score which indicates how many standard deviations an observation is from the mean of the distribution. Z-scores tend to be used mainly in the context of the normal curve, and their interpretation based on the standard normal table.  Non-normal distributions can also be transformed into sets of Z-scores.",
      "question": "Can z score be used for non normal distribution"
    },
    {
      "answer": "A normal distribution is determined by two parameters the mean and the variance.  Now the standard normal distribution is a specific distribution with mean 0 and variance 1. This is the distribution that is used to construct tables of the normal distribution.",
      "question": "What is the difference between a normal distribution and a standard normal distribution"
    },
    {
      "answer": "The standard error of estimate, Se indicates approximately how much error you make when you use the predicted value for Y (on the least-squares line) instead of the actual value of Y.",
      "question": "What does the standard error of the estimate represent"
    },
    {
      "answer": "The component form of simple exponential smoothing is given by: Forecast equation^yt+h|t=\u2113tSmoothing equation\u2113t=\u03b1yt+(1\u2212\u03b1)\u2113t\u22121, Forecast equation y ^ t + h | t = \u2113 t Smoothing equation \u2113 t = \u03b1 y t + ( 1 \u2212 \u03b1 ) \u2113 t \u2212 1 , where \u2113t is the level (or the smoothed value) of the series at time t .",
      "question": "What is the exponential smoothing formula"
    },
    {
      "answer": "The Agglomerative Hierarchical Clustering is the most common type of hierarchical clustering used to group objects in clusters based on their similarity.",
      "question": "Which type of hierarchical clustering algorithm is more commonly used"
    },
    {
      "answer": "The reasoning is the mental process of deriving logical conclusion and making predictions from available knowledge, facts, and beliefs.  In artificial intelligence, the reasoning is essential so that the machine can also think rationally as a human brain, and can perform like a human.",
      "question": "What is reasoning in artificial intelligence"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "What are the uses of eigenvalues"
    },
    {
      "answer": "The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.  The learning rate may be the most important hyperparameter when configuring your neural network.",
      "question": "What is learning rate in CNN"
    },
    {
      "answer": "The most intuitive way to increase the frequency resolution of an FFT is to increase the size while keeping the sampling frequency constant. Doing this will increase the number of frequency bins that are created, decreasing the frequency difference between each.",
      "question": "How can frequency resolution be improved"
    },
    {
      "answer": "The \"Linear-by-Linear\" test is for ordinal (ordered) categories and assumes equal and ordered intervals. The Linear-by-Linear Association test is a test for trends in a larger-than-2x2 table. Its value is shown to be significant and indicates that income tends to rise with values of \"male\" (i.e., from 0 to 1).",
      "question": "What is linear by linear association chi square test"
    },
    {
      "answer": "In logistic regression, as with any flavour of regression, it is fine, indeed usually better, to have continuous predictors. Given a choice between a continuous variable as a predictor and categorising a continuous variable for predictors, the first is usually to be preferred.",
      "question": "Can you use continuous variables in logistic regression"
    },
    {
      "answer": "From the menus of SPSS choose: Analyze Scale Multidimensional Scaling\u2026 In Distances, select either Data are distances or Create distances from data. If your data are distances, you must select at least four numeric variables for analysis, and you can click Shape to indicate the shape of the distance matrix.",
      "question": "How do you do multidimensional scaling in SPSS"
    },
    {
      "answer": "A local minimum of a function (typically a cost function in machine learning, which is something we want to minimize based on empirical data) is a point in the domain of a function that has the following property: the function evaluates to a greater value at every other point in a neighborhood around the local minimum",
      "question": "What is local minima in machine learning"
    },
    {
      "answer": "There are four types of classification. They are Geographical classification, Chronological classification, Qualitative classification, Quantitative classification.",
      "question": "What are the types of classification in statistics"
    },
    {
      "answer": "TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf. data. Datasets , enabling easy-to-use and high-performance input pipelines. To get started see the guide and our list of datasets.",
      "question": "What is dataset in TensorFlow"
    },
    {
      "answer": "Eigenvectors are a special set of vectors associated with a linear system of equations (i.e., a matrix equation) that are sometimes also known as characteristic vectors, proper vectors, or latent vectors (Marcus and Minc 1988, p.  Each eigenvector is paired with a corresponding so-called eigenvalue.",
      "question": "What are eigenvectors of a matrix"
    },
    {
      "answer": "The standard deviation is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance.  If the data points are further from the mean, there is a higher deviation within the data set; thus, the more spread out the data, the higher the standard deviation.",
      "question": "What mean standard deviation"
    },
    {
      "answer": "The (statistical) design of experiments (DOE) is an efficient procedure for planning experiments so that the data obtained can be analyzed to yield valid and objective conclusions. DOE begins with determining the objectives of an experiment and selecting the process factors for the study.",
      "question": "What is statistical design of experiments"
    },
    {
      "answer": "With the LassoCV, RidgeCV, and Linear Regression machine learning algorithms.Define the problem.Gather the data.Clean & Explore the data.Model the data.Evaluate the model.Answer the problem.",
      "question": "How do you predict using machine learning"
    },
    {
      "answer": "Bootstrapping is a type of resampling where large numbers of smaller samples of the same size are repeatedly drawn, with replacement, from a single original sample. For example, let's say your sample was made up of ten numbers: 49, 34, 21, 18, 10, 8, 6, 5, 2, 1. You randomly draw three numbers 5, 1, and 49.",
      "question": "What is an example of bootstrapping"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.",
      "question": "What is the difference between mean and standard deviation"
    },
    {
      "answer": "A simple definition of a sampling frame is the set of source materials from which the sample is selected. The definition also encompasses the purpose of sampling frames, which is to provide a means for choosing the particular members of the target population that are to be interviewed in the survey.",
      "question": "What is the purpose of sampling frame"
    },
    {
      "answer": "A statistic is a characteristic of a sample. Generally, a statistic is used to estimate the value of a population parameter. For instance, suppose we selected a random sample of 100 students from a school with 1000 students. The average height of the sampled students would be an example of a statistic.",
      "question": "What is an example of a statistic in the study"
    },
    {
      "answer": "A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.",
      "question": "What is a random variable in probability theory"
    },
    {
      "answer": "(When does a random variable have a Poisson YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the Poisson distribution"
    },
    {
      "answer": "Bayesian networks are a type of Probabilistic Graphical Model that can be used to build models from data and/or expert opinion. They can be used for a wide range of tasks including prediction, anomaly detection, diagnostics, automated insight, reasoning, time series prediction and decision making under uncertainty.",
      "question": "How the Bayesian network can be used"
    },
    {
      "answer": "A common pattern is the bell-shaped curve known as the \"normal distribution.\" In a normal or \"typical\" distribution, points are as likely to occur on one side of the average as on the other. Note that other distributions look similar to the normal distribution.",
      "question": "What is a normal distribution in a histogram"
    },
    {
      "answer": "3.1 Comparison MatrixClassification AlgorithmsAccuracyF1-ScoreNa\u00efve Bayes80.11%0.6005Stochastic Gradient Descent82.20%0.5780K-Nearest Neighbours83.56%0.5924Decision Tree84.23%0.63083 more rows\u2022",
      "question": "Which algorithm is best for classification"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "Which is better supervised or unsupervised learning"
    },
    {
      "answer": "Listen to pronunciation. (NOR-mul raynj) In medicine, a set of values that a doctor uses to interpret a patient's test results. The normal range for a given test is based on the results that are seen in 95% of the healthy population.",
      "question": "What does normal range mean"
    },
    {
      "answer": "Now, three variable case it is less clear for me. An intuitive definition for covariance function would be Cov(X,Y,Z)=E[(x\u2212E[X])(y\u2212E[Y])(z\u2212E[Z])], but instead the literature suggests using covariance matrix that is defined as two variable covariance for each pair of variables.",
      "question": "How do you find the covariance of three variables"
    },
    {
      "answer": "The simplest example of a non-linear operator (non-linear functional) is a real-valued function of a real argument other than a linear function.  Under other restrictions on K(t,s,u) an Urysohn operator acts on other spaces, for instance, L2[a,b] or maps one Orlicz space LM1[a,b] into another LM2[a,b].",
      "question": "Which is not a linear operator"
    },
    {
      "answer": "A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.",
      "question": "What is random variables in probability"
    },
    {
      "answer": "Multiple regression estimates how the changes in each predictor variable relate to changes in the response variable.  What does it mean to control for the variables in the model? It means that when you look at the effect of one variable in the model, you are holding constant all of the other predictors in the model.",
      "question": "What does it mean to control for a variable in multiple regression"
    },
    {
      "answer": "In a Data Mining sense, the similarity measure is a distance with dimensions describing object features. That means if the distance among two data points is small then there is a high degree of similarity among the objects and vice versa. The similarity is subjective and depends heavily on the context and application.",
      "question": "What are the measures of similarity in data mining"
    },
    {
      "answer": "Here is step by step on how to compute K-nearest neighbors KNN algorithm:Determine parameter K = number of nearest neighbors.Calculate the distance between the query-instance and all the training samples.Sort the distance and determine nearest neighbors based on the K-th minimum distance.More items",
      "question": "How is KNN algorithm calculated"
    },
    {
      "answer": "2:194:05Suggested clip \u00b7 97 secondsChoosing Intervals for a Histogram - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you determine the intervals for a histogram"
    },
    {
      "answer": "Automatic thresholding Select initial threshold value, typically the mean 8-bit value of the original image. Divide the original image into two portions; Pixel values that are less than or equal to the threshold; background. Pixel values greater than the threshold; foreground.",
      "question": "How is the threshold value calculated in image processing"
    },
    {
      "answer": "Since both drifts involve a statistical change in the data, the best approach to detect them is by monitoring its statistical properties, the model's predictions, and their correlation with other factors.",
      "question": "How do you detect data Drifting"
    },
    {
      "answer": "The process of adjusting the weights and threshold of the ADALINE network is based on a learning algorithm named the Delta rule (Widrow and Hoff 1960) or Widrow-Hoff learning rule, also known as LMS (Least Mean Square ) algorithm or Gradient Descent method.",
      "question": "What is the delta rule of Adaline network"
    },
    {
      "answer": "It's a cost function that is used as loss for machine learning models, telling us how bad it's performing, the lower the better. Also it's much easier to reason about the loss this way, to be consistent with the rule of loss functions approaching 0 as the model gets better.",
      "question": "Why do we use negative log likelihood"
    },
    {
      "answer": "The learning algorithm of the Hopfield network is unsupervised, meaning that there is no \u201cteacher\u201d telling the network what is the correct output for a certain input.",
      "question": "Is Hopfield network supervised or unsupervised"
    },
    {
      "answer": "Recall is the number of relevant documents retrieved by a search divided by the total number of existing relevant documents, while precision is the number of relevant documents retrieved by a search divided by the total number of documents retrieved by that search.",
      "question": "What is the difference between precision and recall"
    },
    {
      "answer": "So that we only have to have one area table, rather than an infinite number of area tables. Of course, technology can find area under any normal curve and so tables of values are a bit archaic.",
      "question": "Why do we Standardise normal distribution"
    },
    {
      "answer": "When working with a measurement variable, the Kruskal\u2013Wallis test starts by substituting the rank in the overall data set for each measurement value. The smallest value gets a rank of 1, the second-smallest gets a rank of 2, etc.",
      "question": "How do you rank data for the Kruskal Wallis test"
    },
    {
      "answer": "The Poisson distribution is used to describe the distribution of rare events in a large population. For example, at any particular time, there is a certain probability that a particular cell within a large population of cells will acquire a mutation.",
      "question": "When should I use Poisson distribution"
    },
    {
      "answer": "In class limit, the upper extreme value of the first class interval and the lower extreme value of the next class interval will not be equal. In class boundary, the upper extreme value of the first class interval and the lower extreme value of the next class interval will be equal.",
      "question": "What is the difference between class interval and class boundary"
    },
    {
      "answer": "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.",
      "question": "What is convolutional neural network algorithm"
    },
    {
      "answer": "Multivariate ANOVA (MANOVA) extends the capabilities of analysis of variance (ANOVA) by assessing multiple dependent variables simultaneously. ANOVA statistically tests the differences between three or more group means.  This statistical procedure tests multiple dependent variables at the same time.",
      "question": "Is Anova Multivariate analysis"
    },
    {
      "answer": "A frequent problem in estimating logistic regression models is a failure of the likelihood maximization algorithm to converge. In most cases, this failure is a consequence of data patterns known as complete or quasi-complete separation.  Log-likelihood as a function of the slope, quasi-complete separation.",
      "question": "Is logistic regression guaranteed to converge"
    },
    {
      "answer": "Group projects, discussions, and writing are examples of active learning, because they involve doing something.",
      "question": "Which of the following are examples of active learning"
    },
    {
      "answer": "As a hypothetical example of systematic sampling, assume that in a population of 10,000 people, a statistician selects every 100th person for sampling. The sampling intervals can also be systematic, such as choosing a new sample to draw from every 12 hours.",
      "question": "What is systematic sampling example"
    },
    {
      "answer": "Mathematically speaking, the regret is expressed as the difference between the payoff (reward or return) of a possible action and the payoff of the action that has been actually taken. If we denote the payoff function as u the formula becomes: regret = u(possible action) - u(action taken)",
      "question": "What is regret in reinforcement learning"
    },
    {
      "answer": "Classification/Recognition: Given an image with an object , find out what that object is.  In other words, classify it in a class from a set of predefined categories. Localization : Find where the object is and draw a bounding box around it.",
      "question": "What is localization in deep learning"
    },
    {
      "answer": "Definition. Data Partitioning is the technique of distributing data across multiple tables, disks, or sites in order to improve query processing performance or increase database manageability.",
      "question": "What is partitioning of data"
    },
    {
      "answer": "Definition: Gamma distribution is a distribution that arises naturally in processes for which the waiting times between events are relevant. It can be thought of as a waiting time between Poisson distributed events.",
      "question": "What does gamma distribution mean"
    },
    {
      "answer": "Partial least squares regression (PLS regression) is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the",
      "question": "What is PLS in statistics"
    },
    {
      "answer": "Writing up resultsFirst, present descriptive statistics in a table.  Organize your results in a table (see Table 3) stating your dependent variable (dependent variable = YES) and state that these are \"logistic regression results.\"  When describing the statistics in the tables, point out the highlights for the reader.More items",
      "question": "How do you write logistic regression results"
    },
    {
      "answer": "A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.",
      "question": "What is a probability distribution in statistics"
    },
    {
      "answer": "The sample variance is an estimator for the population variance. When applied to sample data, the population variance formula is a biased estimator of the population variance: it tends to underestimate the amount of variability.  We are using one fitted value (sample mean) in our estimate of the variance.",
      "question": "Why is the formula of sample variance different from population variance"
    },
    {
      "answer": "Correlation measures linearity between X and Y. If \u03c1(X,Y) = 0 we say that X and Y are \u201cuncorrelated.\u201d If two variables are independent, then their correlation will be 0. However, like with covariance.",
      "question": "What is the correlation between two independent random variables"
    },
    {
      "answer": "Detection theory or signal detection theory is a means to measure the ability to differentiate between information-bearing patterns (called stimulus in living organisms, signal in machines) and random patterns that distract from the information (called noise, consisting of background stimuli and random activity of the",
      "question": "What is noise in signal detection theory"
    },
    {
      "answer": "A histogram shows bars representing numerical values by range of value. A bar chart shows categories, not numbers, with bars indicating the amount of each category. Histogram example: student's ages, with a bar showing the number of students in each year.",
      "question": "What can you tell from a histogram"
    },
    {
      "answer": "Discrete random variables can only take on values from a countable set of numbers such as the integers or some subset of integers. (Usually, they can't be fractions.)",
      "question": "Can a discrete variable take any fractional value"
    },
    {
      "answer": "Softmax Thus sigmoid is widely used for binary classification problems. While building a network for a multiclass problem, the output layer would have as many neurons as the number of classes in the target. For instance if you have three classes, there would be three neurons in the output layer.",
      "question": "Which activation function is used for binary classification"
    },
    {
      "answer": "Best Image Processing Projects CollectionLicense plate recognition.Face Emotion recognition.Face recognition.Cancer detection.Object detection.Pedestrian detection.Lane detection for ADAS.Blind assistance systems.More items",
      "question": "Whatt are best image processing ideas"
    },
    {
      "answer": "A single object of the world from which a model will be learned, or on which a model will be used (e.g., for prediction). In most machine learning work, instances are described by feature vectors; some work uses more complex representations (e.g., containing relations between instances or between parts of instances).",
      "question": "What is an instance in machine learning"
    },
    {
      "answer": "First multiply the critical value by the standard deviation. Then divide this result by the error from Step 1. Now square this result. This result is the sample size.",
      "question": "How do you find the sample size when given the mean and standard deviation"
    },
    {
      "answer": "The coefficient of determination is a measurement used to explain how much variability of one factor can be caused by its relationship to another related factor. This correlation, known as the \"goodness of fit,\" is represented as a value between 0.0 and 1.0.",
      "question": "What does the coefficient of determination tell you"
    },
    {
      "answer": "Box plots divide the data into sections that each contain approximately 25% of the data in that set. Box plots are useful as they provide a visual summary of the data enabling researchers to quickly identify mean values, the dispersion of the data set, and signs of skewness.",
      "question": "What is the point of a box plot"
    },
    {
      "answer": "The general idea is that machine learning, while not always the perfect choice, can be powerful in modeling time series data due to its ability to handle non-linear data. The feature engineering applied to the time series data in a machine learning approach is the key to how successful the model will be.",
      "question": "Data Science Can machine learning be used for time series analysis"
    },
    {
      "answer": "Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them. Bivariate analysis can be helpful in testing simple hypotheses of association.",
      "question": "What is the use of bivariate analysis"
    },
    {
      "answer": "Model specification refers to the determination of which independent variables should be included in or excluded from a regression equation.  A multiple regression model is, in fact, a theoretical statement about the causal relationship between one or more independent variables and a dependent variable.",
      "question": "What is a model in regression analysis"
    },
    {
      "answer": "The steps in grouping may be summarized as follows:Decide on the number of classes.Determine the range, i.e., the difference between the highest and lowest observations in the data.Divide range by the number of classes to estimate approximate size of the interval (h).More items",
      "question": "How do you find the class interval in a frequency table"
    },
    {
      "answer": "A joint probability distribution shows a probability distribution for two (or more) random variables. Instead of events being labeled A and B, the norm is to use X and Y. The formal definition is: f(x,y) = P(X = x, Y = y) The whole point of the joint distribution is to look for a relationship between two variables.",
      "question": "What is joint distribution in statistics"
    },
    {
      "answer": "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed.  Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.",
      "question": "Why is the word deep used in deep learning"
    },
    {
      "answer": "How Change Detection WorksDeveloper updates the data model, e.g. by updating a component binding.Angular detects the change.Change detection checks every component in the component tree from top to bottom to see if the corresponding model has changed.If there is a new value, it will update the component's view (DOM)",
      "question": "How does change detection work in angular"
    },
    {
      "answer": "MLP usually means many layers and can be supervised with labels. RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).  RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).",
      "question": "Whats the difference between Multilayer Perceptron and Restricted Boltzmann Machine"
    },
    {
      "answer": "Poisson Formula. P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to \u03bc . The variance is also equal to \u03bc .",
      "question": "What is mean in Poisson distribution"
    },
    {
      "answer": "Vectors have many real-life applications, including situations involving force or velocity. For example, consider the forces acting on a boat crossing a river. The boat's motor generates a force in one direction, and the current of the river generates a force in another direction. Both forces are vectors.",
      "question": "What are some applications of vectors in real life"
    },
    {
      "answer": "Data quality is important when applying Artificial Intelligence techniques, because the results of these solutions will be as good or bad as the quality of the data used.  The algorithms that feed systems based on Artificial Intelligence can only assume that the data to be analyzed are reliable.",
      "question": "Why is data important in AI"
    },
    {
      "answer": "The number of input variables or features for a dataset is referred to as its dimensionality.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.",
      "question": "What is Dimension machine learning"
    },
    {
      "answer": "The Real World is a term by the redpills to refer to reality, the true physical world and life outside the Matrix.",
      "question": "What is the real world in the Matrix"
    },
    {
      "answer": "Weights and biases (commonly referred to as w and b) are the learnable parameters of a machine learning model.  When the inputs are transmitted between neurons, the weights are applied to the inputs along with the bias. A neuron. Weights control the signal (or the strength of the connection) between two neurons.",
      "question": "What is a weight in machine learning"
    },
    {
      "answer": "First, let's review how to calculate the population standard deviation:Calculate the mean (simple average of the numbers).For each number: Subtract the mean. Square the result.Calculate the mean of those squared differences.  Take the square root of that to obtain the population standard deviation.",
      "question": "How do you find the population standard deviation"
    },
    {
      "answer": "A Convolutional Neural Networks Introduction so to speak.Step 1: Convolution Operation.  Step 1(b): ReLU Layer.  Step 2: Pooling.  Step 3: Flattening.  Step 4: Full Connection.  Step 1 - Convolution Operation.  Step 1(b): The Rectified Linear Unit (ReLU)  Step 2 - Max Pooling.More items\u2022",
      "question": "What are the steps in convolution neural network"
    },
    {
      "answer": "In computational learning theory, probably approximately correct (PAC) learning is a framework for mathematical analysis of machine learning.",
      "question": "What is PAC in machine learning"
    },
    {
      "answer": "The disadvantage of the ANOVA F-test is that if we reject the null hypothesis, we do not know which treatments can be said to be significantly different from the others, nor, if the F-test is performed at level \u03b1, can we state that the treatment pair with the greatest mean difference is significantly different at level",
      "question": "What is the limitation of the F ratio in Anova"
    },
    {
      "answer": "The difference between forward and backward chaining is: Backward chaining starts with a goal and then searches back through inference rules to find the facts that support the goal. Forward chaining starts with facts and searches forward through the rules to find a desired goal.",
      "question": "What is the difference between forward and backward chaining in artificial intelligence"
    },
    {
      "answer": "Hypothesis Testing \u2014 2-tailed testSpecify the Null(H0) and Alternate(H1) hypothesis.Choose the level of Significance(\u03b1)Find Critical Values.Find the test statistic.Draw your conclusion.",
      "question": "How do you do a two sided hypothesis test"
    },
    {
      "answer": "The basic idea behind a neural network is to simulate (copy in a simplified but reasonably faithful way) lots of densely interconnected brain cells inside a computer so you can get it to learn things, recognize patterns, and make decisions in a humanlike way.",
      "question": "How does a neural network function"
    },
    {
      "answer": "We use binary cross-entropy loss for classification models which output a probability p. The range of the sigmoid function is [0, 1] which makes it suitable for calculating probability.",
      "question": "Which loss function is used for binary classification"
    },
    {
      "answer": "The uniform distribution defines equal probability over a given range for a continuous distribution. For this reason, it is important as a reference distribution. One of the most important applications of the uniform distribution is in the generation of random numbers.",
      "question": "What is the use of uniform distribution"
    },
    {
      "answer": "Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample. Thus it gives the probability of getting r events out of n trials.",
      "question": "What is the difference between binomial and normal distribution"
    },
    {
      "answer": "Given that the range can easily be computed with information on the maximum and minimum value of the data set, users requiring only a rough indication of the data may prefer to use this indicator over more sophisticated measures of spread, like the standard deviation.",
      "question": "What are the uses of range in statistics"
    },
    {
      "answer": "Nonparametric tests are also called distribution-free tests because they don't assume that your data follow a specific distribution. You may have heard that you should use nonparametric tests when your data don't meet the assumptions of the parametric test, especially the assumption about normally distributed data.",
      "question": "When should nonparametric statistics be used"
    },
    {
      "answer": "Ground truth is a term used in statistics and machine learning that means checking the results of machine learning for accuracy against the real world. The term is borrowed from meteorology, where \"ground truth\" refers to information obtained on site.",
      "question": "What is ground truth in AI"
    },
    {
      "answer": "The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population. In the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.",
      "question": "What does the law of large numbers mean"
    },
    {
      "answer": "Stochastic vs. For example, a stochastic variable is a random variable. A stochastic process is a random process. Typically, random is used to refer to a lack of dependence between observations in a sequence. For example, the rolls of a fair die are random, so are the flips of a fair coin.",
      "question": "What is the difference between random and stochastic"
    },
    {
      "answer": "Descriptive analytics is a statistical method that is used to search and summarize historical data in order to identify patterns or meaning.",
      "question": "What are descriptive analytics"
    },
    {
      "answer": "8 Examples of Artificial IntelligenceGoogle Maps and Ride-Hailing Applications. One doesn't have to put much thought into traveling to a new destination anymore.  Face Detection and Recognition.  Text Editors or Autocorrect.  Search and Recommendation Algorithms.  Chatbots.  Digital Assistants.  Social Media.  E-Payments.",
      "question": "What are some examples of artificial intelligence"
    },
    {
      "answer": "Shift-invariance: this means that if we shift the input in time (or shift the entries in a vector) then the output is shifted by the same amount.",
      "question": "What is shift invariance in a convolutional neural network CNN"
    },
    {
      "answer": "bucketized_column. Represents discretized dense input bucketed by boundaries .",
      "question": "What do you use the TF Feature_column Bucketized_column function for"
    },
    {
      "answer": "Negative binomial regression \u2013 Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean.",
      "question": "When would you use a negative binomial distribution"
    },
    {
      "answer": "Covariance measures the directional relationship between the returns on two assets. A positive covariance means that asset returns move together while a negative covariance means they move inversely.",
      "question": "How do you explain covariance"
    },
    {
      "answer": "A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.",
      "question": "What is a sampling error in research"
    },
    {
      "answer": "The marketplace for predictive analytics software has ballooned: G2Crowd records 92 results in the category. Pricing varies substantially based on the number of users and, in some cases, amount of data, but generally starts around $1,000 per year, though it can easily scale into six figures.",
      "question": "How much does Predictive Analytics cost"
    },
    {
      "answer": "Denying the antecedent, sometimes also called inverse error or fallacy of the inverse, is a formal fallacy of inferring the inverse from the original statement. It is committed by reasoning in the form: If P, then Q. Therefore, if not P, then not Q.",
      "question": "What is denying the antecedent in relation to a propositional fallacy"
    },
    {
      "answer": "An estimate of a population parameter may be expressed in two ways: Point estimate. A point estimate of a population parameter is a single value of a statistic. For example, the sample mean x is a point estimate of the population mean \u03bc.",
      "question": "What are the methods of estimation in statistics"
    },
    {
      "answer": "4:306:35Suggested clip \u00b7 77 secondsMarginal PDF from Joint PDF - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the marginal density function"
    },
    {
      "answer": "It might take about 2-4 hours of coding and 1-2 hours of training if done in Python and Numpy (assuming sensible parameter initialization and a good set of hyperparameters). No GPU required, your old but gold CPU on a laptop will do the job. Longer training time is expected if the net is deeper than 2 hidden layers.",
      "question": "How long do neural networks take to train"
    },
    {
      "answer": "The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions. Factor analysis can be used to simplify data, such as reducing the number of variables in regression models.",
      "question": "What is the purpose of factor analysis"
    },
    {
      "answer": "Neural network regularization is a technique used to reduce the likelihood of model overfitting. There are several forms of regularization. The most common form is called L2 regularization.  L2 regularization tries to reduce the possibility of overfitting by keeping the values of the weights and biases small.",
      "question": "What is l2 regularization in neural networks"
    },
    {
      "answer": "An Iterator is an object that can be used to loop through collections, like ArrayList and HashSet. It is called an \"iterator\" because \"iterating\" is the technical term for looping. To use an Iterator, you must import it from the java.",
      "question": "What is the use of iterator"
    },
    {
      "answer": "Some additional simple scoring methods include:Counts. Count the number of times each word appears in a document.Frequencies. Calculate the frequency that each word appears in a document out of all the words in the document.",
      "question": "How do you calculate bag words"
    },
    {
      "answer": "LSTMs solve the problem using a unique additive gradient structure that includes direct access to the forget gate's activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process.",
      "question": "How does Lstm overcomes vanishing gradient problem"
    },
    {
      "answer": "In its simplest form, the sigmoid is a representation of time (on the horizontal axis) and activity (on the vertical axis). The wonder of this curve is that it really describes most phenomena, regardless of type.  The phenomenon experiences sharp growth. It hits a maturity phase where growth slows, and then stops.",
      "question": "What does a sigmoid curve mean"
    },
    {
      "answer": "There are two main reasons to use logarithmic scales in charts and graphs. The first is to respond to skewness towards large values; i.e., cases in which one or a few points are much larger than the bulk of the data. The second is to show percent change or multiplicative factors.",
      "question": "Why would you use a logarithmic scale"
    },
    {
      "answer": "Symmetrical distribution occurs when the values of variables occur at regular frequencies and the mean, median and mode occur at the same point. In graph form, symmetrical distribution often appears as a bell curve. If a line were drawn dissecting the middle of the graph, it would show two sides that mirror each other.",
      "question": "What is symmetric data distribution"
    },
    {
      "answer": "(i) The value of dimensionless constants cannot be determined by this method. (ii) This method cannot be applied to equations involving exponential and trigonometric functions. (iii) It cannot be applied to an equation involving more than three physical quantities.",
      "question": "What are the advantages and disadvantages of Dimensional Analysis"
    },
    {
      "answer": "Conclusion. Human intelligence revolves around adapting to the environment using a combination of several cognitive processes. The field of Artificial intelligence focuses on designing machines that can mimic human behavior. However, AI researchers are able to go as far as implementing Weak AI, but not the Strong AI.",
      "question": "What is the difference between intelligence and artificial intelligence"
    },
    {
      "answer": "To write a null hypothesis, first start by asking a question. Rephrase that question in a form that assumes no relationship between the variables. In other words, assume a treatment has no effect. Write your hypothesis in a way that reflects this.",
      "question": "How do you write a hypothesis and null hypothesis"
    },
    {
      "answer": "In simple words, stemming technique only looks at the form of the word whereas lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word.",
      "question": "What is the difference between stemming and Lemmatization"
    },
    {
      "answer": "Coefficients of linear discriminants: Shows the linear combination of predictor variables that are used to form the LDA decision rule. for example, LD1 = 0.91*Sepal.",
      "question": "What is coefficients of linear Discriminants"
    },
    {
      "answer": "The higher the number of features, the harder it gets to visualize the training set and then work on it.  Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables. It can be divided into feature selection and feature extraction.",
      "question": "How does dimensionality reduction work"
    },
    {
      "answer": "Both indices take values from zero to one. In a similarity index, a value of 1 means that the two communities you are comparing share all their species, while a value of 0 means they share none. In a dissimilarity index the interpretation is the opposite: 1 means that the communities are totally different.",
      "question": "How do you interpret Sorensen index of similarity"
    },
    {
      "answer": "In short, the problem with neural networks is that a number of parameter have to be set before any training can begin. However, there are no clear rules how to set these parameters.  By combining genetic algorithms with neural networks (GANN), the genetic algorithm is used to find these parameters.",
      "question": "Can we incorporate genetic algorithm concept to artificial neural network"
    },
    {
      "answer": "Probability distributions are a fundamental concept in statistics. They are used both on a theoretical level and a practical level. Some practical uses of probability distributions are: To calculate confidence intervals for parameters and to calculate critical regions for hypothesis tests.",
      "question": "What is the use of probability distribution"
    },
    {
      "answer": "The short answer is: Logistic regression is considered a generalized linear model because the outcome always depends on the sum of the inputs and parameters. Or in other words, the output cannot depend on the product (or quotient, etc.)",
      "question": "Is logistic regression a generalized linear model"
    },
    {
      "answer": "Statistical power, or the power of a hypothesis test is the probability that the test correctly rejects the null hypothesis. That is, the probability of a true positive result.  statistical power is the probability that a test will correctly reject a false null hypothesis.",
      "question": "What is statistical power in research"
    },
    {
      "answer": "Statistical inference involves hypothesis testing (evaluating some idea about a population using a sample) and estimation (estimating the value or potential range of values of some characteristic of the population based on that of a sample).",
      "question": "What does statistical inference take into account"
    },
    {
      "answer": "In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.  In the adaptive control literature, the learning rate is commonly referred to as gain.",
      "question": "What is meant by learning rate"
    },
    {
      "answer": "5 Ways to Avoid Being Fooled By Statistics.  Do A Little Bit of Math and apply Common Sense.  Always Look for the Source and check the authority of the source.  Question if the statistics are biased or statistically insignificant.  Question if the statistics are skewed purposely or Misinterpreted.More items\u2022",
      "question": "How can we avoid misleading statistics"
    },
    {
      "answer": "Multinomial logistic regression (often just called 'multinomial regression') is used to predict a nominal dependent variable given one or more independent variables. It is sometimes considered an extension of binomial logistic regression to allow for a dependent variable with more than two categories.",
      "question": "When would you use multinomial regression"
    },
    {
      "answer": "Getting Familiar with ML Pipelines A machine learning pipeline is used to help automate machine learning workflows. They operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated to achieve an outcome, whether positive or negative.",
      "question": "What do you think is important in a machine learning Pipeline"
    },
    {
      "answer": "In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard error.",
      "question": "Is RMSE and standard error same"
    },
    {
      "answer": "Preference learning is a subfield in machine learning, which is a classification method based on observed preference information. In the view of supervised learning, preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.",
      "question": "What is preference Learning And how is it different from machine learning"
    },
    {
      "answer": "Normalization basically means bringing all the values to once scale and there is nothing wrong using percentage but there must be a base value for normalizing the data and if you are asking about 100 as a base value and then converting everything as % it will not be equal to normalization as in normalization the base",
      "question": "What is normalized percentage"
    },
    {
      "answer": "Consider a binomial distribution with parameters (n, p). When n is large and p is small , approximate the probability using Poisson distribution. When n is large and p is close to 0.5, use normal approximation.",
      "question": "When do I approximate Binomial Distribution with Normal vs Poisson"
    },
    {
      "answer": "Which intuitively says that the probability of has to be \u201creally high\u201d. In other words, if your value is smaller than E[X], then the upper bound of it taking that value is 1 (basically sort of an uninteresting statement, since you already knew the upper bound was 1 or greater).",
      "question": "What is an intuitive explanation of Markovs inequality"
    },
    {
      "answer": "Some Disadvantages of KNNAccuracy depends on the quality of the data.With large data, the prediction stage might be slow.Sensitive to the scale of the data and irrelevant features.Require high memory \u2013 need to store all of the training data.Given that it stores all of the training, it can be computationally expensive.",
      "question": "Which of the following are the disadvantages of using Knn"
    },
    {
      "answer": "Let's GO!Step 0 : Pre-requisites. It is recommended that before jumping on to Deep Learning, you should know the basics of Machine Learning.  Step 1 : Setup your Machine.  Step 2 : A Shallow Dive.  Step 3 : Choose your own Adventure!  Step 4 : Deep Dive into Deep Learning.",
      "question": "How do you implement deep learning"
    },
    {
      "answer": "The disadvantages: Convenience samples do not produce representative results. If you need to extrapolate to the target population, convenience samples aren't going to get you there.",
      "question": "What is the problem with convenience sampling"
    },
    {
      "answer": "Techniques to reduce underfitting :Increase model complexity.Increase number of features, performing feature engineering.Remove noise from the data.Increase the number of epochs or increase the duration of training to get better results.",
      "question": "How do you prevent Underfitting in machine learning"
    },
    {
      "answer": "Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).",
      "question": "What is discrete and continuous distribution"
    },
    {
      "answer": "In regression analysis, the dependent variable is denoted Y and the independent variable is denoted X. So, in this case, Y=total cholesterol and X=BMI. When there is a single continuous dependent variable and a single independent variable, the analysis is called a simple linear regression analysis .",
      "question": "How do you find x and y variables in regression"
    },
    {
      "answer": "So standard deviation gives you more deviation than mean deviation whem there are certain data points that are too far from its mean.",
      "question": "Which is larger average deviation or standard deviation"
    },
    {
      "answer": "Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.",
      "question": "What is a gradient machine learning"
    },
    {
      "answer": "Order of training data during training a neural network matters a great deal. If you are training with a mini batch you may see large fluctuations in accuracy (and cost function) and may end up over fitting correlated portions of your mini batch.",
      "question": "Does the order of training examples within a minibatch matter when training a neural network"
    },
    {
      "answer": "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.",
      "question": "How do you calculate classification accuracy"
    },
    {
      "answer": "SVM tries to finds the \u201cbest\u201d margin (distance between the line and the support vectors) that separates the classes and this reduces the risk of error on the data, while logistic regression does not, instead it can have different decision boundaries with different weights that are near the optimal point.",
      "question": "Is SVM better than logistic regression"
    },
    {
      "answer": "An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.",
      "question": "What is Arima model used for"
    },
    {
      "answer": "In statistics, the kth order statistic of a statistical sample is equal to its kth-smallest value. Together with rank statistics, order statistics are among the most fundamental tools in non-parametric statistics and inference.",
      "question": "What is KTH in statistics"
    },
    {
      "answer": "In simple terms, deep learning is when ANNs learn from large amounts of data. Similar to how humans learn from experience, a deep learning algorithm performs a task repeatedly, each time tweaking it slightly to improve the outcome.",
      "question": "How does a deep neural network learn"
    },
    {
      "answer": "Sampling errors can be reduced by the following methods: (1) by increasing the size of the sample (2) by stratification. Increasing the size of the sample: The sampling error can be reduced by increasing the sample size. If the sample size n is equal to the population size N, then the sampling error is zero.",
      "question": "What is sampling error and how can it be reduced"
    },
    {
      "answer": "The Kruskal-Wallis H test (sometimes also called the \"one-way ANOVA on ranks\") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable.",
      "question": "What is Kruskal Wallis test used for"
    },
    {
      "answer": "3 Answers. Attempts to find an average value of AC would directly provide you the answer zero Hence, RMS values are used. They help to find the effective value of AC (voltage or current). This RMS is a mathematical quantity (used in many math fields) used to compare both alternating and direct currents (or voltage).",
      "question": "Why use root mean square instead of average"
    },
    {
      "answer": "A p-value less than 0.05 (typically \u2264 0.05) is statistically significant. It indicates strong evidence against the null hypothesis, as there is less than a 5% probability the null is correct (and the results are random). Therefore, we reject the null hypothesis, and accept the alternative hypothesis.",
      "question": "Why is the standard p value 0 05"
    },
    {
      "answer": "The most used algorithm to train neural networks is gradient descent. We'll define it later, but for now hold on to the following idea: the gradient is a numeric calculation allowing us to know how to adjust the parameters of a network in such a way that its output deviation is minimized.",
      "question": "What is a gradient in neural network"
    },
    {
      "answer": "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.",
      "question": "What is meant by supervised machine learning"
    },
    {
      "answer": "Definition: Quota sampling is a sampling methodology wherein data is collected from a homogeneous group. It involves a two-step process where two variables can be used to filter information from the population. It can easily be administered and helps in quick comparison.",
      "question": "What is meant by quota sampling"
    },
    {
      "answer": "International communication (also referred to as the study of global communication or transnational communication) is the communication practice that occurs across international borders.  International communication \"encompasses political, economic, social, cultural and military concerns\".",
      "question": "What is the meaning of international communication"
    },
    {
      "answer": "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.  In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible.",
      "question": "What is K means algorithm in machine learning"
    },
    {
      "answer": "The purpose of a neural network is to learn to recognize patterns in your data. Once the neural network has been trained on samples of your data, it can make predictions by detecting similar patterns in future data. Software that learns is truly \"Artificial Intelligence\".",
      "question": "What is the purpose of a neural network"
    },
    {
      "answer": "Object is a copy of the class. Instance is a variable that holds the memory address of the object. You can also have multiple objects of the same class and then multiple instances of each of those objects. In these cases, each object's set of instances are equivalent in value, but the instances between objects are not.",
      "question": "What is the difference between object and instance"
    },
    {
      "answer": "GAN Training Step 1 \u2014 Select a number of real images from the training set. Step 2 \u2014 Generate a number of fake images. This is done by sampling random noise vectors and creating images from them using the generator. Step 3 \u2014 Train the discriminator for one or more epochs using both fake and real images.",
      "question": "How do you create a generative adversarial network"
    },
    {
      "answer": "In implementing most of the machine learning algorithms, we represent each data point with a feature vector as the input. A vector is basically an array of numerics, or in physics, an object with magnitude and direction.",
      "question": "What is data representation in machine learning"
    },
    {
      "answer": "In other words, accuracy describes the difference between the measurement and the part's actual value, while precision describes the variation you see when you measure the same part repeatedly with the same device.",
      "question": "What is the relationship between precision and accuracy"
    },
    {
      "answer": "To find the average, add them together and divide by the number of values (10 in this case). When repeated measurements give different results, we want to know how widely spread the readings are. The spread of values tells us something about the uncertainty of a measurement.",
      "question": "How do you find the uncertainty of a measurement"
    },
    {
      "answer": "The maximum entropy principle is defined as modeling a given set of data by finding the highest entropy to satisfy the constraints of our prior knowledge.  The maximum entropy model is a conditional probability model p(y|x) that allows us to predict class labels given a set of features for a given data point.",
      "question": "What is maximum entropy model in NLP"
    },
    {
      "answer": "Now living under the identity of Scarecrow, Hide helped Koutarou Amon flee from Akihiro Kanou after he was turned into a one-eyed ghoul.",
      "question": "Did hide become a ghoul"
    },
    {
      "answer": "In Semantic networks, we can represent our knowledge in the form of graphical networks. This network consists of nodes representing objects and arcs which describe the relationship between those objects. Semantic networks can categorize the object in different forms and can also link those objects.",
      "question": "How knowledge is represented using semantic network"
    },
    {
      "answer": "For example RSA Encryption padding is randomized, ensuring that the same message encrypted multiple times looks different each time. It also avoids other weaknesses, such as encrypting the same message using different RSA keys leaking the message, or an attacker creating messages derived from some other ciphertexts.",
      "question": "What is padding in RSA encryption"
    },
    {
      "answer": "Predicting Google's Stock Price using Linear RegressionTake a value of x (say x=0)Find the corresponding value of y by putting x=0 in the equation.Store the (x,y) value pair in a table.Repeat the process once or twice or as many times as we want.Plot the points on the graph to obtain the straight line.",
      "question": "How do you use linear regression to predict stock prices"
    },
    {
      "answer": "Truncated Backpropagation Through Time (truncated BPTT) is a widespread method for learning recurrent computational graphs. Truncated BPTT keeps the computational benefits of Backpropagation Through Time (BPTT) while relieving the need for a complete backtrack through the whole data sequence at every step.",
      "question": "What is truncated Bptt"
    },
    {
      "answer": "In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.",
      "question": "What is meant by Hyperplane"
    },
    {
      "answer": "HMMs is the Hidden Markov Models library for Python. It is easy to use, general purpose library, implementing all the important submethods, needed for the training, examining and experimenting with the data models.",
      "question": "What is the best Python library for Hidden Markov Models"
    },
    {
      "answer": "For example, a p-value of 0.01 would mean there is a 1% chance of committing a Type I error. However, using a lower value for alpha means that you will be less likely to detect a true difference if one really exists (thus risking a type II error).",
      "question": "What is the relationship between the p value of a t test and the Type I and Type II errors"
    },
    {
      "answer": "It's O(V+E) because each visit to v of V must visit each e of E where |e| <= V-1. Since there are V visits to v of V then that is O(V).  So total time complexity is O(V + E).",
      "question": "Why is the complexity of DFS o v e"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is supervised and unsupervised learning explain with the examples"
    },
    {
      "answer": "Best Practices of Data CleaningSetting up a Quality Plan. RELATED BLOG.  Fill-out missing values. One of the first steps of fixing errors in your dataset is to find incomplete values and fill them out.  Removing rows with missing values.  Fixing errors in the structure.  Reducing data for proper data handling.",
      "question": "How does machine learning clean data"
    },
    {
      "answer": "In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression.  Such models are called linear models.",
      "question": "How do you explain linear regression"
    },
    {
      "answer": "Some business analysts at claim that AI is a game changer for the personal device market. By 2020, about 60 percent of personal-device technology vendors will depend on AI-enabled Cloud platforms to deliver enhanced functionality and personalized services. AI technology will deliver an \u201cemotional user experience.\u201d",
      "question": "What is the future of AI and machine learning"
    },
    {
      "answer": "Linear models, generalized linear models, and nonlinear models are examples of parametric regression models because we know the function that describes the relationship between the response and explanatory variables.  If the relationship is unknown and nonlinear, nonparametric regression models should be used.",
      "question": "Is linear regression non parametric"
    },
    {
      "answer": "Definition: Given data the maximum likelihood estimate (MLE) for the parameter p is the value of p that maximizes the likelihood P(data |p). That is, the MLE is the value of p for which the data is most likely. 100 P(55 heads|p) = ( 55 ) p55(1 \u2212 p)45.",
      "question": "How do you find the maximum likelihood estimator"
    },
    {
      "answer": "How to Find the Mean. The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count.",
      "question": "How do you find the mean in statistics"
    },
    {
      "answer": "Exponential smoothing is a way to smooth out data for presentations or to make forecasts. It's usually used for finance and economics. If you have a time series with a clear pattern, you could use moving averages \u2014 but if you don't have a clear pattern you can use exponential smoothing to forecast.",
      "question": "When would you use exponential smoothing"
    },
    {
      "answer": "Improving the PF can maximize current-carrying capacity, improve voltage to equipment, reduce power losses, and lower electric bills. The simplest way to improve power factor is to add PF correction capacitors to the electrical system. PF correction capacitors act as reactive current generators.",
      "question": "How can we control the power factor"
    },
    {
      "answer": "Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.",
      "question": "What is the difference between extrapolation and interpolation"
    },
    {
      "answer": "Machine Learning: Reinforcement Learning \u2014 Markov Decision Processes.  A mathematical representation of a complex decision making process is \u201cMarkov Decision Processes\u201d (MDP). MDP is defined by: A state S, which represents every state that one could be in, within a defined world.",
      "question": "What is MDP in machine learning"
    },
    {
      "answer": "Sample moments are those that are utilized to approximate the unknown population moments. Sample moments are calculated from the sample data. Such moments include mean, variance, skewness, and kurtosis.",
      "question": "What are sample moments"
    },
    {
      "answer": "For example, Q-learning is an off-policy learner. On-policy methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, off-policy methods evaluate or improve a policy different from that used to generate the data.11\u200f/04\u200f/2020",
      "question": "What is the difference between on policy and off policy"
    },
    {
      "answer": "In the extended Kalman filter, the state transition and observation models don't need to be linear functions of the state but may instead be differentiable functions.  These matrices can be used in the Kalman filter equations. This process essentially linearizes the non-linear function around the current estimate.",
      "question": "How does extended Kalman filter work"
    },
    {
      "answer": "The purpose of Causal Analysis and Resolution (CAR) is to identify causes of defects and other problems and take action to prevent them from occurring in the future. Introductory Notes The Causal Analysis and Resolution process area involves the following: Identifying and analyzing causes of defects and other problems.",
      "question": "What is causal analysis and resolution"
    },
    {
      "answer": "A control problem involves a system that is described by state variables.  The problem is to find a time control stratergy to make the system reach the terget state that is find conditions for application of force as a function of the control variables of the system (V,W,Th).",
      "question": "What is control problem"
    },
    {
      "answer": "You now know that: Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.",
      "question": "What is tradeoff between bias and variance"
    },
    {
      "answer": "You can reduce High variance, by reducing the number of features in the model. There are several methods available to check which features don't add much value to the model and which are of importance. Increasing the size of the training set can also help the model generalise.",
      "question": "How do you handle high variance data"
    },
    {
      "answer": "If the data is symmetrical - normally distributed - then the mean tell you where the line of symmetry falls. The standard deviation tells you more. It tells you if the data is closely distributed to the mean (small standard deviation) or is the data widely distributed (big standard deviation).",
      "question": "Why do we use standard deviation instead of mean deviation"
    },
    {
      "answer": "No, you don't have to transform your observed variables just because they don't follow a normal distribution. Linear regression analysis, which includes t-test and ANOVA, does not assume normality for either predictors (IV) or an outcome (DV). No way!  Yes, you should check normality of errors AFTER modeling.",
      "question": "Does the dependent variable need to be normally distributed in linear regression"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.",
      "question": "What is bootstrap sampling in machine learning and why is it important 1"
    },
    {
      "answer": "Each of the steps should take about 4\u20136 weeks' time. And in about 26 weeks since the time you started, and if you followed all of the above religiously, you will have a solid foundation in deep learning.",
      "question": "How long will it take to learn deep learning"
    },
    {
      "answer": "there are three general categories of learning that artificial intelligence (AI)/machine learning utilizes to actually learn. They are Supervised Learning, Unsupervised Learning and Reinforcement learning.  The machine then maps the inputs and the outputs.",
      "question": "What is learning and types of learning in artificial intelligence"
    },
    {
      "answer": "Machine learning algorithms are almost always optimized for raw, detailed source data. Thus, the data environment must provision large quantities of raw data for discovery-oriented analytics practices such as data exploration, data mining, statistics, and machine learning.",
      "question": "What type of data does machine learning need"
    },
    {
      "answer": "Here is a brief review of our original seven techniques for dimensionality reduction:Missing Values Ratio.  Low Variance Filter.  High Correlation Filter.  Random Forests/Ensemble Trees.  Principal Component Analysis (PCA).  Backward Feature Elimination.  Forward Feature Construction.",
      "question": "Which technique can be implemented if you want to reduce the dimensionality of a certain statistical problem"
    },
    {
      "answer": "Decision Trees in Machine Learning. Decision Tree models are created using 2 steps: Induction and Pruning. Induction is where we actually build the tree i.e set all of the hierarchical decision boundaries based on our data. Because of the nature of training decision trees they can be prone to major overfitting.",
      "question": "How is a decision tree trained"
    },
    {
      "answer": "Normalization usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1. This standardization is called a z-score, and data points can be standardized with the following formula: A z-score standardizes variables.",
      "question": "What does it mean to normalize a variable"
    },
    {
      "answer": "The optimal number of clusters can be defined as follow:Compute clustering algorithm (e.g., k-means clustering) for different values of k.  For each k, calculate the total within-cluster sum of square (wss).Plot the curve of wss according to the number of clusters k.More items",
      "question": "How do you find the optimal number of clusters"
    },
    {
      "answer": "Credit card tokenization substitutes sensitive customer data with a one-time alphanumeric ID that has no value or connection to the account's owner. This randomly generated token is used to access, pass, transmit and retrieve customer's credit card information safely.",
      "question": "What is tokenization and how does it work"
    },
    {
      "answer": "In our implementation of gradient descent, we have used a function compute_gradient(loss) that computes the gradient of a loss operation in our computational graph with respect to the output of every other node n (i.e. the direction of change for n along which the loss increases the most).",
      "question": "Is backpropagation gradient descent"
    },
    {
      "answer": "Distance Learning Off-line is a mode of delivery that does not require online participation. You do not have to come to campus. Course materials may be available through the internet, but they can also be mailed to you if you prefer.",
      "question": "What is meant by offline classes"
    },
    {
      "answer": "one training example",
      "question": "How many training examples are required by one shot learning for each class"
    },
    {
      "answer": "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.",
      "question": "What does normal distribution mean in statistics"
    },
    {
      "answer": "In a true experiment, participants are randomly assigned to either the treatment or the control group, whereas they are not assigned randomly in a quasi-experiment.  Thus, the researcher must try to statistically control for as many of these differences as possible.",
      "question": "What is the difference between field experiment and quasi experiment"
    },
    {
      "answer": "The effect of the logit transformation is primarily to pull out the ends of the distribution. Over a broad range of intermediate values of the proportion (p), the relationship of logit(p) and p is nearly linear.",
      "question": "Why do we use logit transformation"
    },
    {
      "answer": "KNN represents a supervised classification algorithm that will give new data points accordingly to the k number or the closest data points, while k-means clustering is an unsupervised clustering algorithm that gathers and groups data into k number of clusters.",
      "question": "How is Knn different from K means clustering"
    },
    {
      "answer": "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the",
      "question": "Is Random Forest a classification technique"
    },
    {
      "answer": "A Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 0, it indicates that the data point's score is identical to the mean score.",
      "question": "What does the Z in z score stand for"
    },
    {
      "answer": "Hyperparameters are the variables which determines the network structure(Eg: Number of Hidden Units) and the variables which determine how the network is trained(Eg: Learning Rate). Hyperparameters are set before training(before optimizing the weights and bias).",
      "question": "What are the Hyperparameters of a neural network"
    },
    {
      "answer": "Natural numbers are a part of the number system which includes all the positive integers from 1 till infinity and are also used for counting purpose. It does not include zero (0). In fact, 1,2,3,4,5,6,7,8,9\u2026., are also called counting numbers.",
      "question": "Is 0 part of the natural numbers"
    },
    {
      "answer": "SummaryUse the function cor. test(x,y) to analyze the correlation coefficient between two variables and to get significance level of the correlation.Three possible correlation methods using the function cor.test(x,y): pearson, kendall, spearman.",
      "question": "How do you show the relationship between two variables in R"
    },
    {
      "answer": "Quantiles are points in a distribution that relate to the rank order of values in that distribution.  Centiles/percentiles are descriptions of quantiles relative to 100; so the 75th percentile (upper quartile) is 75% or three quarters of the way up an ascending list of sorted values of a sample.",
      "question": "What is difference between quantile and percentile"
    },
    {
      "answer": "Bias machine learning can even be applied when interpreting valid or invalid results from an approved data model. Nearly all of the common machine learning biased data types come from our own cognitive biases. Some examples include Anchoring bias, Availability bias, Confirmation bias, and Stability bias.",
      "question": "What is bias in machine learning example"
    },
    {
      "answer": "How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.",
      "question": "How do you find the distribution in statistics"
    },
    {
      "answer": "A t-value is the relative error difference in contrast to the null hypothesis. A p-value, is the statistical significance of a measurement in how correct a statistical evidence part, is.",
      "question": "What is the difference between a t value and p value"
    },
    {
      "answer": "Explanation: Correlation is the process of studying the cause and effect relationship that exists between two variables. Correlation coefficient is the measure of the correlation that exists between two variables.",
      "question": "What is the difference between correlation coefficient and correlation"
    },
    {
      "answer": "The method of analyzing an image that has undergone binarization processing is called \"blob analysis\". A blob refers to a lump. Blob analysis is image processing's most basic method for analyzing the shape features of an object, such as the presence, number, area, position, length, and direction of lumps.",
      "question": "What is a blob in image processing"
    },
    {
      "answer": "The \u201cmoments\u201d of a random variable (or of its distribution) are expected values of powers or related functions of the random variable. The rth moment of X is E(Xr). In particular, the first moment is the mean, \u00b5X = E(X). The mean is a measure of the \u201ccenter\u201d or \u201clocation\u201d of a distribution.",
      "question": "What is the moment of a random variable"
    },
    {
      "answer": "Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables.  Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).",
      "question": "Is regression an algorithm"
    },
    {
      "answer": "The expected value (EV) is an anticipated value for an investment at some point in the future. In statistics and probability analysis, the expected value is calculated by multiplying each of the possible outcomes by the likelihood each outcome will occur and then summing all of those values.",
      "question": "What is expected value of probability distribution"
    },
    {
      "answer": "Loss is often used in the training process to find the \"best\" parameter values for your model (e.g. weights in neural network).  Once you find the optimized parameters above, you use this metrics to evaluate how accurate your model's prediction is compared to the true data.",
      "question": "Why is it useful to track loss while the model is being trained"
    },
    {
      "answer": "How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.",
      "question": "How do you find the mean of a probability distribution"
    },
    {
      "answer": "Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution. Figure 1 shows density functions for three Chi Square distributions.",
      "question": "What is the skewness of a chi square distribution"
    },
    {
      "answer": "LDA is a probabilistic generative model that extracts the thematic structure in a big document collection. The model assumes that every topic is a distribution of words in the vocabulary, and every document (described over the same vocabulary) is a distribution of a small subset of these topics.",
      "question": "What is LDA clustering"
    },
    {
      "answer": "Connected components labeling scans an image and groups its pixels into components based on pixel connectivity, i.e. all pixels in a connected component share similar pixel intensity values and are in some way connected with each other.",
      "question": "What is labeling in image processing"
    },
    {
      "answer": "When we know an input value and want to determine the corresponding output value for a function, we evaluate the function.  When we know an output value and want to determine the input values that would produce that output value, we set the output equal to the function's formula and solve for the input.",
      "question": "What is output value"
    },
    {
      "answer": "Q-learning is a model-free reinforcement learning algorithm to learn quality of actions telling an agent what action to take under what circumstances.  \"Q\" names the function that the algorithm computes with the maximum expected rewards for an action taken in a given state.",
      "question": "What is Q function in machine learning"
    },
    {
      "answer": "When most dependent variables are numeric, logistic regression and SVM should be the first try for classification. These models are easy to implement, their parameters easy to tune, and the performances are also pretty good. So these models are appropriate for beginners.",
      "question": "Which algorithm is used for classification"
    },
    {
      "answer": "The binomial distribution model allows us to compute the probability of observing a specified number of \"successes\" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure.",
      "question": "What are the application of binomial distribution"
    },
    {
      "answer": "Systematic sampling is frequently used to select a specified number of records from a computer file. Stratified sampling is commonly used probability method that is superior to random sampling because it reduces sampling error. A stratum is a subset of the population that share at least one common characteristic.",
      "question": "What is stratified and systematic sampling"
    },
    {
      "answer": "Univariate and multivariate represent two approaches to statistical analysis. Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables. Most multivariate analysis involves a dependent variable and multiple independent variables.",
      "question": "What is the difference between univariate and multivariate regression"
    },
    {
      "answer": "It appears that the median is always closest to the high point (the mode), while the mean tends to be farther out on the tail. In a symmetrical distribution, the mean and the median are both centrally located close to the high point of the distribution.",
      "question": "Where is the mean located in relationship to the median"
    },
    {
      "answer": "Assumptions. The assumptions of discriminant analysis are the same as those for MANOVA. The analysis is quite sensitive to outliers and the size of the smallest group must be larger than the number of predictor variables. Multivariate normality: Independent variables are normal for each level of the grouping variable.",
      "question": "What are the assumptions of discriminant analysis"
    },
    {
      "answer": "The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape).",
      "question": "When would you use a Wilcoxon rank sum test"
    },
    {
      "answer": "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data.  A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable.",
      "question": "What is meant by linear regression"
    },
    {
      "answer": "Descriptive statistics are used to describe the basic features of the data in a study. They provide simple summaries about the sample and the measures.  Descriptive statistics are typically distinguished from inferential statistics. With descriptive statistics you are simply describing what is or what the data shows.",
      "question": "What do you mean by descriptive statistics"
    },
    {
      "answer": "Odds Ratio is a measure of the strength of association with an exposure and an outcome.OR > 1 means greater odds of association with the exposure and outcome.OR = 1 means there is no association between exposure and outcome.OR < 1 means there is a lower odds of association between the exposure and outcome.",
      "question": "How do you interpret odds ratio"
    },
    {
      "answer": "Named Entity Recognition can automatically scan entire articles and reveal which are the major people, organizations, and places discussed in them. Knowing the relevant tags for each article help in automatically categorizing the articles in defined hierarchies and enable smooth content discovery.",
      "question": "How do you use a named entity recognition"
    },
    {
      "answer": "In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).",
      "question": "What is an agent artificial intelligence"
    },
    {
      "answer": "Clean, augment, and preprocess the data into a convenient form, if needed. Conduct an exploratory analysis of the data to get a better sense of it. Using what you find as a guide, construct a model of some aspect of the data. Use the model to answer the question you started with, and validate your results.",
      "question": "How do you make a predictive model in R"
    },
    {
      "answer": "On a technical note, estimation of a latent variable is done by analyzing the variance and covariance of the indicators. The measurement model of a latent variable with effect indicators is the set of relationships (modeled as equations) in which the latent variable is set as the predictor of the indicators.",
      "question": "How do you calculate latent variables"
    },
    {
      "answer": "T - test is used to if the means of two populations are equal (assuming similar variance) whereas F-test is used to test if the variances of two populations are equal. F - test can also be extended to check whether the means of three or more groups are different or not (ANOVA F-test).",
      "question": "Whats the difference between an F Test and T Test"
    },
    {
      "answer": "The first step in backward elimination is pretty simple, you just select a significance level, or select the P-value. Usually, in most cases, a 5% significance level is selected. This means the P-value will be 0.05. You can change this value depending on the project.",
      "question": "What is significance level in backward elimination"
    },
    {
      "answer": "An SVM possesses a number of parameters that increase linearly with the linear increase in the size of the input. A NN, on the other hand, doesn't. Even though here we focused especially on single-layer networks, a neural network can have as many layers as we want.",
      "question": "What is the difference between SVM and neural networks"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What does variance mean in at test"
    },
    {
      "answer": "The sample mean is a consistent estimator for the population mean. A consistent estimate has insignificant errors (variations) as sample sizes grow larger. More specifically, the probability that those errors will vary by more than a given amount approaches zero as the sample size increases.",
      "question": "Is the sample mean a consistent estimator"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.",
      "question": "What is difference between standard deviation and standard error"
    },
    {
      "answer": "Linear Growth Model Organisms generally grow in spurts that are dependent on both environment and genetics. Under controlled laboratory conditions, however, one can often observe a constant rate of growth. These periods of constant growth are often referred to as the linear portions of the growth curve.",
      "question": "What is a linear growth curve"
    },
    {
      "answer": "The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit.",
      "question": "What is forget gate in Lstm"
    },
    {
      "answer": "The Z score is a test of statistical significance that helps you decide whether or not to reject the null hypothesis. The p-value is the probability that you have falsely rejected the null hypothesis. Z scores are measures of standard deviation.  Both statistics are associated with the standard normal distribution.",
      "question": "Is Z score the test statistic"
    },
    {
      "answer": "Sensitivity refers to a test's ability to designate an individual with disease as positive. A highly sensitive test means that there are few false negative results, and thus fewer cases of disease are missed. The specificity of a test is its ability to designate an individual who does not have a disease as negative.",
      "question": "What does it mean if a test is sensitive but not specific"
    },
    {
      "answer": "A matrix is a linear operator acting on the vector space of column vectors. Per linear algebra and its isomorphism theorems, any vector space is isomorphic to any other vector space of the same dimension. As such, matrices can be seen as representations of linear operators subject to some basis of column vectors.",
      "question": "Is a matrix an operator"
    },
    {
      "answer": "The population mean of the distribution of sample means is the same as the population mean of the distribution being sampled from.  Thus as the sample size increases, the standard deviation of the means decreases; and as the sample size decreases, the standard deviation of the sample means increases.",
      "question": "How does standard deviation change with sample size"
    },
    {
      "answer": "If you are broadcasting or reinforcing sound outside, and even your best windscreen can't keep out the persistent low-frequency rumble from wind noise, then stopping it right at the source may be your best option. Highpass filters are excellent for this application.",
      "question": "When should I use high pass filter"
    },
    {
      "answer": "Machine Learning This phenomenon states that with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.",
      "question": "What is the curse of dimensionality in machine learning"
    },
    {
      "answer": "Fractional scaling helps you to fully utilize your HiDPI monitors, high-resolution laptops by making your desktop not too small or not too big and keep things in balance. Although the resolution settings are there to help they sometimes are not feasible due to the operating system limitations.",
      "question": "What is fractional scaling ubuntu"
    },
    {
      "answer": "When small samples are used to estimate a population mean, in cases where the population standard deviation is unknown: the t-distribution must be used to obtain the critical value. the resulting margin of error for a confidence interval estimate will tend to be fairly small.",
      "question": "When small samples are used to estimate a population mean in cases where the population standard deviation is unknown"
    },
    {
      "answer": "In probability theory and statistics, Bayes's theorem (alternatively Bayes's law or Bayes's rule), named after Reverend Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.  Bayesian inference is fundamental to Bayesian statistics.",
      "question": "What is Bayes theorem statistics"
    },
    {
      "answer": "Here are some tips for connecting the shape of a histogram with the mean and median:If the histogram is skewed right, the mean is greater than the median.  If the histogram is close to symmetric, then the mean and median are close to each other.  If the histogram is skewed left, the mean is less than the median.",
      "question": "How do you find the mean and median of a histogram"
    },
    {
      "answer": "2 Answers. If M is your matrix, then it represents a linear f:Rn\u2192Rn, thus when you do M(T) by row times column multiplication you obtain a vectorial expression for your f(T). Thus \u2202M\u2202T is just the derivative of the vector MT, which you do component-wise.",
      "question": "Can you take the derivative of a matrix"
    },
    {
      "answer": "The Formula for the Slope For paired data (x,y) we denote the standard deviation of the x data by sx and the standard deviation of the y data by sy. The formula for the slope a of the regression line is: a = r(sy/sx)",
      "question": "How do you find the slope of the regression line in R"
    },
    {
      "answer": "Marginal probability effects are the partial effects of each explanatory variable on. the probability that the observed dependent variable Yi = 1, where in probit. models.",
      "question": "What is marginal effects in probit model"
    },
    {
      "answer": "A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa.",
      "question": "What is FFT and its applications in DAA"
    },
    {
      "answer": "The variance (symbolized by S2) and standard deviation (the square root of the variance, symbolized by S) are the most commonly used measures of spread. We know that variance is a measure of how spread out a data set is. It is calculated as the average squared deviation of each number from the mean of a data set.",
      "question": "What is variance and deviation"
    },
    {
      "answer": "In the terminology of machine learning, classification is considered an instance of supervised learning, i.e., learning where a training set of correctly identified observations is available.  An algorithm that implements classification, especially in a concrete implementation, is known as a classifier.",
      "question": "What is classification learning"
    },
    {
      "answer": "training set\u2014a subset to train a model. test set\u2014a subset to test the trained model.",
      "question": "What is meant by training set and test set"
    },
    {
      "answer": "Random Forest Algorithm The Random Forest ML Algorithm is a versatile supervised learning algorithm that's used for both classification and regression analysis tasks.",
      "question": "Which algorithms can be used for both classification and regression tasks"
    },
    {
      "answer": "- if R-squared value 0.3 < r < 0.5 this value is generally considered a weak or low effect size, - if R-squared value 0.5 < r < 0.7 this value is generally considered a Moderate effect size, - if R-squared value r > 0.7 this value is generally considered strong effect size, Ref: Source: Moore, D. S., Notz, W.",
      "question": "What does a weak R squared value mean"
    },
    {
      "answer": "the t-test is robust against non-normality; this test is in doubt only when there can be serious outliers (long-tailed distributions \u2013 note the finite variance assumption); or when sample sizes are small and distributions are far from normal. 10 / 20 Page 20 . . .",
      "question": "Is t test robust to violations of normality"
    },
    {
      "answer": "Therefore, a number of alternative ways of handling the missing data has been developed.Listwise or case deletion.  Pairwise deletion.  Mean substitution.  Regression imputation.  Last observation carried forward.  Maximum likelihood.  Expectation-Maximization.  Multiple imputation.More items\u2022",
      "question": "How do you handle missing data in regression analysis"
    },
    {
      "answer": "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).",
      "question": "What is an adversarial neural network"
    },
    {
      "answer": "The normalisation ensures that the inputs have a mean of 0 and a standard deviation of 1, meaning that the input distribution to every neuron will be the same, thereby fixing the problem of internal covariate shift and providing regularisation.",
      "question": "How does Batch normalization address the problem of Internal Covariate Shift"
    },
    {
      "answer": "2.1 The Early Days. Constraint satisfaction, in its basic form, involves finding a value for each one of a set of problem variables where constraints specify that some subsets of values cannot be used together.",
      "question": "What is constraints satisfaction problem in AI"
    },
    {
      "answer": "Cohen came up with a mechanism to calculate a value which represents the level of agreement between judges negating the agreement by chance.  You can see that balls which are agreed on by chance are removed both from agreed and total number of balls. And that is the whole intuition of Kappa value aka Kappa coefficient.",
      "question": "What is an intuitive explanation of Cohens kappa statistic"
    },
    {
      "answer": "The false discovery rate (FDR) is a method of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons.  Thus, FDR-controlling procedures have greater power, at the cost of increased numbers of Type I errors.",
      "question": "What is FDR correction"
    },
    {
      "answer": "Mean and Variance of a Binomial Distribution The variance of a Binomial Variable is always less than its mean. \u2234 npq<np. For Maximum Variance: p=q=0.5 and \u03c3max = n/4.",
      "question": "What is the maximum value of the variance of binomial distribution"
    },
    {
      "answer": "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.",
      "question": "What is classification accuracy"
    },
    {
      "answer": "5 Successful ExamplesSentiment Analysis Examples.Reputation Management - Social Media Monitoring - Brand Monitoring.Market Research, Competitor Analysis.Product Analytics.Customer Analysis.Customer Support.",
      "question": "What are the most popular application areas for sentiment analysis"
    },
    {
      "answer": "This is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting. A simple relation for linear regression looks like this.",
      "question": "What is the use of regularization in machine learning"
    },
    {
      "answer": "Advantages and Disadvantages of Artificial Intelligence Reduction in Human Error: The phrase \u201chuman error\u201d was born because humans make mistakes from time to time.   Takes risks instead of Humans:   Available 24x7:   Helping in Repetitive Jobs:   Digital Assistance:   Faster Decisions:   Daily Applications:   New Inventions:",
      "question": "What are some of the benefits of AI development"
    },
    {
      "answer": "Lab Color is a more accurate color space.  It specifies a color using a 3-axis system. The a-axis (green to red), b-axis (blue to yellow) and Lightness axis. The best thing about Lab Color is that it's device-independent. That means that it's easier to achieve exactly the same color across different media.",
      "question": "What does lab color mean"
    },
    {
      "answer": "In-group favoritism, sometimes known as in-group\u2013out-group bias, in-group bias, intergroup bias, or in-group preference, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.",
      "question": "What does having biased groups mean"
    },
    {
      "answer": "Basically, you're just pre-setting some of the weights of the new network. Be sure to initialize the new connections to have similar distributions. Make the last layer a concatenation of their results and then add another few layers. Make the last layer a concatenation of their results and the original input.",
      "question": "How do I connect two neural networks"
    },
    {
      "answer": "The matrix norm is similar to the magnitude of a vector. It is useful whenever a system/problem can be formulated into a matrix that has some physical meaning.",
      "question": "What is Matrix norm used for"
    },
    {
      "answer": "Factor-Label Method",
      "question": "What does dimensional analysis mean"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent, e.g., the \u201cgradient\u201d part of gradient boosting models. Specifically, the gradient of the training loss is used to change the target variables for each successive tree.",
      "question": "What is loss function in gradient boosting"
    },
    {
      "answer": "In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.",
      "question": "What does it mean to be exponentially distributed"
    },
    {
      "answer": "Exponential moving averages, or EMA, give more weighting to recent prices. They reduce the effect of the lag that comes from using previous price data and can help you identify a trend earlier, so it's a useful indicator for trading short-term contracts.",
      "question": "In trading why would we use the exponential moving average over the simple moving average"
    },
    {
      "answer": "1 Introduction. The partial least squares (PLS) algorithm was first introduced for regression tasks and then evolved into a classification method that is well known as PLS-discriminant analysis (PLS-DA).",
      "question": "Whats the abbreviation for orthogonal partial least squares discriminant analysis"
    },
    {
      "answer": "Decision tree builds classification or regression models in the form of a tree structure.  The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.",
      "question": "Can decision trees be used for classification"
    },
    {
      "answer": "In simple terms, a quantile is where a sample is divided into equal-sized, adjacent, subgroups (that's why it's sometimes called a \u201cfractile\u201c).  The median cuts a distribution into two equal areas and so it is sometimes called 2-quantile. Quartiles are also quantiles; they divide the distribution into four equal parts.",
      "question": "What is quantile example"
    },
    {
      "answer": "Probabilistic data structures are a group of data structures that are extremely useful for big data and streaming applications. Generally speaking, these data structures use hash functions to randomize and compactly represent a set of items.",
      "question": "What is a probabilistic data structure"
    },
    {
      "answer": "There are several methods through which you can evaluate a Logistic regression model:Goodness of Fit.Likelihood ratio test.Wald's Test.Hosmer-Lemeshov Test.ROC (AUC) curve.Confidence Intervals.Correlation factors and coefficients.Variance Inflation Factor(VIF)More items",
      "question": "How do you evaluate a logit model"
    },
    {
      "answer": "Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several.",
      "question": "What is a Synset in WordNet"
    },
    {
      "answer": "Stratified random sampling refers to a sampling method that has the following properties.The population consists of N elements.The population is divided into H groups, called strata.Each element of the population can be assigned to one, and only one, stratum.More items",
      "question": "What are the properties of stratified random sampling"
    },
    {
      "answer": "The solution involves four steps.Make sure the samples from each population are big enough to model differences with a normal distribution.  Find the mean of the difference in sample proportions: E(p1 - p2) = P1 - P2 = 0.52 - 0.47 = 0.05.Find the standard deviation of the difference.  Find the probability.",
      "question": "How do you find the difference between sample proportions"
    },
    {
      "answer": "The normal distribution is a probability distribution. As with any probability distribution, the proportion of the area that falls under the curve between two points on a probability distribution plot indicates the probability that a value will fall within that interval.",
      "question": "How is the concept of probability related to the normal distribution"
    },
    {
      "answer": "The median is another form of an average. It usually represents the middle number in a given sequence of numbers when it's ordered by rank.",
      "question": "Is the median the average"
    },
    {
      "answer": "Similar to the t-test/correlation equivalence, the relationship between two dichotomous variables is the same as the difference between two groups when the dependent variable is dichotmous. The appropriate test to compare group differences with a dichotmous outcome is the chi-square statistic.",
      "question": "Which statistical technique is appropriate for find out the correlation between two dichotomous variables"
    },
    {
      "answer": "Gaussian RBF(Radial Basis Function) is another popular Kernel method used in SVM models for more. RBF kernel is a function whose value depends on the distance from the origin or from some point. Gaussian Kernel is of the following format; ||X1 \u2014 X2 || = Euclidean distance between X1 & X2.",
      "question": "What is gaussian kernel in SVM"
    },
    {
      "answer": "In short, it ensures each subgroup within the population receives proper representation within the sample. As a result, stratified random sampling provides better coverage of the population since the researchers have control over the subgroups to ensure all of them are represented in the sampling.",
      "question": "What's stratified sampling Why is it preferred"
    },
    {
      "answer": "Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.  dot represent numpy dot product of all input and its corresponding weights.",
      "question": "What is dense layer in sequential model"
    },
    {
      "answer": "Adjusted R-squared value can be calculated based on value of r-squared, number of independent variables (predictors), total sample size. Every time you add a independent variable to a model, the R-squared increases, even if the independent variable is insignificant. It never declines.",
      "question": "How is adjusted r2 calculated"
    },
    {
      "answer": "The primary goal of EDA is to maximize the analyst's insight into a data set and into the underlying structure of a data set, while providing all of the specific items that an analyst would want to extract from a data set, such as: a good-fitting, parsimonious model. a list of outliers.",
      "question": "What are the two goals of exploratory data analysis"
    },
    {
      "answer": "In your case, with three groups, you'd run ANOVA. If you need to compare the 5-point scales one at a time, then non-parametric statistics are more appropriate. To compare two groups use the Mann-Whitney U test. To compare three or more groups use the Kruskal\u2013Wallis H test.",
      "question": "Which statistical test should I use to compare 3 ordinal variables"
    },
    {
      "answer": "In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.",
      "question": "What is convergence in neural network"
    },
    {
      "answer": "In terms of machine learning, \"concept learning\" can be defined as: \u201cThe problem of searching through a predefined space of potential hypotheses for the hypothesis that best fits the training examples.\u201d \u2014 Tom Michell. Much of human learning involves acquiring general concepts from past experiences.",
      "question": "What is concept in machine learning"
    },
    {
      "answer": "The agent function is a mathematical function that maps a sequence of perceptions into action. The function is implemented as the agent program. The part of the agent taking an action is called an actuator. environment -> sensors -> agent function -> actuators -> environment.",
      "question": "What is Agent function in artificial intelligence"
    },
    {
      "answer": "There are two reasons why Mean Squared Error(MSE) is a bad choice for binary classification problems:  If we use maximum likelihood estimation(MLE), assuming that the data is from a normal distribution(a wrong assumption, by the way), we get the MSE as a Cost function for optimizing our model.",
      "question": "Why is squared loss bad for classification"
    },
    {
      "answer": "Sentiment analysis also means you'll be able to detect changes in the overall opinion towards your brand. Because it provides insight into the way your customers are feeling when they approach you, you can monitor trends and see if overall opinion towards your company drops or rises.",
      "question": "What are the benefits of sentiment analysis"
    },
    {
      "answer": "The main difference between probability and likelihood is that the former is normalized.  Probability refers to the occurrence of future events, while a likelihood refers to past events with known outcomes. Probability is used when describing a function of the outcome given a fixed parameter value.",
      "question": "What is the difference between probability and likelihood"
    },
    {
      "answer": "A decision tree is simply a set of cascading questions. When you get a data point (i.e. set of features and values), you use each attribute (i.e. a value of a given feature of the data point) to answer a question. The answer to each question decides the next question.",
      "question": "How do you explain a decision tree"
    },
    {
      "answer": "Logistic regression is quite different than linear regression in that it does not make several of the key assumptions that linear and general linear models (as well as other ordinary least squares algorithm based models) hold so close: (1) logistic regression does not require a linear relationship between the dependent",
      "question": "Does logistic regression data need to be normally distributed"
    },
    {
      "answer": "It is often pointed out that when ANOVA is applied to just two groups, and when therefore one can calculate both a t-statistic and an F-statistic from the same data, it happens that the two are related by the simple formula: t2 = F.",
      "question": "What is the relationship between F statistic and T statistic"
    },
    {
      "answer": "A classification is an ordered set of related categories used to group data according to its similarities. It consists of codes and descriptors and allows survey responses to be put into meaningful categories in order to produce useful data. A classification is a useful tool for anyone developing statistical surveys.",
      "question": "What is meant by classification in statistics"
    },
    {
      "answer": "A set is countable if: (1) it is finite, or (2) it has the same cardinality (size) as the set of natural numbers (i.e., denumerable). Equivalently, a set is countable if it has the same cardinality as some subset of the set of natural numbers. Otherwise, it is uncountable.",
      "question": "What is countable set in analysis"
    },
    {
      "answer": "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.",
      "question": "What is NLP problem"
    },
    {
      "answer": "Z-tests are statistical calculations that can be used to compare population means to a sample's. T-tests are calculations used to test a hypothesis, but they are most useful when we need to determine if there is a statistically significant difference between two independent sample groups.",
      "question": "What is the difference between z test and t test"
    },
    {
      "answer": "If a variable can take on any value between two specified values, it is called a continuous variable; otherwise, it is called a discrete variable. Some examples will clarify the difference between discrete and continuous variables.  The number of heads could be any integer value between 0 and plus infinity.",
      "question": "What is difference between discrete and continuous variable"
    },
    {
      "answer": "Artificial intelligence (AI) is a branch of computer science.  Most AI programs are not used to control robots. Even when AI is used to control robots, the AI algorithms are only part of the larger robotic system, which also includes sensors, actuators, and non-AI programming.",
      "question": "How artificial intelligence is related to robotics"
    },
    {
      "answer": "The model works by first splitting the input image into a grid of cells, where each cell is responsible for predicting a bounding box if the center of a bounding box falls within it. Each grid cell predicts a bounding box involving the x, y coordinate and the width and height and the confidence.",
      "question": "How does a bounding box work"
    },
    {
      "answer": "Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. It is a very simple idea that can result in accurate forecasts on a range of time series problems.",
      "question": "What are autoregressive models in machine learning"
    },
    {
      "answer": "Gradient descent is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.",
      "question": "What are the conditions in which Gradient descent is applied"
    },
    {
      "answer": "Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.  Therefore, Softmax loss is just these two appended together.",
      "question": "Is Softmax a loss function"
    },
    {
      "answer": "Parametric statistics are based on assumptions about the distribution of population from which the sample was taken. Nonparametric statistics are not based on assumptions, that is, the data can be collected from a sample that does not follow a specific distribution.",
      "question": "What is parametric statistics and nonparametric statistics"
    },
    {
      "answer": "Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.",
      "question": "What is dimensional analysis method"
    },
    {
      "answer": "Having good test re-test reliability signifies the internal validity of a test and ensures that the measurements obtained in one sitting are both representative and stable over time.",
      "question": "Why is test retest reliability important"
    },
    {
      "answer": "Multidimensional scaling is a visual representation of distances or dissimilarities between sets of objects.  Objects that are more similar (or have shorter distances) are closer together on the graph than objects that are less similar (or have longer distances).",
      "question": "What is multidimensional scaling in statistics"
    },
    {
      "answer": "Feature Selection vs Dimensionality Reduction While both methods are used for reducing the number of features in a dataset, there is an important difference. Feature selection is simply selecting and excluding given features without changing them. Dimensionality reduction transforms features into a lower dimension.",
      "question": "Whats the difference between dimensionality reduction and feature selection"
    },
    {
      "answer": "Top 10 Machine Learning ApplicationsTraffic Alerts.Social Media.Transportation and Commuting.Products Recommendations.Virtual Personal Assistants.Self Driving Cars.Dynamic Pricing.Google Translate.More items\u2022",
      "question": "What are the applications of machine learning"
    },
    {
      "answer": "Explanation: Simple reflex agent is based on the present condition and so it is condition action rule. 5. What are the composition for agents in artificial intelligence? Explanation: An agent program will implement function mapping percepts to actions.",
      "question": "What are the composition for agents in artificial intelligence"
    },
    {
      "answer": "Linear regression is a linear method to model the relationship between your independent variables and your dependent variables. Advantages include how simple it is and ease with implementation and disadvantages include how is' lack of practicality and how most problems in our real world aren't \u201clinear\u201d.",
      "question": "What are the advantages and disadvantages of linear regression"
    },
    {
      "answer": "A greedy algorithm is used to construct a Huffman tree during Huffman coding where it finds an optimal solution. In decision tree learning, greedy algorithms are commonly used, however they are not guaranteed to find the optimal solution. One popular such algorithm is the ID3 algorithm for decision tree construction.",
      "question": "Where greedy algorithm is used"
    },
    {
      "answer": "This approach involves either forward selection, adding features one at a time, or backward selection, removing features one at a time until some criterion is reached. Additionally, a bidirectional selection method is available that involves adding or removing a feature at each step.",
      "question": "What is backward selection"
    },
    {
      "answer": "Spectroscopy in chemistry and physics, a method of analyzing the properties of matter from their electromagnetic interactions. Spectral estimation, in statistics and signal processing, an algorithm that estimates the strength of different frequency components (the power spectrum) of a time-domain signal.",
      "question": "How is spectral analysis used"
    },
    {
      "answer": "Batch size controls the accuracy of the estimate of the error gradient when training neural networks. Batch, Stochastic, and Minibatch gradient descent are the three main flavors of the learning algorithm. There is a tension between batch size and the speed and stability of the learning process.",
      "question": "Does batch size affect accuracy"
    },
    {
      "answer": "4:1410:53Suggested clip \u00b7 113 secondsStochastic Gradient Descent, Clearly Explained!!! - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you use stochastic gradient descent"
    },
    {
      "answer": "The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.",
      "question": "How do you solve the vanishing gradient problem"
    },
    {
      "answer": "In this view, associative networks are fundamentally unorganized lists of features. By specifying what attributes to include, a frame structure promises to provide the \"framework\" upon which to organize and hang what a consumer knows about a product.",
      "question": "What do you know about associative network and frames"
    },
    {
      "answer": "You might also see this written as something like \u201cAn unbiased estimator is when the mean of the statistic's sampling distribution is equal to the population's parameter.\u201d This essentially means the same thing: if the statistic equals the parameter, then it's unbiased.",
      "question": "How do you prove an estimator is unbiased"
    },
    {
      "answer": "You can use a bivariate Pearson Correlation to test whether there is a statistically significant linear relationship between height and weight, and to determine the strength and direction of the association.",
      "question": "When would you use a bivariate correlation"
    },
    {
      "answer": "Fuelled by successes in Computer Go, Monte Carlo tree search (MCTS) has achieved widespread adoption within the games community. Its links to traditional reinforcement learning (RL) methods have been outlined in the past; however, the use of RL techniques within tree search has not been thoroughly studied yet.",
      "question": "Is Monte Carlo Tree Search reinforcement learning"
    },
    {
      "answer": "A latent variable is a random variable which you can't observe neither in training nor in test phase . It is derived from the latin word lat\u0113re which means hidden. Intuitionally, some phenomenons like incidences,altruism one can't measure while others like speed or height one can.",
      "question": "What are latent variables in machine learning"
    },
    {
      "answer": "The three main metrics used to evaluate a classification model are accuracy, precision, and recall. Accuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.",
      "question": "How do you evaluate machine learning algorithms"
    },
    {
      "answer": "Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. Whereas a classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account.",
      "question": "What is CRF in machine learning"
    },
    {
      "answer": "Formally, a statistic T(X1,\u00b7\u00b7\u00b7,Xn) is said to be sufficient for \u03b8 if the conditional distribution of X1,\u00b7\u00b7\u00b7,Xn, given T = t, does not depend on \u03b8 for any value of t. In other words, given the value of T, we can gain no more knowledge about \u03b8 from knowing more about the probability distribution of X1,\u00b7\u00b7\u00b7,Xn.",
      "question": "How do you prove a statistic is sufficient"
    },
    {
      "answer": "Anomaly detection (or outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.",
      "question": "What is outlier detection in machine learning"
    },
    {
      "answer": "Machine learning usually has to achieve multiple targets, which are often conflicting with each other. Multi-objective model selection to improve the performance of learning models, such as neural networks, support vector machines, decision trees, and fuzzy systems.",
      "question": "What are some Machine Learning techniques for objective optimization"
    },
    {
      "answer": "Two random variables X and Y are said to be bivariate normal, or jointly normal, if aX+bY has a normal distribution for all a,b\u2208R. In the above definition, if we let a=b=0, then aX+bY=0. We agree that the constant zero is a normal random variable with mean and variance 0.",
      "question": "How do you know if a bivariate is normal distribution"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "Where do we use eigenvalues"
    },
    {
      "answer": "Nonparametric tests are sometimes called distribution-free tests because they are based on fewer assumptions (e.g., they do not assume that the outcome is approximately normally distributed).  There are several statistical tests that can be used to assess whether data are likely from a normal distribution.",
      "question": "Why would you use a nonparametric test"
    },
    {
      "answer": "Rather than using the past values of the forecast variable in a regression, a moving average model uses past forecast errors in a regression-like model.  While, the autoregressive model(AR) uses the past forecasts to predict future values.",
      "question": "What are the differences between autoregressive and moving average models"
    },
    {
      "answer": "Coef. A regression coefficient describes the size and direction of the relationship between a predictor and the response variable. Coefficients are the numbers by which the values of the term are multiplied in a regression equation.",
      "question": "What do the coefficients in logistic regression mean"
    },
    {
      "answer": "RELU activation solves this by having a gradient slope of 1, so during backpropagation, there isn't gradients passed back that are progressively getting smaller and smaller. but instead they are staying the same, which is how RELU solves the vanishing gradient problem.",
      "question": "How does ReLU solve vanishing gradient problem"
    },
    {
      "answer": "As you have seen, in order to perform a likelihood ratio test, one must estimate both of the models one wishes to compare. The advantage of the Wald and Lagrange multiplier (or score) tests is that they approximate the LR test, but require that only one model be estimated.",
      "question": "How do you calculate the likelihood ratio"
    },
    {
      "answer": "Answer. When the ROC curve dips prominently into the lower right half of the graph, this is likely a sign that either the wrong State Value has been specified or the wrong Test-State association direction has been specified in the \"Test Direction\" area of the \"ROC Curve:Options\" dialog.",
      "question": "Why is my ROC curve inverted"
    },
    {
      "answer": "The Least Squares AssumptionsUseful Books for This Topic:  ASSUMPTION #1: The conditional distribution of a given error term given a level of an independent variable x has a mean of zero.  ASSUMPTION #2: (X,Y) for all n are independently and identically distributed.  ASSUMPTION #3: Large outliers are unlikely.More items\u2022",
      "question": "What are the least squares assumptions"
    },
    {
      "answer": "Keras is a neural network library while TensorFlow is the open-source library for a number of various tasks in machine learning. TensorFlow provides both high-level and low-level APIs while Keras provides only high-level APIs.",
      "question": "What is the relationship between tensorflow with keras"
    },
    {
      "answer": "It's more of an approach than a process. Predictive analytics and machine learning go hand-in-hand, as predictive models typically include a machine learning algorithm. These models can be trained over time to respond to new data or values, delivering the results the business needs.",
      "question": "Is predictive modeling machine learning"
    },
    {
      "answer": "8 Powerful Tricks That Make You Grasp New Concepts Faster1) Use mental associations. Colours, acronyms and word associations can be especially useful tools to help you hold on to thoughts, patterns and concepts.  2) Apply the 80/20 principle.  3) Break it down.  4) Write it down.  5) Connect existing knowledge.  6) Try Brain exercises.  7) Learn your way.  8) Teach other people.",
      "question": "How do you understand a concept deeply"
    },
    {
      "answer": "Linear regression is used to find the best fitting line between all the points of your dataset (by computing the minimum of a given distance), it does not, in itself, reduce the dimensionality of your data.",
      "question": "Why cant we use linear regression for dimension reduction"
    },
    {
      "answer": "Convergence in distribution is in some sense the weakest type of convergence. All it says is that the CDF of Xn's converges to the CDF of X as n goes to infinity. It does not require any dependence between the Xn's and X. We saw this type of convergence before when we discussed the central limit theorem.",
      "question": "What does convergence in distribution mean"
    },
    {
      "answer": "Hidden Markov models have been around for a pretty long time (1970s at least). It's a misnomer to call them machine learning algorithms.  It is most useful, IMO, for state sequence estimation, which is not a machine learning problem since it is for a dynamical process, not a static classification task.",
      "question": "Is Markov model machine learning"
    },
    {
      "answer": "The Unsharp Mask filter adjusts the contrast of the edge detail and creates the illusion of a more focused image.",
      "question": "What does the unsharp mask filter do"
    },
    {
      "answer": "The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X \u2264 x, Y \u2264 y),where X and Y are continuous or discrete. For example, the probability.  P(x1 \u2264 X \u2264 x2,y1 \u2264 Y \u2264 y2) = F(x2,y2) \u2212 F(x2,y1) \u2212 F(x1,y2) + F(x1,y1).",
      "question": "How do you find the joint distribution of two random variables"
    },
    {
      "answer": "Spearman Rank Correlation: Worked Example (No Tied Ranks)The formula for the Spearman rank correlation coefficient when there are no tied ranks is:  Step 1: Find the ranks for each individual subject.  Step 2: Add a third column, d, to your data.  Step 5: Insert the values into the formula.More items\u2022",
      "question": "How do you use Spearman's rank correlation coefficient"
    },
    {
      "answer": "Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used to solve complex problems.  Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.",
      "question": "What do you mean by knowledge representation"
    },
    {
      "answer": "Feature extraction describes the relevant shape information contained in a pattern so that the task of classifying the pattern is made easy by a formal procedure. In pattern recognition and in image processing, feature extraction is a special form of dimensionality reduction.",
      "question": "What is feature extraction in image processing"
    },
    {
      "answer": "The goodness of fit test is a statistical hypothesis test to see how well sample data fit a distribution from a population with a normal distribution. Put differently, this test shows if your sample data represents the data you would expect to find in the actual population or if it is somehow skewed.",
      "question": "What is the purpose of a goodness of fit test"
    },
    {
      "answer": "If your p-value is less than or equal to the set significance level, the data is considered statistically significant. As a general rule, the significance level (or alpha) is commonly set to 0.05, meaning that the probability of observing the differences seen in your data by chance is just 5%.",
      "question": "How do you test if a difference is statistically significant"
    },
    {
      "answer": "Machine learning is changing the world by transforming all segments including healthcare services, education, transport, food, entertainment, and different assembly line and many more. It will impact lives in almost every aspect, including housing, cars, shopping, food ordering, etc.",
      "question": "How is Machine Learning changing the world"
    },
    {
      "answer": "In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables.",
      "question": "What should I choose simple linear regression or multiple linear regression"
    },
    {
      "answer": "Prior probability represents what is originally believed before new evidence is introduced, and posterior probability takes this new information into account.  A posterior probability can subsequently become a prior for a new updated posterior probability as new information arises and is incorporated into the analysis.",
      "question": "What is prior and posterior"
    },
    {
      "answer": "The Moment Generating Function of the Binomial Distribution (3) dMx(t) dt = n(q + pet)n\u22121pet = npet(q + pet)n\u22121. Evaluating this at t = 0 gives (4) E(x) = np(q + p)n\u22121 = np.",
      "question": "What is the moment generating function of binomial distribution"
    },
    {
      "answer": "It is usually defined as the ratio of the variance to the mean. As a formula, that's: D = \u03c32 / \u03bc.",
      "question": "How do you find the variance of a ratio"
    },
    {
      "answer": "Expectation maximization is applicable whenever the data are missing completely at random or missing at random-but unsuitable when the data are not missing at random.",
      "question": "What is Expectation Maximization for missing data"
    },
    {
      "answer": "Biased but consistent , it approaches the correct value, and so it is consistent. ), these are both negatively biased but consistent estimators.",
      "question": "Can a biased estimator be consistent"
    },
    {
      "answer": "Importance sampling is a variance reduction technique that can be used in the Monte Carlo method. The idea behind importance sampling is that certain values of the input random variables in a simulation have more impact on the parameter being estimated than others.",
      "question": "What is the importance of a sampling approach to the estimation of expected values in Monte Carlo algorithms"
    },
    {
      "answer": "To perform principal component analysis using the correlation matrix using the prcomp() function, set the scale argument to TRUE . Plot the first two PCs of the correlation matrix using the autoplot() function.",
      "question": "How do you do principal component analysis in R"
    },
    {
      "answer": "Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable. The nature of target or dependent variable is dichotomous, which means there would be only two possible classes.  Mathematically, a logistic regression model predicts P(Y=1) as a function of X.",
      "question": "How does logistic regression algorithm work"
    },
    {
      "answer": "In the study of probability theory, the central limit theorem (CLT) states that the distribution of sample approximates a normal distribution (also known as a \u201cbell curve\u201d) as the sample size becomes larger, assuming that all samples are identical in size, and regardless of the population distribution shape.",
      "question": "What is central limit theorem in probability"
    },
    {
      "answer": "Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)",
      "question": "What is learning algorithm in machine learning"
    },
    {
      "answer": "Risk tolerance",
      "question": "What is the opposite of risk aversion"
    },
    {
      "answer": "There are basically two methods to reduce autocorrelation, of which the first one is most important:Improve model fit. Try to capture structure in the data in the model.  If no more predictors can be added, include an AR1 model.",
      "question": "How do you fix autocorrelation"
    },
    {
      "answer": "In statistics, Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference.",
      "question": "Is linear regression Bayesian"
    },
    {
      "answer": "0:3910:15Suggested clip \u00b7 118 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do a regression analysis with multiple variables"
    },
    {
      "answer": "Creative Ways to Benefit From Social Media AnalyticsEngage Better With Your Audience. Many businesses have a hard time keeping up with the vast amount of social media activity that impacts their brand.  Improve Customer Relations.  Monitor Your Competition.  Identify and Engage With Your Top Customers.  Find Out Where Your Industry is Heading.",
      "question": "What are the benefits of social media analytics"
    },
    {
      "answer": "Area in TailsConfidence LevelArea between 0 and z-scorez-score50%0.25000.67480%0.40001.28290%0.45001.64595%0.47501.9602 more rows",
      "question": "What is the z score for 50 confidence interval"
    },
    {
      "answer": "Advantages of Naive Bayes ClassifierIt is simple and easy to implement.It doesn't require as much training data.It handles both continuous and discrete data.It is highly scalable with the number of predictors and data points.It is fast and can be used to make real-time predictions.More items\u2022",
      "question": "What are the advantages of using a naive Bayes classifier as opposed to other methods"
    },
    {
      "answer": "Since a Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.",
      "question": "How does naive Bayes work in text classification"
    },
    {
      "answer": "The Taguchi loss function is graphical depiction of loss developed by the Japanese business statistician Genichi Taguchi to describe a phenomenon affecting the value of products produced by a company.  This means that if the product dimension goes out of the tolerance limit the quality of the product drops suddenly.",
      "question": "What does the Taguchi loss function indicate"
    },
    {
      "answer": "Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.",
      "question": "How does the Adam Optimizer work"
    },
    {
      "answer": "In (and after) TensorFlow version 0.11. 0RC1, you can save and restore your model directly by calling tf. train. export_meta_graph and tf.",
      "question": "How do I save and restore model in Tensorflow"
    },
    {
      "answer": "In computer science, a universal Turing machine (UTM) is a Turing machine that simulates an arbitrary Turing machine on arbitrary input.  In terms of computational complexity, a multi-tape universal Turing machine need only be slower by logarithmic factor compared to the machines it simulates.",
      "question": "What is universal Turing machine in TOC"
    },
    {
      "answer": "A feature vector is just a vector that contains information describing an object's important characteristics. In image processing, features can take many forms. A simple feature representation of an image is the raw intensity value of each pixel. However, more complicated feature representations are also possible.",
      "question": "What is CNN feature vector"
    },
    {
      "answer": "The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.",
      "question": "What is weighted kappa"
    },
    {
      "answer": "Decision Tree node splitting is an important step, the core issue is how to choose the splitting attribute.  5, the splitting criteria is calculating information gain of each attribute, then the attribute with the maximum information gain or information gain ratio is selected as splitting attribute.",
      "question": "What is splitting criterion in data mining"
    },
    {
      "answer": "Multinomial logistic regression does have assumptions, such as the assumption of independence among the dependent variable choices. This assumption states that the choice of or membership in one category is not related to the choice or membership of another category (i.e., the dependent variable).",
      "question": "What are the assumptions of multinomial logistic regression"
    },
    {
      "answer": "he confidence interval tells you more than just the possible range around the estimate. It also tells you about how stable the estimate is. A stable estimate is one that would be close to the same value if the survey were repeated.",
      "question": "What does the confidence interval tell you"
    },
    {
      "answer": "Assuming the sample size is constant across sampling methods, cluster sampling generally provides less precision than either simple random sampling or stratified sampling. This is the main disadvantage of cluster sampling.",
      "question": "What is the disadvantage of cluster sampling"
    },
    {
      "answer": "The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. A supervised machine learning algorithm uses historical data to learn patterns and uncover relationships between other features of your dataset and the target.",
      "question": "What is a target in machine learning"
    },
    {
      "answer": "Bias is stated as a penchant that prevents objective consideration of an issue or situation; basically the formation of opinion beforehand without any examination. Selection is stated as the act of choosing or selecting a preference; resulting in a carefully chosen and representative choice.",
      "question": "What is the difference between bias and selection"
    },
    {
      "answer": "Using proper validation techniques helps you understand your model, but most importantly, estimate an unbiased generalization performance.Splitting your data.  k-Fold Cross-Validation (k-Fold CV)  Leave-one-out Cross-Validation (LOOCV)  Nested Cross-Validation.  Time Series CV.  Comparing Models.",
      "question": "How do you validate a model performance"
    },
    {
      "answer": "One drawback of boxplots is that they tend to emphasize the tails of a distribution, which are the least certain points in the data set. They also hide many of the details of the distribution.",
      "question": "What are the disadvantages of a box plot"
    },
    {
      "answer": "Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.",
      "question": "How would you prepare a dataset for deep learning"
    },
    {
      "answer": "\u2013 Rejection sampling: reject samples disagreeing with evidence. \u2013 Markov chain Monte Carlo (MCMC): sample from a stochastic process. whose stationary distribution is the true posterior.",
      "question": "What does rejection sampling mean in Bayesian nets"
    },
    {
      "answer": "Every probability pi is a number between 0 and 1, and the sum of all the probabilities is equal to 1. Examples of discrete random variables include: The number of eggs that a hen lays in a given day (it can't be 2.3) The number of people going to a given soccer match.",
      "question": "What is an example of a discrete random variable"
    },
    {
      "answer": "A sequence of random variables is covariance stationary if all the terms of the sequence have the same mean, and if the covariance between any two terms of the sequence depends only on the relative positions of the two terms, that is, on how far apart they are located from each other, and not on their absolute position",
      "question": "How do you prove covariance stationary"
    },
    {
      "answer": "Auxiliary Classifiers are type of architectural component that seek to improve the convergence of very deep networks. They are classifier heads we attach to layers before the end of the network.",
      "question": "What is auxiliary classifier"
    },
    {
      "answer": "Try to avoid implementing cheap tricks to make your code run faster.Optimize your Code using Appropriate Algorithm.  Optimize Your Code for Memory.  printf and scanf Vs cout and cin.  Using Operators.  if Condition Optimization.  Problems with Functions.  Optimizing Loops.  Data Structure Optimization.More items\u2022",
      "question": "How do you optimize code"
    },
    {
      "answer": "Word2Vec slightly customizes the process and calls it negative sampling. In Word2Vec, the words for the negative samples (used for the corrupted pairs) are drawn from a specially designed distribution, which favours less frequent words to be drawn more often.",
      "question": "What is negative sampling in Word2Vec"
    },
    {
      "answer": "Feature extraction is a general term for methods of constructing combinations of the variables to get around these problems while still describing the data with sufficient accuracy. Many machine learning practitioners believe that properly optimized feature extraction is the key to effective model construction.",
      "question": "What are feature extraction algorithms"
    },
    {
      "answer": "A discrete distribution is a statistical distribution that shows the probabilities of discrete (countable) outcomes, such as 1, 2, 3  Overall, the concepts of discrete and continuous probability distributions and the random variables they describe are the underpinnings of probability theory and statistical analysis.",
      "question": "What are discrete distributions"
    },
    {
      "answer": "Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing (NLP), speech recognition and machine vision.",
      "question": "Is AI Artificial Intelligence"
    },
    {
      "answer": "2 Answers. If you have two classes (i.e. binary classification), you should use a binary crossentropy loss. If you have more than two you should use a categorical crossentropy loss.",
      "question": "How do I tell which loss function is suitable for image classification"
    },
    {
      "answer": "Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.  Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy.",
      "question": "Does unlabeled data really help in semi supervised learning"
    },
    {
      "answer": "Classification is a type of supervised learning. It specifies the class to which data elements belong to and is best used when the output has finite and discrete values. It predicts a class for an input variable as well.",
      "question": "What is ML classification"
    },
    {
      "answer": "As already discussed, SVM aims at maximizing the geometric margin and returns the corresponding hyperplane.  Such points are called as support vectors (fig. - 1). Therefore, the optimization problem as defined above is equivalent to the problem of maximizing the margin value (not geometric/functional margin values).",
      "question": "What does SVM optimize"
    },
    {
      "answer": "At Google, we call it Wide & Deep Learning. It's useful for generic large-scale regression and classification problems with sparse inputs (categorical features with a large number of possible feature values), such as recommender systems, search, and ranking problems.",
      "question": "What is wide and deep learning"
    },
    {
      "answer": "A studentized residual is calculated by dividing the residual by an estimate of its standard deviation. The standard deviation for each residual is computed with the observation excluded. For this reason, studentized residuals are sometimes referred to as externally studentized residuals.",
      "question": "How do you find the Studentized residual"
    },
    {
      "answer": "Poisson Formula. P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to \u03bc . The variance is also equal to \u03bc .",
      "question": "What is Poisson distribution formula"
    },
    {
      "answer": "F-test is used either for testing the hypothesis about the equality of two population variances or the equality of two or more population means. The equality of two population means was dealt with t-test. Besides a t-test, we can also apply F-test for testing equality of two population means.",
      "question": "What are the applications of F test"
    },
    {
      "answer": "The value of the odds ratio tells you how much more likely someone under 25 might be to make a claim, for example, and the associated confidence interval indicates the degree of uncertainty associated with that ratio.",
      "question": "How do you interpret confidence intervals and odds ratio"
    },
    {
      "answer": "Cross Entropy is definitely a good loss function for Classification Problems, because it minimizes the distance between two probability distributions - predicted and actual.  So cross entropy make sure we are minimizing the difference between the two probability. This is the reason.",
      "question": "Why is cross entropy used for classification"
    },
    {
      "answer": "Class limits specify the span of data values that fall within a class. Class boundaries are values halfway between the upper class limit of one class and the lower class limit of the next.  Class limits are not possible data values. Class boundaries specify the span of data values that fall within a class.",
      "question": "What is the difference between a class boundary in a class limit"
    },
    {
      "answer": "Unsupervised feature learning is learning features from unlabeled data. The goal of unsupervised feature learning is often to discover low-dimensional features that captures some structure underlying the high-dimensional input data.",
      "question": "What is unsupervised feature learning"
    },
    {
      "answer": "Statistically significant means a result is unlikely due to chance. The p-value is the probability of obtaining the difference we saw from a sample (or a larger one) if there really isn't a difference for all users.  Statistical significance doesn't mean practical significance.",
      "question": "What does it mean if a test is not statistically significant"
    },
    {
      "answer": "Motivation. Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization.  Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.",
      "question": "Why do we normalize a feature"
    },
    {
      "answer": "Naive Bayes uses a similar method to predict the probability of different class based on various attributes. This algorithm is mostly used in text classification and with problems having multiple classes.",
      "question": "In what real world applications is Naive Bayes classifier used"
    },
    {
      "answer": "Implementing Deep Q-Learning using TensorflowPrerequisites: Deep Q-Learning.Step 1: Importing the required libraries.Step 2: Building the Environment.Step 3: Building the learning agent.Step 4: Finding the Optimal Strategy.The agent tries different methods to reach the top and thus gaining knowledge from each episode.Step 5: Testing the Learning Agent.More items\u2022",
      "question": "How is deep Q learning implemented"
    },
    {
      "answer": "Q-learning is called off-policy because the updated policy is different from the behavior policy, so Q-Learning is off-policy. In other words, it estimates the reward for future actions and appends a value to the new state without actually following any greedy policy.",
      "question": "Why Q learning is off policy"
    },
    {
      "answer": "The formula for calculating a z-score is is z = (x-\u03bc)/\u03c3, where x is the raw score, \u03bc is the population mean, and \u03c3 is the population standard deviation. As the formula shows, the z-score is simply the raw score minus the population mean, divided by the population standard deviation.",
      "question": "How do you calculate z score normalization"
    },
    {
      "answer": "How to find accuracy of ARIMA model?Problem description: Prediction on CPU utilization.  Step 1: From Elasticsearch I collected 1000 observations and exported on Python.Step 2: Plotted the data and checked whether data is stationary or not.Step 3: Used log to convert the data into stationary form.Step 4: Done DF test, ACF and PACF.More items\u2022",
      "question": "How do you know if Arima model is accurate"
    },
    {
      "answer": "Generally a cosine similarity between two documents is used as a similarity measure of documents. In Java, you can use Lucene (if your collection is pretty large) or LingPipe to do this. The basic concept would be to count the terms in every document and calculate the dot product of the term vectors.",
      "question": "How do you find the similarity between two documents"
    },
    {
      "answer": "The significance level for a given hypothesis test is a value for which a P-value less than or equal to is considered statistically significant. Typical values for are 0.1, 0.05, and 0.01. These values correspond to the probability of observing such an extreme value by chance.",
      "question": "What does a significance level of 0.01 mean"
    },
    {
      "answer": "We will learn Classification algorithms, types of classification algorithms, support vector machines(SVM), Naive Bayes, Decision Tree and Random Forest Classifier in this tutorial.",
      "question": "What are the different classifiers in machine learning"
    },
    {
      "answer": "the condition or quality of being true, correct, or exact; freedom from error or defect; precision or exactness; correctness. Chemistry, Physics. the extent to which a given measurement agrees with the standard value for that measurement. Compare precision (def. 6).",
      "question": "What do you mean accuracy"
    },
    {
      "answer": "In statistics, self-selection bias arises in any situation in which individuals select themselves into a group, causing a biased sample with nonprobability sampling.  In such fields, a poll suffering from such bias is termed a self-selected listener opinion poll or \"SLOP\".",
      "question": "What does self selection bias mean"
    },
    {
      "answer": "A normality test is used to determine whether sample data has been drawn from a normally distributed population (within some tolerance). A number of statistical tests, such as the Student's t-test and the one-way and two-way ANOVA require a normally distributed sample population.",
      "question": "What does a normality test show"
    },
    {
      "answer": "Importance sampling is a useful technique for investigating the properties of a distri- bution while only having samples drawn from a different (proposal) distribution.",
      "question": "Whats the advantage of importance sampling"
    },
    {
      "answer": "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.",
      "question": "What is the purpose of batch normalization"
    },
    {
      "answer": "In machine learning, the hinge loss is a loss function used for training classifiers. The hinge loss is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs). For an intended output t = \u00b11 and a classifier score y, the hinge loss of the prediction y is defined as.",
      "question": "What is hinge loss in machine learning"
    },
    {
      "answer": "Adaptive resonance theory is a type of neural network technique developed by Stephen Grossberg and Gail Carpenter in 1987. The basic ART uses unsupervised learning technique.",
      "question": "What type of learning is involved in Adaptive Resonance Theory"
    },
    {
      "answer": "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.",
      "question": "What is the use of matrix factorization"
    },
    {
      "answer": "So, a highly significant intercept in your model is generally not a problem. By the same token, if the intercept is not significant you usually would not want to remove it from the model because by doing this you are creating a model that says that the response function must be zero when the predictors are all zero.",
      "question": "What if intercept is not significant in regression"
    },
    {
      "answer": "In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.",
      "question": "When would you use a hierarchical model"
    },
    {
      "answer": "The true error rate is statistically defined as the error rate of the classifier on a large number of new cases that converge in the limit to the actual population distribution.  It turns out that there are a number of ways of presenting sample cases to a classifier to get better estimates of the true error rate.",
      "question": "What is true error rate"
    },
    {
      "answer": "One-shot learning is a classification task where one example (or a very small number of examples) is given for each class, that is used to prepare a model, that in turn must make predictions about many unknown examples in the future.",
      "question": "How does SHOT learning work"
    },
    {
      "answer": "Keras is a high-level interface and uses Theano or Tensorflow for its backend. It runs smoothly on both CPU and GPU. Keras supports almost all the models of a neural network \u2013 fully connected, convolutional, pooling, recurrent, embedding, etc. Furthermore, these models can be combined to build more complex models.",
      "question": "Is keras a part of TensorFlow"
    },
    {
      "answer": "Disadvantages of Sampling Since choice of sampling method is a judgmental task, there exist chances of biasness as per the mindset of the person who chooses it. Improper selection of sampling techniques may cause the whole process to defunct. Selection of proper size of samples is a difficult job.",
      "question": "What are the disadvantages of sampling"
    },
    {
      "answer": "Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks. Perceptron is a linear classifier (binary). Also, it is used in supervised learning. It helps to classify the given input data.",
      "question": "Is neural network a linear classifier"
    },
    {
      "answer": "AUC represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.  AUC is scale-invariant.",
      "question": "What is AUC score in machine learning"
    },
    {
      "answer": "Def: A uniform random permutation is one in which each of the n! possible permutations are equally likely.  Def Given a set of n elements, a k-permutation is a sequence containing k of the n elements.",
      "question": "What is uniform random permutation"
    },
    {
      "answer": "The standard error is also inversely proportional to the sample size; the larger the sample size, the smaller the standard error because the statistic will approach the actual value. The standard error is considered part of descriptive statistics. It represents the standard deviation of the mean within a dataset.",
      "question": "How does sample size effect standard error"
    },
    {
      "answer": "Therefore, a low test\u2013retest reliability correlation might be indicative of a measure with low reliability, of true changes in the persons being measured, or both. That is, in the test\u2013retest method of estimating reliability, it is not possible to separate the reliability of measure from its stability.",
      "question": "What does low test retest reliability mean"
    },
    {
      "answer": "2.1 Steps of Bayesian Data Analysis Choose a statistical model for the data in relation to the research questions. The model should have good theoretical justification and have parameters that are meaningful for the research questions.  Obtain the posterior distributions for the model parameters.",
      "question": "What are the steps involved in Bayesian data analysis"
    },
    {
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch.",
      "question": "How does a regression tree work"
    },
    {
      "answer": "Quality Glossary Definition: Reliability. Reliability is defined as the probability that a product, system, or service will perform its intended function adequately for a specified period of time, or will operate in a defined environment without failure.",
      "question": "What do you mean by reliability"
    },
    {
      "answer": "You can tell if two random variables are independent by looking at their individual probabilities. If those probabilities don't change when the events meet, then those variables are independent. Another way of saying this is that if the two variables are correlated, then they are not independent.",
      "question": "How do you prove that two distributions are independent"
    },
    {
      "answer": "The original AlphaGo demonstrated superhuman Go-playing ability, but needed the expertise of human players to get there. Namely, it used a dataset of more than 100,000 Go games as a starting point for its own knowledge. AlphaGo Zero, by comparison, has only been programmed with the basic rules of Go.",
      "question": "Why was AlphaGo able to play go so well"
    },
    {
      "answer": "A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.",
      "question": "What is the difference between false positive and false negative"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.",
      "question": "Why does bootstrap work in machine learning"
    },
    {
      "answer": "7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.",
      "question": "What do you do with an unbalanced data set"
    },
    {
      "answer": "frequency\u2013inverse document frequency",
      "question": "What does TF IDF stand for"
    },
    {
      "answer": "Descriptive, prescriptive, and normative are three main areas of decision theory and each studies a different type of decision making.",
      "question": "What are the different theories of decision making"
    },
    {
      "answer": "Positive feedback occurs to increase the change or output: the result of a reaction is amplified to make it occur more quickly.  Some examples of positive feedback are contractions in child birth and the ripening of fruit; negative feedback examples include the regulation of blood glucose levels and osmoregulation.",
      "question": "What is an example of positive feedback"
    },
    {
      "answer": "Moments are are very useful in statistics because they tell you much about your data. There are four commonly used moments in statistics: the mean, variance, skewness, and kurtosis. The mean gives you a measure of center of the data.",
      "question": "What are the uses of moments"
    },
    {
      "answer": "Kalman filters combine two sources of information, the predicted states and noisy measurements, to produce optimal, unbiased estimates of system states. The filter is optimal in the sense that it minimizes the variance in the estimated states.",
      "question": "Is Kalman filter optimal"
    },
    {
      "answer": "AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.",
      "question": "What is AB testing in Analytics"
    },
    {
      "answer": "The technique of Monte Carlo Simulation (MCS) was originally developed for use in nuclear weapons design. It provides an efficient way to simulate processes involving chance and uncertainty and can be applied in areas as diverse as market sizing, customer lifetime value measurement and customer service management.",
      "question": "What are some interesting applications of Monte Carlo method"
    },
    {
      "answer": "Regularized regression is a type of regression where the coefficient estimates are constrained to zero. The magnitude (size) of coefficients, as well as the magnitude of the error term, are penalized. Complex models are discouraged, primarily to avoid overfitting.",
      "question": "What is regularization coefficient"
    },
    {
      "answer": "Essentially, the process goes as follows:Select k centroids. These will be the center point for each segment.Assign data points to nearest centroid.Reassign centroid value to be the calculated mean value for each cluster.Reassign data points to nearest centroid.Repeat until data points stay in the same cluster.",
      "question": "How do you find the centroid in K means clustering"
    },
    {
      "answer": "Increase Training Dataset Size Leaning on the law of large numbers, perhaps the simplest approach to reduce the model variance is to fit the model on more training data. In those cases where more data is not readily available, perhaps data augmentation methods can be used instead.",
      "question": "How do you reduce variance in machine learning"
    },
    {
      "answer": "Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).",
      "question": "What is conditional probability examples"
    },
    {
      "answer": "Eigenvectors can be used to represent a large dimensional matrix. This means that a matrix M and a vector o can be replaced by a scalar n and a vector o. In this instance, o is the eigenvector and n is the eigenvalue and our target is to find o and n.",
      "question": "What do the eigenvectors indicate"
    },
    {
      "answer": "Singularity enables users to have full control of their environment. Singularity containers can be used to package entire scientific workflows, software and libraries, and even data.  The Singularity software can import your Docker images without having Docker installed or being a superuser.",
      "question": "What is singularity container"
    },
    {
      "answer": "An activation function is a function used in artificial neural networks which outputs a small value for small inputs, and a larger value if its inputs exceed a threshold. If the inputs are large enough, the activation function \"fires\", otherwise it does nothing.",
      "question": "What is the definition of squashing function in machine learning"
    },
    {
      "answer": "The most important difference between deep learning and traditional machine learning is its performance as the scale of data increases. When the data is small, deep learning algorithms don't perform that well. This is because deep learning algorithms need a large amount of data to understand it perfectly.",
      "question": "Which of the following is true with regards to classical machine learning vs deep learning"
    },
    {
      "answer": "A CNN has multiple layers. Weight sharing happens across the receptive field of the neurons(filters) in a particular layer. Weights are the numbers within each filter.  These filters act on a certain receptive field/ small section of the image. When the filter moves through the image, the filter does not change.",
      "question": "What is weight sharing in CNN"
    },
    {
      "answer": "If we assume that there is some variation in our data, we will be able to disregard the possibility that either of these standard deviations is zero. Therefore the sign of the correlation coefficient will be the same as the sign of the slope of the regression line.",
      "question": "Is there a relationship between the correlation coefficient and the slope of a linear regression line"
    },
    {
      "answer": "In General, A Discriminative model \u200cmodels the decision boundary between the classes. A Generative Model \u200cexplicitly models the actual distribution of each class.  A Discriminative model \u200clearns the conditional probability distribution p(y|x). Both of these models were generally used in supervised learning problems.",
      "question": "What is the difference between generative and discriminative models"
    },
    {
      "answer": "In signal processing, the Fourier transform can reveal important characteristics of a signal, namely, its frequency components. y k + 1 = \u2211 j = 0 n - 1 \u03c9 j k x j + 1 . \u03c9 = e - 2 \u03c0 i / n is one of n complex roots of unity where i is the imaginary unit. For x and y , the indices j and k range from 0 to n - 1 .",
      "question": "How do you find the Fourier transform of a signal"
    },
    {
      "answer": "Transfer learning is useful when you have insufficient data for a new domain you want handled by a neural network and there is a big pre-existing data pool that can be transferred to your problem.",
      "question": "What is transfer learning and how is it useful"
    },
    {
      "answer": "In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).",
      "question": "What is agent system in artificial intelligence"
    },
    {
      "answer": "Lasso Regression Another Tolerant Method for dealing with multicollinearity known as Least Absolute Shrinkage and Selection Operator (LASSO) regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity.",
      "question": "Does Lasso regression take care of Multicollinearity"
    },
    {
      "answer": "Classification is one of the most fundamental concepts in data science. Classification algorithms are predictive calculations used to assign data to preset categories by analyzing sets of training data.\u1042\u1040\u1042\u1040\u104a \u1029 \u1042\u1046",
      "question": "What are classification algorithms in machine learning"
    },
    {
      "answer": "The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients. And gradients are used to update the weights of the Neural Net.",
      "question": "What is loss in a neural network"
    },
    {
      "answer": "How to train your Deep Neural NetworkTraining data.  Choose appropriate activation functions.  Number of Hidden Units and Layers.  Weight Initialization.  Learning Rates.  Hyperparameter Tuning: Shun Grid Search - Embrace Random Search.  Learning Methods.  Keep dimensions of weights in the exponential power of 2.More items\u2022",
      "question": "How do I train a deep neural network"
    },
    {
      "answer": "Model calibration is the process of adjustment of the model parameters and forcing within the margins of the uncertainties (in model parameters and / or model forcing) to obtain a model representation of the processes of interest that satisfies pre-agreed criteria (Goodness-of-Fit or Cost Function).",
      "question": "What does model calibration mean"
    },
    {
      "answer": "Statistics is a very good major in terms of job market and salary scale, it also open doors for many graduate courses, unless you are poor at math ,statistics is worth taking.",
      "question": "Is a statistics degree useful"
    },
    {
      "answer": "In this module, we have discussed on various data preprocessing methods for Machine Learning such as rescaling, binarizing, standardizing, one hot encoding, and label encoding.",
      "question": "Which method is used for data preprocessing in machine learning"
    },
    {
      "answer": "KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.",
      "question": "Why KNN algorithm is used"
    },
    {
      "answer": "The Analysis of covariance (ANCOVA) is done by using linear regression. This means that Analysis of covariance (ANCOVA) assumes that the relationship between the independent variable and the dependent variable must be linear in nature.",
      "question": "How is analysis of covariance done"
    },
    {
      "answer": "The difference between quota sampling and stratified sampling is: although both \"group\" participants by an important characteristic, stratified sampling relies on random selection within each group, while quota sampling relies on convenience sampling within each group.",
      "question": "What is the difference between quota sampling and stratified sampling"
    },
    {
      "answer": "Support Vector Machine can also be used as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.",
      "question": "Can SVM used for regression"
    },
    {
      "answer": "Predictive analytics is the use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data. The goal is to go beyond knowing what has happened to providing a best assessment of what will happen in the future.",
      "question": "What do you mean by predictive analytics"
    },
    {
      "answer": "The Bayesian Optimization algorithm can be summarized as follows:Select a Sample by Optimizing the Acquisition Function.Evaluate the Sample With the Objective Function.Update the Data and, in turn, the Surrogate Function.Go To 1.",
      "question": "How do I implement a Bayesian optimization"
    },
    {
      "answer": "Handling overfittingReduce the network's capacity by removing layers or reducing the number of elements in the hidden layers.Apply regularization , which comes down to adding a cost to the loss function for large weights.Use Dropout layers, which will randomly remove certain features by setting them to zero.",
      "question": "How do you deal with Overfitting in deep learning"
    },
    {
      "answer": "In summary, model parameters are estimated from data automatically and model hyperparameters are set manually and are used in processes to help estimate model parameters. Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that must be set manually and tuned.",
      "question": "What is the difference between a model parameter and a learning algorithm\u2019s hyper parameter"
    },
    {
      "answer": "A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input.",
      "question": "What is the use of convolutional neural network"
    },
    {
      "answer": "Concept shift is closely related to concept drift. This occurs when a model learned from data sampled from one distribution needs to be applied to data drawn from another.",
      "question": "What is Concept shift"
    },
    {
      "answer": "Null and alternate hypothesis are different and you can't interchange them. Alternate hypothesis is just the opposite of null which means there is a statistical difference in Mean / median of both the data sets.",
      "question": "Can I switch around the null and alternative hypothesis in hypothesis testing"
    },
    {
      "answer": "Three keys to managing bias when building AIChoose the right learning model for the problem. There's a reason all AI models are unique: Each problem requires a different solution and provides varying data resources.  Choose a representative training data set.  Monitor performance using real data.",
      "question": "How can machine learning overcome bias"
    },
    {
      "answer": "For a hypothesis test, a researcher collects sample data.  If the statistic falls within a specified range of values, the researcher rejects the null hypothesis . The range of values that leads the researcher to reject the null hypothesis is called the region of rejection.",
      "question": "What is the region of rejection"
    },
    {
      "answer": "The Purpose of Statistics: Statistics teaches people to use a limited sample to make intelligent and accurate conclusions about a greater population. The use of tables, graphs, and charts play a vital role in presenting the data being used to draw these conclusions.",
      "question": "What is statistics and its purpose"
    },
    {
      "answer": "To calculate the similarity between two examples, you need to combine all the feature data for those two examples into a single numeric value. For instance, consider a shoe data set with only one feature: shoe size. You can quantify how similar two shoes are by calculating the difference between their sizes.",
      "question": "How do you calculate similarity"
    },
    {
      "answer": "Some of the more common ways to normalize data include:Transforming data using a z-score or t-score.  Rescaling data to have values between 0 and 1.  Standardizing residuals: Ratios used in regression analysis can force residuals into the shape of a normal distribution.Normalizing Moments using the formula \u03bc/\u03c3.More items",
      "question": "How do you normalize data in statistics"
    },
    {
      "answer": "If your regression model contains independent variables that are statistically significant, a reasonably high R-squared value makes sense.  Correspondingly, the good R-squared value signifies that your model explains a good proportion of the variability in the dependent variable.",
      "question": "What do you report in a multiple regression to say whether the variables are significant or not"
    },
    {
      "answer": "Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.",
      "question": "How do you tell if an event is independent or dependent"
    },
    {
      "answer": "3 layers",
      "question": "How many layers are there in deep learning"
    },
    {
      "answer": "There is a broad range of opportunities to study optimization problems that cannot be solved with an exact algorithm.  This work proposes the use of neural networks such as heuristics to resolve optimization problems in those cases where the use of linear programming or Lagrange multipliers is not feasible.",
      "question": "Can neural networks be used for optimization"
    },
    {
      "answer": "While implementing the decision tree we will go through the following two phases:Building Phase. Preprocess the dataset. Split the dataset from train and test using Python sklearn package. Train the classifier.Operational Phase. Make predictions. Calculate the accuracy.",
      "question": "How do you implement a decision tree"
    },
    {
      "answer": "For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length of time, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts.",
      "question": "What is exponential distribution example"
    },
    {
      "answer": "In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body.",
      "question": "What is topic Modelling used for"
    },
    {
      "answer": "Because the distance function used to find the k nearest neighbors is not linear, so it usually won't lead to a linear decision boundary.  kNN does not build a model of your data, it simply assumes that instances that are close together in space are similar.",
      "question": "Can Knn have linear decision boundary"
    },
    {
      "answer": "AlphaGo Zero is a version of DeepMind's Go software AlphaGo.  By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days.",
      "question": "What is significant about Alpha Go Zero"
    },
    {
      "answer": "Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).",
      "question": "What is the difference between discrete and continuous distribution"
    },
    {
      "answer": "The bits of linguistic information that enter into one person's mind, from another, cause people to entertain a new thought with profound effects on his world knowledge, inferencing, and subsequent behavior. Language neither creates nor distorts conceptual life. Thought comes first, while language is an expression.",
      "question": "What is the relationship between language and thought"
    },
    {
      "answer": "Machine learning, a subset of artificial intelligence (AI), depends on the quality, objectivity and size of training data used to teach it.  Machine learning bias generally stems from problems introduced by the individuals who design and/or train the machine learning systems.",
      "question": "Is Machine Learning Biased"
    },
    {
      "answer": "TensorFlow Lite inferenceAndroid Platform.iOS Platform.Linux Platform.",
      "question": "Which devices support TensorFlow Lite for inference"
    },
    {
      "answer": "Jakob Bernoulli",
      "question": "Who created the law of averages"
    },
    {
      "answer": "Simple regression analysis uses a single x variable for each dependent \u201cy\u201d variable. For example: (x1, Y1). Multiple regression uses multiple \u201cx\u201d variables for each independent variable: (x1)1, (x2)1, (x3)1, Y1).",
      "question": "What is a regression model example"
    },
    {
      "answer": "Training deep learning neural networks is very challenging. The best general algorithm known for solving this problem is stochastic gradient descent, where model weights are updated each iteration using the backpropagation of error algorithm. Optimization in general is an extremely difficult task.",
      "question": "What are the challenges in training a neural network"
    },
    {
      "answer": "In robust statistics, robust regression is a form of regression analysis designed to overcome some limitations of traditional parametric and non-parametric methods. Regression analysis seeks to find the relationship between one or more independent variables and a dependent variable.",
      "question": "What are robust regressions and robust statistics"
    },
    {
      "answer": "The term \u201cmultivariate statistics\u201d is appropriately used to include all statistics where there are more than two variables simultaneously analyzed. You are already familiar with bivariate statistics such as the Pearson product moment correlation coefficient and the independent groups t-test.",
      "question": "What is multivariate variable"
    },
    {
      "answer": "Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.",
      "question": "What does regression analysis tell you"
    },
    {
      "answer": "The most common hash functions used in digital forensics are Message Digest 5 (MD5), and Secure Hashing Algorithm (SHA) 1 and 2.",
      "question": "What are the two common hash functions"
    },
    {
      "answer": "Multiclass classification with logistic regression can be done either through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.",
      "question": "How do you use logistic regression for multi class classification"
    },
    {
      "answer": "Bias can damage research, if the researcher chooses to allow his bias to distort the measurements and observations or their interpretation. When faculty are biased about individual students in their courses, they may grade some students more or less favorably than others, which is not fair to any of the students.",
      "question": "Why is being bias bad"
    },
    {
      "answer": "Forward chaining starts from known facts and applies inference rule to extract more data unit it reaches to the goal. Backward chaining starts from the goal and works backward through inference rules to find the required facts that support the goal.  Backward chaining reasoning applies a depth-first search strategy.",
      "question": "What is forward and backward chaining in AI"
    },
    {
      "answer": "Random error can be reduced by: Using an average measurement from a set of measurements, or. Increasing sample size.",
      "question": "What is random error and how can it be reduced"
    },
    {
      "answer": "An example of pattern recognition is classification, which attempts to assign each input value to one of a given set of classes (for example, determine whether a given email is \"spam\" or \"non-spam\").  This is opposed to pattern matching algorithms, which look for exact matches in the input with pre-existing patterns.",
      "question": "What is an example of pattern recognition"
    },
    {
      "answer": "In short, Softmax Loss is actually just a Softmax Activation plus a Cross-Entropy Loss. Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.",
      "question": "Is the softmax loss the same as the cross entropy loss"
    },
    {
      "answer": "In Convolutional Neural Networks, Filters detect spatial patterns such as edges in an image by detecting the changes in intensity values of the image.",
      "question": "What are filters in neural networks"
    },
    {
      "answer": "Covariance Matrix is a measure of how much two random variables gets change together.  The Covariance Matrix is also known as dispersion matrix and variance-covariance matrix. The covariance between two jointly distributed real-valued random variables X and Y with finite second moments is defined as.",
      "question": "What is covariance matrix example"
    },
    {
      "answer": "Deconvolution layer is a very unfortunate name and should rather be called a transposed convolutional layer. Visually, for a transposed convolution with stride one and no padding, we just pad the original input (blue entries) with zeroes (white entries) (Figure 1).",
      "question": "What is a deconvolution layer"
    },
    {
      "answer": "Examples in natural systems of swarm intelligence include bird flocking, ant foraging, and fish schooling. Inspired by swarm's such behavior, a class of algorithms is proposed for tackling optimization problems, usually under the title of swarm intelligence algorithms (SIAs) [203].",
      "question": "What are the common aspects of swarm intelligence observed in nature"
    },
    {
      "answer": "Simple random sampling: By using the random number generator technique, the researcher draws a sample from the population called simple random sampling. Simple random samplings are of two types.  Cluster sampling: Cluster sampling occurs when a random sample is drawn from certain aggregational geographical groups.",
      "question": "Is cluster sampling random or non random"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.  That when using the bootstrap you must choose the size of the sample and the number of repeats.",
      "question": "What is bootstrap method in statistics"
    },
    {
      "answer": "Principal components analysis (PCA) is a statistical technique that allows identifying underlying linear patterns in a data set so it can be expressed in terms of other data set of a significatively lower dimension without much loss of information.",
      "question": "What is PCA in neural network"
    },
    {
      "answer": "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value.",
      "question": "What is the use of ridge regression"
    },
    {
      "answer": "A hypothesis is an approximate explanation that relates to the set of facts that can be tested by certain further investigations. There are basically two types, namely, null hypothesis and alternative hypothesis. A research generally starts with a problem.",
      "question": "What are the two types of hypothesis testing"
    },
    {
      "answer": "One major disadvantage of non-probability sampling is that it's impossible to know how well you are representing the population. Plus, you can't calculate confidence intervals and margins of error.",
      "question": "What are the disadvantages of non probability sampling"
    },
    {
      "answer": "Univariate analysis is the simplest form of analyzing data. \u201cUni\u201d means \u201cone\u201d, so in other words your data has only one variable. It doesn't deal with causes or relationships (unlike regression ) and it's major purpose is to describe; It takes data, summarizes that data and finds patterns in the data.",
      "question": "How do you analyze univariate data"
    },
    {
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are: How trees are built: random forests builds each tree independently while gradient boosting builds one tree at a time.",
      "question": "What is the difference between random forest and gradient boosting"
    },
    {
      "answer": "Bias in Machine Learning is defined as the phenomena of observing results that are systematically prejudiced due to faulty assumptions.  This also results in bias which arises from the choice of training and test data and their representation of the true population.",
      "question": "What are bias in machine learning"
    },
    {
      "answer": "Categorical variables require special attention in regression analysis because, unlike dichotomous or continuous variables, they cannot by entered into the regression equation just as they are. Instead, they need to be recoded into a series of variables which can then be entered into the regression model.",
      "question": "Can you do multiple regression with categorical variables"
    },
    {
      "answer": "The larger the sample size is the smaller the effect size that can be detected. The reverse is also true; small sample sizes can detect large effect sizes.  Thus an appropriate determination of the sample size used in a study is a crucial step in the design of a study.",
      "question": "Is it important to determine the sample size"
    },
    {
      "answer": "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation is the default activation when developing multilayer Perceptron and convolutional neural networks.",
      "question": "What is ReLU function in neural network"
    },
    {
      "answer": "A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.",
      "question": "What's the difference between false negative and false positive"
    },
    {
      "answer": "The mean, expected value, or expectation of a random variable X is writ- ten as E(X) or \u00b5X. If we observe N random values of X, then the mean of the N values will be approximately equal to E(X) for large N. The expectation is defined differently for continuous and discrete random variables.",
      "question": "What is the expectation of a random variable"
    },
    {
      "answer": "Noun. optimizer (plural optimizers) A person in a large business whose task is to maximize profits and make the business more efficient. (computing) A program that uses linear programming to optimize a process. (computing) A compiler or assembler that produces optimized code.",
      "question": "What does Optimizer mean"
    },
    {
      "answer": "It is well known that correlation does not prove causation. What is less well known is that causation can exist when correlation is zero. The upshot of these two facts is that, in general and without additional information, correlation reveals literally nothing about causation.",
      "question": "Is it possible for two things to have a causal relationship but not be correlated"
    },
    {
      "answer": "Cost Function It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. Depending on the problem Cost Function can be formed in many different ways.",
      "question": "What is a cost function in machine learning"
    },
    {
      "answer": "Content-based filtering, makes recommendations based on user preferences for product features. Collaborative filtering mimics user-to-user recommendations. It predicts users preferences as a linear, weighted combination of other user preferences. Both methods have limitations.",
      "question": "What is the difference between content based filtering and collaborative filtering"
    },
    {
      "answer": "Yes, there are. One example is the WEKA MOA framework [1]. This framework implements standard algorithms in the literature of concept drift detection.  The nice thing about this framework is that it allows users to generate new data streams which contains concept drifts of different types.",
      "question": "Is there a good library for concept drift detection algorithms"
    },
    {
      "answer": "The random forest is a model made up of many decision trees. Rather than just simply averaging the prediction of trees (which we could call a \u201cforest\u201d), this model uses two key concepts that gives it the name random: Random sampling of training data points when building trees.",
      "question": "Why is random forest called random"
    },
    {
      "answer": "Logistic Regression, also known as Logit Regression or Logit Model, is a mathematical model used in statistics to estimate (guess) the probability of an event occurring having been given some previous data. Logistic Regression works with binary data, where either the event happens (1) or the event does not happen (0).",
      "question": "What is logistic regression simple explanation"
    },
    {
      "answer": "Explanation: Entropy (S) by the modern definition is the amount of energy dispersal in a system. Therefore, the system entropy will increase when the amount of motion within the system increases. For example, the entropy increases when ice (solid) melts to give water (liquid).",
      "question": "What does it mean when it says increase or decrease in entropy"
    },
    {
      "answer": "The main difference between Binomial and Poisson Distribution is that the Binomial distribution is only for a certain frame or a probability of success and the Poisson distribution is used for events that could occur a very large number of times.",
      "question": "What is the main difference between the binomial distribution and the Poisson distribution"
    },
    {
      "answer": "EXC functions both find a requested quartile of a supplied data set. The difference between these two functions is that QUARTILE. INC bases its calculation on a percentile range of 0 to 1 inclusive, whereas QUARTILE. EXC bases its calculation on a percentile range of 0 to 1 exclusive.",
      "question": "What is the difference between quartile exc and quartile inc"
    },
    {
      "answer": "A multi-agent system (MAS or \"self-organized system\") is a computerized system composed of multiple interacting intelligent agents.  Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning.",
      "question": "What are multi agents in artificial intelligence"
    },
    {
      "answer": "Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them.",
      "question": "What is data augmentation in deep learning"
    },
    {
      "answer": "Log loss is used when we have {0,1} response. This is usually because when we have {0,1} response, the best models give us values in terms of probabilities. In simple words, log loss measures the UNCERTAINTY of the probabilities of your model by comparing them to the true labels.",
      "question": "Why do we use log loss in logistic regression"
    },
    {
      "answer": "As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.",
      "question": "How do you work out Standardised scores"
    },
    {
      "answer": "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.  It is a term and set of techniques known in machine learning in the training and operation of deep learning models can be described in terms of tensors.",
      "question": "What is a tensor ML"
    },
    {
      "answer": "A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease. The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant.",
      "question": "What do negative coefficients mean in regression"
    },
    {
      "answer": "In machine learning, multiclass or multinomial classification is the problem of classifying instances into one of three or more classes (classifying instances into one of two classes is called binary classification).",
      "question": "What is multi class classification in machine learning"
    },
    {
      "answer": "Bias is a disproportionate weight in favor of or against an idea or thing, usually in a way that is closed-minded, prejudicial, or unfair. Biases can be innate or learned. People may develop biases for or against an individual, a group, or a belief. In science and engineering, a bias is a systematic error.",
      "question": "What does bias mean"
    },
    {
      "answer": "Steps for Making decision treeGet list of rows (dataset) which are taken into consideration for making decision tree (recursively at each nodes).Calculate uncertanity of our dataset or Gini impurity or how much our data is mixed up etc.Generate list of all question which needs to be asked at that node.More items\u2022",
      "question": "How do you make a decision in tree machine learning"
    },
    {
      "answer": "On each iteration, we update the parameters in the opposite direction of the gradient of the objective function J(w) w.r.t the parameters where the gradient gives the direction of the steepest ascent. The size of the step we take on each iteration to reach the local minimum is determined by the learning rate \u03b1.",
      "question": "How are the parameters updates during the gradient descent process"
    },
    {
      "answer": "In general, there is no universal rule of thumb indicating that the accuracy of a learner is directly proportional to the number of features used to train it.",
      "question": "Does increasing the number of feature variables of the dataset improve the accuracy of the training model"
    },
    {
      "answer": "Hidden Markov models are known for their applications to thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory, pattern recognition - such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and",
      "question": "Where does the hidden Markov model is used"
    },
    {
      "answer": "Face detection is a broader term than face recognition. Face detection just means that a system is able to identify that there is a human face present in an image or video.  Face recognition can confirm identity. It is therefore used to control access to sensitive areas.",
      "question": "What is difference between face detection and face recognition"
    },
    {
      "answer": "Significance level and p-value \u03b1 is the maximum probability of rejecting the null hypothesis when the null hypothesis is true. If \u03b1 = 1 we always reject the null, if \u03b1 = 0 we never reject the null hypothesis.  If we choose to compare the p-value to \u03b1 = 0.01, we are insisting on a stronger evidence!",
      "question": "How small of an alpha value can you choose and still have sufficient evidence to reject the null hypothesis"
    },
    {
      "answer": "You can use test statistics to determine whether to reject the null hypothesis. The test statistic compares your data with what is expected under the null hypothesis. The test statistic is used to calculate the p-value. A test statistic measures the degree of agreement between a sample of data and the null hypothesis.",
      "question": "What is the appropriate test statistic"
    },
    {
      "answer": "In mathematics, the operator norm is a means to measure the \"size\" of certain linear operators. Formally, it is a norm defined on the space of bounded linear operators between two given normed vector spaces.",
      "question": "What is the operator norm of a matrix"
    },
    {
      "answer": "How to Get Started with AIPick a topic you are interested in.Find a quick solution.Improve your simple solution.Share your solution.Repeat steps 1-4 for different problems.Complete a Kaggle competition.Use machine learning professionally.",
      "question": "How do I start learning artificial intelligence"
    },
    {
      "answer": "EdgeRank",
      "question": "What is the name for Facebook's ranking algorithm"
    },
    {
      "answer": "The distinction between probability and likelihood is fundamentally important: Probability attaches to possible results; likelihood attaches to hypotheses. Explaining this distinction is the purpose of this first column. Possible results are mutually exclusive and exhaustive.",
      "question": "What is difference between probability and likelihood"
    },
    {
      "answer": "Random assignment is however a process of randomly assigning subjects to experimental or control groups. This is a standard practice in true experimental research to ensure that treatment groups are similar (equivalent) to each other and to the control group, prior to treatment administration.",
      "question": "Are based on the idea that subjects are randomly assigned to groups"
    },
    {
      "answer": "A sampling distribution is a probability distribution of a statistic obtained from a larger number of samples drawn from a specific population. The sampling distribution of a given population is the distribution of frequencies of a range of different outcomes that could possibly occur for a statistic of a population.",
      "question": "What is a normal sample distribution"
    },
    {
      "answer": "Well labeled dataset can be used to train a custom model.In the Data Labeling Service UI, you create a dataset and import items into it from the same page.Open the Data Labeling Service UI.  Click the Create button in the title bar.On the Add a dataset page, enter a name and description for the dataset.More items",
      "question": "How do I create a labeled dataset"
    },
    {
      "answer": "Logic, as per the definition of the Oxford dictionary, is \"the reasoning conducted or assessed according to strict principles and validity\". In Artificial Intelligence also, it carries somewhat the same meaning. Logic can be defined as the proof or validation behind any reason provided.",
      "question": "What is logic in artificial intelligence"
    },
    {
      "answer": "Quartile deviation is the difference between \u201cfirst and third quartiles\u201d in any distribution. Standard deviation measures the \u201cdispersion of the data set\u201d that is relative to its mean.",
      "question": "What is the difference between standard deviation and quartile deviation"
    },
    {
      "answer": "Variance: Var(X) To calculate the Variance: square each value and multiply by its probability. sum them up and we get \u03a3x2p. then subtract the square of the Expected Value \u03bc",
      "question": "How do you find a variance of a function"
    },
    {
      "answer": "A deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables. It is a network of symmetrically coupled stochastic binary units. It comprises a set of visible units and layers of hidden units .",
      "question": "What is deep Boltzmann machine"
    },
    {
      "answer": "According to Bezdek (1994), Computational Intelligence is a subset of Artificial Intelligence. There are two types of machine intelligence: the artificial one based on hard computing techniques and the computational one based on soft computing methods, which enable adaptation to many situations.",
      "question": "What is computational intelligence and how is it related to AI"
    },
    {
      "answer": "Definition. Predictive analytics is an area of statistics that deals with extracting information from data and using it to predict trends and behavior patterns.  Predictive analytics statistical techniques include data modeling, machine learning, AI, deep learning algorithms and data mining.",
      "question": "How is predictive analytics done"
    },
    {
      "answer": "It is very much like the exponential distribution, with \u03bb corresponding to 1/p, except that the geometric distribution is discrete while the exponential distribution is continuous.",
      "question": "Is exponential distribution discrete or continuous"
    },
    {
      "answer": "For most common clustering software, the default distance measure is the Euclidean distance.  Correlation-based distance considers two objects to be similar if their features are highly correlated, even though the observed values may be far apart in terms of Euclidean distance.",
      "question": "What is distance measure in clustering"
    },
    {
      "answer": "A/B tests are easy and seem harmless, but many consumers become disturbed when they find out they're being tested without knowing it. Some argue that A/B testing tracks along the same ethical lines as a product launch; others believe organizations\u200b must be transparent about their testing even if it seems harmless.",
      "question": "Is a B testing ethical"
    },
    {
      "answer": "From the mathematical point of view, linear regression and ANOVA are identical: both break down the total variance of the data into different \u201cportions\u201d and verify the equality of these \u201csub-variances\u201d by means of a test (\u201cF\u201d Test).",
      "question": "Is Anova the same as linear regression"
    },
    {
      "answer": "1:3610:15Suggested clip \u00b7 117 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do a regression in Excel with multiple variables"
    },
    {
      "answer": "The General Linear Model (GLM) is a useful framework for comparing how several variables affect different continuous variables. In it's simplest form, GLM is described as: Data = Model + Error (Rutherford, 2001, p.3) GLM is the foundation for several statistical tests, including ANOVA, ANCOVA and regression analysis.",
      "question": "What is the general linear model GLM Why does it matter"
    },
    {
      "answer": "Word2Vec takes texts as training data for a neural network. The resulting embedding captures whether words appear in similar contexts. GloVe focuses on words co-occurrences over the whole corpus. Its embeddings relate to the probabilities that two words appear together.",
      "question": "What is the difference between GloVe and word2vec"
    },
    {
      "answer": "Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance.",
      "question": "What does principal component analysis do"
    },
    {
      "answer": "In a positively skewed distribution, the mean is usually greater than the median because the few high scores tend to shift the mean to the right.  In a positively skewed distribution, the mode is always less than the mean and median.",
      "question": "Which is typical of a positively skewed distribution"
    },
    {
      "answer": "For years, people have been forecasting weather patterns, economic and political events, sports outcomes, and more.  Because we try to predict so many different events, there are a wide variety of ways in which forecasts can be developed.",
      "question": "What is forecasting in machine learning"
    },
    {
      "answer": "Non parametric do not assume that the data is normally distributed.  For example: the Kruskal Willis test is the non parametric alternative to the One way ANOVA and the Mann Whitney is the non parametric alternative to the two sample t test. The main nonparametric tests are: 1-sample sign test.",
      "question": "Which is an example of non parametric statistic"
    },
    {
      "answer": "The decision for converting a predicted probability or scoring into a class label is governed by a parameter referred to as the \u201cdecision threshold,\u201d \u201cdiscrimination threshold,\u201d or simply the \u201cthreshold.\u201d The default value for the threshold is 0.5 for normalized predicted probabilities or scores in the range between 0",
      "question": "What is threshold machine learning"
    },
    {
      "answer": "SummaryWeighted Mean: A mean where some values contribute more than others.When the weights add to 1: just multiply each weight by the matching value and sum it all up.Otherwise, multiply each weight w by its matching value x, sum that all up, and divide by the sum of weights: Weighted Mean = \u03a3wx\u03a3w.",
      "question": "How do you calculate weighted mean"
    },
    {
      "answer": "Try a series of runs with different amounts of training data: randomly sample 20% of it, say, 10 times and observe performance on the validation data, then do the same with 40%, 60%, 80%. You should see both greater performance with more data, but also lower variance across the different random samples.",
      "question": "How do you split your data between training and validation"
    },
    {
      "answer": "The sample standard deviation (s) is a point estimate of the population standard deviation (\u03c3). The sample mean (\u0304x) is a point estimate of the population mean, \u03bc The sample variance (s2 is a point estimate of the population variance (\u03c32).",
      "question": "What is the point estimate of the population standard deviation"
    },
    {
      "answer": "In a nutshell, the goal of Bayesian inference is to maintain a full posterior probability distribution over a set of random variables.  Sampling algorithms based on Monte Carlo Markov Chain (MCMC) techniques are one possible way to go about inference in such models.",
      "question": "What is Bayesian sampling"
    },
    {
      "answer": "The 7 Steps of Machine Learning1 - Data Collection. The quantity & quality of your data dictate how accurate our model is.  2 - Data Preparation. Wrangle data and prepare it for training.  3 - Choose a Model.  4 - Train the Model.  5 - Evaluate the Model.  6 - Parameter Tuning.  7 - Make Predictions.",
      "question": "What are the steps in designing a machine learning problem"
    },
    {
      "answer": "A Blob is a group of connected pixels in an image that share some common property ( E.g grayscale value ). In the image above, the dark connected regions are blobs, and the goal of blob detection is to identify and mark these regions.",
      "question": "What is blob in OBject detection"
    },
    {
      "answer": "Overall, Sentiment analysis may involve the following types of classification algorithms: Linear Regression. Naive Bayes. Support Vector Machines.",
      "question": "Which algorithm is used for sentiment analysis"
    },
    {
      "answer": "One or two of the sections is the \u201crejection region\u201c; if your test value falls into that region, then you reject the null hypothesis. A one tailed test with the rejection rejection in one tail. The critical value is the red line to the left of that region.",
      "question": "How do you find the critical value and rejection region"
    },
    {
      "answer": "Calculation. The formula given in most textbooks is Skew = 3 * (Mean \u2013 Median) / Standard Deviation. This is known as an alternative Pearson Mode Skewness. You could calculate skew by hand.",
      "question": "How do you find the skew of a distribution"
    },
    {
      "answer": "Class Boundaries. Separate one class in a grouped frequency distribution from another. The boundaries have one more decimal place than the raw data and therefore do not appear in the data. There is no gap between the upper boundary of one class and the lower boundary of the next class.",
      "question": "What is class boundary in frequency distribution"
    },
    {
      "answer": "Ambiguity. The main challenge of NLP is the understanding and modeling of elements within a variable context. In a natural language, words are unique but can have different meanings depending on the context resulting in ambiguity on the lexical, syntactic, and semantic levels.",
      "question": "What is the main challenge s of NLP"
    },
    {
      "answer": "Deep learning is an AI function that mimics the workings of the human brain in processing data for use in detecting objects, recognizing speech, translating languages, and making decisions. Deep learning AI is able to learn without human supervision, drawing from data that is both unstructured and unlabeled.",
      "question": "What is deep learning and how does it relate to AI"
    },
    {
      "answer": "0:294:16Suggested clip \u00b7 116 secondsGeometric distribution moment generating function - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the moment generating function of a geometric distribution"
    },
    {
      "answer": "The biggest negative of transfer learning is that it's very hard to do right and very easy to mess up. Especially in NLP this kind of approach has only been mainstream for about a year, which just isn't enough time when model runs take weeks.",
      "question": "What are the disadvantages of transfer learning"
    },
    {
      "answer": "The Monty Hall problem is one of those rare curiosities \u2013 a mathematical problem that has made the front pages of national news. Everyone now knows, or thinks they know, the answer but a realistic look at the problem demonstrates that the standard mathematician's answer is wrong.",
      "question": "Is the Monty Hall problem correct"
    },
    {
      "answer": "The t distribution is therefore leptokurtic. The t distribution approaches the normal distribution as the degrees of freedom increase.  Since the t distribution is leptokurtic, the percentage of the distribution within 1.96 standard deviations of the mean is less than the 95% for the normal distribution.",
      "question": "Does a t distribution have a normal distribution"
    },
    {
      "answer": "Let's explore 5 common techniques used for extracting information from the above text.Named Entity Recognition. The most basic and useful technique in NLP is extracting the entities in the text.  Sentiment Analysis.  Text Summarization.  Aspect Mining.  Topic Modeling.",
      "question": "How do I extract information from a text"
    },
    {
      "answer": "Optuna is an automated hyperparameter optimization software framework that is knowingly invented for the machine learning-based tasks. It emphasizes an authoritative, define-by-run approach user API.",
      "question": "What is Optuna"
    },
    {
      "answer": "Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained.  During the fitting process, you run an algorithm on data for which you know the target variable, known as \u201clabeled\u201d data, and produce a machine learning model.",
      "question": "What is fitting in machine learning"
    },
    {
      "answer": "The central limit theorem states that the CDF of Zn converges to the standard normal CDF. converges in distribution to the standard normal random variable as n goes to infinity, that is limn\u2192\u221eP(Zn\u2264x)=\u03a6(x), for all x\u2208R,  The Xi's can be discrete, continuous, or mixed random variables.",
      "question": "Does the central limit theorem apply to discrete random variables"
    },
    {
      "answer": "0:315:15Suggested clip \u00b7 110 secondsMultinomial Distributions: Examples (Basic Probability and Statistics YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you solve a multinomial distribution"
    },
    {
      "answer": "The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",
      "question": "What is difference between regression and classification"
    },
    {
      "answer": "Not only are nose strips bad for those with sensitive skin, they also worsen other skin conditions. Pore strips exacerbate rosacea-prone skin , especially if they contain irritating ingredients like alcohol and astringents. They also aggravate extremely dry skin, eczema and psoriasis .",
      "question": "Is pore strip bad"
    },
    {
      "answer": "If k is given, the K-means algorithm can be executed in the following steps: Partition of objects into k non-empty subsets. Identifying the cluster centroids (mean point) of the current partition.  Compute the distances from each point and allot points to the cluster where the distance from the centroid is minimum.",
      "question": "What is K means algorithm with example"
    },
    {
      "answer": "A sampling distribution is where you take a population (N), and find a statistic from that population.  This is repeated for all possible samples from the population. Example: You hold a survey about college student's GRE scores and calculate that the standard deviation is 1.",
      "question": "How do you describe the sampling distribution"
    },
    {
      "answer": "A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non \u2013 linear functions. Figure 4 shows a multi layer perceptron with a single hidden layer.",
      "question": "What is single layer Perceptron and Multilayer Perceptron"
    },
    {
      "answer": "A continuous distribution has a range of values that are infinite, and therefore uncountable. For example, time is infinite: you could count from 0 seconds to a billion seconds\u2026a trillion seconds\u2026and so on, forever.",
      "question": "What are some examples of continuous distribution probability"
    },
    {
      "answer": "The binomial distribution model allows us to compute the probability of observing a specified number of \"successes\" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure.",
      "question": "What is the importance of binomial distribution"
    },
    {
      "answer": "Regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors in the model constant.  The coefficient indicates that for every additional meter in height you can expect weight to increase by an average of 106.5 kilograms.",
      "question": "What is a coefficient in a regression model"
    },
    {
      "answer": "2:107:35Suggested clip \u00b7 110 secondsLinear Regression R Program Make Predictions - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you predict a value in linear regression in R"
    },
    {
      "answer": "The nominator is the joint probability and the denominator is the probability of the given outcome.  This is the conditional probability: P(A\u2223B)=P(A\u2229B)P(B) This is the Bayes' rule: P(A\u2223B)=P(B|A)\u2217P(A)P(B).",
      "question": "What is the difference between Bayes rule and conditional probability"
    },
    {
      "answer": "The Fourier transform of a function of time is a complex-valued function of frequency, whose magnitude (absolute value) represents the amount of that frequency present in the original function, and whose argument is the phase offset of the basic sinusoid in that frequency.",
      "question": "What does Fourier transform represent"
    },
    {
      "answer": "The Four Assumptions of Linear RegressionLinear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.Independence: The residuals are independent.  Homoscedasticity: The residuals have constant variance at every level of x.Normality: The residuals of the model are normally distributed.",
      "question": "What are the four assumptions of linear regression"
    },
    {
      "answer": "The logarithm is to exponentiation as division is to multiplication: The logarithm is the inverse of the exponent: it undoes exponentiation. When studying logarithms, always remember the following fundamental equivalence: if and only if . Whenever one of these is true, so is the other.",
      "question": "What is the intuition behind the logarithm"
    },
    {
      "answer": "Batch Normalization during inference During testing or inference phase we can't apply the same batch-normalization as we did during training because we might pass only sample at a time so it doesn't make sense to find mean and variance on a single sample.",
      "question": "Is batch normalization used in inference"
    },
    {
      "answer": "(1 p)xp = (1 p)a+1p + \u00b7\u00b7\u00b7 + (1 p)bp = (1 p)a+1p (1 p)b+1p 1 (1 p) = (1 p)a+1 (1 p)b+1 We can take a = 0 to find the distribution function for a geometric random variable. The initial d indicates density and p indicates the probability from the distribution function.",
      "question": "How do you find the distribution function of a random variable"
    },
    {
      "answer": "If the limit of |a[n+1]/a[n]| is less than 1, then the series (absolutely) converges. If the limit is larger than one, or infinite, then the series diverges.",
      "question": "How do you test for convergence and divergence in a series"
    },
    {
      "answer": "Data visualization is a technique that uses an array of static and interactive visuals within a specific context to help people understand and make sense of large amounts of data. The data is often displayed in a story format that visualizes patterns, trends and correlations that may otherwise go unnoticed.",
      "question": "What is visualization in machine learning"
    },
    {
      "answer": "Deep Learning is extensively used for Predictive Analytics, NLP, Computer Vision, and Object Recognition.",
      "question": "Does NLP use deep learning"
    },
    {
      "answer": "If you see a lowercase x or y, that's the kind of variable you're used to in algebra. It refers to an unknown quantity or quantities. If you see an uppercase X or Y, that's a random variable and it usually refers to the probability of getting a certain outcome.",
      "question": "How do you identify a random variable"
    },
    {
      "answer": "Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.",
      "question": "How is gradient descent used in machine learning"
    },
    {
      "answer": "It is a process of converting a sentence to forms \u2013 list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.",
      "question": "What is part of speech tagging in NLP"
    },
    {
      "answer": "Structural equation modeling is a multivariate statistical analysis technique that is used to analyze structural relationships. This technique is the combination of factor analysis and multiple regression analysis, and it is used to analyze the structural relationship between measured variables and latent constructs.",
      "question": "What is structural equation modeling used for"
    },
    {
      "answer": "(Note that how a support vector machine classifies points that fall on a boundary line is implementation dependent. In our discussions, we have said that points falling on the line will be considered negative examples, so the classification equation is w . u + b \u2264 0.)",
      "question": "What equations are used for Classificationion in a support vector machine"
    },
    {
      "answer": "Matrix theory is a branch of mathematics which is focused on study of matrices. Initially, it was a sub-branch of linear algebra, but soon it grew to cover subjects related to graph theory, algebra, combinatorics and statistics as well.",
      "question": "What is the Matrix theory"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What does activation function do in neural network"
    },
    {
      "answer": "While the variance and the standard error of the mean are different estimates of variability, one can be derived from the other. Multiply the standard error of the mean by itself to square it. This step assumes that the standard error is a known quantity.",
      "question": "Is variance and standard error the same"
    },
    {
      "answer": "Variable screening is the process of filtering out irrelevant variables, with the aim to reduce the dimensionality from ultrahigh to high while retaining all important variables.  The main theme of this thesis is to develop variable screening and variable selection methods for high dimensional data analysis.",
      "question": "What is variable screening"
    },
    {
      "answer": "Probability Role of probability in statistics:  Use probability to predict results of experiment under assumptions. Compute probability of error larger than given amount. Compute probability of given departure between prediction and results under assumption.",
      "question": "What is the role of probability to statistic"
    },
    {
      "answer": "Probability is the study of random events. It is used in analyzing games of chance, genetics, weather prediction, and a myriad of other everyday events. Statistics is the mathematics we use to collect, organize, and interpret numerical data.",
      "question": "What are statistics and probability"
    },
    {
      "answer": "Probability density function (PDF) is a statistical expression that defines a probability distribution (the likelihood of an outcome) for a discrete random variable (e.g., a stock or ETF) as opposed to a continuous random variable.",
      "question": "What does probability density function represent"
    },
    {
      "answer": "Train a neural network with TensorFlowStep 1: Import the data.Step 2: Transform the data.Step 3: Construct the tensor.Step 4: Build the model.Step 5: Train and evaluate the model.Step 6: Improve the model.",
      "question": "How do you train a neural network in TensorFlow"
    },
    {
      "answer": "Covariance: An Overview. Variance and covariance are mathematical terms frequently used in statistics and probability theory. Variance refers to the spread of a data set around its mean value, while a covariance refers to the measure of the directional relationship between two random variables.",
      "question": "What is the meaning of covariance in statistics"
    },
    {
      "answer": "The Random Variable is X = \"The sum of the scores on the two dice\". Let's count how often each value occurs, and work out the probabilities: 2 occurs just once, so P(X = 2) = 1/36. 3 occurs twice, so P(X = 3) = 2/36 = 1/18.",
      "question": "How do you find the random variable"
    },
    {
      "answer": "NMF stands for non-negative matrix factorization, a technique for obtaining low rank representation of matrices with non-negative or positive elements.  In information retrieval and text mining, we rely on term-document matrices for representing document collections.",
      "question": "What is NMF machine learning"
    },
    {
      "answer": "Error -- subtract the theoretical value (usually the number the professor has as the target value) from your experimental data point. Percent error -- take the absolute value of the error divided by the theoretical value, then multiply by 100.",
      "question": "How do you determine data error"
    },
    {
      "answer": "In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.",
      "question": "What is a nonparametric test what is a parametric test"
    },
    {
      "answer": "The Structural Topic Model allows researchers to flexibly estimate a topic model that includes document-level metadata.  The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.",
      "question": "What is structural topic modeling"
    },
    {
      "answer": "We can interpret the Poisson regression coefficient as follows: for a one unit change in the predictor variable, the difference in the logs of expected counts is expected to change by the respective regression coefficient, given the other predictor variables in the model are held constant.",
      "question": "How do you interpret Poisson regression results"
    },
    {
      "answer": "The obvious difference between ANOVA and a \"Multivariate Analysis of Variance\" (MANOVA) is the \u201cM\u201d, which stands for multivariate. In basic terms, A MANOVA is an ANOVA with two or more continuous response variables. Like ANOVA, MANOVA has both a one-way flavor and a two-way flavor.",
      "question": "What is the difference between Anova and Manova"
    },
    {
      "answer": "Humans are error-prone and biased, but that doesn't mean that algorithms are necessarily better.  But these systems can be biased based on who builds them, how they're developed, and how they're ultimately used. This is commonly known as algorithmic bias.",
      "question": "How are algorithms biased"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is supervised and unsupervised data"
    },
    {
      "answer": "Bad Sampling. The data can be misleading due to the sampling method used to obtain data. For instance, the size and the type of sample used in any statistics play a significant role \u2014 many polls and questionnaires target certain audiences that provide specific answers, resulting in small and biased sample sizes.",
      "question": "How can statistics be mislead"
    },
    {
      "answer": "In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors.  Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers. AI is going to make our lives better in the future.",
      "question": "How AI will change the future"
    },
    {
      "answer": "We will run the ANOVA using the five-step approach.Set up hypotheses and determine level of significance. H0: \u03bc1 = \u03bc2 = \u03bc3 = \u03bc4 H1: Means are not all equal \u03b1=0.05.Select the appropriate test statistic.  Set up decision rule.  Compute the test statistic.  Conclusion.",
      "question": "What are the steps to carry out analysis of variance"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What are the differences between supervised and unsupervised learning"
    },
    {
      "answer": "A heuristic is a mental shortcut that allows people to solve problems and make judgments quickly and efficiently. These rule-of-thumb strategies shorten decision-making time and allow people to function without constantly stopping to think about their next course of action.",
      "question": "How do heuristics affect decision making"
    },
    {
      "answer": "A distribution with a single mode is said to be unimodal. A distribution with more than one mode is said to be bimodal, trimodal, etc., or in general, multimodal.",
      "question": "Is the distribution unimodal or multimodal"
    },
    {
      "answer": "The least squares method is a statistical procedure to find the best fit for a set of data points by minimizing the sum of the offsets or residuals of points from the plotted curve. Least squares regression is used to predict the behavior of dependent variables.",
      "question": "What are the uses of least square method"
    },
    {
      "answer": "The planning problem in Artificial Intelligence is about the decision making performed by intelligent creatures like robots, humans, or computer programs when trying to achieve some goal.  In the following we discuss a number of ways of formalizing planning, and show how the planning problem can be solved automatically.",
      "question": "What is planning problem in AI"
    },
    {
      "answer": "In order to fit the best intercept line between the points in the above scatter plots, we use a metric called \u201cSum of Squared Errors\u201d (SSE) and compare the lines to find out the best fit by reducing errors.",
      "question": "What is the metric used by ordinary least squares OLS to determine the best fit line"
    },
    {
      "answer": "In statistics, a sequence (or a vector) of random variables is homoscedastic /\u02ccho\u028amo\u028ask\u0259\u02c8d\u00e6st\u026ak/ if all its random variables have the same finite variance. This is also known as homogeneity of variance. The complementary notion is called heteroscedasticity.",
      "question": "What is Homoscedasticity in statistics"
    },
    {
      "answer": "Overall, Sentiment analysis may involve the following types of classification algorithms:Linear Regression.Naive Bayes.Support Vector Machines.RNN derivatives LSTM and GRU.",
      "question": "Which algorithm is best for sentiment analysis"
    },
    {
      "answer": "While measures of central tendency are used to estimate \"normal\" values of a dataset, measures of dispersion are important for describing the spread of the data, or its variation around a central value. A proper description of a set of data should include both of these characteristics.",
      "question": "Why are measures of dispersion used in addition to measures of central tendency"
    },
    {
      "answer": "Logistic regression is a model for binary classification predictive modeling.  Under this framework, a probability distribution for the target variable (class label) must be assumed and then a likelihood function defined that calculates the probability of observing the outcome given the input data and the model.",
      "question": "What is likelihood function in logistic regression"
    },
    {
      "answer": "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction\u2014forward\u2014from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.",
      "question": "How does feedforward neural network work"
    },
    {
      "answer": "Increase the sample size. Often, the most practical way to decrease the margin of error is to increase the sample size.  Reduce variability. The less that your data varies, the more precisely you can estimate a population parameter.  Use a one-sided confidence interval.  Lower the confidence level.",
      "question": "How do you reduce the margin of error in statistics"
    },
    {
      "answer": "A Bayesian network is a compact, flexible and interpretable representation of a joint probability distribution. It is also an useful tool in knowledge discovery as directed acyclic graphs allow representing causal relations between variables. Typically, a Bayesian network is learned from data.",
      "question": "What is Bayesian network in machine learning"
    },
    {
      "answer": "A t score is one form of a standardized test statistic (the other you'll come across in elementary statistics is the z-score). The t score formula enables you to take an individual score and transform it into a standardized form>one which helps you to compare scores.",
      "question": "What is the T score in statistics"
    },
    {
      "answer": "We can call a Logistic Regression a Linear Regression model but the Logistic Regression uses a more complex cost function, this cost function can be defined as the 'Sigmoid function' or also known as the 'logistic function' instead of a linear function.",
      "question": "What is the cost function used in logistic regression"
    },
    {
      "answer": "Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics.",
      "question": "Why is Bayesian inference"
    },
    {
      "answer": "3.2 How to test for differences between samplesDecide on a hypothesis to test, often called the \u201cnull hypothesis\u201d (H0 ). In our case, the hypothesis is that there is no difference between sets of samples.  Decide on a statistic to test the truth of the null hypothesis.Calculate the statistic.Compare it to a reference value to establish significance, the P-value.",
      "question": "How do you know if two samples are significantly different"
    },
    {
      "answer": "Mean, variance, and standard deviation The mean of the sampling distribution of the sample mean will always be the same as the mean of the original non-normal distribution. In other words, the sample mean is equal to the population mean. where \u03c3 is population standard deviation and n is sample size.",
      "question": "Is sample mean equal to population mean"
    },
    {
      "answer": "In sampling with replacement the mean of all sample means equals the mean of the population:  Whatever the shape of the population distribution, the distribution of sample means is approximately normal with better approximations as the sample size, n, increases.",
      "question": "What is sampling distribution of mean with replacement"
    },
    {
      "answer": "A statistical model is a mathematical representation (or mathematical model) of observed data. When data analysts apply various statistical models to the data they are investigating, they are able to understand and interpret the information more strategically.",
      "question": "What are statistical models used for"
    },
    {
      "answer": "If the mean more accurately represents the center of the distribution of your data, and your sample size is large enough, use a parametric test. If the median more accurately represents the center of the distribution of your data, use a nonparametric test even if you have a large sample size.",
      "question": "How do you know whether to use parametric or nonparametric"
    },
    {
      "answer": "The Basics of a One-Tailed Test Hypothesis testing is run to determine whether a claim is true or not, given a population parameter. A test that is conducted to show whether the mean of the sample is significantly greater than and significantly less than the mean of a population is considered a two-tailed test.",
      "question": "What is a one sided vs a two sided hypothesis test"
    },
    {
      "answer": "The distribution for z is the standard normal distribution; it has a mean of 0 and a standard deviation of 1. For Ha: p \u2260 26, the P-value would be P(z \u2264 -1.83) + P(z \u2265 1.83) = 2 * P(z \u2264 -1.83). Regardless of Ha, z = (p\u0302 - p0) / sqrt(p0 * (1 - p0) / n), where z gives the number of standard deviations p\u0302 is from p0.",
      "question": "How do you find the p value in a normal distribution"
    },
    {
      "answer": "A certain continuous random variable has a probability density function (PDF) given by: f ( x ) = C x ( 1 \u2212 x ) 2 , f(x) = C x (1-x)^2, f(x)=Cx(1\u2212x)2, where x x x can be any number in the real interval [ 0 , 1 ] [0,1] [0,1]. Compute C C C using the normalization condition on PDFs.",
      "question": "How do you find the probability density function of a continuous random variable"
    },
    {
      "answer": "There is no non-parametric form of any regression. Regression means you are assuming that a particular parameterized model generated your data, and trying to find the parameters. Non-parametric tests are test that make no assumptions about the model that generated your data.",
      "question": "What is the non parametric equivalent of the linear regression"
    },
    {
      "answer": "How to Deal with MulticollinearityRedesign the study to avoid multicollinearity.  Increase sample size.  Remove one or more of the highly-correlated independent variables.  Define a new variable equal to a linear combination of the highly-correlated variables.",
      "question": "How do you handle multicollinearity in regression modeling"
    },
    {
      "answer": "The F ratio is the ratio of two mean square values. If the null hypothesis is true, you expect F to have a value close to 1.0 most of the time. A large F ratio means that the variation among group means is more than you'd expect to see by chance.",
      "question": "What does an F ratio mean"
    },
    {
      "answer": "The ability to detect certain types of stimuli, like movements, shape, and angles, requires specialized cells in the brain called feature detectors. Without these, it would be difficult, if not impossible, to detect a round object, like a baseball, hurdling toward you at 90 miles per hour.",
      "question": "What do feature detectors detect"
    },
    {
      "answer": "NLP is short for natural language processing while NLU is the shorthand for natural language understanding. Similarly named, the concepts both deal with the relationship between natural language (as in, what we as humans speak, not what computers understand) and artificial intelligence.",
      "question": "What is NLU and NLP"
    },
    {
      "answer": "A curve that represents the cumulative frequency distribution of grouped data on a graph is called a Cumulative Frequency Curve or an Ogive.",
      "question": "Which plot is required for cumulative frequency distribution"
    },
    {
      "answer": "Depth is the number of filters. Depth column (or fibre) is the set of neurons that are all pointing to the same receptive field. Stride has the objective of producing smaller output volumes spatially. For example, if a stride=2, the filter will shift by the amount of 2 pixels as it convolves around the input volume.",
      "question": "What is depth in CNN"
    },
    {
      "answer": "In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased.  When a biased estimator is used, bounds of the bias are calculated.",
      "question": "What is bias function"
    },
    {
      "answer": "Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample.  Poisson distribution describes the distribution of binary data from an infinite sample.",
      "question": "What is the difference between binomial Poisson and normal distributions"
    },
    {
      "answer": "How To Develop a Machine Learning Model From ScratchDefine adequately our problem (objective, desired outputs\u2026).Gather data.Choose a measure of success.Set an evaluation protocol and the different protocols available.Prepare the data (dealing with missing values, with categorial values\u2026).Spilit correctly the data.More items",
      "question": "How do you make a deep learning model from scratch"
    },
    {
      "answer": "We can use MLE in order to get more robust parameter estimates. Thus, MLE can be defined as a method for estimating population parameters (such as the mean and variance for Normal, rate (lambda) for Poisson, etc.) from sample data such that the probability (likelihood) of obtaining the observed data is maximized.",
      "question": "Why do we use maximum likelihood estimation"
    },
    {
      "answer": "An RNN has a looping mechanism that acts as a highway to allow information to flow from one step to the next. Passing Hidden State to next time step. This information is the hidden state, which is a representation of previous inputs. Let's run through an RNN use case to have a better understanding of how this works.",
      "question": "What is a hidden state in RNN"
    },
    {
      "answer": "In simple random sampling, each member of a population has an equal chance of being included in the sample. Also, each combination of members of the population has an equal chance of composing the sample. Those two properties are what defines simple random sampling.",
      "question": "What is the probability of a simple random sample"
    },
    {
      "answer": "jackknifing is calculation with data sets sampled randomly from the original data.  Bootstrapping is similar to jackknifing except that the position chosen at random may include multiple copies of the same position, to form data sets of the same size as original, to preserve statistical properties of data sampling.",
      "question": "Why is it called bootstrapping statistics"
    },
    {
      "answer": "Gradient boosted regression and classification is an additive training tree classification method where trees are build in series (iteratively) and compared to each other based on a mathematically derived score of splits. The trees are compared based on weighted leaf scores within each tree.",
      "question": "How does gradient boosting work for classification"
    },
    {
      "answer": "AlphaGo was initially trained to mimic human play by attempting to match the moves of expert players from recorded historical games, using a database of around 30 million moves.",
      "question": "How was AlphaGo trained"
    },
    {
      "answer": "Classification accuracy is the ratio of correct predictions to total predictions made. classification accuracy = correct predictions / total predictions. 1. classification accuracy = correct predictions / total predictions. It is often presented as a percentage by multiplying the result by 100.",
      "question": "What is accuracy in confusion matrix"
    },
    {
      "answer": "MANOVA is useful in experimental situations where at least some of the independent variables are manipulated. It has several advantages over ANOVA. First, by measuring several dependent variables in a single experiment, there is a better chance of discovering which factor is truly important.",
      "question": "Why use a Manova instead of Anova"
    },
    {
      "answer": "Essentially, multivariate analysis is a tool to find patterns and relationships between several variables simultaneously. It lets us predict the effect a change in one variable will have on other variables.",
      "question": "What is multivariate analysis used for"
    },
    {
      "answer": "7 Best Models for Image Classification using Keras1 Xception. It translates to \u201cExtreme Inception\u201d.  2 VGG16 and VGG19: This is a keras model with 16 and 19 layer network that has an input size of 224X224.  3 ResNet50. The ResNet architecture is another pre-trained model highly useful in Residual Neural Networks.  4 InceptionV3.  5 DenseNet.  6 MobileNet.  7 NASNet.",
      "question": "What is the best model for image classification"
    },
    {
      "answer": "Definition 1. Suppose that events A and B are defined on the same probability space, and the event B is such that P(B) > 0. The conditional probability of A given that B has occurred is given by P(A|B) = P(A \u2229 B)/P(B).",
      "question": "How do you prove conditional probability"
    },
    {
      "answer": "Message passing algorithm which is an iterative decoding algorithm factorizes the global function of many variables into product of simpler local functions, whose arguments are the subset of variables. In order to visualize this factorization we use factor graph.",
      "question": "What is message passing algorithm"
    },
    {
      "answer": "This means that the sum of two independent normally distributed random variables is normal, with its mean being the sum of the two means, and its variance being the sum of the two variances (i.e., the square of the standard deviation is the sum of the squares of the standard deviations).",
      "question": "Is the sum of two normal distributions normal"
    },
    {
      "answer": "Postprocessing procedures usually include various pruning routines, rule quality processing, rule filtering, rule combination, model combination, or even knowledge integration. All these procedures provide a kind of symbolic filter for noisy, imprecise, or non-user-friendly knowledge derived by an inductive algorithm.",
      "question": "What is post processing in machine learning"
    },
    {
      "answer": "Summary: Population variance refers to the value of variance that is calculated from population data, and sample variance is the variance calculated from sample data.  As a result both variance and standard deviation derived from sample data are more than those found out from population data.",
      "question": "What is the difference between population variance and sample variance"
    },
    {
      "answer": "Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models.",
      "question": "What is filter method in feature selection"
    },
    {
      "answer": "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.",
      "question": "What does a normal distribution model"
    },
    {
      "answer": "Generally, z-tests are used when we have large sample sizes (n > 30), whereas t-tests are most helpful with a smaller sample size (n < 30). Both methods assume a normal distribution of the data, but the z-tests are most useful when the standard deviation is known.",
      "question": "When is the t test preferred to the Z test"
    },
    {
      "answer": "Here are 5 common machine learning problems and how you can overcome them.1) Understanding Which Processes Need Automation.  2) Lack of Quality Data.  3) Inadequate Infrastructure.  4) Implementation.  5) Lack of Skilled Resources.",
      "question": "What are the problems of machine learning"
    },
    {
      "answer": "Select a File for Image ChangeFrom the Toolbox, select Change Detection > Image Change Workflow. Select an input file from the File Selection dialog.  To apply a mask, select the Input Mask tab in the File Selection panel.  Select the Input Files tab again.Enter the path and filename for the Time 2 File.  Click Next.",
      "question": "How do you do change detection ENVI"
    },
    {
      "answer": "The sampling distribution of the sample mean is very useful because it can tell us the probability of getting any specific mean from a random sample.",
      "question": "What is the sampling distribution of the means and why is it useful"
    },
    {
      "answer": "While the chi-squared test relies on an approximation, Fisher's exact test is one of exact tests. Especially when more than 20% of cells have expected frequencies < 5, we need to use Fisher's exact test because applying approximation method is inadequate.",
      "question": "When should Fisher's exact test be used"
    },
    {
      "answer": "Strictly speaking, a neural network (also called an \u201cartificial neural network\u201d) is a type of machine learning model that is usually used in supervised learning.  A perceptron is a simplified model of a human neuron that accepts an input and performs a computation on that input.",
      "question": "Does machine learning use neural networks"
    },
    {
      "answer": "Here are 25 phases that you can use to increase confidence and self-esteem in your children.\u201cYou are capable.\"  \u201cThat was brave.\"  \u201cYou've got this.\"  \u201cI believe in you.\"  \u201cYou can do hard things.\"  \u201cNo matter what happens, I love you.\"  \u201cLet's try it together.\"  \u201cHow'd you do that?\"More items",
      "question": "What words improve your confidence levels"
    },
    {
      "answer": "An object detector that uses anchor boxes can process an entire image at once, making real-time object detection systems possible. Because a convolutional neural network (CNN) can process an input image in a convolutional manner, a spatial location in the input can be related to a spatial location in the output.",
      "question": "How do anchor boxes in object detection really work"
    },
    {
      "answer": "To conclude, the important thing to remember about the odds ratio is that an odds ratio greater than 1 is a positive association (i.e., higher number for the predictor means group 1 in the outcome), and an odds ratio less than 1 is negative association (i.e., higher number for the predictor means group 0 in the outcome",
      "question": "How do you interpret the odds ratio in logistic regression"
    },
    {
      "answer": "Multinomial Na\u00efve Bayes uses term frequency i.e. the number of times a given term appears in a document.  After normalization, term frequency can be used to compute maximum likelihood estimates based on the training data to estimate the conditional probability.",
      "question": "How does multinomial naive Bayes work"
    },
    {
      "answer": "Energy is quantized in some systems, meaning that the system can have only certain energies and not a continuum of energies, unlike the classical case. This would be like having only certain speeds at which a car can travel because its kinetic energy can have only certain values.",
      "question": "Why is energy quantized"
    },
    {
      "answer": "The More Formal Formula You can solve these types of problems using the steps above, or you can us the formula for finding the probability for a continuous uniform distribution: P(X) = d \u2013 c / b \u2013 a. This is also sometimes written as: P(X) = x2 \u2013 x1 / b \u2013 a.",
      "question": "How do you find the continuous probability of a uniform"
    },
    {
      "answer": "The use of sigmoidal nonlinear functions was inspired by the ouputs of biological neurons.  However, this function is not smooth (it fails to be differential at the threshold value). Therefore, the sigmoid class of functions is a differentiable alternative that still captures much of the behavior of biological neurons.",
      "question": "Why is sigmoid nonlinear"
    },
    {
      "answer": "Chi-square Test. The Pearson's \u03c72 test (after Karl Pearson, 1900) is the most commonly used test for the difference in distribution of categorical variables between two or more independent groups.",
      "question": "How do you find the difference between two categorical variables"
    },
    {
      "answer": "Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. The additional term controls the excessively fluctuating function such that the coefficients don't take extreme values.",
      "question": "Why is regularization used"
    },
    {
      "answer": "2:1510:12Suggested clip \u00b7 108 secondsHistograms In Photography - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How are histograms used in photography"
    },
    {
      "answer": "Abstract: The dimensionality curse phenomenon states that in high dimensional spaces distances between nearest and farthest points from query points become almost equal. Therefore, nearest neighbor calculations cannot discriminate candidate points.",
      "question": "What is curse of dimensionality in Knn"
    },
    {
      "answer": "The following are common methods:Mean imputation. Simply calculate the mean of the observed values for that variable for all individuals who are non-missing.  Substitution.  Hot deck imputation.  Cold deck imputation.  Regression imputation.  Stochastic regression imputation.  Interpolation and extrapolation.",
      "question": "How do you impute missing values"
    },
    {
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.",
      "question": "What is the difference between boosting and bagging"
    },
    {
      "answer": "There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.",
      "question": "Is a way of finding the K value for K means clustering"
    },
    {
      "answer": "Say we want to estimate the mean of a population. While the most used estimator is the average of the sample, another possible estimator is simply the first number drawn from the sample.  In theory, you could have an unbiased estimator whose variance is asymptotically nonzero, and that would be inconsistent.",
      "question": "Can an estimator be unbiased or inconsistent"
    },
    {
      "answer": "The term normal score is used with two different meanings in statistics.  A given data point is assigned a value which is either exactly, or an approximation, to the expectation of the order statistic of the same rank in a sample of standard normal random variables of the same size as the observed data set.",
      "question": "What is a normal score in statistics"
    },
    {
      "answer": "You can use a generative model. You can also use simple tricks. For example, with photograph image data, you can get big gains by randomly shifting and rotating existing images. It improves the generalization of the model to such transforms in the data if they are to be expected in new data.",
      "question": "How can you improve the generalization of the deep learning model"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What is activation function used in a neural network"
    },
    {
      "answer": "The objective of Unsupervised Anomaly Detection is to detect previously unseen rare objects or events without any prior knowledge about these. The only information available is that the percentage of anomalies in the dataset is small, usually less than 1%.",
      "question": "What is unsupervised anomaly detection"
    },
    {
      "answer": "Steps for Using ANOVAStep 1: Compute the Variance Between. First, the sum of squares (SS) between is computed:  Step 2: Compute the Variance Within. Again, first compute the sum of squares within.  Step 3: Compute the Ratio of Variance Between and Variance Within. This is called the F-ratio.",
      "question": "How is analysis of variance calculated"
    },
    {
      "answer": "Use simple logistic regression when you have one nominal variable and one measurement variable, and you want to know whether variation in the measurement variable causes variation in the nominal variable.",
      "question": "When should you use logistic regression"
    },
    {
      "answer": "A multinomial experiment is almost identical with one main difference: a binomial experiment can have two outcomes, while a multinomial experiment can have multiple outcomes.  A binomial experiment will have a binomial distribution.",
      "question": "What is difference between binomial and multinomial distribution"
    },
    {
      "answer": "Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.",
      "question": "What are regression models used for"
    },
    {
      "answer": "The primary reason skew is important is that analysis based on normal distributions incorrectly estimates expected returns and risk.  Knowing that the market has a 70% probability of going up and a 30% probability of going down may appear helpful if you rely on normal distributions.",
      "question": "Why is skewness important in statistics"
    },
    {
      "answer": "What you want is multi-label classification, so you will use Binary Cross-Entropy Loss or Sigmoid Cross-Entropy loss. It is a Sigmoid activation plus a Cross-Entropy loss.",
      "question": "What loss function will you use to measure multi label problems"
    },
    {
      "answer": "According to Cohen's original article, values \u2264 0 as indicating no agreement and 0.01\u20130.20 as none to slight, 0.21\u20130.40 as fair, 0.41\u2013 0.60 as moderate, 0.61\u20130.80 as substantial, and 0.81\u20131.00 as almost perfect agreement.",
      "question": "What is acceptable inter rater reliability"
    },
    {
      "answer": "Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.",
      "question": "What is Gan in deep learning"
    },
    {
      "answer": "Models that are pre-trained on ImageNet are good at detecting high-level features like edges, patterns, etc. These models understand certain feature representations, which can be reused.",
      "question": "Why it is beneficial to use pre trained models"
    },
    {
      "answer": "Time series data means that data is in a series of particular time periods or intervals. The data is considered in three types: Time series data: A set of observations on the values that a variable takes at different times. Cross-sectional data: Data of one or more variables, collected at the same point in time.",
      "question": "What is time series data in statistics"
    },
    {
      "answer": "There are two types of hierarchical clustering, Divisive and Agglomerative.",
      "question": "What are the two types of hierarchical clustering"
    },
    {
      "answer": "In terms of linear regression, variance is a measure of how far observed values differ from the average of predicted values, i.e., their difference from the predicted value mean. The goal is to have a value that is low.",
      "question": "What is variance in multiple regression"
    },
    {
      "answer": "PDF according to input X being discrete or continuous generates probability mass functions and CDF does the same but generates cumulative mass function. That means, PDF is derivative of CDF and CDF can be applied at any point where PDF has been applied.  The cumulative function is the integral of the density function.",
      "question": "What is the difference between a probability distribution function and a cumulative"
    },
    {
      "answer": "6 Freebies to Help You Increase the Performance of Your Object Detection ModelsVisually Coherent Image Mix-up for Object Detection (+3.55% mAP Boost)Classification Head Label Smoothening (+2.16% mAP Boost)Data Pre-processing (Mixed Results)Training Scheduler Revamping (+1.44% mAP Boost)More items",
      "question": "How can you improve the accuracy of an object detection"
    },
    {
      "answer": "The chi-square goodness of fit test is appropriate when the following conditions are met: The sampling method is simple random sampling. The variable under study is categorical. The expected value of the number of sample observations in each level of the variable is at least 5.",
      "question": "What are the conditions for conducting a chi square goodness of fit test"
    },
    {
      "answer": "In this context, correlation only makes sense if the relationship is indeed linear. Second, the slope of the regression line is proportional to the correlation coefficient: slope = r*(SD of y)/(SD of x) Third: the square of the correlation, called \"R-squared\", measures the \"fit\" of the regression line to the data.",
      "question": "Is R the slope of the regression line"
    },
    {
      "answer": "Weaknesses. Histograms have many benefits, but there are two weaknesses. A histogram can present data that is misleading. For example, using too many blocks can make analysis difficult, while too few can leave out important data.",
      "question": "What are the disadvantages of using a histogram"
    },
    {
      "answer": "The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.",
      "question": "How do you determine a false positive rate"
    },
    {
      "answer": "Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items\u2022",
      "question": "Which regression model is best"
    },
    {
      "answer": "In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.",
      "question": "What is a positive skew in statistics"
    },
    {
      "answer": "Ridge regression has an additional factor called \u03bb (lambda) which is called the penalty factor which is added while estimating beta coefficients. This penalty factor penalizes high value of beta which in turn shrinks beta coefficients thereby reducing the mean squared error and predicted error.",
      "question": "Why does ridge regression reduce variance"
    },
    {
      "answer": "Eigenface",
      "question": "Which algorithm is used for face detection"
    },
    {
      "answer": "Learning Rate and Gradient Descent Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. The learning rate controls how quickly the model is adapted to the problem.",
      "question": "What is the learning rate in the context of deep learning"
    },
    {
      "answer": "Informally, a neural attention mechanism equips a neural network with the ability to focus on a subset of its inputs (or features): it selects specific inputs.",
      "question": "What is Attention neural network"
    },
    {
      "answer": "Seriously, the p value is literally a confounded index because it reflects both the size of the underlying effect and the size of the sample. Hence any information included in the p value is ambiguous (Lang et al. 1998).  The smaller the sample, the less likely the result will be statistically significant.",
      "question": "Why are p values considered confounded statistics"
    },
    {
      "answer": "However, experts expect that it won't be until 2060 until AGI has gotten good enough to pass a \"consciousness test\". In other words, we're probably looking at 40 years from now before we see an AI that could pass for a human.",
      "question": "How far away are we from AGI"
    },
    {
      "answer": "A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function. We must compose multiple logical operations by using a hidden layer to represent the XOR function.",
      "question": "Can a 2 layer neural network represent the XOR function"
    },
    {
      "answer": "The F Distribution The distribution of all possible values of the f statistic is called an F distribution, with v1 = n1 - 1 and v2 = n2 - 1 degrees of freedom. The curve of the F distribution depends on the degrees of freedom, v1 and v2.",
      "question": "What is an F distribution in statistics"
    },
    {
      "answer": "The focus will especially be on applications of stochastic processes as key technologies in various research areas, such as Markov chains, renewal theory, control theory, nonlinear theory, queuing theory, risk theory, communication theory engineering and traffic engineering.",
      "question": "What are the applications of stochastic process"
    },
    {
      "answer": "Advantages of Machine LearningContinuous Improvement. Machine Learning algorithms are capable of learning from the data we provide.  Automation for everything.  Trends and patterns identification.  Wide range of applications.  Data Acquisition.  Highly error-prone.  Algorithm Selection.  Time-consuming.",
      "question": "What are the advantages of machine learning"
    },
    {
      "answer": "The potential solutions include the following:Remove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "What do you do when a variable is correlated"
    },
    {
      "answer": "According to SAS, predictive analytics is \u201cthe use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data.  In short, predictive intelligence drives marketing decisions.\u201d",
      "question": "Do predictive analytics drive more informed decisions"
    },
    {
      "answer": "POS tags make it possible for automatic text processing tools to take into account which part of speech each word is. This facilitates the use of linguistic criteria in addition to statistics.",
      "question": "Why is POS tagging useful"
    },
    {
      "answer": "(Example: a test with 90% specificity will correctly return a negative result for 90% of people who don't have the disease, but will return a positive result \u2014 a false-positive \u2014 for 10% of the people who don't have the disease and should have tested negative.)",
      "question": "What is a good false positive rate"
    },
    {
      "answer": "It basically defined on probability estimates and measures the performance of a classification model where the input is a probability value between 0 and 1. It can be understood more clearly by differentiating it with accuracy.",
      "question": "What is performance measure in machine learning"
    },
    {
      "answer": "TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. TensorBoard currently supports five visualizations: scalars, images, audio, histograms, and graphs.",
      "question": "What is tensor board"
    },
    {
      "answer": "For a discrete random variable, the expected value, usually denoted as or , is calculated using: \u03bc = E ( X ) = \u2211 x i f ( x i )",
      "question": "What is the expected value of a discrete distribution"
    },
    {
      "answer": "The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image.  The result shows how abruptly or smoothly the image changes at each pixel, and therefore how likely it is that that pixel represents an edge.",
      "question": "How does Sobel edge detection work"
    },
    {
      "answer": "Multinomial logistic regression is used when the dependent variable in question is nominal (equivalently categorical, meaning that it falls into any one of a set of categories that cannot be ordered in any meaningful way) and for which there are more than two categories.",
      "question": "When would you use a multinomial"
    },
    {
      "answer": "A Z score is the number of standard deviations a given result is above (positive score) or below (negative score) the age- and sex-adjusted population mean. Results that are within the IGF-1 reference interval will have a Z score between -2.0 and +2.0.",
      "question": "What is Z score in blood test"
    },
    {
      "answer": "Sensitivity is a measure of the proportion of actual positive cases that got predicted as positive (or true positive).  This implies that there will be another proportion of actual positive cases, which would get predicted incorrectly as negative (and, thus, could also be termed as the false negative).",
      "question": "What is sensitivity in machine learning"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "Where do we use eigen values"
    },
    {
      "answer": "IBM SPSS Statistics for Mac is the ultimate tool for managing your statistics data and research. This super-app affords you complete control over your data.",
      "question": "Can you get SPSS on Mac"
    },
    {
      "answer": "Despite having similar aims and processes, there are two main differences between them: Machine learning works out predictions and recalibrates models in real-time automatically after design. Meanwhile, predictive analytics works strictly on \u201ccause\u201d data and must be refreshed with \u201cchange\u201d data.",
      "question": "What is the difference between analytics and machine learning"
    },
    {
      "answer": "The main difference between Independant and Independent is that the Independant is a misspelling of independent and Independent is a Not dependent; free; not subject to control by others; not relying on others.",
      "question": "What is the difference between independent and independant"
    },
    {
      "answer": "Statistical researchers often use a linear relationship to predict the (average) numerical value of Y for a given value of X using a straight line (called the regression line). If you know the slope and the y-intercept of that regression line, then you can plug in a value for X and predict the average value for Y.",
      "question": "How do you use linear regression to predict future values"
    },
    {
      "answer": "The binomial theorem is valid more generally for any elements x and y of a semiring satisfying xy = yx. The theorem is true even more generally: alternativity suffices in place of associativity. The binomial theorem can be stated by saying that the polynomial sequence {1, x, x2, x3, } is of binomial type.",
      "question": "What is binomial theorem"
    },
    {
      "answer": "In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss. A variant for classification is also sometimes used.",
      "question": "What is Huber regression"
    },
    {
      "answer": "The p-value is calculated using the sampling distribution of the test statistic under the null hypothesis, the sample data, and the type of test being done (lower-tailed test, upper-tailed test, or two-sided test).  an upper-tailed test is specified by: p-value = P(TS ts | H 0 is true) = 1 - cdf(ts)",
      "question": "What is the P value formula"
    },
    {
      "answer": "A unimodal distribution only has one peak in the distribution, a bimodal distribution has two peaks, and a multimodal distribution has three or more peaks. Another way to describe the shape of histograms is by describing whether the data is skewed or symmetric.",
      "question": "How many peaks does a multimodal distribution have"
    },
    {
      "answer": "Since this derivation of the LDA direction via least squares does not use a Gaussian assumption for the features, its applicability extends beyond the realm of Gaussian data. However the derivation of the particular intercept or cut-point given in (4.11) does require Gaussian data.",
      "question": "Does Linear Discriminant Analysis work for distributions other than Gaussian"
    },
    {
      "answer": "Consistency refers to logical and numerical coherence. Context: An estimator is called consistent if it converges in probability to its estimand as sample increases (The International Statistical Institute, \"The Oxford Dictionary of Statistical Terms\", edited by Yadolah Dodge, Oxford University Press, 2003).",
      "question": "What does consistent mean in statistics"
    },
    {
      "answer": "For a normal distribution, the average deviation is somewhat less efficient than the standard deviation as a measure of scale, but this advantage quickly reverses for distributions with heavier tails.",
      "question": "What is the advantage of the standard deviation over the average deviation"
    },
    {
      "answer": "The principle of maximum likelihood is a method of obtaining the optimum values of the parameters that define a model. And while doing so, you increase the likelihood of your model reaching the \u201ctrue\u201d model.",
      "question": "What is the principle of maximum likelihood"
    },
    {
      "answer": "Loss value implies how poorly or well a model behaves after each iteration of optimization. An accuracy metric is used to measure the algorithm's performance in an interpretable way. The accuracy of a model is usually determined after the model parameters and is calculated in the form of a percentage.",
      "question": "What is loss value"
    },
    {
      "answer": "Sampling error is one of two reasons for the difference between an estimate and the true, but unknown, value of the population parameter.  The sampling error for a given sample is unknown but when the sampling is random, the maximum likely size of the sampling error is called the margin of error.",
      "question": "What is the difference between sampling error and margin of error"
    },
    {
      "answer": "Below are the different regression techniques: Ridge Regression. Lasso Regression. Polynomial Regression. Bayesian Linear Regression.",
      "question": "What are the types of regression analysis"
    },
    {
      "answer": "Support vectors are the elements of the training set that would change the position of the dividing hyperplane if removed. d+ = the shortest distance to the closest positive point d- = the shortest distance to the closest negative point The margin (gutter) of a separating hyperplane is d+ + d\u2013.",
      "question": "How do you find the support vector"
    },
    {
      "answer": "Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.",
      "question": "What is one shot learning in neural networks"
    },
    {
      "answer": "Fine tuning is one approach to transfer learning. In Transfer Learning or Domain Adaptation we train the model with a dataset and after we train the same model with another dataset that has a different distribution of classes, or even with other classes than in the training dataset).",
      "question": "Is fine tuning a pre trained model equivalent to transfer learning"
    },
    {
      "answer": "A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.",
      "question": "What is ResNet neural network"
    },
    {
      "answer": "Optimization falls in this category \u2014 given an optimization problem, you can, in principle, find a solution to the problem, without any ambiguity whatsoever. Machine learning, on the other hand, falls in the domain of engineering. Problems in engineering are often not mathematically well-defined.",
      "question": "What is the difference between an optimization problem and a machine learning problem"
    },
    {
      "answer": "Class limits specify the span of data values that fall within a class. Class boundaries are possible data values. Class boundaries are not possible data values.",
      "question": "What is the difference between class limits and class boundaries in statistics"
    },
    {
      "answer": "Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model with training data distributed over a large number of clients each with unreliable and relatively slow network connections.",
      "question": "What is a federated learning model"
    },
    {
      "answer": "In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.",
      "question": "What does neural network convergence mean"
    },
    {
      "answer": "The mean is an important measure because it incorporates the score from every subject in the research study. The required steps for its calculation are: count the total number of cases\u2014referred in statistics as n; add up all the scores and divide by the total number of cases.",
      "question": "Why is the mean useful in statistics"
    },
    {
      "answer": "Interpreting. If skewness is positive, the data are positively skewed or skewed right, meaning that the right tail of the distribution is longer than the left. If skewness is negative, the data are negatively skewed or skewed left, meaning that the left tail is longer.",
      "question": "How do you interpret a positively skewed distribution"
    },
    {
      "answer": "Principal Component Analysis (PCA) is used to explain the variance-covariance structure of a set of variables through linear combinations. It is often used as a dimensionality-reduction technique.",
      "question": "What is the use of principal component analysis"
    },
    {
      "answer": "Y hat (written \u0177 ) is the predicted value of y (the dependent variable) in a regression equation. It can also be considered to be the average value of the response variable.  The equation is calculated during regression analysis.",
      "question": "What is Y hat in regression"
    },
    {
      "answer": "15:3248:19Suggested clip \u00b7 37 secondsMotion 5 | How to Use Motion Tracking, Analyze Motion, and Match YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you analyze motion"
    },
    {
      "answer": "A parameter is any summary number, like an average or percentage, that describes the entire population. The population mean (the greek letter \"mu\") and the population proportion p are two different population parameters. For example:  The population comprises all likely American voters, and the parameter is p.",
      "question": "What is parameter with example"
    },
    {
      "answer": "FP. N. FN. TN. where: P = Positive; N = Negative; TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.",
      "question": "What is TP TN FP FN"
    },
    {
      "answer": "Epsilon greedy policy is a way of selecting random actions with uniform distribution from a set of available actions.  This policy selects random actions in twice if the value of epsilon is 0.2. Consider a following example, There is a robot with capability to move in 4 direction. Up,down,left,right.",
      "question": "What is Epsilon greedy policy"
    },
    {
      "answer": "7 Advantages of Robots in the WorkplaceSafety. Safety is the most obvious advantage of utilizing robotics.  Speed. Robots don't get distracted or need to take breaks.  Consistency. Robots never need to divide their attention between a multitude of things.  Perfection. Robots will always deliver quality.  Happier Employees.  Job Creation.  Productivity.",
      "question": "What are the positive effects of robots"
    },
    {
      "answer": "Given any collection of pairs of numbers (except when all the x-values are the same) and the corresponding scatter diagram, there always exists exactly one straight line that fits the data better than any other, in the sense of minimizing the sum of the squared errors. It is called the least squares regression line.",
      "question": "What is special about a least squares regression line"
    },
    {
      "answer": "There are two main differences between regression and structural equation modelling. The first is that SEM allows us to develop complex path models with direct and indirect effects. This allows us to more accurately model causal mechanisms we are interested in. The second key difference is to do with measurement.",
      "question": "What is the difference between regression and structural equation modeling"
    },
    {
      "answer": "A unit of measurement is some specific quantity that has been chosen as the standard against which other measurements of the same kind are made.  The term standard refers to the physical object on which the unit of measurement is based.",
      "question": "What is unit and standard unit"
    },
    {
      "answer": "Eigenvalues and eigenvectors allow us to \"reduce\" a linear operation to separate, simpler, problems. For example, if a stress is applied to a \"plastic\" solid, the deformation can be dissected into \"principle directions\"- those directions in which the deformation is greatest.",
      "question": "What is the application of eigenvalues and eigenvectors"
    },
    {
      "answer": "Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. Random Forest is a tree-based model and hence does not require feature scaling.",
      "question": "Is feature scaling required for random forest"
    },
    {
      "answer": "2 Multivariate Data. Multivariate data contains, at each sample point, multiple scalar values that represent different simulated or measured quantities.",
      "question": "What is a multivariate data set"
    },
    {
      "answer": "Uncertainty is a popular phenomenon in machine learning and a variety of methods to model uncertainty at different levels has been developed.  Different types of uncertainty can be observed: (i) Input data are subject to noise, outliers, and errors.",
      "question": "What is uncertainty in machine learning"
    },
    {
      "answer": "In computer vision, the bag-of-words model (BoW model) sometimes called bag-of-visual-words model can be applied to image classification, by treating image features as words. In document classification, a bag of words is a sparse vector of occurrence counts of words; that is, a sparse histogram over the vocabulary.",
      "question": "What is Bag of Words in image processing"
    },
    {
      "answer": "The main benefit claimed for feature selection, which is the main focus in this manuscript, is that it increases classification accuracy. It is believed that removing non-informative signal can reduce noise, and can increase the contrast between labelled groups.",
      "question": "Does feature selection improve classification accuracy"
    },
    {
      "answer": "When used as nouns, quantile means one of the class of values of a variate which divides the members of a batch or sample into equal-sized subgroups of adjacent values or a probability distribution into distributions of equal probability, whereas quartile means any of the three points that divide an ordered",
      "question": "In statistics what is the difference between a quartile and a quantile"
    },
    {
      "answer": "A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.",
      "question": "How does residual network work"
    },
    {
      "answer": "Thus, the t-statistic measures how many standard errors the coefficient is away from zero. Generally, any t-value greater than +2 or less than \u2013 2 is acceptable. The higher the t-value, the greater the confidence we have in the coefficient as a predictor.",
      "question": "What is a good T stat"
    },
    {
      "answer": "A facial recognition system uses biometrics to map facial features from a photograph or video. It compares the information with a database of known faces to find a match.  That's because facial recognition has all kinds of commercial applications. It can be used for everything from surveillance to marketing.",
      "question": "How does facial verification work"
    },
    {
      "answer": "If X takes values in [a, b] and Y takes values in [c, d] then the pair (X, Y ) takes values in the product [a, b] \u00d7 [c, d]. The joint probability density function (joint pdf) of X and Y is a function f(x, y) giving the probability density at (x, y).",
      "question": "How do you find the joint probability density function"
    },
    {
      "answer": "Some common types of problems built on top of classification and regression include recommendation and time series prediction respectively. Some popular examples of supervised machine learning algorithms are: Linear regression for regression problems. Random forest for classification and regression problems.",
      "question": "What problems are suitable for supervised machine learning"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What is an activation function in machine learning"
    },
    {
      "answer": "In statistical classification, Bayes error rate is the lowest possible error rate for any classifier of a random outcome (into, for example, one of two categories) and is analogous to the irreducible error. A number of approaches to the estimation of the Bayes error rate exist.",
      "question": "What is the Bayesian probability of an error"
    },
    {
      "answer": "A cross-sectional study involves looking at data from a population at one specific point in time.  Cross-sectional studies are observational in nature and are known as descriptive research, not causal or relational, meaning that you can't use them to determine the cause of something, such as a disease.",
      "question": "What is a cross sectional study in statistics"
    },
    {
      "answer": "A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit overfitting without substantially increasing error due to bias is why they are such powerful models. One way Random Forests reduce variance is by training on different samples of the data.",
      "question": "Is Random Forest a decision tree"
    },
    {
      "answer": "Low Pass filtering: It is also known as the smoothing filter. It removes the high-frequency content from the image.  Median Filtering: It is also known as nonlinear filtering. It is used to eliminate salt and pepper noise.",
      "question": "Is median filter a low pass filter"
    },
    {
      "answer": "Linear regression is the next step up after correlation. It is used when we want to predict the value of a variable based on the value of another variable. The variable we want to predict is called the dependent variable (or sometimes, the outcome variable).",
      "question": "What is linear regression used for"
    },
    {
      "answer": "A person who engages in banditry is known as a bandit and primarily commits crimes such as extortion, robbery, and murder, either as an individual or in groups. Banditry is a vague concept of criminality and in modern usage can be synonymous for gangsterism, brigandage, marauding, and thievery.",
      "question": "What did bandits do"
    },
    {
      "answer": "Difference between K Means and Hierarchical clustering Hierarchical clustering can't handle big data well but K Means clustering can. This is because the time complexity of K Means is linear i.e. O(n) while that of hierarchical clustering is quadratic i.e. O(n2).",
      "question": "Which is better K means or hierarchical clustering"
    },
    {
      "answer": "In statistics, the phrase \"correlation does not imply causation\" refers to the inability to legitimately deduce a cause-and-effect relationship between two variables solely on the basis of an observed association or correlation between them.",
      "question": "If correlation does not imply causation what does it do"
    },
    {
      "answer": "Tests of Correlation: The validity of a test is measured by the strength of association, or correlation, between the results obtained by the test and by the criterion measure.",
      "question": "How do you measure validity in statistics"
    },
    {
      "answer": "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",
      "question": "What does gradient mean in Machine Learning"
    },
    {
      "answer": "To deal with categorical variables that have more than two levels, the solution is one-hot encoding. This takes every level of the category (e.g., Dutch, German, Belgian, and other), and turns it into a variable with two levels (yes/no).",
      "question": "How do you handle a categorical variable with many levels"
    },
    {
      "answer": "Brief Description. The Fourier Transform is an important image processing tool which is used to decompose an image into its sine and cosine components. The output of the transformation represents the image in the Fourier or frequency domain, while the input image is the spatial domain equivalent.",
      "question": "What is Fourier transform of an image"
    },
    {
      "answer": "The Bayes theorem describes the probability of an event based on the prior knowledge of the conditions that might be related to the event. If we know the conditional probability , we can use the bayes rule to find out the reverse probabilities .",
      "question": "When can Bayes theorem be used"
    },
    {
      "answer": "Type 1 error, in statistical hypothesis testing, is the error caused by rejecting a null hypothesis when it is true. Type II error is the error that occurs when the null hypothesis is accepted when it is not true.",
      "question": "What is the difference between a Type I error and a Type II error"
    },
    {
      "answer": "Distance MatrixThe proximity between object can be measured as distance matrix.  For example, distance between object A = (1, 1) and B = (1.5, 1.5) is computed as.Another example of distance between object D = (3, 4) and F = (3, 3.5) is calculated as.More items",
      "question": "How do you find the distance of a clustered Matrix"
    },
    {
      "answer": "What Are Moments in Statistics?Moments About the MeanFirst, calculate the mean of the values.Next, subtract this mean from each value.Then raise each of these differences to the sth power.Now add the numbers from step #3 together.Finally, divide this sum by the number of values we started with.",
      "question": "How do you find the moment in statistics"
    },
    {
      "answer": "Additivity is a property pertaining to a set of interdependent index numbers related by definition or by accounting constraints under which an aggregate is defined as the sum of its components; additivity requires this identity to be preserved when the values of both an aggregate and its components in some reference",
      "question": "What is additivity in statistics"
    },
    {
      "answer": "The first four are: 1) The mean, which indicates the central tendency of a distribution. 2) The second moment is the variance, which indicates the width or deviation. 3) The third moment is the skewness, which indicates any asymmetric 'leaning' to either left or right.",
      "question": "What are the four moments of statistics"
    },
    {
      "answer": "You probably have a numerical stability issue. This may happen due to zero division or any operation that is making a number(s) extremely big.",
      "question": "Why do l get NaN values when l train my neural network with a rectified linear unit"
    },
    {
      "answer": "The beta distribution of the first kind, usually written in terms of the incom- plete beta function, can be used to model the distribution of measurements whose values all lie between zero and one. It can also be used to model the distribution for the probability of occurrence of some discrete event.",
      "question": "What is the significance of the beta distribution What are some common applications"
    },
    {
      "answer": "Random event/process/variable: an event/process that is not and cannot be made exact and, consequently, whose outcome cannot be predicted, e.g., the sum of the numbers on two rolled dice.",
      "question": "What random events mean"
    },
    {
      "answer": "metric system. A system of measurement in which the basic units are the meter, the second, and the kilogram. In this system, the ratios between units of measurement are multiples of ten. For example, a kilogram is a thousand grams, and a centimeter is one-hundredth of a meter.",
      "question": "What is the definition of metric system"
    },
    {
      "answer": "A correlation between two variables does not imply causation. On the other hand, if there is a causal relationship between two variables, they must be correlated. Example: A study shows that there is a negative correlation between a student's anxiety before a test and the student's score on the test.",
      "question": "Are there ever any circumstances when a correlation can be interpreted as evidence for a causal connection between two variables"
    },
    {
      "answer": "A negative binomial random variable is the number X of repeated trials to produce r successes in a negative binomial experiment. The probability distribution of a negative binomial random variable is called a negative binomial distribution.  Suppose we flip a coin repeatedly and count the number of heads (successes).",
      "question": "What does the negative in negative binomial distribution signify"
    },
    {
      "answer": "The standard deviation of this set of mean values is the standard error. In lieu of taking many samples one can estimate the standard error from a single sample. This estimate is derived by dividing the standard deviation by the square root of the sample size.",
      "question": "What is the standard error of the mean difference"
    },
    {
      "answer": "An autoregressive model is when a value from a time series is regressed on previous values from that same time series.  The order of an autoregression is the number of immediately preceding values in the series that are used to predict the value at the present time.",
      "question": "What is autoregression time series"
    },
    {
      "answer": "Technically, the probability density of variable X , means the probability per unit increment of X . The units of probability density are the reciprocal of the units of X \u2014 if the units of X are dollars, the units of probability density are probability per dollar increment.",
      "question": "What are the units of a probability density function"
    },
    {
      "answer": "The term \"running median\" is typically used to refer to the median of a subset of data.",
      "question": "What is a running median"
    },
    {
      "answer": "How to calculate margin of errorGet the population standard deviation (\u03c3) and sample size (n).Take the square root of your sample size and divide it into your population standard deviation.Multiply the result by the z-score consistent with your desired confidence interval according to the following table:",
      "question": "How do you calculate the margin of error"
    },
    {
      "answer": "Spatiotemporal models arise when data are collected across time as well as space and has at least one spatial and one temporal property. An event in a spatiotemporal dataset describes a spatial and temporal phenomenon that exists at a certain time t and location x.",
      "question": "What is spatio temporal model"
    },
    {
      "answer": "In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation.  The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.",
      "question": "What is vanishing gradient problem in neural networks"
    },
    {
      "answer": "In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum.",
      "question": "How do you plot a box plot"
    },
    {
      "answer": "Inference over a Bayesian network can come in two forms. The first is simply evaluating the joint probability of a particular assignment of values for each variable (or a subset) in the network.  We would calculate P(\u00acx | e) in the same fashion, just setting the value of the variables in x to false instead of true.",
      "question": "What is inference in Bayesian networks"
    },
    {
      "answer": "Decision trees provide an effective method of Decision Making because they: Clearly lay out the problem so that all options can be challenged. Allow us to analyze fully the possible consequences of a decision. Provide a framework to quantify the values of outcomes and the probabilities of achieving them.",
      "question": "How is the decision tree useful"
    },
    {
      "answer": "There are several ways to check your Linear Regression model accuracy. Usually, you may use Root mean squared error. You may train several Linear Regression models, adding or removing features to your dataset, and see which one has the lowest RMSE - the best one in your case.",
      "question": "How do you find the accuracy of a linear regression model"
    },
    {
      "answer": "There are two types of factor analyses, exploratory and confirmatory. Exploratory factor analysis (EFA) is method to explore the underlying structure of a set of observed variables, and is a crucial step in the scale development process. The first step in EFA is factor extraction.",
      "question": "What are the types of factor analysis"
    },
    {
      "answer": "Advantages and disadvantagesAre simple to understand and interpret.  Have value even with little hard data.  Help determine worst, best and expected values for different scenarios.Use a white box model.  Can be combined with other decision techniques.",
      "question": "What are the advantages and disadvantages of decision tree"
    },
    {
      "answer": "If there are other predictor variables, all coefficients will be changed.  All the coefficients are jointly estimated, so every new variable changes all the other coefficients already in the model. This is one reason we do multiple regression, to estimate coefficient B1 net of the effect of variable Xm.",
      "question": "Why do coefficients change in multiple regression"
    },
    {
      "answer": "Random errors are statistical fluctuations (in either direction) in the measured data due to the precision limitations of the measurement device. Random errors usually result from the experimenter's inability to take the same measurement in exactly the same way to get exact the same number.",
      "question": "What are random errors"
    },
    {
      "answer": "The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.",
      "question": "Why is sigmoid a good activation function"
    },
    {
      "answer": "Ensemble learning methods are widely used nowadays for its predictive performance improvement. Ensemble learning combines multiple predictions (forecasts) from one or multiple methods to overcome accuracy of simple prediction and to avoid possible overfit.",
      "question": "Is it possible to use ensemble learning for time series forecast"
    },
    {
      "answer": "The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed.",
      "question": "What is the use of finding the root mean square error"
    },
    {
      "answer": "The distribution pX (x) is called the target distribution, while qX (x) is the sampling distribution or the proposal distribution.",
      "question": "In importance sampling what is the difference between p x and q x"
    },
    {
      "answer": "If there is no relationship between X and Y, the best guess for all values of X is the mean of Y. At any rate, the regression line always passes through the means of X and Y. This means that, regardless of the value of the slope, when X is at its mean, so is Y.",
      "question": "Why does regression line go through mean"
    },
    {
      "answer": "How to Calculate a CorrelationFind the mean of all the x-values.Find the standard deviation of all the x-values (call it sx) and the standard deviation of all the y-values (call it sy).  For each of the n pairs (x, y) in the data set, take.Add up the n results from Step 3.Divide the sum by sx \u2217 sy.More items",
      "question": "How do you find the correlation coefficient between two sets of data"
    },
    {
      "answer": "Selection bias can result when the selection of subjects into a study or their likelihood of being retained in the study leads to a result that is different from what you would have gotten if you had enrolled the entire target population.",
      "question": "How does selection bias affect results"
    },
    {
      "answer": "Regression analysis refers to assessing the relationship between the outcome variable and one or more variables.  For example, a correlation of r = 0.8 indicates a positive and strong association among two variables, while a correlation of r = -0.3 shows a negative and weak association.",
      "question": "What is meant by correlation and regression analysis"
    },
    {
      "answer": "The standard error of the regression (S), also known as the standard error of the estimate, represents the average distance that the observed values fall from the regression line. Conveniently, it tells you how wrong the regression model is on average using the units of the response variable.",
      "question": "What does standard error of estimate tell you"
    },
    {
      "answer": "A sampling frame is a list of all the items in your population. It's a complete list of everyone or everything you want to study. The difference between a population and a sampling frame is that the population is general and the frame is specific.",
      "question": "Can a sampling frame be seen as a population"
    },
    {
      "answer": "Fewer than 1,000 steps a day is sedentary. 1,000 to 10,000 steps or about 4 miles a day is Lightly Active. 10,000 to 23,000 steps or 4 to 10 miles a day is considered Active. More than 23,000 steps or 10 miles a day is Highly active.",
      "question": "What is considered active activity level"
    },
    {
      "answer": "A series converges uniformly on if the sequence of partial sums defined by. (2) converges uniformly on . To test for uniform convergence, use Abel's uniform convergence test or the Weierstrass M-test.",
      "question": "What is uniform convergence series"
    },
    {
      "answer": "Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)",
      "question": "What is meant by machine learning algorithms"
    },
    {
      "answer": "Transfer learning without any labeled data from the target domain is referred to as unsupervised transfer learning.",
      "question": "Is transfer learning unsupervised"
    },
    {
      "answer": "Bootstrapping is any test or metric that uses random sampling with replacement, and falls under the broader class of resampling methods. Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates.",
      "question": "What does bootstrapping mean in statistics"
    },
    {
      "answer": ": a function (such as y = loga x or y = ln x) that is the inverse of an exponential function (such as y = ax or y = ex) so that the independent variable appears in a logarithm.",
      "question": "What is a logarithmic function definition"
    },
    {
      "answer": "Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods.",
      "question": "What do you mean by constraint satisfaction problem"
    },
    {
      "answer": "A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.",
      "question": "What is mean by sampling error"
    },
    {
      "answer": "The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.",
      "question": "How do you fix a vanishing gradient problem"
    },
    {
      "answer": "Fisher's exact test is a statistical test used to determine if there are nonrandom associations between two categorical variables. . For each one, calculate the associated conditional probability using (2), where the sum of these probabilities must be 1.",
      "question": "What is Fisher's exact test used for"
    },
    {
      "answer": ": being or having the shape of a normal curve or a normal distribution.",
      "question": "What does Gaussian mean"
    },
    {
      "answer": "A low R-squared value indicates that your independent variable is not explaining much in the variation of your dependent variable - regardless of the variable significance, this is letting you know that the identified independent variable, even though significant, is not accounting for much of the mean of your",
      "question": "What does a low R squared value mean"
    },
    {
      "answer": "A little bit of coding skills is enough, but it's better to have knowledge of data structures, algorithms, and OOPs concept. Some of the popular programming languages to learn machine learning in are Python, R, Java, and C++.",
      "question": "Is coding required in machine learning"
    },
    {
      "answer": "Natural Language processing is considered a difficult problem in computer science. It's the nature of the human language that makes NLP difficult.  While humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.",
      "question": "Why is NLP difficult"
    },
    {
      "answer": "A high-pass filter (HPF) is an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency. The amount of attenuation for each frequency depends on the filter design.",
      "question": "How does a high pass RC filter work"
    },
    {
      "answer": "For example, a two-way ANOVA allows a company to compare worker productivity based on two independent variables, such as salary and skill set. It is utilized to observe the interaction between the two factors and tests the effect of two factors at the same time.",
      "question": "What is analysis of variance example"
    },
    {
      "answer": "Best practices \u2013 Machine Learning models and applicationsIdentify the business problem and the right success metrics.  Begin with it.  Gather correct data.  Move the algorithms instead of your data.  Initiate tests before the actual launch.  Avoid data dropping while machine learning algorithms train.  Keep away from objectives that are unaligned.  Keep using codes.More items\u2022",
      "question": "What are some best practices for training machine learning models"
    },
    {
      "answer": "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.",
      "question": "How do you find the similarity between two vectors"
    },
    {
      "answer": "Train the model using a suitable machine learning algorithm such as SVM (Support Vector Machines), decision trees, random forest, etc. Training is the process through which the model learns or recognizes the patterns in the given data for making suitable predictions. The test set contains already predicted values.",
      "question": "Which machine learning technique is used for pattern recognition"
    },
    {
      "answer": "The 2nd moment around the mean = \u03a3(xi \u2013 \u03bcx)2. The second is the variance. In practice, only the first two moments are ever used in statistics.",
      "question": "How do you find second moment in statistics"
    },
    {
      "answer": "In statistics and research, internal consistency is typically a measure based on the correlations between different items on the same test (or the same subscale on a larger test). It measures whether several items that propose to measure the same general construct produce similar scores.",
      "question": "What is Internal Consistency in testing"
    },
    {
      "answer": "Gravity tries to keep things together through attraction and thus tends to lower statistical entropy. The universal law of increasing entropy (2nd law of thermodynamics) states that the entropy of an isolated system which is not in equilibrium will tend to increase with time, approaching a maximum value at equilibrium.",
      "question": "How is gravity related to entropy"
    },
    {
      "answer": "Connectionism, an approach to artificial intelligence (AI) that developed out of attempts to understand how the human brain works at the neural level and, in particular, how people learn and remember.  (For that reason, this approach is sometimes referred to as neuronlike computing.)",
      "question": "What is connectionist AI"
    },
    {
      "answer": "An (ordinary) Poisson process is a special Markov process [ref. to Stadje in this volume], in continuous time, in which the only possible jumps are to the next higher state. A Poisson process may also be viewed as a counting process that has particular, desirable, properties.",
      "question": "Is Poisson process a Markov process"
    },
    {
      "answer": "Clustering analysis is broadly used in many applications such as market research, pattern recognition, data analysis, and image processing. Clustering can also help marketers discover distinct groups in their customer base. And they can characterize their customer groups based on the purchasing patterns.",
      "question": "Where can cluster analysis be applied"
    },
    {
      "answer": "The false alarm probability is the probability that exceeds a certain threshold when there is no signal.",
      "question": "What is probability of false alarm"
    },
    {
      "answer": "Classification Accuracy It is the ratio of number of correct predictions to the total number of input samples. It works well only if there are equal number of samples belonging to each class. For example, consider that there are 98% samples of class A and 2% samples of class B in our training set.",
      "question": "How do you know if a classification model is accurate"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is the difference between supervised and unsupervised machine learning"
    },
    {
      "answer": "Correlation is the concept of linear relationship between two variables.  Whereas correlation coefficient is a measure that measures linear relationship between two variables.",
      "question": "What is the difference between correlation and correlation coefficient"
    },
    {
      "answer": "Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.",
      "question": "How are decision trees used for regression"
    },
    {
      "answer": "Increase the power of your analysis.larger sample size.better data collection (reducing error)better/correct model (more complex model, account for covariates, etc.)use a one-sided test instead of a two-sided test.",
      "question": "How do you decrease P value in regression"
    },
    {
      "answer": "In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.",
      "question": "What are fixed effects in regression"
    },
    {
      "answer": "Specifical- ly, for periodic signals we can define the Fourier transform as an impulse train with the impulses occurring at integer multiples of the fundamental frequency and with amplitudes equal to 27r times the Fourier series coefficients.",
      "question": "What is the Fourier transform of a periodic signal"
    },
    {
      "answer": "The crucial difference between FIR and IIR filter is that the FIR filter provides an impulse response of finite period. As against IIR is a type of filter that generates impulse response of infinite duration for a dynamic system.",
      "question": "What is difference between FIR and IIR filters"
    },
    {
      "answer": "Bivariate statistics is a type of inferential statistics that deals with the relationship between two variables.  When bivariate statistics is employed to examine a relationship between two variables, bivariate data is used. Bivariate data consists of data collected from a sample on two different variables.",
      "question": "What is bivariate in statistics"
    },
    {
      "answer": "IAT is a popular measure in social psychology to measure the relative strength of association between pairs of concepts (Greenwald, McGhee, & Schwartz, 1998).  Studies have found that racial bias IAT studies have a test-retest reliability score of only 0.44, while the IAT overall is just around 0.5.",
      "question": "Is the Implicit Association Test having poor test retest reliability"
    },
    {
      "answer": "Bimodal Distribution: Two Peaks. The bimodal distribution has two peaks.  However, if you think about it, the peaks in any distribution are the most common number(s). The two peaks in a bimodal distribution also represent two local maximums; these are points where the data points stop increasing and start decreasing.",
      "question": "How do you describe bimodal distribution"
    },
    {
      "answer": "The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases.  Therefore, as a sample size increases, the sample mean and standard deviation will be closer in value to the population mean \u03bc and standard deviation \u03c3 .",
      "question": "What happens if the sample size increases"
    },
    {
      "answer": "5:1515:11Suggested clip \u00b7 109 secondsStatQuest: Linear Discriminant Analysis (LDA) clearly explained YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do linear discriminant analysis"
    },
    {
      "answer": "1 Answer. Normalized discounted cumulative gain is one of the standard method of evaluating ranking algorithms. You will need to provide a score to each of the recommendations that you give. If your algorithm assigns a low (better) rank to a high scoring entity, your NDCG score will be higher, and vice versa.",
      "question": "How do you evaluate a rank algorithm"
    },
    {
      "answer": "Linear Activation Function A linear activation function takes the form: A = cx. It takes the inputs, multiplied by the weights for each neuron, and creates an output signal proportional to the input. In one sense, a linear function is better than a step function because it allows multiple outputs, not just yes and no.",
      "question": "What is linear activation function in neural network"
    },
    {
      "answer": "\u23e9 optimal policy: the best action to take at each state, for maximum rewards over time. To help our agent do this, we need two things: A way to determine the value of a state in MDP. An estimated value of an action taken at a particular state.",
      "question": "What is optimal policy in reinforcement learning"
    },
    {
      "answer": "Classification is a machine learning concept. It is used for categorical dependent variables, where we need to classify into required groups. Logistic regression is a algorithm within classification.",
      "question": "What is the difference between logistic regression and classification"
    },
    {
      "answer": "In the mathematical discipline of linear algebra, a matrix decomposition or matrix factorization is a factorization of a matrix into a product of matrices. There are many different matrix decompositions; each finds use among a particular class of problems.",
      "question": "Can you Factorise matrices"
    },
    {
      "answer": "The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image.",
      "question": "What is Histogram of Oriented Gradients and how does it work"
    },
    {
      "answer": "The t\u2010distribution is used as an alternative to the normal distribution when sample sizes are small in order to estimate confidence or determine critical values that an observation is a given distance from the mean.",
      "question": "Why do we use t distribution"
    },
    {
      "answer": "Mixed effects models are useful when we have data with more than one source of random variability. For example, an outcome may be measured more than once on the same person (repeated measures taken over time). When we do that we have to account for both within-person and across-person variability.",
      "question": "When would you use a mixed model"
    },
    {
      "answer": "Inverted dropout is a variant of the original dropout technique developed by Hinton et al.  The one difference is that, during the training of a neural network, inverted dropout scales the activations by the inverse of the keep probability q=1\u2212p q = 1 \u2212 p .",
      "question": "What is inverted dropout technique"
    },
    {
      "answer": "Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference.  Particle filters update their prediction in an approximate (statistical) manner.",
      "question": "What is a particle filter used for"
    },
    {
      "answer": "Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.",
      "question": "What do you understand by bias variance trade off"
    },
    {
      "answer": "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated. One cycle through the entire training dataset is called a training epoch.",
      "question": "How does batch gradient descent work"
    },
    {
      "answer": "Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels. it can be done with convolution. For examples, mean/average filters or Gaussian filtering. A non-linear filtering is one that cannot be done with convolution or Fourier multiplication.",
      "question": "What is difference between linear filtersand nonlinear filters"
    },
    {
      "answer": "For linear algebra, it's very helpful to prepare by doing simple practice problems with the basic axioms of vector spaces and inner products. I was always mediocre at algebra, but good at visualizing 2D and 3D things.",
      "question": "How do you prepare linear algebra"
    },
    {
      "answer": "Joint probability is calculated by multiplying the probability of event A, expressed as P(A), by the probability of event B, expressed as P(B). For example, suppose a statistician wishes to know the probability that the number five will occur twice when two dice are rolled at the same time.",
      "question": "How do you find joint probability"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What is the meaning of variance"
    },
    {
      "answer": "3.1. Coreference resolution (or anaphora) is an expression, the interpretation of which depends on another word or phrase presented earlier in the text (antecedent). For example, \u201cTom has a backache. He was injured.\u201d Here the words \u201cTom\u201d and \u201cHe\u201d refer to the same entity.",
      "question": "How do coreference resolution anaphora resolution algorithms work"
    },
    {
      "answer": "Multinomial logistic regression is used to predict categorical placement in or the probability of category membership on a dependent variable based on multiple independent variables. The independent variables can be either dichotomous (i.e., binary) or continuous (i.e., interval or ratio in scale).",
      "question": "What is meant by multinomial logistic regression"
    },
    {
      "answer": "Marginal probability: the probability of an event occurring (p(A)), it may be thought of as an unconditional probability. It is not conditioned on another event. Example: the probability that a card drawn is red (p(red) = 0.5).",
      "question": "What is marginal probability in statistics"
    },
    {
      "answer": "DBSCAN works as such: Divides the dataset into n dimensions. For each point in the dataset, DBSCAN forms an n dimensional shape around that data point, and then counts how many data points fall within that shape. DBSCAN counts this shape as a cluster.",
      "question": "How does Dbscan algorithm work"
    },
    {
      "answer": "The general procedure for using regression to make good predictions is the following:Research the subject-area so you can build on the work of others.  Collect data for the relevant variables.Specify and assess your regression model.If you have a model that adequately fits the data, use it to make predictions.",
      "question": "How do you predict regression"
    },
    {
      "answer": "Q-Learning is a value-based reinforcement learning algorithm which is used to find the optimal action-selection policy using a Q function. Our goal is to maximize the value function Q. The Q table helps us to find the best action for each state.  Initially we explore the environment and update the Q-Table.",
      "question": "What is Q function explain Q learning with suitable example"
    },
    {
      "answer": "A decision tree is a simple representation for classifying examples. For this section, assume that all of the input features have finite discrete domains, and there is a single target feature called the \"classification\". Each element of the domain of the classification is called a class.",
      "question": "What is a class in decision tree learning"
    },
    {
      "answer": "A qualitative variable, also called a categorical variable, is a variable that isn't numerical. It describes data that fits into categories. For example: Eye colors (variables include: blue, green, brown, hazel).",
      "question": "Is colour a qualitative variable"
    },
    {
      "answer": "One-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is a heuristic method for using binary classification algorithms for multi-class classification. It involves splitting the multi-class dataset into multiple binary classification problems.",
      "question": "What is one vs all classification in machine learning"
    },
    {
      "answer": "Any sum or difference or independent normal random variables is also normally distributed. A binomial setting arises when we perform several independent trials of the same chance process and record the number of times a particular outcome occurs.",
      "question": "What happens if two independent normal random variables are combined"
    },
    {
      "answer": "Cluster sampling refers to a type of sampling method . With cluster sampling, the researcher divides the population into separate groups, called clusters. Then, a simple random sample of clusters is selected from the population. The researcher conducts his analysis on data from the sampled clusters.",
      "question": "How does cluster sampling work"
    },
    {
      "answer": "According to the realistic conflict theory, ingroup bias arises from competition for resources between groups. Since different groups are all competing for the same available resources, it serves the best interests of the group to favor members while spurning outsiders.",
      "question": "Why does ingroup bias occur"
    },
    {
      "answer": "The cosine similarity is the cosine of the angle between two vectors. Figure 1 shows three 3-dimensional vectors and the angles between each pair. In text analysis, each vector can represent a document. The greater the value of \u03b8, the less the value of cos \u03b8, thus the less the similarity between two documents.",
      "question": "How do you find the cosine similarity between two documents"
    },
    {
      "answer": "Another view however is that the parameter value used to generate the data that are obtained in your study is just one drawn parameter value, where the draw is from some distribution (the prior).  as parameters, but rather as random or latent effects.",
      "question": "Are parameters random"
    },
    {
      "answer": "So here are some signs you're highly intelligent, even if you don't feel like it.You're Empathetic And Compassionate. Andrew Zaeh for Bustle.  You're Curious About The World.  You're Observant.  You Have Self-Control.  You Have A Good Working Memory.  You Like To Go With The Flow.More items\u2022",
      "question": "How can you tell if someone is highly intelligent"
    },
    {
      "answer": "In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge.",
      "question": "What are convolutional filters"
    },
    {
      "answer": "Covariance is calculated by analyzing at-return surprises (standard deviations from the expected return) or by multiplying the correlation between the two variables by the standard deviation of each variable.",
      "question": "How do you find the covariance between two variables"
    },
    {
      "answer": "Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Supervised learning allows you to collect data or produce a data output from the previous experience. Unsupervised machine learning helps you to finds all kind of unknown patterns in data.",
      "question": "Is Machine Learning supervised or unsupervised"
    },
    {
      "answer": "You can use tf. function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use SavedModel .  function works under the hood so you can use it effectively.",
      "question": "What is TF function"
    },
    {
      "answer": "Frequency distribution in statistics is a representation that displays the number of observations within a given interval. The representation of a frequency distribution can be graphical or tabular so that it is easier to understand.",
      "question": "What is a frequency distribution in statistics"
    },
    {
      "answer": "Feature Extraction using Convolution Neural Networks (CNN) and Deep Learning.  It is a process which involves the following tasks of pre-processing the image (normalization), image segmentation, extraction of key features and identification of the class.",
      "question": "What is feature extraction in CNN"
    },
    {
      "answer": "Sometimes we want to know the probability of getting one result or another. When events are mutually exclusive and we want to know the probability of getting one event OR another, then we can use the OR rule.  P(A or B) = P(A) + P(B) for mutually exclusive events.",
      "question": "What is the OR rule in probability"
    },
    {
      "answer": "K nearest neighbors is a simple algorithm that stores all available cases and predict the numerical target based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.",
      "question": "Can Knn be used for prediction"
    },
    {
      "answer": "First, logistic regression does not require a linear relationship between the dependent and independent variables. Second, the error terms (residuals) do not need to be normally distributed.  This means that the independent variables should not be too highly correlated with each other.",
      "question": "Should independent variables be normally distributed for ordered logit model"
    },
    {
      "answer": "The pdf represents the relative frequency of failure times as a function of time. The cdf is a function, F(x)\\,\\!, of a random variable X\\,\\!, and is defined for a number x\\,\\!",
      "question": "What is the relationship between PDF and CDF"
    },
    {
      "answer": "In regression analysis, the dependent variable is denoted \"Y\" and the independent variables are denoted by \"X\".",
      "question": "How do you identify independent and dependent variables in regression analysis"
    },
    {
      "answer": "11 websites to find free, interesting datasetsFiveThirtyEight.  BuzzFeed News.  Kaggle.  Socrata.  Awesome-Public-Datasets on Github.  Google Public Datasets.  UCI Machine Learning Repository.  Data.gov.More items",
      "question": "How do I find datasets"
    },
    {
      "answer": "Random error varies unpredictably from one measurement to another, while systematic error has the same value or proportion for every measurement. Random errors are unavoidable, but cluster around the true value.",
      "question": "What is the difference between random errors and non random errors in experimental data"
    },
    {
      "answer": "In mathematics, a generating function is a way of encoding an infinite sequence of numbers (an) by treating them as the coefficients of a formal power series.  Generating functions are often expressed in closed form (rather than as a series), by some expression involving operations defined for formal series.",
      "question": "What is meant by generating function"
    },
    {
      "answer": "The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution. But where the chi-squared distribution deals with the degree of freedom with one set of variables, the F-distribution deals with multiple levels of events having different degrees of freedom.",
      "question": "What is af distribution"
    },
    {
      "answer": "10:1614:33Suggested clip \u00b7 106 secondsPermutation Hypothesis Test in R with Examples | R Tutorial 4.6 YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do permutation test in R"
    },
    {
      "answer": "Real numbers consist of zero (0), the positive and negative integers (-3, -1, 2, 4), and all the fractional and decimal values in between (0.4, 3.1415927, 1/2). Real numbers are divided into rational and irrational numbers.",
      "question": "Is 0 a real number"
    },
    {
      "answer": "XGboost is the most widely used algorithm in machine learning, whether the problem is a classification or a regression problem. It is known for its good performance as compared to all other machine learning algorithms.",
      "question": "Is XGBoost good for regression"
    },
    {
      "answer": "Bayesian learning uses Bayes' theorem to determine the conditional probability of a hypotheses given some evidence or observations.",
      "question": "What is Bayesian learning in machine learning"
    },
    {
      "answer": "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable.",
      "question": "What does linear regression tell you"
    },
    {
      "answer": "Mentor: Well, if the line is a good fit for the data then the residual plot will be random. However, if the line is a bad fit for the data then the plot of the residuals will have a pattern.",
      "question": "How do you know if a residual plot is good"
    },
    {
      "answer": "Build the model on the training set and then use the test set as a holdout sample to test your trained model using the test data. Compare the predicted values with the actual values by calculating the error using measures such as the \"Mean Absolute Percent Error\" (MAPE) for example.",
      "question": "How can you tell if the predictive model is accurate"
    },
    {
      "answer": "The Implicit Association Test (IAT) measures the strength of associations between concepts (e.g., black people, gay people) and evaluations (e.g., good, bad) or stereotypes (e.g., athletic, clumsy). The main idea is that making a response is easier when closely related items share the same response key.",
      "question": "How does the implicit bias test work"
    },
    {
      "answer": "The key to interpreting a hierarchical cluster analysis is to look at the point at which any given pair of cards \u201cjoin together\u201d in the tree diagram. Cards that join together sooner are more similar to each other than those that join together later.",
      "question": "How do you interpret a hierarchical cluster analysis"
    },
    {
      "answer": "Most data can be categorized into 4 basic types from a Machine Learning perspective: numerical data, categorical data, time-series data, and text.",
      "question": "What are the different types of data sets used in ML"
    },
    {
      "answer": "Two types of statistical methods are used in analyzing data: descriptive statistics and inferential statistics. Descriptive statistics are used to synopsize data from a sample exercising the mean or standard deviation. Inferential statistics are used when data is viewed as a subclass of a specific population.",
      "question": "What are the different types of statistics used in research"
    },
    {
      "answer": "A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem. \u2014 Practical recommendations for gradient-based training of deep architectures, 2012.",
      "question": "What should be the learning rate"
    },
    {
      "answer": "Key Differences between AI, ML, and NLP ML is an application of AI. Machine Learning is basically the ability of a system to learn by itself without being explicitly programmed. Deep Learning is a part of Machine Learning which is applied to larger data-sets and based on ANN (Artificial Neural Networks).",
      "question": "What is the difference between AI machine learning NLP and deep learning"
    },
    {
      "answer": "The relative frequencies add up to 1.",
      "question": "Aside in a relative frequency distribution what should the relative frequencies add up to"
    },
    {
      "answer": "Quartiles let us quickly divide a set of data into four groups, making it easy to see which of the four groups a particular data point is in. For example, a professor has graded an exam from 0-100 points.",
      "question": "How are quartiles used in real life"
    },
    {
      "answer": "The exponential distribution is a continuous probability distribution used to model the time we need to wait before a given event occurs. It is the continuous counterpart of the geometric distribution, which is instead discrete.",
      "question": "Why do we use exponential distribution"
    },
    {
      "answer": "Hyperparameter optimization is a big part of deep learning. The reason is that neural networks are notoriously difficult to configure and there are a lot of parameters that need to be set. On top of that, individual models can be very slow to train.",
      "question": "Why do we need to do Hyperparameter tuning in neural networks"
    },
    {
      "answer": "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.  The rows represent the predicted values of the target variable.",
      "question": "What is confusion matrix in machine learning"
    },
    {
      "answer": "A learning algorithm is a method used to process data to extract patterns appropriate for application in a new situation. In particular, the goal is to adapt a system to a specific input-output transformation task.",
      "question": "What is a learning algorithm"
    },
    {
      "answer": "Basically, the test compares the fit of two models. The null hypothesis is that the smaller model is the \u201cbest\u201d model; It is rejected when the test statistic is large. In other words, if the null hypothesis is rejected, then the larger model is a significant improvement over the smaller one.",
      "question": "What is the null hypothesis for likelihood ratio test"
    },
    {
      "answer": "In computational linguistics, second-order co-occurrence pointwise mutual information is a semantic similarity measure. To assess the degree of association between two given words, it uses pointwise mutual information (PMI) to sort lists of important neighbor words of the two target words from a large corpus.",
      "question": "How does second order pointwise mutual information information retrieval work"
    },
    {
      "answer": "In cryptography, padding is any of a number of distinct practices which all include adding data to the beginning, middle, or end of a message prior to encryption.",
      "question": "What is padding in encryption"
    },
    {
      "answer": "Matrix factorization using the alternating least squares algorithm for collaborative filtering. Alternating least squares (ALS) is an optimization technique to solve the matrix factorization problem. This technique achieves good performance and has proven relatively easy to implement.",
      "question": "What is the significance of alternating least squares in collaborative filtering"
    },
    {
      "answer": "Predictive modeling is the process of using known results to create, process, and validate a model that can be used to forecast future outcomes. It is a tool used in predictive analytics, a data mining technique that attempts to answer the question \"what might possibly happen in the future?\"",
      "question": "How does predictive modeling work"
    },
    {
      "answer": "So the probability that the sample mean will be >22 is the probability that Z is > 1.6 We use the Z table to determine this: P( > 22) = P(Z > 1.6) = 0.0548.",
      "question": "How do you find the probability of a sample mean"
    },
    {
      "answer": "The gradients carry information used in the RNN parameter update and when the gradient becomes smaller and smaller, the parameter updates become insignificant which means no real learning is done. Let's have a short reminder of how RNNs look like.",
      "question": "What is gradient RNN"
    },
    {
      "answer": "The probability that a random variable X X X takes a value in the (open or closed) interval [ a , b ] [a,b] [a,b] is given by the integral of a function called the probability density function f X ( x ) f_X(x) fX\u200b(x): P ( a \u2264 X \u2264 b ) = \u222b a b f X ( x ) d x .",
      "question": "How do you find the probability density function of a random variable"
    },
    {
      "answer": "1:2611:18Suggested clip \u00b7 118 secondsMultiple Logistic Regression in SPSS - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do a multiple logistic regression in SPSS"
    },
    {
      "answer": "In short, it ensures each subgroup within the population receives proper representation within the sample. As a result, stratified random sampling provides better coverage of the population since the researchers have control over the subgroups to ensure all of them are represented in the sampling.",
      "question": "Why is stratified sampling used"
    },
    {
      "answer": "How to Use GA for Optimization Problems?Generate the initial population randomly.Select the initial solution with the best fitness values.Recombine the selected solutions using mutation and crossover operators.Insert offspring into the population.More items",
      "question": "How is genetic algorithm used in neural networks"
    },
    {
      "answer": "Correlation analysis explores the association between two or more variables and makes inferences about the strength of the relationship.  Technically, association refers to any relationship between two variables, whereas correlation is often used to refer only to a linear relationship between two variables.",
      "question": "What is Association and correlation in data mining"
    },
    {
      "answer": "Under the batch processing model, a set of data is collected over time, then fed into an analytics system. In other words, you collect a batch of information, then send it in for processing. Under the streaming model, data is fed into analytics tools piece-by-piece. The processing is usually done in real time.",
      "question": "What are the differences between batch processing and stream processing systems"
    },
    {
      "answer": "In systematic sampling, the list of elements is \"counted off\". That is, every kth element is taken.  Stratified sampling also divides the population into groups called strata. However, this time it is by some characteristic, not geographically.",
      "question": "What is the difference between stratified sampling and systematic sampling"
    },
    {
      "answer": "Vector autoregression (VAR) is a statistical model used to capture the relationship between multiple quantities as they change over time.  VAR models generalize the single-variable (univariate) autoregressive model by allowing for multivariate time series. VAR models are often used in economics and the natural sciences.",
      "question": "What is VAR model in econometrics"
    },
    {
      "answer": "Topic modelling refers to the task of identifying topics that best describes a set of documents.  And the goal of LDA is to map all the documents to the topics in a way, such that the words in each document are mostly captured by those imaginary topics.",
      "question": "How does LDA topic modeling work"
    },
    {
      "answer": "Deep learning (sometimes known as deep structured learning) is a subset of machine learning, where machines employ artificial neural networks to process information. Inspired by biological nodes in the human body, deep learning helps computers to quickly recognize and process images and speech.",
      "question": "What is deep learning and how is it useful"
    },
    {
      "answer": "Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.",
      "question": "What is the use of gradient descent in machine learning"
    },
    {
      "answer": "A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.",
      "question": "What is ResNet in deep learning"
    },
    {
      "answer": "7 Answers. Gradient is covariant!  The components of a vector contravariant because they transform in the inverse (i.e. contra) way of the vector basis. It is customary to denote these components with an upper index.",
      "question": "Why is gradient covariant"
    },
    {
      "answer": "OCR converts images of typed or handwritten text into machine-encoded text. The major steps in image recognition process are gather and organize data, build a predictive model and use it to recognize images.",
      "question": "How does image recognition AI work"
    },
    {
      "answer": "more  A symbol for a value we don't know yet. It is usually a letter like x or y. Example: in x + 2 = 6, x is the variable.",
      "question": "What is variable and example"
    },
    {
      "answer": "The general algorithm is The Backpropagation algorithm is suitable for the feed forward neural network on fixed sized input-output pairs. The Backpropagation Through Time is the application of Backpropagation training algorithm which is applied to the sequence data like the time series.",
      "question": "What is the difference between backpropagation algorithm and Backpropagation through time Bptt algorithm"
    },
    {
      "answer": "The range is influenced too much by extreme values.",
      "question": "Which difficulty of range as a measure of variability is overcome by interquartile range"
    },
    {
      "answer": "Stochastic processes appear in many different fields, including the physical sciences such as biology, chemistry, ecology, neuroscience, and physics as well as technology and engineering fields such as image processing, signal processing, information theory, computer science,, cryptography and telecommunications.",
      "question": "Where is stochastic processes used"
    },
    {
      "answer": "Define Population Distribution; and sketch a graph: The population distribution gives the values of the variable for all the individuals in the population.  The sampling distribution shows the statistic values from all the possible samples of the same size from the population. It is a distribution of the statistic.",
      "question": "What is the difference between a sampling distribution and a population distribution"
    },
    {
      "answer": "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.  But if we instead take steps proportional to the positive of the gradient, we approach a local maximum of that function; the procedure is then known as gradient ascent.",
      "question": "Is gradient descent an optimization algorithm"
    },
    {
      "answer": "Iterable is an object, which one can iterate over. It generates an Iterator when passed to iter() method. Iterator is an object, which is used to iterate over an iterable object using __next__() method.  Note that every iterator is also an iterable, but not every iterable is an iterator.",
      "question": "What are iterators and Iterables in Python"
    },
    {
      "answer": "Gibbs Sampling is based on sampling from condi- tional distributions of the variables of the posterior.  For LDA, we are interested in the latent document-topic portions \u03b8d, the topic-word distributions \u03c6(z), and the topic index assignments for each word zi.",
      "question": "What is Gibbs sampling in LDA"
    },
    {
      "answer": "This cross-sectional sample provides us with a snapshot of that population, at that one point in time.  Panel data differs from pooled cross-sectional data across time, because it deals with the observations on the same subjects in different times whereas the latter observes different subjects in different time periods.",
      "question": "What is the difference between cross sectional data and panel data"
    },
    {
      "answer": "Popular algorithms that can be used for binary classification include:Logistic Regression.k-Nearest Neighbors.Decision Trees.Support Vector Machine.Naive Bayes.",
      "question": "Which algorithms are used to do a binary classification"
    },
    {
      "answer": "Textual entailment (TE) in natural language processing is a directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. In the TE framework, the entailing and entailed texts are termed text (t) and hypothesis (h), respectively.",
      "question": "How can you explain the concept of Recognizing Textual Entailment in NLP"
    },
    {
      "answer": "An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled.",
      "question": "What is the purpose of an F test"
    },
    {
      "answer": "Example: One nanogram of Plutonium-239 will have an average of 2.3 radioactive decays per second, and the number of decays will follow a Poisson distribution.",
      "question": "What is the real life example of Poisson distribution"
    },
    {
      "answer": "Dimensionality Reduction and PCA. Dimensionality reduction refers to reducing the number of input variables for a dataset. If your data is represented using rows and columns, such as in a spreadsheet, then the input variables are the columns that are fed as input to a model to predict the target variable.",
      "question": "What is PCA dimensionality reduction"
    },
    {
      "answer": "While a P value can inform the reader whether an effect exists, the P value will not reveal the size of the effect. In reporting and interpreting studies, both the substantive significance (effect size) and statistical significance (P value) are essential results to be reported.",
      "question": "Is AP value an effect size"
    },
    {
      "answer": "In probability theory, an event is an outcome or defined collection of outcomes of a random experiment. Since the collection of all possible outcomes to a random experiment is called the sample space, another definiton of event is any subset of a sample space.",
      "question": "What is the definition of an event in statistics"
    },
    {
      "answer": "Linear filters process time-varying input signals to produce output signals, subject to the constraint of linearity.  Since linear time-invariant filters can be completely characterized by their response to sinusoids of different frequencies (their frequency response), they are sometimes known as frequency filters.",
      "question": "What makes a filter linear"
    },
    {
      "answer": "Stationarity. A common assumption in many time series techniques is that the data are stationary. A stationary process has the property that the mean, variance and autocorrelation structure do not change over time.",
      "question": "What is stationarity in time series analysis"
    },
    {
      "answer": "The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population. In the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.",
      "question": "What does the law of large numbers say"
    },
    {
      "answer": "The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes. The ID3 algorithm builds decision trees using a top-down greedy search approach through the space of possible branches with no backtracking.",
      "question": "Which method is used in decision tree algorithm"
    },
    {
      "answer": "A classification problem is when the output variable is a category, such as \u201cred\u201d or \u201cblue\u201d or \u201cdisease\u201d and \u201cno disease\u201d. A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes.",
      "question": "What are classification problems in machine learning"
    },
    {
      "answer": "To review, the Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.",
      "question": "Which of the following gates in Lstm decides on keeping relevant features from the current input"
    },
    {
      "answer": "A mean can be determined for grouped data, or data that is placed in intervals.  The sum of the products divided by the total number of values will be the value of the mean.",
      "question": "What is the mean for grouped data"
    },
    {
      "answer": "Recurrent Neural Networks (RNNs) are a form of machine learning algorithm that are ideal for sequential data such as text, time series, financial data, speech, audio, video among others.",
      "question": "Does recurrent neural networks are best suited for text processing"
    },
    {
      "answer": "Robust regression is an alternative to least squares regression when data is contaminated with outliers or influential observations and it can also be used for the purpose of detecting influential observations. Please note: The purpose of this page is to show how to use various data analysis commands.",
      "question": "When should I use robust regression"
    },
    {
      "answer": "Meta-learning, also known as \u201clearning to learn\u201d, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples.  Humans, in contrast, learn new concepts and skills much faster and more efficiently.",
      "question": "How does meta learning work"
    },
    {
      "answer": "Inductive Learning is where we are given examples of a function in the form of data (x) and the output of the function (f(x)). The goal of inductive learning is to learn the function for new data (x). Classification: when the function being learned is discrete. Regression: when the function being learned is continuous.",
      "question": "What is inductive learning in machine learning"
    },
    {
      "answer": "An activation function is defined by and defines the output of a neuron in terms of its input (aka induced local field) . There are three types of activation functions. Threshhold function an example of which is. This function is also termed the Heaviside function. Piecewise Linear.",
      "question": "What is activation function and its types"
    },
    {
      "answer": "How to Detect Omitted Variable Bias and Identify Confounding Variables. You saw one method of detecting omitted variable bias in this post. If you include different combinations of independent variables in the model, and you see the coefficients changing, you're watching omitted variable bias in action!",
      "question": "How do you identify omitted variable bias"
    },
    {
      "answer": "It can be seen that the function of the loss of quality is a U-shaped curve, which is determined by the following simple quadratic function: L(x)= Quality loss function. x = Value of the quality characteristic (observed). N = Nominal value of the quality characteristic (Target value \u2013 target).",
      "question": "How is the target value of a Taguchi loss function identified"
    },
    {
      "answer": "Anything central is in the middle of something \u2014 or essential to it. Central things are fundamental and important. Think about the center of a circle: it's right in the middle, equidistant from all sides. Similarly, anything central is in the middle of something.",
      "question": "What does the word central mean"
    },
    {
      "answer": "In contrast to the non-stationary process that has a variable variance and a mean that does not remain near, or returns to a long-run mean over time, the stationary process reverts around a constant long-term mean and has a constant variance independent of time.",
      "question": "What is the difference between stationary and non stationary time series"
    },
    {
      "answer": "The Google Goggles app is an image-recognition mobile app that uses visual search technology to identify objects through a mobile device's camera. Users can take a photo of a physical object, and Google searches and retrieves information about the image.",
      "question": "How can I identify an object in a picture"
    },
    {
      "answer": "The kurtosis of any univariate normal distribution is 3. It is common to compare the kurtosis of a distribution to this value. Distributions with kurtosis less than 3 are said to be platykurtic, although this does not imply the distribution is \"flat-topped\" as is sometimes stated.",
      "question": "What is the kurtosis of a normal distribution"
    },
    {
      "answer": "Rule-based systems process data and output information, but they also process rules and make decisions.  Knowledge-based systems also process data and rules to output information and make decisions. In addition, they also process expert knowledge to output answers, recommendations, and expert advice.",
      "question": "What is the difference between a rule based system and a knowledge based system"
    },
    {
      "answer": "It's a method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.",
      "question": "What is loss function in machine learning"
    },
    {
      "answer": "How to train your Deep Neural NetworkTraining data.  Choose appropriate activation functions.  Number of Hidden Units and Layers.  Weight Initialization.  Learning Rates.  Hyperparameter Tuning: Shun Grid Search - Embrace Random Search.  Learning Methods.  Keep dimensions of weights in the exponential power of 2.More items\u2022",
      "question": "How do I train deep neural networks"
    },
    {
      "answer": "Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable. Feature selection is primarily focused on removing non-informative or redundant predictors from the model.",
      "question": "What are feature selection techniques in machine learning"
    },
    {
      "answer": "In Regression Clustering (RC), K (>1) regression functions are applied to the dataset simultaneously which guide the clustering of the dataset into K subsets each with a simpler distribution matching its guiding function. Each function is regressed on its own subset of data with a much smaller residue error.",
      "question": "What is clustering in regression"
    },
    {
      "answer": "17. Deep Convolutional Network (DCN): Convolutional Neural Networks are neural networks used primarily for classification of images, clustering of images and object recognition.",
      "question": "What is neural network classification"
    },
    {
      "answer": "The function scipy. linalg. eig computes eigenvalues and eigenvectors of a square matrix .",
      "question": "What is the function to get both eigenvalues and eigenvectors of a matrix"
    },
    {
      "answer": "The confidence of an association rule is a percentage value that shows how frequently the rule head occurs among all the groups containing the rule body.  Thus, the confidence of a rule is the percentage equivalent of m/n, where the values are: m. The number of groups containing the joined rule head and rule body.",
      "question": "What is confidence in association rule"
    },
    {
      "answer": "A simple random sample is used to represent the entire data population and. randomly selects individuals from the population without any other consideration. A stratified random sample, on the other hand, first divides the population into smaller groups, or strata, based on shared characteristics.",
      "question": "What is the difference between random sampling and stratified sampling"
    },
    {
      "answer": "Parametric tests assume a normal distribution of values, or a \u201cbell-shaped curve.\u201d For example, height is roughly a normal distribution in that if you were to graph height from a group of people, one would see a typical bell-shaped curve.",
      "question": "What is an example of parametric statistics"
    },
    {
      "answer": "Overfitting can be identified by checking validation metrics such as accuracy and loss. The validation metrics usually increase until a point where they stagnate or start declining when the model is affected by overfitting.",
      "question": "How do we know whether a model is overfitting"
    },
    {
      "answer": "Morpheus: If real is what you can feel, smell, taste and see, then 'real' is simply electrical signals interpreted by your brain.",
      "question": "What is the Matrix Morpheus quote"
    },
    {
      "answer": "A squashing function is essentially defined as a function that squashes the input to one of the ends of a small interval. In Neural Networks, these can be used at nodes in a hidden layer to squash the input. This introduces non-linearity to the NN and allows the NN to be effective.",
      "question": "Why squashing function is important in neural network"
    },
    {
      "answer": "Definition 1. A statistic d is called an unbiased estimator for a function of the parameter g(\u03b8) provided that for every choice of \u03b8, E\u03b8d(X) = g(\u03b8). Any estimator that not unbiased is called biased.  Note that the mean square error for an unbiased estimator is its variance.",
      "question": "What is an unbiased estimator of variance"
    },
    {
      "answer": "Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. That is, data sets with high kurtosis tend to have heavy tails, or outliers. Data sets with low kurtosis tend to have light tails, or lack of outliers. A uniform distribution would be the extreme case.",
      "question": "What does kurtosis indicate"
    },
    {
      "answer": "In neural networks, a hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output. In short, the hidden layers perform nonlinear transformations of the inputs entered into the network.",
      "question": "What is the purpose of hidden layer in neural network"
    },
    {
      "answer": "AI means getting a computer to mimic human behavior in some way.  Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems.",
      "question": "How are the terms artificial intelligence machine learning and deep learning related"
    },
    {
      "answer": "Loss is the penalty for a bad prediction. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater.",
      "question": "What is the loss in machine learning"
    },
    {
      "answer": "Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.",
      "question": "How can algorithms be biased"
    },
    {
      "answer": "Description. VGG-19 is a convolutional neural network that is 19 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database [1]. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals.",
      "question": "What is Vgg in deep learning"
    },
    {
      "answer": "The SD is usually more useful to describe the variability of the data while the variance is usually much more useful mathematically. For example, the sum of uncorrelated distributions (random variables) also has a variance that is the sum of the variances of those distributions.",
      "question": "Which is better variance or standard deviation"
    },
    {
      "answer": "K-fold cross-validationRandomly split the data set into k-subsets (or k-fold) (for example 5 subsets)Reserve one subset and train the model on all other subsets.Test the model on the reserved subset and record the prediction error.Repeat this process until each of the k subsets has served as the test set.More items\u2022",
      "question": "How do you do k fold cross validation in R"
    },
    {
      "answer": "- YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the median for continuous data"
    },
    {
      "answer": "How to calculate percentileRank the values in the data set in order from smallest to largest.Multiply k (percent) by n (total number of values in the data set).  If the index is not a round number, round it up (or down, if it's closer to the lower number) to the nearest whole number.Use your ranked data set to find your percentile.",
      "question": "How is percentile calculated"
    },
    {
      "answer": "The general linear model requires that the response variable follows the normal distribution whilst the generalized linear model is an extension of the general linear model that allows the specification of models whose response variable follows different distributions.",
      "question": "What is the difference between linear model and generalized linear model"
    },
    {
      "answer": "If there are c or less defective items in the sample, the lot is accepted. If there are more than c defective items in the sample, the lot is rejected. In other words, the acceptance or rejection of the lot depends on the inspection results of a single sample.",
      "question": "Under what conditions is lot for lot acceptance sampling not accepted"
    },
    {
      "answer": "The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.",
      "question": "How does neural network determine the number of hidden layers"
    },
    {
      "answer": "Gaussian processes are useful in statistical modelling, benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly.",
      "question": "What are Gaussian processes used for"
    },
    {
      "answer": "August 2017) (Learn how and when to remove this template message) In natural language processing, the latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.",
      "question": "What is Latent Dirichlet Allocation in machine learning"
    },
    {
      "answer": "Six quick tips to improve your regression modelingA.1. Fit many models.  A.2. Do a little work to make your computations faster and more reliable.  A.3. Graphing the relevant and not the irrelevant.  A.4. Transformations.  A.5. Consider all coefficients as potentially varying.  A.6. Estimate causal inferences in a targeted way, not as a byproduct of a large regression.",
      "question": "How can statistical models be improved"
    },
    {
      "answer": "The Binomial Theorem is a quick way (okay, it's a less slow way) of expanding (or multiplying out) a binomial expression that has been raised to some (generally inconveniently large) power. For instance, the expression (3x \u2013 2)10 would be very painful to multiply out by hand.",
      "question": "How do you use the binomial theorem"
    },
    {
      "answer": "Use of AI in Following Things/Fields/Areas:Virtual Assistant or Chatbots.Agriculture and Farming.Autonomous Flying.Retail, Shopping and Fashion.Security and Surveillance.Sports Analytics and Activities.Manufacturing and Production.Live Stock and Inventory Management.More items\u2022",
      "question": "Where is artificial intelligence used"
    },
    {
      "answer": "In statistics, the t-statistic is the ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.  For example, the T-statistic is used in estimating the population mean from a sampling distribution of sample means if the population standard deviation is unknown.",
      "question": "What does the t statistic mean"
    },
    {
      "answer": "To solve the problem using logistic regression we take two parameters w, which is n dimensional vector and b which is a real number. The logistic regression model to solve this is : Equation for Logistic Regression. We apply sigmoid function so that we contain the result of \u0177 between 0 and 1 (probability value).",
      "question": "What is W and B in logistic regression"
    },
    {
      "answer": "1.1 The Role of Logic in Artificial Intelligence Logic, for instance, can provide a specification for a programming language by characterizing a mapping from programs to the computations that they license.",
      "question": "What is the role of logic in artificial intelligence"
    },
    {
      "answer": "Every probability pi is a number between 0 and 1, and the sum of all the probabilities is equal to 1. Examples of discrete random variables include: The number of eggs that a hen lays in a given day (it can't be 2.3) The number of people going to a given soccer match.",
      "question": "What is a discrete random variable What are some examples"
    },
    {
      "answer": "The mean is also to the left of the peak. A right-skewed distribution has a long right tail.  Next, you'll see a fair amount of negatively skewed distributions. For example, household income in the U.S. is negatively skewed with a very long left tail.",
      "question": "What is an example of skewed data"
    },
    {
      "answer": "A linear threshold unit is a simple artificial neuron whose output is its thresholded total net input. That is, an LTU with threshold T calculates the weighted sum of its inputs, and then outputs 0 if this sum is less than T, and 1 if the sum is greater than T.",
      "question": "What is linear threshold unit"
    },
    {
      "answer": "The Pearson's correlation coefficient is calculated as the covariance of the two variables divided by the product of the standard deviation of each data sample. It is the normalization of the covariance between the two variables to give an interpretable score.",
      "question": "How do you find the correlation between many variables"
    },
    {
      "answer": "Among the learning algorithms, one of the most popular and easiest to understand is the decision tree induction. The popularity of this method is related to three nice characteristics: interpretability, efficiency, and flexibility. Decision tree can be used for both classification and regression kind of problem.",
      "question": "What are the important characteristics of decision tree induction algorithm"
    },
    {
      "answer": "RBMs were invented by Geoffrey Hinton and can be used for dimensionality reduction, classification, regression, collaborative filtering, feature learning, and topic modeling. RBMs are a special class of Boltzmann Machines and they are restricted in terms of the connections between the visible and the hidden units.",
      "question": "What are restricted Boltzmann machines used for"
    },
    {
      "answer": "In the context of neural networks, a perceptron is an artificial neuron using the Heaviside step function as the activation function. The perceptron algorithm is also termed the single-layer perceptron, to distinguish it from a multilayer perceptron, which is a misnomer for a more complicated neural network.",
      "question": "What is Perceptron in neural network"
    },
    {
      "answer": "Image processing is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.",
      "question": "What do you mean by image processing"
    },
    {
      "answer": "Regression analysis is a powerful statistical method that allows you to examine the relationship between two or more variables of interest. While there are many types of regression analysis, at their core they all examine the influence of one or more independent variables on a dependent variable.",
      "question": "What is regression effect in data collection"
    },
    {
      "answer": "You description is confusing, but it is totally possible to have test error both lower and higher than training error. A lower training error is expected when a method easily overfits to the training data, yet, poorly generalizes.",
      "question": "Is it possible to have a higher train error than a test error in machine learning"
    },
    {
      "answer": "Aspin-Welch t-test",
      "question": "What test should you use to determine the equality of the two sample means when the population standard deviation is unknown"
    },
    {
      "answer": "Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay.  It is often used in signal processing for analyzing functions or series of values, such as time domain signals.",
      "question": "What is autocorrelation in signal and system"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "How do you explain variance"
    },
    {
      "answer": "There are 3 main ways of describing the intensity of an activity \u2013 vigorous, moderate, and gentle. Vigorous activities tend to make you \u201chuff and puff\u201d.",
      "question": "How do you describe your activity level"
    },
    {
      "answer": "If X and Y are normed vector spaces (a special type of TVS), then L is bounded if and only if there exists some M \u2265 0 such that for all x in X, ||Lx||Y \u2264 M ||x||X. The smallest such M, denoted by ||L||, is called the operator norm of L.",
      "question": "How do you show an operator is bounded"
    },
    {
      "answer": "A bell curve is a common type of distribution for a variable, also known as the normal distribution. The term \"bell curve\" originates from the fact that the graph used to depict a normal distribution consists of a symmetrical bell-shaped curve.",
      "question": "What is the distribution of a bell curve"
    },
    {
      "answer": "The terms cost and loss functions almost refer to the same meaning. But, loss function mainly applies for a single training set as compared to the cost function which deals with a penalty for a number of training sets or the complete batch.  The cost function is calculated as an average of loss functions.",
      "question": "What is the difference between a cost function and a loss function in machine learning"
    },
    {
      "answer": "Max pooling is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.",
      "question": "What is the purpose of Max pooling"
    },
    {
      "answer": "Properties. Unlike the classical conditional entropy, the conditional quantum entropy can be negative.  Positive conditional entropy of a state thus means the state cannot reach even the classical limit, while the negative conditional entropy provides for additional information.",
      "question": "Can conditional entropy negative"
    },
    {
      "answer": "A quartile is a statistical term that describes a division of observations into four defined intervals based on the values of the data and how they compare to the entire set of observations.",
      "question": "What is the definition of quartile in statistics"
    },
    {
      "answer": "The nominator is the joint probability and the denominator is the probability of the given outcome.  This is the conditional probability: P(A\u2223B)=P(A\u2229B)P(B) This is the Bayes' rule: P(A\u2223B)=P(B|A)\u2217P(A)P(B).",
      "question": "What is the difference between conditional probability and Bayes Theorem"
    },
    {
      "answer": "The mean (average) of a data set is found by adding all numbers in the data set and then dividing by the number of values in the set. The median is the middle value when a data set is ordered from least to greatest. The mode is the number that occurs most often in a data set.",
      "question": "What is the mean value in statistics"
    },
    {
      "answer": "Word embeddings are created using a neural network with one input layer, one hidden layer and one output layer. The computer does not understand that the words king, prince and man are closer together in a semantic sense than the words queen, princess, and daughter. All it sees are encoded characters to binary.",
      "question": "How are word Embeddings generated"
    },
    {
      "answer": "These are the steps we are going to do:Make a stupid model as an example, train and store it.Fetch the variables you need from your stored model.Build the tensor info from them.Create the model signature.Create and save a model builder.Download a Docker image with TensorFlow serving already compile on it.More items\u2022",
      "question": "How do you deploy TensorFlow in production"
    },
    {
      "answer": "Face recognition systems use computer algorithms to pick out specific, distinctive details about a person's face. These details, such as distance between the eyes or shape of the chin, are then converted into a mathematical representation and compared to data on other faces collected in a face recognition database.",
      "question": "How does the facial recognition technology work"
    },
    {
      "answer": "Logarithmic scales reduce wide-ranging quantities to tiny scopes. For example, the decibel (dB) is a unit used to express ratio as logarithms, mostly for signal power and amplitude (of which sound pressure is a common example). In chemistry, pH is a logarithmic measure for the acidity of an aqueous solution.",
      "question": "What are logarithms used for"
    },
    {
      "answer": "While the previous study (Wu et al., 2015) suggests that ingroup derogation is a specialized mechanism which disregards explicit disease-relevant information mediated by outgroup members, a different pattern was observed in Experiment 2.",
      "question": "What is ingroup derogation"
    },
    {
      "answer": "2:1422:33Suggested clip \u00b7 114 secondsRegression Trees, Clearly Explained!!! - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you interpret a regression tree"
    },
    {
      "answer": "Definition. A study design that randomly assigns participants into an experimental group or a control group. As the study is conducted, the only expected difference between the control and experimental groups in a randomized controlled trial (RCT) is the outcome variable being studied.",
      "question": "Is a randomized controlled trial an experimental design"
    },
    {
      "answer": "P \u2227 Q means P and Q. P \u2228 Q means P or Q. An argument is valid if the following conditional holds: If all the premises are true, the conclusion must be true.  So, when you attempt to write a valid argument, you should try to write out what the logical structure of the argument is by symbolizing it.",
      "question": "What does P \u2227 Q mean"
    },
    {
      "answer": "Regularization is a set of techniques that can prevent overfitting in neural networks and thus improve the accuracy of a Deep Learning model when facing completely new data from the problem domain.",
      "question": "What is regularization in deep learning"
    },
    {
      "answer": "The 'd' means a \u0394 in the limit approaching zero. Basically the slope is approximately \u0394y/\u0394x but if you let \u0394x approach zero, you reach the exactly slope which is then dy/dx.",
      "question": "What does the D stand for in differentiation"
    },
    {
      "answer": "A statistical hypothesis is an explanation about the relationship between data populations that is interpreted probabilistically.  A machine learning hypothesis is a candidate model that approximates a target function for mapping inputs to outputs.",
      "question": "What is specific hypothesis in machine learning"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.",
      "question": "What is bootstrap in machine learning"
    },
    {
      "answer": "Moments About the MeanFirst, calculate the mean of the values.Next, subtract this mean from each value.Then raise each of these differences to the sth power.Now add the numbers from step #3 together.Finally, divide this sum by the number of values we started with.",
      "question": "How do you calculate moments in statistics"
    },
    {
      "answer": "Covariance indicates the relationship of two variables whenever one variable changes. If an increase in one variable results in an increase in the other variable, both variables are said to have a positive covariance.  Both variables move together in the same direction when they change.",
      "question": "What does Covariance indicate"
    },
    {
      "answer": "Clustering is considered unsupervised learning, because there's no labeled target variable in clustering. Clustering algorithms try to, well, cluster data points into similar groups (or\u2026 clusters) based on different characteristics of the data.",
      "question": "Is clustering supervised or unsupervised How do you classify it"
    },
    {
      "answer": "As in classification, support vector regression (SVR) is characterized by the use of kernels, sparse solution, and VC control of the margin and the number of support vectors. Although less popular than SVM, SVR has been proven to be an effective tool in real-value function estimation.",
      "question": "What is SVR regression"
    },
    {
      "answer": "The linear Discriminant analysis estimates the probability that a new set of inputs belongs to every class.  LDA uses Bayes' Theorem to estimate the probabilities. If the output class is (k) and the input is (x), here is how Bayes' theorem works to estimate the probability that the data belongs to each class.",
      "question": "How does linear discriminant analysis work"
    },
    {
      "answer": "In neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from every element of the previous layer. In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer.",
      "question": "What is the difference between a neural network and a convolutional network"
    },
    {
      "answer": "A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function. SLP is the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target (1 , 0).",
      "question": "What is a single layer Perceptron"
    },
    {
      "answer": "Multicollinearity occurs when independent variables in a regression model are correlated. This correlation is a problem because independent variables should be independent. If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.",
      "question": "Why is Multicollinearity a problem in linear regression select the correct option"
    },
    {
      "answer": "Question: 1. When A Value Of Y Is Calculated Using The Regression Equation (Y_hat), It Is Called: -the Fitted Value -the Estimated Value -the Predicted Value -all Of The Above 2.",
      "question": "When a value of y is calculated using the regression equation it is called"
    },
    {
      "answer": "The fact is almost all big data sets, generated by systems powered by ML/AI based models, are known to be biased. However, most ML modelers are not aware of these biases and even if they are, they do not know what to do about it.  Most (almost all) big datasets generated by ML powered systems are biased.",
      "question": "Is all data biased"
    },
    {
      "answer": "Q-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It's considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn't needed.",
      "question": "How does Q learning work"
    },
    {
      "answer": "Cohen suggested the Kappa result be interpreted as follows: values \u2264 0 as indicating no agreement and 0.01\u20130.20 as none to slight, 0.21\u20130.40 as fair, 0.41\u2013 0.60 as moderate, 0.61\u20130.80 as substantial, and 0.81\u20131.00 as almost perfect agreement.",
      "question": "How do you interpret Cohen's kappa"
    },
    {
      "answer": "Accuracy is well defined for any number of classes, so if you use this, a single plot should suffice. Precision and recall, however, are defined only for binary problems.",
      "question": "How many learning curves should I plot for a multi class logistic regression classifier"
    },
    {
      "answer": "In order to calculate the sample size needed for your survey or experiment, you will need to follow these steps: Determine the total population size.Complete the calculation.Determine the total population size.  Decide on a margin of error.  Choose a confidence level.  Pick a standard of deviation.  Complete the calculation.",
      "question": "How do you calculate sample size needed"
    },
    {
      "answer": "The main advantage of CNN compared to its predecessors is that it automatically detects the important features without any human supervision. For example, given many pictures of cats and dogs, it can learn the key features for each class by itself.",
      "question": "What is the advantage of CNN"
    },
    {
      "answer": "When you reject the null hypothesis with a t-test, you are saying that the means are statistically different. The difference is meaningful. Chi Square:  When you reject the null hypothesis with a Chi-Square, you are saying that there is a relationship between the two variables.",
      "question": "What is the difference between at test and a chi square"
    },
    {
      "answer": "Classification SVM Type 1 (also known as C-SVM classification); Classification SVM Type 2 (also known as nu-SVM classification); Regression SVM Type 1 (also known as epsilon-SVM regression); Regression SVM Type 2 (also known as nu-SVM regression).",
      "question": "What are the two classification methods that SVM can handle"
    },
    {
      "answer": "For values of x > 0, the gamma function is defined using an integral formula as \u0393(x) = Integral on the interval [0, \u221e ] of \u222b 0\u221et x \u22121 e\u2212t dt. The probability density function for the gamma distribution is given by. The mean of the gamma distribution is \u03b1\u03b2 and the variance (square of the standard deviation) is \u03b1\u03b22.",
      "question": "What is the mean of gamma distribution"
    },
    {
      "answer": "The most effective tool found for the task for image recognition is a deep neural network, specifically a Convolutional Neural Network (CNN).",
      "question": "Which algorithm is best for image processing"
    },
    {
      "answer": "A Sampling unit is one of the units selected for the purpose of sampling. Each unit being regarded as individual and indivisible when the selection is made. CONTEXT: Many times the Sampling frame and the Sampling unit are derived from Administrative data.",
      "question": "What is sampling unit and sampling frame"
    },
    {
      "answer": "Probability limits are used when the parameter is considered as the realization of a random variable with given prior distribution.",
      "question": "What is a probability limit"
    },
    {
      "answer": "Naive Bayes algorithm works on Bayes theorem and takes a probabilistic approach, unlike other classification algorithms. The algorithm has a set of prior probabilities for each class. Once data is fed, the algorithm updates these probabilities to form something known as posterior probability.",
      "question": "Which algorithm is used in artificial intelligence"
    },
    {
      "answer": "The general application of the matrix norm is the derivative form of finding proof in terms of interplay and tandem of vectorial normalized formats to whom are extended.. It can be used in tandem with Graphical processing, image processing, all kinds of algorithmics in terms of calculations and derivatives..",
      "question": "What is the application of matrix norm"
    },
    {
      "answer": "Software Testing MethodologiesFunctional vs. Non-functional Testing.  Unit Testing. Unit testing is the first level of testing and is often performed by the developers themselves.  Integration Testing.  System Testing.  Acceptance Testing.  Performance Testing.  Security Testing.  Usability Testing.More items",
      "question": "What are different testing techniques"
    },
    {
      "answer": "A machine learning task is the type of prediction or inference being made, based on the problem or question that is being asked, and the available data. For example, the classification task assigns data to categories, and the clustering task groups data according to similarity.",
      "question": "What are the tasks in machine learning"
    },
    {
      "answer": "The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting). The variance is an error from sensitivity to small fluctuations in the training set.",
      "question": "What is bias in machine learning algorithms"
    },
    {
      "answer": "hamming distance",
      "question": "Which distance metric do we use in Knn for categorical variables"
    },
    {
      "answer": "The modern mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the \"problem of points\").",
      "question": "Who developed the theory of probability"
    },
    {
      "answer": ". Thus logit regression is simply the GLM when describing it in terms of its link function, and logistic regression describes the GLM in terms of its activation function.",
      "question": "Whats the difference between logit and logistic regression 1"
    },
    {
      "answer": "A boxplot is a standardized way of displaying the distribution of data based on a five number summary (\u201cminimum\u201d, first quartile (Q1), median, third quartile (Q3), and \u201cmaximum\u201d).  It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.",
      "question": "What do box plots tell you"
    },
    {
      "answer": ": one half of the difference obtained by subtracting the first quartile from the third quartile in a frequency distribution.",
      "question": "What is quartile deviation"
    },
    {
      "answer": "A conditional probability estimate is a probability estimate that we make given or assuming the occurrence of some other event. In this case we might start with an estimate that the probability of rain is 30% and then make a conditional probability estimate that the probability of rain given a cloudy sky is 65%.",
      "question": "Is a conditional probability estimate"
    },
    {
      "answer": "Accuracy is the percentage of correctly classifies instances out of all instances.  Kappa or Cohen's Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset.",
      "question": "What is accuracy and Kappa"
    },
    {
      "answer": "Hyperparameter optimization in machine learning intends to find the hyperparameters of a given machine learning algorithm that deliver the best performance as measured on a validation set. Hyperparameters, in contrast to model parameters, are set by the machine learning engineer before training.",
      "question": "What is Hyperparameter optimization in deep learning"
    },
    {
      "answer": "Standard deviation looks at how spread out a group of numbers is from the mean, by looking at the square root of the variance. The variance measures the average degree to which each point differs from the mean\u2014the average of all data points.",
      "question": "Why do we use standard deviation over variance"
    },
    {
      "answer": "Nonparametric tests have the following limitations: Nonparametric tests are usually less powerful than corresponding parametric test when the normality assumption holds. Thus, you are less likely to reject the null hypothesis when it is false if the data comes from the normal distribution.",
      "question": "What are the main limitations of non parametric test"
    },
    {
      "answer": "Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.",
      "question": "How do you explain logistic regression model"
    },
    {
      "answer": "You can tell if two random variables are independent by looking at their individual probabilities. If those probabilities don't change when the events meet, then those variables are independent. Another way of saying this is that if the two variables are correlated, then they are not independent.",
      "question": "How do you prove a random variable is independent"
    },
    {
      "answer": "To recap the differences between the two: Machine learning uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned. Deep learning structures algorithms in layers to create an \"artificial neural network\u201d that can learn and make intelligent decisions on its own.",
      "question": "What is the relationship between machine learning and deep learning"
    },
    {
      "answer": "Mean of General discrete uniform distribution The expected value of discrete uniform random variable is E ( X ) = a + b 2 .",
      "question": "What are the expected moments of a uniform discrete distribution"
    },
    {
      "answer": "Moments help in finding AM, standard deviation and variance of the population directly, and they help in knowing the graphic shapes of the population. We can call moments as the constants used in finding the graphic shape, as the graphic shape of the population also help a lot in characterizing a population.",
      "question": "What is the use of moments in statistics"
    },
    {
      "answer": "Ensemble methods are learning models that achieve performance by combining the opinions of multiple learners.  Ensemble methods are learning models that achieve performance by combining the opinions of multiple learners.",
      "question": "How do ensemble methods work and why are they superior to individual models"
    },
    {
      "answer": "Markov Chain Monte Carlo (MCMC) methods are a class of algorithms for sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution.",
      "question": "How does MCMC sampling work"
    },
    {
      "answer": "Artificial intelligence has close connections with philosophy because both use concepts that have the same names and these include intelligence, action, consciousness, epistemology, and even free will.  These factors contributed to the emergence of the philosophy of artificial intelligence.",
      "question": "Is artificial intelligence possible philosophy"
    },
    {
      "answer": "Summary. The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems. It's easy to implement and understand, but has a major drawback of becoming significantly slows as the size of that data in use grows.",
      "question": "What is K Nearest Neighbor machine learning"
    },
    {
      "answer": "Cross correlation and autocorrelation are very similar, but they involve different types of correlation: Cross correlation happens when two different sequences are correlated. Autocorrelation is the correlation between two of the same sequences. In other words, you correlate a signal with itself.",
      "question": "What is the difference between correlation and autocorrelation"
    },
    {
      "answer": "Establish face validity.Conduct a pilot test.Enter the pilot test in a spreadsheet.Use principal component analysis (PCA)Check the internal consistency of questions loading onto the same factors.Revise the questionnaire based on information from your PCA and CA.",
      "question": "How do you establish reliability and validity of a questionnaire"
    },
    {
      "answer": "The regression slope intercept formula, b0 = y \u2013 b1 * x is really just an algebraic variation of the regression equation, y' = b0 + b1x where \u201cb0\u201d is the y-intercept and b1x is the slope. Once you've found the linear regression equation, all that's required is a little algebra to find the y-intercept (or the slope).",
      "question": "How do you find the Y intercept of a least squares regression line"
    },
    {
      "answer": "Neural network momentum is a simple technique that often improves both training speed and accuracy. Training a neural network is the process of finding values for the weights and biases so that for a given set of input values, the computed output values closely match the known, correct, target values.",
      "question": "What is momentum in neural network"
    },
    {
      "answer": "In natural language processing, the latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.",
      "question": "What is a good explanation of Latent Dirichlet Allocation"
    },
    {
      "answer": "The decision rule is: Reject H0 if Z < 1.645. The decision rule is: Reject H0 if Z < -1.960 or if Z > 1.960. The complete table of critical values of Z for upper, lower and two-tailed tests can be found in the table of Z values to the right in \"Other Resources.\"",
      "question": "How do you find the decision rule"
    },
    {
      "answer": "When a data set has a negative value, the axis will be shifted upward by \u2013MIN(R) where R is the data range containing the data. Thus if R ranges from -10 to 20, the range in the chart will range from 0 to 30.",
      "question": "How can the box plot chart have negative values"
    },
    {
      "answer": "0:008:06Suggested clip \u00b7 106 secondsSPSS - Correspondence Analysis - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do correspondence analysis in SPSS"
    },
    {
      "answer": "Do you know how to choose the right machine learning algorithm among 7 different types?1-Categorize the problem.  2-Understand Your Data.  Analyze the Data.  Process the data.  Transform the data.  3-Find the available algorithms.  4-Implement machine learning algorithms.  5-Optimize hyperparameters.More items",
      "question": "How do I know which ML model to use"
    },
    {
      "answer": "Recursive neural network models",
      "question": "Which model is best suited for recursive data"
    },
    {
      "answer": "Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.",
      "question": "What is machine learning and its applications"
    },
    {
      "answer": "Communalities \u2013 This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.",
      "question": "What is communality in factor analysis"
    },
    {
      "answer": "If X takes values in [a, b] and Y takes values in [c, d] then the pair (X, Y ) takes values in the product [a, b] \u00d7 [c, d]. The joint probability density function (joint pdf) of X and Y is a function f(x, y) giving the probability density at (x, y).",
      "question": "How do you find the density of a joint function"
    },
    {
      "answer": "A standard deviation is a measure of variability for a distribution of scores in a single sample or in a population of scores. A standard error is the standard deviation in a distribution of means of all possible samples of a given size from a particular population of individual scores.",
      "question": "What is the difference between standard deviation and standard error quizlet"
    },
    {
      "answer": "Naive Bayes is a Supervised Machine Learning algorithm based on the Bayes Theorem that is used to solve classification problems by following a probabilistic approach. It is based on the idea that the predictor variables in a Machine Learning model are independent of each other.",
      "question": "What is naive Bayes in R"
    },
    {
      "answer": "Image processing is often viewed as arbitrarily manipulating an image to achieve an aesthetic standard or to support a preferred reality. However, image processing is more accurately defined as a means of translation between the human visual system and digital imaging devices.",
      "question": "What is the importance of image processing"
    },
    {
      "answer": "7 Top Linear Algebra Resources For Machine Learning BeginnersEssence Of Linear Algebra By 3Blue1Brown.Linear Algebra By Khan Academy.Basic Linear Algebra for Deep Learning By Niklas Donges.Computational Linear Algebra for Coders By fast.ai.Deep Learning Book By Ian Goodfellow and Yoshua Bengio and Aaron Courville.Linear Algebra for Machine Learning By AppliedAICourse.More items\u2022",
      "question": "How do I learn linear algebra for machine learning"
    },
    {
      "answer": "Discrete data involves round, concrete numbers that are determined by counting. Continuous data involves complex numbers that are measured across a specific time interval.",
      "question": "How can you tell the difference between continuous and discrete data"
    },
    {
      "answer": "Deep Reinforcement Learning: From Toys to Enteprise When paired with simulations, reinforcement learning is a powerful tool for training AI models that can help increase automation or optimize operational efficiency of sophisticated systems such as robotics, manufacturing, and supply chain logistics.",
      "question": "What is reinforcement learning good for"
    },
    {
      "answer": "Summing up, a more precise statement of the universality theorem is that neural networks with a single hidden layer can be used to approximate any continuous function to any desired precision.",
      "question": "Can neural networks approximate any function"
    },
    {
      "answer": "A t-test tests a null hypothesis about two means; most often, it tests the hypothesis that two means are equal, or that the difference between them is zero.  A chi-square test tests a null hypothesis about the relationship between two variables.",
      "question": "What is the difference between T distribution and chi square distribution"
    },
    {
      "answer": "This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting.",
      "question": "Why is pooling used in convolutional neural network"
    },
    {
      "answer": "Classic linear regression is one form of general linear model. But with a general linear model you can have any number of continuous or nominal independent variables and their interactions.",
      "question": "Can nominal variables be used in regression analysis"
    },
    {
      "answer": "Unlike humans, artificial neural networks are fed with massive amount of data to learn.  Also, real neurons do not stay on until the inputs change and the outputs may encode information using complex pulse arrangements.",
      "question": "Is there a difference between how humans and artificial neural networks learn"
    },
    {
      "answer": "One of the most widely used predictive analytics models, the forecast model deals in metric value prediction, estimating numeric value for new data based on learnings from historical data. This model can be applied wherever historical numerical data is available.",
      "question": "Which model is used for prediction"
    },
    {
      "answer": "Offline evaluations test the effectiveness of recommender system algorithms on a certain dataset. Online evaluation attempts to evaluate recommender systems by a method called A/B testing where a part of users are served by recommender system A and the another part of users by recommender system B.",
      "question": "What is offline evaluation"
    },
    {
      "answer": "This is why it is important to distinguish between the statistical significance of a result and the practical significance of that result.  Null hypothesis testing is a formal approach to deciding whether a statistical relationship in a sample reflects a real relationship in the population or is just due to chance.",
      "question": "What is the difference between statistical significance testing and null hypothesis testing"
    },
    {
      "answer": "Bag of Words just creates a set of vectors containing the count of word occurrences in the document (reviews), while the TF-IDF model contains information on the more important words and the less important ones as well.",
      "question": "What is difference between Bag of Words and TF IDF"
    },
    {
      "answer": "Multiple regression models forecast a variable using a linear combination of predictors, whereas autoregressive models use a combination of past values of the variable.  These concepts and techniques are used by technical analysts to forecast security prices.",
      "question": "What is difference between linear regression and autoregressive model in time series analysis"
    },
    {
      "answer": "When working with box plots, the IQR is computed by subtracting the first quartile from the third quartile. In a standard normal distribution (with mean 0 and standard deviation 1), the first and third quartiles are located at -0.67448 and +0.67448 respectively. Thus the interquartile range (IQR) is 1.34896.",
      "question": "How do you find the Iqr with the mean and standard deviation"
    },
    {
      "answer": "To develop or improve your inductive reasoning, focus on the following skills: Paying attention to detail: No one can draw conclusions based on details without first noticing those details; paying attention is crucial to inductive reasoning.",
      "question": "How does one improve his or her inductive reasoning skills"
    },
    {
      "answer": "Regression is the statistical model that you use to predict a continuous outcome on the basis of one or more continuous predictor variables. In contrast, ANOVA is the statistical model that you use to predict a continuous outcome on the basis of one or more categorical predictor variables.",
      "question": "When do you apply regression analysis and analysis of variance"
    },
    {
      "answer": "It is one of several methods statisticians and researchers use to extract a sample from a larger population; other methods include stratified random sampling and probability sampling. The advantages of a simple random sample include its ease of use and its accurate representation of the larger population.",
      "question": "What are the advantages of simple random sampling"
    },
    {
      "answer": "Let's return to our example comparing the mean of a sample to a given value x using a t-test. Our null hypothesis is that the mean is equal to x. A one-tailed test will test either if the mean is significantly greater than x or if the mean is significantly less than x, but not both.",
      "question": "What is the difference between null hypothesis and alternative hypothesis one tailed tests and two tailed test"
    },
    {
      "answer": "Stochastic effects have been defined as those for which the probability increases with dose, without a threshold. Nonstochastic effects are those for which incidence and severity depends on dose, but for which there is a threshold dose. These definitions suggest that the two types of effects are not related.",
      "question": "What is the difference between stochastic and non stochastic"
    },
    {
      "answer": "A statistical project is the process of answering a research question using statistical techniques and presenting the work in a written report. The research question may arise from any field of scientific endeavor, such as athletics, advertising, aerodynamics, or nutrition.",
      "question": "What is a statistical project"
    },
    {
      "answer": "K-nearest neighbor (KNN) decision boundary K-nearest neighbor is an algorithm based on the local geometry of the distribution of the data on the feature hyperplane (and their relative distance measures). The decision boundary, therefore, comes up as nonlinear and non-smooth.",
      "question": "What is decision boundary in Knn"
    },
    {
      "answer": "Deep learning requires large amounts of labeled data. For example, driverless car development requires millions of images and thousands of hours of video. Deep learning requires substantial computing power. High-performance GPUs have a parallel architecture that is efficient for deep learning.",
      "question": "What is needed for deep learning"
    },
    {
      "answer": "There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.",
      "question": "How can we choose a good K for K means clustering"
    },
    {
      "answer": "Selectors are the names given to styles in internal and external style sheets. In this CSS Beginner Tutorial we will be concentrating on HTML selectors, which are simply the names of HTML tags and are used to change the style of a specific type of element.",
      "question": "What are selectors"
    },
    {
      "answer": "Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them. Bivariate analysis can be helpful in testing simple hypotheses of association.",
      "question": "What is the purpose of bivariate analysis"
    },
    {
      "answer": "k-Means Clustering is an unsupervised learning algorithm that is used for clustering whereas KNN is a supervised learning algorithm used for classification.",
      "question": "Can Knn be used for clustering"
    },
    {
      "answer": "Linear regression is used for predicting the continuous dependent variable using a given set of independent features whereas Logistic Regression is used to predict the categorical. Linear regression is used to solve regression problems whereas logistic regression is used to solve classification problems.",
      "question": "Why we use logistic regression instead of linear regression"
    },
    {
      "answer": "You can use the ArffViewer:(Tools -> ArffViewer or Ctrl+A). Then open your CSV file.Next go to File -> Save as and select Arff data files (should be selected by default.",
      "question": "How do I convert text files to arff format weka"
    },
    {
      "answer": "FFTs are great at analyzing vibration when there are a finite number of dominant frequency components; but power spectral densities (PSD) are used to characterize random vibration signals.",
      "question": "What is the difference between FFT and PSD"
    },
    {
      "answer": "Explanation: Asynchronous update ensures that the next state is at most unit hamming distance from current state. 5. If pattern is to be stored, then what does stable state should have updated value of?",
      "question": "What is asynchronous update in Hopfield model"
    },
    {
      "answer": "Object recognition is a computer vision technique for identifying objects in images or videos. Object recognition is a key output of deep learning and machine learning algorithms.  The goal is to teach a computer to do what comes naturally to humans: to gain a level of understanding of what an image contains.",
      "question": "What is object recognition in image processing"
    },
    {
      "answer": "The reason dividing by n-1 corrects the bias is because we are using the sample mean, instead of the population mean, to calculate the variance. Since the sample mean is based on the data, it will get drawn toward the center of mass for the data.",
      "question": "Why does dividing by n 1 instead of n remove the bias when calculating sample variance"
    },
    {
      "answer": "Some of the main drawbacks of association rule algorithms in e-learning are: the used algorithms have too many parameters for somebody non expert in data mining and the obtained rules are far too many, most of them non-interesting and with low comprehensibility.",
      "question": "What is the limitations behind rule generation in association rule mining"
    },
    {
      "answer": "Backtracking is a technique based on algorithm to solve problem. It uses recursive calling to find the solution by building a solution step by step increasing values with time. It removes the solutions that doesn't give rise to the solution of the problem based on the constraints given to solve the problem.",
      "question": "What is backtracking algorithm in data structure"
    },
    {
      "answer": "Definition. Univariate analyses are used extensively in quality of life research. Univariate analysis is defined as analysis carried out on only one (\u201cuni\u201d) variable (\u201cvariate\u201d) to summarize or describe the variable (Babbie, 2007; Trochim, 2006).",
      "question": "What do you mean by univariate analysis"
    },
    {
      "answer": "The SD line goes through the point of averages, and has slope equal to SDY/SDX if the correlation coefficient r is greater than or equal to zero. The SD line has slope \u2212SDY/SDX if r is negative.  The line slopes up to the right, because r is positive (0.5 at first).",
      "question": "Does the regression line go through the point of averages"
    },
    {
      "answer": "Yes, the vectors from a word2vec model can be used as input in the learning of a new task, and in some (not all) cases, may yield better performance in the new model.",
      "question": "Does word2vec transfer learning"
    },
    {
      "answer": "Binomial counts successes in a fixed number of trials, while Negative binomial counts failures until a fixed number successes. The Bernoulli and Geometric distributions are the simplest cases of the Binomial and Negative Binomial distributions.",
      "question": "What is the difference between binomial and negative binomial distribution"
    },
    {
      "answer": "Step 1: Learn the fundamental data structures and algorithms. First, pick a favorite language to focus on and stick with it.  Step 2: Learn advanced concepts, data structures, and algorithms.  Step 1+2: Practice.  Step 3: Lots of reading + writing.  Step 4: Contribute to open-source projects.  Step 5: Take a break.",
      "question": "How do I start learning algorithms"
    },
    {
      "answer": "The natural logarithm function is negative for values less than one and positive for values greater than one. So yes, it is possible that you end up with a negative value for log-likelihood (for discrete variables it will always be so).",
      "question": "Can the likelihood be negative"
    },
    {
      "answer": "You will need to know the standard deviation of the population in order to calculate the sampling distribution. Add all of the observations together and then divide by the total number of observations in the sample.",
      "question": "How do you find the sampling distribution"
    },
    {
      "answer": "Cluster sampling is typically used in market research. It's used when a researcher can't get information about the population as a whole, but they can get information about the clusters. For example, a researcher may be interested in data about city taxes in Florida.",
      "question": "What is the purpose of cluster sampling"
    },
    {
      "answer": "Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron.",
      "question": "Why activation function is used in neural network"
    },
    {
      "answer": "Approximately Normal Distributions with Discrete Data. If a random variable is actually discrete, but is being approximated by a continuous distribution, a continuity correction is needed.",
      "question": "Can discrete random variables be normally distributed"
    },
    {
      "answer": "In mathematics, a nonnegative matrix, written. is a matrix in which all the elements are equal to or greater than zero, that is, A positive matrix is a matrix in which all the elements are strictly greater than zero.",
      "question": "What is non negative matrix"
    },
    {
      "answer": "Explanation: The objective of perceptron learning is to adjust weight along with class identification.",
      "question": "What is the objective of Perceptron learning *"
    },
    {
      "answer": "It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.  The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.",
      "question": "Why is rectified linear unit a good activation function"
    },
    {
      "answer": "The major difference between using a Z score and a T statistic is that you have to estimate the population standard deviation. The T test is also used if you have a small sample size (less than 30).",
      "question": "What is Z statistics and t statistics"
    },
    {
      "answer": "An ROC curve shows the relationship between clinical sensitivity and specificity for every possible cut-off. The ROC curve is a graph with: The x-axis showing 1 \u2013 specificity (= false positive fraction = FP/(FP+TN)) The y-axis showing sensitivity (= true positive fraction = TP/(TP+FN))",
      "question": "What does a ROC curve tell you"
    },
    {
      "answer": "4:551:11:29Suggested clip \u00b7 112 secondsRodrigo Agundez: Building a live face recognition system | Pydata YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you create a face recognition system"
    },
    {
      "answer": "One such step is eliminating duplicate data as discussed above. Another step is resolving any conflicting data. Sometimes, datasets will have information that conflicts with each other, so data normalization is meant to address this conflicting issue and solve it before continuing. A third step is formatting the data.",
      "question": "When and why do we need data normalization"
    },
    {
      "answer": "Markov models are useful to model environments and problems involving sequential, stochastic decisions over time. Representing such environments with decision trees would be confusing or intractable, if at all possible, and would require major simplifying assumptions [2].",
      "question": "Why Markov model is useful"
    },
    {
      "answer": "To understand potential interaction effects, compare the lines from the interaction plot: If the lines are parallel, there is no interaction. If the lines are not parallel, there is an interaction.",
      "question": "How do you know if there is an interaction effect"
    },
    {
      "answer": "A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.  See Get ONNX models for Windows ML for more information.",
      "question": "What is ML model"
    },
    {
      "answer": "With cluster sampling, the researcher divides the population into separate groups, called clusters. Then, a simple random sample of clusters is selected from the population.  For example, given equal sample sizes, cluster sampling usually provides less precision than either simple random sampling or stratified sampling.",
      "question": "What is the difference between simple random sampling and cluster sampling"
    },
    {
      "answer": "The short answer is yes\u2014because most regression models will not perfectly fit the data at hand. If you need a more complex model, applying a neural network to the problem can provide much more prediction power compared to a traditional regression.",
      "question": "Are neural networks good for regression"
    },
    {
      "answer": "Random forest will reduce variance part of error rather than bias part, so on a given training data set decision tree may be more accurate than a random forest. But on an unexpected validation data set, Random forest always wins in terms of accuracy.",
      "question": "How is random forest better than decision tree"
    },
    {
      "answer": "Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and what the corresponding output is in the training data) where the data is continuously split according to a certain parameter.  An example of a decision tree can be explained using above binary tree.",
      "question": "What is decision trees in machine learning"
    },
    {
      "answer": "Decision tree is unstable because training a tree with a slightly different sub-sample causes the structure of the tree to change drastically. It overfits by learning from noise data as well and optimises for that particular sample, which causes its variable importance order to change significantly.",
      "question": "Why are decision trees unstable"
    },
    {
      "answer": "Types of machine learning AlgorithmsSupervised learning.Unsupervised Learning.Semi-supervised Learning.Reinforcement Learning.",
      "question": "What are the different types of learning that algorithms use"
    },
    {
      "answer": "Here are five ways to identify segments.Cross-Tab. Cross-tabbing is the process of examining more than one variable in the same table or chart (\u201ccrossing\u201d them).  Cluster Analysis.  Factor Analysis.  Latent Class Analysis (LCA)  Multidimensional Scaling (MDS)",
      "question": "How do you find clusters in data"
    },
    {
      "answer": "The k-modes algorithm tries to minimize the sum of within-cluster Hamming distance from the mode of that cluster, summed over all clusters.  The procedure is similar to k-means: a number of clusters (k) is chosen, and k cluster-mode vectors are chosen at random (or according to accepted heuristics).",
      "question": "How does K modes work"
    },
    {
      "answer": "\u2022 h is the Vapnik Chervonenkis (VC) dimension and is a measure of the capacity or complexity of the machine.",
      "question": "What is VC dimension in SVM"
    },
    {
      "answer": "Neural network ensemble is a learning paradigm where many neural networks are jointly used to solve a problem.  Then it assigns random weights to those networks and employs genetic algorithm to evolve the weights so that they can characterize to some extent the fitness of the neural networks in constituting an ensemble.",
      "question": "What is ensemble neural network"
    },
    {
      "answer": "So, if you are constrained either by the size of the data or the number of trials you want to try, you may have to go with random forests. There is one fundamental difference in performance between the two that may force you to choose Random Forests over Gradient Boosted Machines (GBMs).",
      "question": "When would one use Random Forests over Gradient Boosted Machines GBMs"
    },
    {
      "answer": "In statistics, the method of moments is a method of estimation of population parameters. It starts by expressing the population moments (i.e., the expected values of powers of the random variable under consideration) as functions of the parameters of interest.  The solutions are estimates of those parameters.",
      "question": "What is the method of moments estimator"
    },
    {
      "answer": "Using the Interquartile Rule to Find Outliers Multiply the interquartile range (IQR) by 1.5 (a constant used to discern outliers). Add 1.5 x (IQR) to the third quartile. Any number greater than this is a suspected outlier. Subtract 1.5 x (IQR) from the first quartile.",
      "question": "How do you use interquartile range to find outliers"
    },
    {
      "answer": "The GRU is like a long short-term memory (LSTM) with a forget gate, but has fewer parameters than LSTM, as it lacks an output gate.  GRU's performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM.",
      "question": "Are GRU Gated Recurrent Unit a special case of LSTM"
    },
    {
      "answer": "The low-pass filter has a gain response with a frequency range from zero frequency (DC) to \u03c9C. Any input that has a frequency below the cutoff frequency \u03c9C gets a pass, and anything above it gets attenuated or rejected. The gain approaches zero as frequency increases to infinity.",
      "question": "What is the frequency response of low pass filter"
    },
    {
      "answer": "A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.",
      "question": "What is Markov chain in probability"
    },
    {
      "answer": "Another strategy OTs typically recommend is something called \u201cbackward chaining.\" Backward chaining is working backward from the goal. For example, the goal is put on a T-shirt.  Pull shirt over head. Push right arm up through right sleeve.",
      "question": "What is an example of backward chaining"
    },
    {
      "answer": "Differential calculus is usually taught first. I think most students find it more intuitive because they deal with rates of change in real life. Integral calculus is more abstract, and indefinite integrals are much easier to evaluate if you understand differentiation.",
      "question": "Which comes first differential or integral calculus"
    },
    {
      "answer": "Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.",
      "question": "What is Dimension reduction in machine learning"
    },
    {
      "answer": "1. A Multi-Agent System (MAS) is a loosely coupled network of software agents that interact to solve problems that are beyond the individual capacities or knowledge of each software agent. Learn more in: Using Multi-Agent Systems to Support e-Health Services. A system composed of multiple interacting intelligent agents",
      "question": "What are multi agent systems 1"
    },
    {
      "answer": "Theorem 1.2 Suppose that \u03c8 is a simple random point process that has both stationary and independent increments. Then in fact, \u03c8 is a Poisson process. Thus the Poisson process is the only simple point process with stationary and independent increments.",
      "question": "Is Poisson process stationary"
    },
    {
      "answer": "Some of the most popular methods for outlier detection are:Z-Score or Extreme Value Analysis (parametric)Probabilistic and Statistical Modeling (parametric)Linear Regression Models (PCA, LMS)Proximity Based Models (non-parametric)Information Theory Models.More items",
      "question": "What methods do you use to identify outliers within a data set"
    },
    {
      "answer": "Reduce Variance of an Estimate If we want to reduce the amount of variance in a prediction, we must add bias. Consider the case of a simple statistical estimate of a population parameter, such as estimating the mean from a small random sample of data. A single estimate of the mean will have high variance and low bias.",
      "question": "How do you reduce the variance of data"
    },
    {
      "answer": "The lognormal distribution is a probability distribution whose logarithm has a normal distribution. The mean m and variance v of a lognormal random variable are functions of the lognormal distribution parameters \u00b5 and \u03c3: m = exp ( \u03bc + \u03c3 2 / 2 ) v = exp ( 2 \u03bc + \u03c3 2 ) ( exp ( \u03c3 2 ) \u2212 1 )",
      "question": "What is the mean and variance of lognormal distribution"
    },
    {
      "answer": "2. Exponential Moving Average (EMA) The other type of moving average is the exponential moving average (EMA), which gives more weight to the most recent price points to make it more responsive to recent data points.",
      "question": "Which moving average is more responsive"
    },
    {
      "answer": "A batch size of 32 means that 32 samples from the training dataset will be used to estimate the error gradient before the model weights are updated.",
      "question": "Why is batch size 32"
    },
    {
      "answer": "Epsilon is used when we are selecting specific actions base on the Q values we already have. As an example if we select pure greedy method ( epsilon = 0 ) then we are always selecting the highest q value among the all the q values for a specific state.",
      "question": "What is Epsilon in Q learning"
    },
    {
      "answer": "Variance",
      "question": "Which gives the measure of randomness of the random variable"
    },
    {
      "answer": "The technological singularity\u2014also, simply, the singularity\u2014is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.",
      "question": "What is it called when AI becomes self aware"
    },
    {
      "answer": "Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning.  LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",
      "question": "What is Lstm in neural network"
    },
    {
      "answer": "Feature Selection.  The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones.",
      "question": "What is the difference between feature selection and feature extraction"
    },
    {
      "answer": "Digital image processing, as a computer-based technology, carries out automatic processing, manipulation and interpretation of such visual information, and it plays an increasingly important role in many aspects of our daily life, as well as in a wide variety of disciplines and fields in science and technology, with",
      "question": "What are the application of image processing"
    },
    {
      "answer": "1. Agglomerative approach: This method is also called a bottom-up approach shown in Figure 6.7. In this method, each node represents a single cluster at the beginning; eventually, nodes start merging based on their similarities and all nodes belong to the same cluster.",
      "question": "Which of clustering algorithms is called bottom up approach"
    },
    {
      "answer": "Introduction. The standard deviation is a measure of the spread of scores within a set of data. Usually, we are interested in the standard deviation of a population. However, as we are often presented with data from a sample only, we can estimate the population standard deviation from a sample standard deviation.",
      "question": "Do you use sample or population standard deviation"
    },
    {
      "answer": "The mean of a discrete random variable X is a weighted average of the possible values that the random variable can take. Unlike the sample mean of a group of observations, which gives each observation equal weight, the mean of a random variable weights each outcome xi according to its probability, pi.",
      "question": "What is the mean of a discrete random variable"
    },
    {
      "answer": "There are often only a handful of possible classes or results. For a given classification, one tries to measure the probability of getting different evidence or patterns.  Using Bayes rule, we use this to get what is desired, the conditional probability of the classification given the evidence.",
      "question": "Why do you think you need conditional probability"
    },
    {
      "answer": "The essential difference between these two is that Logistic regression is used when the dependent variable is binary in nature. In contrast, Linear regression is used when the dependent variable is continuous and nature of the regression line is linear.",
      "question": "What are the two main differences between logistic regression and linear regression"
    },
    {
      "answer": "The p-value is calculated using the sampling distribution of the test statistic under the null hypothesis, the sample data, and the type of test being done (lower-tailed test, upper-tailed test, or two-sided test).  a lower-tailed test is specified by: p-value = P(TS ts | H 0 is true) = cdf(ts)",
      "question": "How is P value calculated"
    },
    {
      "answer": "Nonresponse bias occurs when some respondents included in the sample do not respond. The key difference here is that the error comes from an absence of respondents instead of the collection of erroneous data.  Most often, this form of bias is created by refusals to participate or the inability to reach some respondents.",
      "question": "How does non response cause bias"
    },
    {
      "answer": "The survival function is a function that gives the probability that a patient, device, or other object of interest will survive beyond any specified time. The survival function is also known as the survivor function or reliability function.",
      "question": "What does survival function mean"
    },
    {
      "answer": "The test statistic used in ANOVA is Student's t. One characteristic of the F distribution is that F cannot be negative. One characteristic of the F distribution is that the computed F can only range between -1 and +1.",
      "question": "What is a characteristic of the F distribution that is used in Anova"
    },
    {
      "answer": "A good maximum sample size is usually 10% as long as it does not exceed 1000. A good maximum sample size is usually around 10% of the population, as long as this does not exceed 1000. For example, in a population of 5000, 10% would be 500. In a population of 200,000, 10% would be 20,000.",
      "question": "What is a good representative sample size"
    },
    {
      "answer": "Use systematic sampling when there's low risk of data manipulation. Systematic sampling is the preferred method over simple random sampling when a study maintains a low risk of data manipulation.",
      "question": "When would you use systematic sampling"
    },
    {
      "answer": "When Longitudinal data looks like a time series is when we measure the same thing over time. The big difference is that in a time series we can measure the overall change in the measurement over time (or by group) while in a longitudinal analysis you actually have the measurement of change at the individual level.",
      "question": "What is the difference between time series and longitudinal data"
    },
    {
      "answer": "Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.",
      "question": "What does transfer learning mean"
    },
    {
      "answer": "Compare r to the appropriate critical value in the table. If r is not between the positive and negative critical values, then the correlation coefficient is significant. If r is significant, then you may want to use the line for prediction. Suppose you computed r=0.801 using n=10 data points.",
      "question": "How do you know if a correlation coefficient is statistically significant"
    },
    {
      "answer": "A factorial ANOVA compares means across two or more independent variables. Again, a one-way ANOVA has one independent variable that splits the sample into two or more groups, whereas the factorial ANOVA has two or more independent variables that split the sample in four or more groups.",
      "question": "What is the difference between one way Anova and factorial Anova"
    },
    {
      "answer": "If you want to process the gradients before applying them you can instead use the optimizer in three steps:Compute the gradients with compute_gradients().Process the gradients as you wish.Apply the processed gradients with apply_gradients().",
      "question": "How does one do gradient clipping in TensorFlow"
    },
    {
      "answer": "A disadvantage is when researchers can't classify every member of the population into a subgroup. Stratified random sampling is different from simple random sampling, which involves the random selection of data from the entire population so that each possible sample is equally likely to occur.",
      "question": "What are the drawbacks disadvantage of stratified sampling"
    },
    {
      "answer": "Once you have generated a prediction model (also called training a model), you can put it to use making predictions.  The scoring process examines a dataset and predicts results for each record based on similarities to records analyzed during model training.",
      "question": "What is the predictive score model"
    },
    {
      "answer": "Squaring the residuals, averaging the squares, and taking the square root gives us the r.m.s error. You then use the r.m.s. error as a measure of the spread of the y values about the predicted y value.",
      "question": "How do you find the root mean square error"
    },
    {
      "answer": "A support vector machine is a machine learning model that is able to generalise between two different classes if the set of labelled data is provided in the training set to the algorithm. The main function of the SVM is to check for that hyperplane that is able to distinguish between the two classes.",
      "question": "How do support vector machines work"
    },
    {
      "answer": "Hidden Markov model (HMM) has been successfully used for sequential data modeling problems.  In the proposed GenHMM, each HMM hidden state is associated with a neural network based generative model that has tractability of exact likelihood and provides efficient likelihood computation.",
      "question": "Is a hidden Markov model a neural network"
    },
    {
      "answer": "Softmax is a non-linear activation function, and is arguably the simplest of the set. In this expression, zi is the current value. The denominator in the expression is the sum across every value passed to a node in the layer.",
      "question": "Is Softmax a linear function"
    },
    {
      "answer": "A Classification and Regression Tree(CART) is a predictive algorithm used in machine learning. It explains how a target variable's values can be predicted based on other values. It is a decision tree where each fork is a split in a predictor variable and each node at the end has a prediction for the target variable.",
      "question": "What is a classification and regression tree CART"
    },
    {
      "answer": "The sign of a regression coefficient tells you whether there is a positive or negative correlation between each independent variable the dependent variable. A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase.",
      "question": "How do you interpret regression results"
    },
    {
      "answer": "The square of the correlation coefficient, r\u00b2, is a useful value in linear regression. This value represents the fraction of the variation in one variable that may be explained by the other variable.  The correlation coefficient also relates directly to the regression line Y = a + bX for any two variables, where .",
      "question": "How is the regression line related to the correlation coefficient"
    },
    {
      "answer": "A sampling frame is a list or other device used to define a researcher's population of interest. The sampling frame defines a set of elements from which a researcher can select a sample of the target population.  Comprehensiveness refers to the degree to which a sampling frame covers the entire target population.",
      "question": "What do you mean by sampling frame"
    },
    {
      "answer": "Abstract: The generalized likelihood ratio test (GLRT), which is commonly used in composite hypothesis testing problems, is investigated. Conditions for asymptotic optimality of the GLRT in the Neyman-Pearson sense are studied and discussed.",
      "question": "What is GLRT"
    },
    {
      "answer": "Multimodal machine learning is a vibrant multi-disciplinary research field which addresses some of the original goals of artificial intelligence by integrating and modeling multiple communicative modalities, including linguistic, acoustic and visual messages.",
      "question": "What is multimodal machine learning"
    },
    {
      "answer": "You do not need to learn linear algebra before you get started in machine learning, but at some time you may wish to dive deeper.  It will give you the tools to help you with the other areas of mathematics required to understand and build better intuitions for machine learning algorithms.",
      "question": "Do you need to know Linear Algebra for machine learning"
    },
    {
      "answer": "The margin of error increases as the level of confidence increases because the larger the expected proportion of intervals that will contain the\u200b parameter, the larger the margin of error.  The larger the level of confidence\u200b is, the larger number of intervals that will contain the parameter.",
      "question": "What increases the margin of error"
    },
    {
      "answer": "It is often used as a gauge of economic inequality, measuring income distribution or, less commonly, wealth distribution among a population. The coefficient ranges from 0 (or 0%) to 1 (or 100%), with 0 representing perfect equality and 1 representing perfect inequality.",
      "question": "What does a lower Gini coefficient mean"
    },
    {
      "answer": "\"The difference between discrete choice models and conjoint models is that discrete choice models present experimental replications of the market with the focus on making accurate predictions regarding the market, while conjoint models do not, using product profiles to estimate underlying utilities (or partworths)",
      "question": "What is the difference between a discrete choice and a conjoint analysis"
    },
    {
      "answer": "The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 \u2013 FPR). Classifiers that give curves closer to the top-left corner indicate a better performance. As a baseline, a random classifier is expected to give points lying along the diagonal (FPR = TPR).",
      "question": "How do you read a ROC curve"
    },
    {
      "answer": "Variational Bayesian methods are primarily used for two purposes: To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.",
      "question": "Why do variational inferences occur"
    },
    {
      "answer": "A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data.",
      "question": "What is Gaussian process in machine learning"
    },
    {
      "answer": "It depends. If the message you want to carry is about the spread and variability of the data, then standard deviation is the metric to use. If you are interested in the precision of the means or in comparing and testing differences between means then standard error is your metric.",
      "question": "Can you use standard error instead of standard deviation"
    },
    {
      "answer": "Active learning engages students in learning, using activities such as reading, writing, discussion, or problem solving, which promote analysis, synthesis, and evaluation of class content. Active in-class learning also provides students with informal opportunities for feedback on how well they understood the material.",
      "question": "What are active learning strategies"
    },
    {
      "answer": "Joint probability is calculated by multiplying the probability of event A, expressed as P(A), by the probability of event B, expressed as P(B). For example, suppose a statistician wishes to know the probability that the number five will occur twice when two dice are rolled at the same time.",
      "question": "How do you calculate joint probability"
    },
    {
      "answer": "In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation.  The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.",
      "question": "Why is vanishing gradient a problem"
    },
    {
      "answer": "Box plots are useful as they show outliers within a data set. An outlier is an observation that is numerically distant from the rest of the data. When reviewing a box plot, an outlier is defined as a data point that is located outside the whiskers of the box plot.",
      "question": "Can a Boxplot be used to detect outliers"
    },
    {
      "answer": "Weights control the signal (or the strength of the connection) between two neurons. In other words, a weight decides how much influence the input will have on the output. Biases, which are constant, are an additional input into the next layer that will always have the value of 1.",
      "question": "What are weights in machine learning"
    },
    {
      "answer": "Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.",
      "question": "How does Adam Optimizer work"
    },
    {
      "answer": "To find the mean absolute deviation of the data, start by finding the mean of the data set. Find the sum of the data values, and divide the sum by the number of data values. Find the absolute value of the difference between each data value and the mean: |data value \u2013 mean|.",
      "question": "How do you get the mean absolute deviation"
    },
    {
      "answer": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.",
      "question": "What is the exact meaning of artificial intelligence"
    },
    {
      "answer": "In statistics and control theory, Kalman filtering, also known as linear quadratic estimation (LQE), is an algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a",
      "question": "What is Kalman filter used for"
    },
    {
      "answer": "A (non-mathematical) definition I like by Miller (2017)3 is: Interpretability is the degree to which a human can understand the cause of a decision.  The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made.",
      "question": "What is model interpretability"
    },
    {
      "answer": "In a histogram, the total range of data set (i.e from minimum value to maximum value) is divided into 8 to 15 equal parts. These equal parts are known as bins or class intervals. Each and every observation (or value) in the data set is placed in the appropriate bin.",
      "question": "What is binning in histogram"
    },
    {
      "answer": "Sampling is used any time data is to be gathered. Data cannot be collected until the sample size (how much) and sample frequency (how often) have been determined. Sampling should be periodically reviewed.",
      "question": "Under what circumstances sampling is used"
    },
    {
      "answer": "TensorFlow applications can be run on most any target that's convenient: a local machine, a cluster in the cloud, iOS and Android devices, CPUs or GPUs. If you use Google's own cloud, you can run TensorFlow on Google's custom TensorFlow Processing Unit (TPU) silicon for further acceleration.",
      "question": "Where can I use TensorFlow"
    },
    {
      "answer": "A one-tailed test is also known as a directional hypothesis or directional test. A two-tailed test, on the other hand, is designed to examine both sides of a specified data range to test whether a sample is greater than or less than the range of values.",
      "question": "What is the differences between marginal distribution and the two tailed test"
    },
    {
      "answer": "Note the difference between parameters and arguments: Function parameters are the names listed in the function's definition. Function arguments are the real values passed to the function. Parameters are initialized to the values of the arguments supplied.",
      "question": "What is the difference between an argument and a parameter"
    },
    {
      "answer": "The output of the network is a single vector (also with 10,000 components) containing, for every word in our vocabulary, the probability that a randomly selected nearby word is that vocabulary word. In word2vec, a distributed representation of a word is used.",
      "question": "What is the output of Word2Vec"
    },
    {
      "answer": "Creating A Target VariableFrom the menu: Click View > User Variables. The Variables dialog box appears. Click Add Target.From the Target pane: Right-click a linked field and select Edit Lookup Criteria. The Edit Lookup Criteria for the selected field appears. Click Edit Lookup Formula. The Edit Formula for the selected field appears.",
      "question": "How do you create a target variable"
    },
    {
      "answer": "This occurs when the line-of-best-fit for describing the relationship between x and y is a straight line. The linear relationship between two variables is positive when both increase together; in other words, as values of x get larger values of y get larger. This is also known as a direct relationship.",
      "question": "How do you tell if there is a linear relationship between two variables"
    },
    {
      "answer": "Root Mean Squared Error or RMSE RMSE is the standard deviation of the errors which occur when a prediction is made on a dataset. This is the same as MSE (Mean Squared Error) but the root of the value is considered while determining the accuracy of the model. from sklearn.",
      "question": "What is root mean square error in machine learning"
    },
    {
      "answer": "In statistics and regression analysis, moderation occurs when the relationship between two variables depends on a third variable. The third variable is referred to as the moderator variable or simply the moderator.",
      "question": "If you control for a variable and examine the relationship between two others is this moderation"
    },
    {
      "answer": "Continuous probability distribution: A probability distribution in which the random variable X can take on any value (is continuous). Because there are infinite values that X could assume, the probability of X taking on any one specific value is zero.  The normal distribution is one example of a continuous distribution.",
      "question": "What is continuous probability distribution"
    },
    {
      "answer": "In the real world, knowledge plays a vital role in intelligence as well as creating artificial intelligence. It demonstrates the intelligent behavior in AI agents or systems. It is possible for an agent or system to act accurately on some input only when it has the knowledge or experience about the input.",
      "question": "What is the role of knowledge in AI"
    },
    {
      "answer": "The lognormal distribution is a distribution skewed to the right. The pdf starts at zero, increases to its mode, and decreases thereafter. The degree of skewness increases as increases, for a given . For the same , the pdf's skewness increases as increases.",
      "question": "What properties do a log normal distribution have"
    },
    {
      "answer": "A stratified sample is one that ensures that subgroups (strata) of a given population are each adequately represented within the whole sample population of a research study. For example, one might divide a sample of adults into subgroups by age, like 18\u201329, 30\u201339, 40\u201349, 50\u201359, and 60 and above.",
      "question": "What is an example of a stratified sample"
    },
    {
      "answer": "Under the hood, these RDDs are stored in partitions on different cluster nodes. Partition basically is a logical chunk of a large distributed data set. It provides the possibility to distribute the work across the cluster, divide the task into smaller parts, and reduce memory requirements for each node.",
      "question": "How is RDD partitioned"
    },
    {
      "answer": "Multinomial logistic regression is used when you have a categorical dependent variable with two or more unordered levels (i.e. two or more discrete outcomes).  One level of the dependent variable is chosen as the reference category. This is typically the most common or the most frequent category.",
      "question": "What is a multinomial variable"
    },
    {
      "answer": "Random errors in experimental measurements are caused by unknown and unpredictable changes in the experiment. These changes may occur in the measuring instruments or in the environmental conditions.",
      "question": "What is random error"
    },
    {
      "answer": "If the correlation between education and unobserved ability is positive, omitted variables bias will occur in an upward direction. Conversely, if the correlation between an explanatory variable and an unobserved relevant variable is negative, omitted variables bias will occur in a downward direction.",
      "question": "How do you determine the direction of omitted variable bias"
    },
    {
      "answer": "Len Gould. Answered November 6, 2016 \u00b7 Author has 6.4K answers and 3M answer views. Outgroups are simply the people who are not members of your ingroup. Obvious examples of bases for forming ingroups are according to their race, culture, gender, age or religion.",
      "question": "What is ingroup and outgroup examples"
    },
    {
      "answer": "The difference between true random number generators(TRNGs) and pseudo-random number generators(PRNGs) is that TRNGs use an unpredictable physical means to generate numbers (like atmospheric noise), and PRNGs use mathematical algorithms (completely computer-generated).",
      "question": "What is the difference between random number and pseudo random number"
    },
    {
      "answer": "Nonparametric tests are also called distribution-free tests because they don't assume that your data follow a specific distribution. You may have heard that you should use nonparametric tests when your data don't meet the assumptions of the parametric test, especially the assumption about normally distributed data.",
      "question": "In the field of statistics when are nonparametric tests preferred over parametric tests"
    },
    {
      "answer": "Stratified random sampling is a method of sampling that involves the division of a population into smaller sub-groups known as strata. In stratified random sampling, or stratification, the strata are formed based on members' shared attributes or characteristics such as income or educational attainment.",
      "question": "What is a stratified random sample"
    },
    {
      "answer": "Systematic random samplingCalculate the sampling interval (the number of households in the population divided by the number of households needed for the sample)Select a random start between 1 and sampling interval.Repeatedly add sampling interval to select subsequent households.",
      "question": "How do you do systematic sampling"
    },
    {
      "answer": "Bivariate analysis means the analysis of bivariate data. It is one of the simplest forms of statistical analysis, used to find out if there is a relationship between two sets of values. It usually involves the variables X and Y. Univariate analysis is the analysis of one (\u201cuni\u201d) variable.",
      "question": "When will we use bivariate analysis"
    },
    {
      "answer": "In deep multilayer Perceptron networks, exploding gradients can result in an unstable network that at best cannot learn from the training data and at worst results in NaN weight values that can no longer be updated. \u2026 exploding gradients can make learning unstable.",
      "question": "Do ReLU networks suffer from the exploding gradient problem"
    },
    {
      "answer": "Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost.",
      "question": "Why is deep learning needed"
    },
    {
      "answer": "Data science is an umbrella term for a group of fields that are used to mine large datasets. Data analytics software is a more focused version of this and can even be considered part of the larger process. Analytics is devoted to realizing actionable insights that can be applied immediately based on existing queries.",
      "question": "What is the difference between working in analytics and data science"
    },
    {
      "answer": "Definition. Stimulus generalization is the tendency of a new stimulus to evoke responses or behaviors similar to those elicited by another stimulus. For example, Ivan Pavlov conditioned dogs to salivate using the sound of a bell and food powder.",
      "question": "What is an example of stimulus generalization"
    },
    {
      "answer": "4.3 The method: evolutionary computation. EC is a computational intelligence technique inspired from natural evolution. An EC algorithm starts with creating a population consisting of individuals that represent solutions to the problem. The first population could be created randomly or fed into the algorithm.",
      "question": "What is evolutionary computation in AI"
    },
    {
      "answer": "In unsupervised learning, an AI system is presented with unlabeled, uncategorized data and the system's algorithms act on the data without prior training. The output is dependent upon the coded algorithms. Subjecting a system to unsupervised learning is an established way of testing the capabilities of that system.",
      "question": "How does unsupervised machine learning work"
    },
    {
      "answer": "ReLu bounded negative outputs to 0 & above. This works well in hidden layers than the final output layer.  It is not typical, since in this case, the ouput value is not bounded in a range.",
      "question": "Why ReLU is not used in output layer"
    },
    {
      "answer": "four outcomes",
      "question": "How many outcomes are in the sample space"
    },
    {
      "answer": "Bias can damage research, if the researcher chooses to allow his bias to distort the measurements and observations or their interpretation. When faculty are biased about individual students in their courses, they may grade some students more or less favorably than others, which is not fair to any of the students.",
      "question": "What is the problem with bias"
    },
    {
      "answer": "Big data analytics as the name suggest is the analysis of big data by discovering hidden patterns or extracting information from it.  Big data has got more to do with High-Performance Computing, while Machine Learning is a part of Data Science. Machine learning performs tasks where human interaction doesn't matter.",
      "question": "Is Big Data Machine Learning"
    },
    {
      "answer": "Step 1: Learn the fundamental data structures and algorithms. First, pick a favorite language to focus on and stick with it.  Step 2: Learn advanced concepts, data structures, and algorithms.  Step 1+2: Practice.  Step 3: Lots of reading + writing.  Step 4: Contribute to open-source projects.  Step 5: Take a break.",
      "question": "What is the best way to learn algorithms"
    },
    {
      "answer": "The key assumption in ordinal regression is that the effects of any explanatory variables are consistent or proportional across the different thresholds, hence this is usually termed the assumption of proportional odds (SPSS calls this the assumption of parallel lines but it's the same thing).",
      "question": "What are the assumptions of ordinal logistic regression"
    },
    {
      "answer": "\u2013 Validation set: A set of examples used to tune the parameters of a classifier, for example to choose the number of hidden units in a neural network. \u2013 Test set: A set of examples used only to assess the performance of a fully-specified classifier.",
      "question": "What is the difference between test set and validation set"
    },
    {
      "answer": "When all the points on a scatterplot lie on a straight line, you have what is called a perfect correlation between the two variables (see below). A scatterplot in which the points do not have a linear trend (either positive or negative) is called a zero correlation or a near-zero correlation (see below).",
      "question": "Is it possible for a scatter plot to have a positive or negative association that is not linear"
    },
    {
      "answer": "A generative model includes the distribution of the data itself, and tells you how likely a given example is. For example, models that predict the next word in a sequence are typically generative models (usually much simpler than GANs) because they can assign a probability to a sequence of words.",
      "question": "What are generative models used for"
    },
    {
      "answer": "A random variable is a numerical description of the outcome of a statistical experiment. A random variable that may assume only a finite number or an infinite sequence of values is said to be discrete; one that may assume any value in some interval on the real number line is said to be continuous.",
      "question": "What is a random variable in statistics"
    },
    {
      "answer": "Intuitively, two random variables X and Y are independent if knowing the value of one of them does not change the probabilities for the other one. In other words, if X and Y are independent, we can write P(Y=y|X=x)=P(Y=y), for all x,y.",
      "question": "Does random variables imply independence"
    },
    {
      "answer": "Explanation: The two types of Fourier series are- Trigonometric and exponential.",
      "question": "What are the two types of Fourier series"
    },
    {
      "answer": "The SVM classifier is a frontier which best segregates the two classes (hyper-plane/ line). You can look at support vector machines and a few examples of its working here.",
      "question": "What are the two classification methods that SVM support vector machine can handle"
    },
    {
      "answer": "The main difference between the two, is that a Perceptron takes that binary response (like a classification result) and computes an error used to update the weights, whereas an Adaline uses a continous response value to update the weights (so before the binarized output is produced).",
      "question": "What is the difference between a Perceptron Adaline and neural network model"
    },
    {
      "answer": "Hierarchical regression is a way to show if variables of your interest explain a statistically significant amount of variance in your Dependent Variable (DV) after accounting for all other variables. This is a framework for model comparison rather than a statistical method.",
      "question": "What is hierarchical regression used for"
    },
    {
      "answer": "The Non-Linear Decision Boundary SVM works well when the data points are linearly separable. If the decision boundary is non-liner then SVM may struggle to classify. Observe the below examples, the classes are not linearly separable. SVM has no direct theory to set the non-liner decision boundary models.",
      "question": "What is non linear decision boundary"
    },
    {
      "answer": "In the statistical analysis of time series, autoregressive\u2013moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression (AR) and the second for the moving average (MA).",
      "question": "What is ARMA model used for"
    },
    {
      "answer": "The parameters of LDA model have the prior distribution, and are estimated by Bayesian method. LDA model has attracted many scholars' attention since its start, but its mathematical theory is too complex to understand quickly.",
      "question": "Is LDA a Bayesian"
    },
    {
      "answer": "Example 1: Fair Dice Roll The number of desired outcomes is 3 (rolling a 2, 4, or 6), and there are 6 outcomes in total. The a priori probability for this example is calculated as follows: A priori probability = 3 / 6 = 50%. Therefore, the a priori probability of rolling a 2, 4, or 6 is 50%.",
      "question": "How do you calculate a priori probability"
    },
    {
      "answer": "The SVM in particular defines the criterion to be looking for a decision surface that is maximally far away from any data point. This distance from the decision surface to the closest data point determines the margin of the classifier.  Figure 15.1 shows the margin and support vectors for a sample problem.",
      "question": "What is a margin in SVM"
    },
    {
      "answer": "Interpret the key results for Fit Mixed Effects ModelStep 1: Determine whether the random terms significantly affect the response.Step 2: Determine whether the fixed effect terms significantly affect the response.Step 3: Determine how well the model fits your data.Step 4: Evaluate how each level of a fixed effect term affects the response.More items",
      "question": "How do you read mixed model results"
    },
    {
      "answer": "EXAMPLES OF DATA MINING APPLICATIONS Marketing. Data mining is used to explore increasingly large databases and to improve market segmentation.  It is commonly applied to credit ratings and to intelligent anti-fraud systems to analyse transactions, card transactions, purchasing patterns and customer financial data.",
      "question": "What is data mining and example"
    },
    {
      "answer": "E(Y | Xi) = f (Xi) is known as conditional expectation function(CEF) or population regression function (PRF) or population regression (PR) for short. In simple terms, it tells how the mean or average of response of Y varies with X.",
      "question": "What is the conditional expectation function or the population regression function"
    },
    {
      "answer": "NAT (Network Address Translation) is a feature of the Firewall Software Blade and replaces IPv4 and IPv6 addresses to add more security. You can enable NAT for all SmartDashboard objects to help manage network traffic. NAT protects the identity of a network and does not show internal IP addresses to the Internet.",
      "question": "What is a NAT policy"
    },
    {
      "answer": "Epsilon is used when we are selecting specific actions base on the Q values we already have.  In conclusion learning rate is associated with how big you take a leap and epsilon is associated with how random you take an action.",
      "question": "What is Epsilon in reinforcement learning"
    },
    {
      "answer": "A psychometric and capability test aims to provide measurable, objective data that can give you a better versatile view of a candidate's skills and suitability for a position. Assessments offer scientific, valid reliable and objectivity to the process of recruiting.",
      "question": "What is psychometric and skills testing"
    },
    {
      "answer": "Statistical classification helps in determining the set to which a particular observation belongs. Multiple methods can be used for the classification process, namely, Frequentest procedure and Bayesian procedure among others. It helps in quicker arranging and collection of data,as well as more efficient work rate.",
      "question": "What is statistical classification What is the importance of such a classification"
    },
    {
      "answer": "A sampling frame is a list of all the items in your population. It's a complete list of everyone or everything you want to study. The difference between a population and a sampling frame is that the population is general and the frame is specific.",
      "question": "Is sampling frame the same as population"
    },
    {
      "answer": "Because a researcher rarely has direct access to the entire population of interest in social science research, a researcher must rely upon a sampling frame to represent all of the elements of the population of interest. Generally, sampling frames can be divided into two types, list and nonlist.",
      "question": "What is the importance of a sample frame"
    },
    {
      "answer": "The random (or precision) error for this data point is defined as the reading minus the average of readings, or -1.20 - (-1.42) = 0.22oC. Thus, the maximum absolute value of random error is 0.22oC. You can verify that the magnitude of the random error for any of the other data points is less than this.",
      "question": "How do you find the maximum random error"
    },
    {
      "answer": "Gladwell's purpose for writing The Outliers was to inform reader's on how successful people achieve success through the help of others, practice, and opportunity. He also wanted to get rid of our society's crude perspective on how outliers become successful.",
      "question": "What is Gladwell's purpose in outliers"
    },
    {
      "answer": "Well, if you break down the words, forward implies moving ahead and propagation is a term for saying spreading of anything. forward propagation means we are moving in only one direction, from input to the output, in a neural network.",
      "question": "What is forward propagation in machine learning"
    },
    {
      "answer": "Normal distributions are symmetric, unimodal, and asymptotic, and the mean, median, and mode are all equal. A normal distribution is perfectly symmetrical around its center. That is, the right side of the center is a mirror image of the left side. There is also only one mode, or peak, in a normal distribution.",
      "question": "What are the characteristics of a normal distribution"
    },
    {
      "answer": "Machine learning has a limited scope. AI is working to create an intelligent system which can perform various complex tasks. Machine learning is working to create machines that can perform only those specific tasks for which they are trained. AI system is concerned about maximizing the chances of success.",
      "question": "What is the distinction between artificial intelligence AI and machine learning from your perspective what are some of the legitimate concerns about the future of AI"
    },
    {
      "answer": "The reason why Convolutional Neural Networks (CNNs) do so much better than classic neural networks on images and videos is that the convolutional layers take advantage of inherent properties of images. Simple feedforward neural networks don't see any order in their inputs.",
      "question": "Why convolutional neural networks are better suited for image recognition than fully connected networks"
    },
    {
      "answer": "To convert this distance metric into the similarity metric, we can divide the distances of objects with the max distance, and then subtract it by 1 to score the similarity between 0 and 1. We will look at the example after discussing the cosine metric.",
      "question": "How do you measure similarity"
    },
    {
      "answer": "The Euclidean distance corresponds to the L2-norm of a difference between vectors. The cosine similarity is proportional to the dot product of two vectors and inversely proportional to the product of their magnitudes.",
      "question": "Why cosine similarity is better than Euclidean distance"
    },
    {
      "answer": "It will be easier to learn and use. If you are in the industry where you need to deploy models in production, Tensorflow is your best choice. You can use Keras/Pytorch for prototyping if you want. But you don't need to switch as Tensorflow is here to stay.",
      "question": "Should I use PyTorch or TensorFlow"
    },
    {
      "answer": "In statistical hypothesis testing, a type I error is the rejection of a true null hypothesis (also known as a \"false positive\" finding or conclusion; example: \"an innocent person is convicted\"), while a type II error is the non-rejection of a false null hypothesis (also known as a \"false negative\" finding or conclusion",
      "question": "What is the difference between Type 1 and Type 2 error in statistics"
    },
    {
      "answer": "Systematic random sampling is the random sampling method that requires selecting samples based on a system of intervals in a numbered population. For example, Lucas can give a survey to every fourth customer that comes in to the movie theater.",
      "question": "What is systematic random sampling with example"
    },
    {
      "answer": "Within an artificial neural network, a neuron is a mathematical function that model the functioning of a biological neuron. Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.",
      "question": "What does a neuron compute in neural network"
    },
    {
      "answer": "If you are studying one group, use a paired t-test to compare the group mean over time or after an intervention, or use a one-sample t-test to compare the group mean to a standard value. If you are studying two groups, use a two-sample t-test. If you want to know only whether a difference exists, use a two-tailed test.",
      "question": "How do you know what t test to use"
    },
    {
      "answer": "Deep learning techniques do not perform well when dealing with data with complex hierarchical structures. Deep learning identifies correlations between sets of features that are themselves \u201cflat\u201d or non-hierarchical, as in a simple, unstructured list, but much human and linguistic knowledge is more structured.",
      "question": "What deep learning Cannot do"
    },
    {
      "answer": "Below are the steps to implement the handwritten digit recognition project:Import the libraries and load the dataset. First, we are going to import all the modules that we are going to need for training our model.  Preprocess the data.  Create the model.  Train the model.  Evaluate the model.  Create GUI to predict digits.",
      "question": "How do you make a digit recognizer"
    },
    {
      "answer": "The first benefit of time series analysis is that it can help to clean data. This makes it possible to find the true \u201csignal\u201d in a data set, by filtering out the noise. This can mean removing outliers, or applying various averages so as to gain an overall perspective of the meaning of the data.",
      "question": "What are the advantages of time series analysis"
    },
    {
      "answer": "Our Big Data Hadoop certification training course lets you master the concepts of the Hadoop framework, Big Data tools, and methodologies to prepare you for success in your role as a Big Data Developer. Learn how various components of the Hadoop ecosystem fit into the Big Data processing lifecycle.",
      "question": "What is big data Course"
    },
    {
      "answer": "Very expensive voltmeters are often made to measure \u201ctrue RMS\u201d, because that is what is desired. Low-cost voltmeters approximate the RMS value. To approximate the RMS value for a sine wave, one could simply find the peak value of the sine wave and multiply it by .",
      "question": "Do voltmeters measure RMS or peak"
    },
    {
      "answer": "Sometimes we are given a chart showing frequencies of certain groups instead of the actual values.  If we multiply each midpoint by its frequency, and then divide by the total number of values in the frequency distribution, we have an estimate of the mean.",
      "question": "What does frequency distribution mean"
    },
    {
      "answer": "The discriminator in a GAN is simply a classifier. It tries to distinguish real data from the data created by the generator. It could use any network architecture appropriate to the type of data it's classifying. Figure 1: Backpropagation in discriminator training.",
      "question": "What is discriminator in Gan"
    },
    {
      "answer": "We will use the RAND() function to generate a random value between 0 and 1 on our Y-axis and then get the inverse of it with the NORM. INV function which will result in our random normal value on the X-axis. Mean \u2013 This is the mean of the normal distribution.",
      "question": "How do you generate a random number from a normal distribution"
    },
    {
      "answer": "The collaborative filtering algorithm uses \u201cUser Behavior\u201d for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information.",
      "question": "Which algorithms are used in recommendation system"
    },
    {
      "answer": "Qualitative Variables - Variables that are not measurement variables. Their values do not result from measuring or counting. Examples: hair color, religion, political party, profession. Designator - Values that are used to identify individuals in a table.",
      "question": "What is qualitative variable"
    },
    {
      "answer": "The skip-gram model. Both the input vector x and the output y are one-hot encoded word representations. The hidden layer is the word embedding of size N.",
      "question": "Which layer of the skip gram model has an actual word embedding representation"
    },
    {
      "answer": "Values range from 0 to 1, where 0 is perfect disagreement and 1 is perfect agreement. Krippendorff suggests: \u201c[I]t is customary to require \u03b1 \u2265 . 800. Where tentative conclusions are still acceptable, \u03b1 \u2265 .",
      "question": "What is a good krippendorff's Alpha"
    },
    {
      "answer": "load_model functionv2. 0. Load a model from a shortcut link, package or data path. If called with a shortcut link or package name, spaCy will assume the model is a Python package and import and call its load() method.",
      "question": "Which function is used to load a model in spaCy"
    },
    {
      "answer": "All Answers (8) A matrix is a two dimensional array of numbers (or values from some field or ring). A 2-rank tensor is a linear map from two vector spaces, over some field such as the real numbers, to that field.",
      "question": "What is the difference between a matrix and a tensor"
    },
    {
      "answer": "The higher the threshold, or closer to (0, 0), the higher the specificity and the lower the sensitivity. The lower the threshold, or closer to (1,1), the higher the sensitivity and lower the specificity. So which threshold value one should pick?",
      "question": "How do you choose the threshold in logistic regression"
    },
    {
      "answer": "Multiclass classification with logistic regression can be done either through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.  By default, multi_class is set to 'ovr'.",
      "question": "Can we use logistic regression for multi class classification"
    },
    {
      "answer": "Cluster Analysis and Factor Analysis. Latent Class Analysis is similar to cluster analysis. Observed data is analyzed, connections are found, and the data is grouped into clusters.  Another difference is that LCA includes discrete latent categorical variables that have a multinomial distribution.",
      "question": "What is the difference between cluster analysis and latent class analysis"
    },
    {
      "answer": "AI is a bigger concept to create intelligent machines that can simulate human thinking capability and behavior, whereas, machine learning is an application or subset of AI that allows machines to learn from data without being programmed explicitly.",
      "question": "What is the difference between machine learning"
    },
    {
      "answer": "Log-loss is an appropriate performance measure when you're model output is the probability of a binary outcome. The log-loss measure considers confidence of the prediction when assessing how to penalize incorrect classification.",
      "question": "What is log loss and how it helps to improve performance"
    },
    {
      "answer": "OLS (linear regression, linear model) assumes normally distributed residuals.  Ordinary least squares assumes things like equal variance of the noise at every x location. Generalized least squares does not assume a diagonal co-variance matrix.",
      "question": "Regression statistics What is the difference between Ordinary least square and generalized least squares"
    },
    {
      "answer": "First, make a list of the possible outcomes for each flip. Next, count the number of the possible outcomes for each flip. There are two outcomes for each flip of a coin: heads or tails. Then, multiply the number of outcomes by the number of flips.",
      "question": "How do you find the outcome of a sample space"
    },
    {
      "answer": "To say it informally, the filter size is how many neighbor information you can see when processing the current layer. When the filter size is 3*3, that means each neuron can see its left, right, upper, down, upper left, upper right, lower left, lower right, as a total of 8 neighbor information.",
      "question": "What is filter size in CNN"
    },
    {
      "answer": "Use In Exponential Distributions It is defined as the reciprocal of the scale parameter and indicates how quickly decay of the exponential function occurs. When the rate parameter = 1, there is no decay. Values close to 1 (e.g. 0.8 or 0.9) indicate a slow decay.",
      "question": "What is exponential distribution rate"
    },
    {
      "answer": "A rank-2 tensor gets two rotation matrices. This pattern generalizes to tensors of arbitrary rank. In a particular coordinate system, a rank-2 tensor can be expressed as a square matrix, but one should not marry the concepts of tensors and matrices, just like one should think of vectors simply as arrays of numbers.",
      "question": "What is a rank 2 tensor"
    },
    {
      "answer": "Intelligence Quotient",
      "question": "What does IQ mean"
    },
    {
      "answer": "1 Answer. In word2vec, you train to find word vectors and then run similarity queries between words. In doc2vec, you tag your text and you also get tag vectors.  If two authors generally use the same words then their vector will be closer.",
      "question": "What is the difference between word2vec and Doc2Vec"
    },
    {
      "answer": "A \"single-layer\" perceptron can't implement XOR. The reason is because the classes in XOR are not linearly separable. You cannot draw a straight line to separate the points (0,0),(1,1) from the points (0,1),(1,0). Led to invention of multi-layer networks.",
      "question": "Why can t Perceptron learn XOR"
    },
    {
      "answer": "To convert a frequency distribution to a probability distribution, divide area of the bar or interval of x by the total area of all the Bars. A simpler formula is: , N is the total Frequency and w is the interval of x.",
      "question": "How do you construct a probability distribution from a frequency distribution"
    },
    {
      "answer": "A lazy learner delays abstracting from the data until it is asked to make a prediction while an eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset.",
      "question": "What is the main difference between lazy and eager learning methods in nearest neighbor clustering"
    },
    {
      "answer": "1950s",
      "question": "When did artificial intelligence start"
    },
    {
      "answer": "Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters).",
      "question": "How does Lasso regression work"
    },
    {
      "answer": "One tool they can use to do so is a decision tree. Decision trees are flowchart graphs or diagrams that help explore all of the decision alternatives and their possible outcomes.  Decision tree software helps businesses draw out their trees, assigns value and probabilities to each branch and analyzes each option.",
      "question": "How do decision trees help business decision making"
    },
    {
      "answer": "Negentropy is reverse entropy. It means things becoming more in order. By 'order' is meant organisation, structure and function: the opposite of randomness or chaos. One example of negentropy is a star system such as the Solar System.  The opposite of entropy is negentropy.",
      "question": "What is the opposite of entropy"
    },
    {
      "answer": "You can convert measures from discrete to continuous or from continuous to discrete. Click the field and choose Discrete or Continuous. The field is green when it is continuous, and blue when it is discrete. For measures in the Data pane, right-click the field and choose Convert to Discrete or Convert to Continuous.",
      "question": "How do you convert discrete data to continuous data"
    },
    {
      "answer": "A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis. If the points in a residual plot are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a nonlinear model is more appropriate.",
      "question": "How do you explain a residual plot"
    },
    {
      "answer": "If you are working on a classification problem, the best score is 100% accuracy. If you are working on a regression problem, the best score is 0.0 error. These scores are an impossible to achieve upper/lower bound. All predictive modeling problems have prediction error.",
      "question": "What is a good accuracy for machine learning model"
    },
    {
      "answer": "You can regularize your network by introducing a dropout layer soon after the convolution layer. So a typical layer of Conv->Relu becomes Conv->Dropout->Relu. You may play around with the architecture rather than simply use pre-defined ones like VGG or AlexNet.",
      "question": "How is regularization implemented in the VGGNet 16 network"
    },
    {
      "answer": "Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.",
      "question": "What is a logistic regression used for"
    },
    {
      "answer": "On-policy methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, off-policy methods evaluate or improve a policy different from that used to generate the data.",
      "question": "What is on policy and off policy"
    },
    {
      "answer": "The converse of Theorem 1 is the following: Given vector field F = Pi + Qj on D with C1 coefficients, if Py = Qx, then F is the gradient of some function.",
      "question": "How do you tell if a vector field is a gradient field"
    },
    {
      "answer": "Equality of result- making certain that people achieve the same result. An example is making sure that all students get the same grade no matter the race. Equality of opportunity- giving people an equal chance to succeed.",
      "question": "What is the difference between equality of opportunity and equality of results quizlet"
    },
    {
      "answer": "FDR is a very simple concept. It is the number of false discoveries in an experiment divided by total number of discoveries in that experiment.  (You calculate one P-value for each sample or test in your experiment.)",
      "question": "How is FDR calculated"
    },
    {
      "answer": "The first postulate of statistical mechanics \ufffd This postulate is often called the principle of equal a priori probabilities. It says that if the microstates have the same energy, volume, and number of particles, then they occur with equal frequency in the ensemble.",
      "question": "What is equal a priori probability"
    },
    {
      "answer": "The first thing you need to do is learn a programming language. Though there are a lot of languages that you can start with, Python is what many prefer to start with because its libraries are better suited to Machine Learning. Here are some good resources for Python: CodeAcademy.",
      "question": "Where do I start with artificial intelligence"
    },
    {
      "answer": "Since most natural phenomena are complex and have many factors, the same logic as above applies and distribution of measures of such phenomena tend to have most values near the mean (normal distibution has a desirable property of mean and mode being the same - i.e. the mean is the same as the most frequent value).",
      "question": "Why does the normal distribution show up so often in nature"
    },
    {
      "answer": "Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.",
      "question": "How do you organize data for machine learning"
    },
    {
      "answer": "One way to par- allelize neural network training is to use a technique called Network Parallel Training (NPT). In this approach the neu- rons of the ANN are divided across machines in the cluster, so that each machine holds a portion of the neural network.",
      "question": "How do you parallelize neural network training"
    },
    {
      "answer": "SummaryWeighted Mean: A mean where some values contribute more than others.When the weights add to 1: just multiply each weight by the matching value and sum it all up.Otherwise, multiply each weight w by its matching value x, sum that all up, and divide by the sum of weights: Weighted Mean = \u03a3wx\u03a3w.",
      "question": "How do you work out the weighted mean"
    },
    {
      "answer": "In the statistical theory of design of experiments, randomization involves randomly allocating the experimental units across the treatment groups.  Randomization reduces bias by equalising other factors that have not been explicitly accounted for in the experimental design (according to the law of large numbers).",
      "question": "What is randomization experiment"
    },
    {
      "answer": "An interpolated string is a string literal that might contain interpolation expressions. When an interpolated string is resolved to a result string, items with interpolation expressions are replaced by the string representations of the expression results.",
      "question": "What does string interpolation mean"
    },
    {
      "answer": "The correlation coefficient is a statistical measure of the strength of the relationship between the relative movements of two variables. The values range between -1.0 and 1.0. A calculated number greater than 1.0 or less than -1.0 means that there was an error in the correlation measurement.",
      "question": "What is a correlation coefficient in simple words"
    },
    {
      "answer": "The work efficiency formula is efficiency = output / input, and you can multiply the result by 100 to get work efficiency as a percentage. This is used across different methods of measuring energy and work, whether it's energy production or machine efficiency.",
      "question": "How do we calculate efficiency"
    },
    {
      "answer": "The 95% confidence interval (CI) is a range of values calculated from our data, that most likely, includes the true value of what we're estimating about the population.",
      "question": "What is confidence interval in machine learning"
    },
    {
      "answer": "Linear Regression Is Limited to Linear Relationships By its nature, linear regression only looks at linear relationships between dependent and independent variables. That is, it assumes there is a straight-line relationship between them. Sometimes this is incorrect.",
      "question": "What is the common problem with linear regression"
    },
    {
      "answer": "SYNONYMS FOR outlier 2 nonconformist, maverick; original, eccentric, bohemian; dissident, dissenter, iconoclast, heretic; outsider.",
      "question": "What is another word for outlier"
    },
    {
      "answer": "The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image.",
      "question": "What is hog computer vision"
    },
    {
      "answer": "To get a p-value we compare our observed test- statistic to the randomization distribution of test- statistics obtained by assuming the null is true. The p-value will be the proportion of test- statistics in the randomization distribution that are as or more extreme than the observed test- statistic.",
      "question": "How do you find the p value for a randomization test"
    },
    {
      "answer": "5 Techniques to Prevent Overfitting in Neural NetworksSimplifying The Model. The first step when dealing with overfitting is to decrease the complexity of the model.  Early Stopping. Early stopping is a form of regularization while training a model with an iterative method, such as gradient descent.  Use Data Augmentation.  Use Regularization.  Use Dropouts.",
      "question": "What steps can we take to prevent Overfitting in a neural network"
    },
    {
      "answer": "The questionable cause\u2014also known as causal fallacy, false cause, or non causa pro causa (\"non-cause for cause\" in Latin)\u2014is a category of informal fallacies in which a cause is incorrectly identified. For example: \"Every time I go to sleep, the sun goes down.",
      "question": "What is an example of a false cause fallacy"
    },
    {
      "answer": "So year is a discretized measure of a continuous interval variable, so quantitative.",
      "question": "Is year a quantitative variable"
    },
    {
      "answer": "Usually a pattern recognition system uses training samples from known categories to form a decision rule for unknown patterns.  Clustering methods simply try to group similar patterns into clusters whose members are more similar to each other (according to some distance measure) than to members of other clusters.",
      "question": "What is clustering in pattern recognition"
    },
    {
      "answer": "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).  Stemming is also a part of queries and Internet search engines.",
      "question": "What is stemming in NLP"
    },
    {
      "answer": "S-Curves are used to visualize the progress of a project over time. They plot either cumulative work, based on person-hours, or costs over time. The name is derived from the fact that the data usually takes on an S-shape, with slower progress at the beginning and end of a project.",
      "question": "What is S curve used for"
    },
    {
      "answer": "The Cox proportional-hazards model (Cox, 1972) is essentially a regression model commonly used statistical in medical research for investigating the association between the survival time of patients and one or more predictor variables.",
      "question": "What is Cox regression survival analysis"
    },
    {
      "answer": "Qualitative Differences The population standard deviation is a parameter, which is a fixed value calculated from every individual in the population. A sample standard deviation is a statistic. This means that it is calculated from only some of the individuals in a population.",
      "question": "Is population standard deviation the same as standard deviation"
    },
    {
      "answer": "In statistics, bivariate data is data on each of two variables, where each value of one of the variables is paired with a value of the other variable.  For example, bivariate data on a scatter plot could be used to study the relationship between stride length and length of legs.",
      "question": "What is bivariate variable"
    },
    {
      "answer": "The correlation structure between the dependent variables provides additional information to the model which gives MANOVA the following enhanced capabilities: Greater statistical power: When the dependent variables are correlated, MANOVA can identify effects that are smaller than those that regular ANOVA can find.",
      "question": "Why use a Manova instead of Anova"
    },
    {
      "answer": "Regression attempts to establish how X causes Y to change and the results of the analysis will change if X and Y are swapped. With correlation, the X and Y variables are interchangeable.  Correlation is a single statistic, whereas regression produces an entire equation.",
      "question": "What is the univariate correlation matrix Is it different from the Pearson correlation analysis"
    },
    {
      "answer": "A variable xj is said to be endogenous within the causal model M if its value is determined or influenced by one or more of the independent variables X (excluding itself). A purely endogenous variable is a factor that is entirely determined by the states of other variables in the system.",
      "question": "How do you identify endogenous variables"
    },
    {
      "answer": "We propose that especially in the context of introducing automated decision aids to explicitly reduce human error, people become primed to use decision aids in biased ways. Rather than necessarily leading to fewer errors, automated decision aids may simply lead to di!erent kinds or classes of errors.",
      "question": "Does automation bias decision making"
    },
    {
      "answer": "Ridge regression has two main benefits. First, adding a penalty term reduces overfitting. Second, the penalty term guarantees that we can find a solution. I think the second part is easier to explain.",
      "question": "What are the benefits of using ridge regression over ordinary linear regression"
    },
    {
      "answer": "A recurrent neural network is shown one input each timestep and predicts one output. Conceptually, BPTT works by unrolling all input timesteps. Each timestep has one input timestep, one copy of the network, and one output. Errors are then calculated and accumulated for each timestep.",
      "question": "How does backpropagation work in RNN"
    },
    {
      "answer": "Word embeddings are widely used nowadays in Distributional Semantics and for a variety of tasks in NLP. Embeddings can be evaluated using ex- trinsic evaluation methods, i.e. the trained em- beddings are evaluated on a specific task such as part-of-speech tagging or named-entity recogni- tion (Schnabel et al., 2015).",
      "question": "How are word Embeddings usually evaluated"
    },
    {
      "answer": "A negative binomial distribution is concerned with the number of trials X that must occur until we have r successes. The number r is a whole number that we choose before we start performing our trials. The random variable X is still discrete. However, now the random variable can take on values of X = r, r+1, r+2,",
      "question": "How do you know if a binomial distribution is negative"
    },
    {
      "answer": "Put simply, batch processing is the process by which a computer completes batches of jobs, often simultaneously, in non-stop, sequential order. It's also a command that ensures large jobs are computed in small parts for efficiency during the debugging process.",
      "question": "What is the meaning of batch processing"
    },
    {
      "answer": "Convolution has applications that include probability, statistics, computer vision, natural language processing, image and signal processing, engineering, and differential equations.",
      "question": "What are the applications of convolution"
    },
    {
      "answer": "For example, medical diagnosis, image processing, prediction, classification, learning association, regression etc. The intelligent systems built on machine learning algorithms have the capability to learn from past experience or historical data.",
      "question": "What is machine learning examples"
    },
    {
      "answer": "Verify that the partial derivative Fxy is correct by calculating its equivalent, Fyx, taking the derivatives in the opposite order (d/dy first, then d/dx). In the above example, the derivative d/dy of the function f(x,y) = 3x^2*y - 2xy is 3x^2 - 2x.",
      "question": "How do you find the partial derivative of fxy"
    },
    {
      "answer": "We can reduce the size of a Tensorflow Model using the below mentioned methods: Freezing: Convert the variables stored in a checkpoint file of the SavedModel into constants stored directly in the model graph. This reduces the overall size of the model.",
      "question": "How do I reduce the size of a TensorFlow model"
    },
    {
      "answer": "In information theory, the information content, self-information, surprisal, or Shannon information is a basic quantity derived from the probability of a particular event occurring from a random variable.  The Shannon information can be interpreted as quantifying the level of \"surprise\" of a particular outcome.",
      "question": "What does information content mean"
    },
    {
      "answer": "AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.",
      "question": "What is a B testing and how does it work"
    },
    {
      "answer": "An odds ratio is a measure of association between the presence or absence of two properties.  The value of the odds ratio tells you how much more likely someone under 25 might be to make a claim, for example, and the associated confidence interval indicates the degree of uncertainty associated with that ratio.",
      "question": "What is odds ratio and confidence interval"
    },
    {
      "answer": "Deep Neural Networks (DNN) have greater capabilities for image pattern recognition and are widely used in Computer Vision algorithms. And, Convolutional Neural Network (CNN, or ConvNet) is a class of DNN which is most commonly applied to analyzing visual imagery.",
      "question": "Why convolutional neural networks are preferred for computer vision applications"
    },
    {
      "answer": "In statistics, a Poisson distribution is a statistical distribution that shows how many times an event is likely to occur within a specified period of time. It is used for independent events which occur at a constant rate within a given interval of time.",
      "question": "What is the Poisson distribution used for"
    },
    {
      "answer": "Quota sampling means to take a very tailored sample that's in proportion to some characteristic or trait of a population.  For example, if your population consists of 45% female and 55% male, your sample should reflect those percentages.",
      "question": "What is quota sampling and example"
    },
    {
      "answer": "In general, K-means is a heuristic algorithm that partitions a data set into K clusters by minimizing the sum of squared distance in each cluster.  In this paper, the simulation of basic k-means algorithm is done, which is implemented using Euclidian distance metric.",
      "question": "What is the distance metric used in the standard implementation of K means to calculate the cluster assignments"
    },
    {
      "answer": "Divide the total by the number of members of the cluster. In the example above, 283 divided by four is 70.75, and 213 divided by four is 53.25, so the centroid of the cluster is (70.75, 53.25).",
      "question": "How do you find the centroid in statistics"
    },
    {
      "answer": "The Binomial Theorem: Formulas. The Binomial Theorem is a quick way (okay, it's a less slow way) of expanding (or multiplying out) a binomial expression that has been raised to some (generally inconveniently large) power. For instance, the expression (3x \u2013 2)10 would be very painful to multiply out by hand.",
      "question": "How does the binomial theorem work"
    },
    {
      "answer": "There are several approaches to avoiding overfitting in building decision trees.Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set.Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree.",
      "question": "How do you solve overfitting in decision tree"
    },
    {
      "answer": "n_estimators : This is the number of trees you want to build before taking the maximum voting or averages of predictions. Higher number of trees give you better performance but makes your code slower.",
      "question": "What is N_estimators in random forest"
    },
    {
      "answer": "The item response theory (IRT), also known as the latent response theory refers to a family of mathematical models that attempt to explain the relationship between latent traits (unobservable characteristic or attribute) and their manifestations (i.e. observed outcomes, responses or performance).",
      "question": "What is IRT model"
    },
    {
      "answer": "The hazard function is not a density or a probability. However, we can think of it as the probability of failure in an infinitesimally small time period between y and y + \u2202y given that the subject has survived up till time y.",
      "question": "Is the hazard function a probability"
    },
    {
      "answer": "A rule-based system (e.g., production system, expert system) uses rules as the knowledge representation. These rules are coded into the system in the form of if-then-else statements.  So, let's regard rule-based systems as the simplest form of AI.",
      "question": "How does rule based AI model work"
    },
    {
      "answer": "0:002:44Suggested clip \u00b7 118 secondsGeometric Distribution: Mean - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the mean of a geometric distribution"
    },
    {
      "answer": "Augmented reality holds the promise of creating direct, automatic, and actionable links between the physical world and electronic information. It provides a simple and immediate user interface to an electronically enhanced physical world.",
      "question": "What is the scope of augmented reality"
    },
    {
      "answer": "Alternate-form reliability is the consistency of test results between two different \u2013 but equivalent \u2013 forms of a test. Alternate-form reliability is used when it is necessary to have two forms of the same tests.  \u2013 Alternative-form reliability is needed whenever two test forms are being used to measure the same thing.",
      "question": "What is alternate form of reliability"
    },
    {
      "answer": "Recall quantifies the number of positive class predictions made out of all positive examples in the dataset. F-Measure provides a single score that balances both the concerns of precision and recall in one number.",
      "question": "What is the recall score for the machine learning model"
    },
    {
      "answer": "While precision refers to the percentage of your results which are relevant, recall refers to the percentage of total relevant results correctly classified by your algorithm. Unfortunately, it is not possible to maximize both these metrics at the same time, as one comes at the cost of another.",
      "question": "How do you interpret precision and recall"
    },
    {
      "answer": "According to Bezdek (1994), Computational Intelligence is a subset of Artificial Intelligence. There are two types of machine intelligence: the artificial one based on hard computing techniques and the computational one based on soft computing methods, which enable adaptation to many situations.",
      "question": "What is the difference between computational intelligence and artificial intelligence"
    },
    {
      "answer": "The accuracy is a measure of the degree of closeness of a measured or calculated value to its actual value. The percent error is the ratio of the error to the actual value multiplied by 100. The precision of a measurement is a measure of the reproducibility of a set of measurements.  A systematic error is human error.",
      "question": "Does percent error measure accuracy or precision explain"
    },
    {
      "answer": "Predictive modeling is a form of artificial intelligence that uses data mining and probability to forecast or estimate more granular, specific outcomes. For example, predictive modeling could help identify customers who are likely to purchase our new One AI software over the next 90 days.",
      "question": "Is predictive modeling AI"
    },
    {
      "answer": "Computer vision, however, is more than machine learning applied. It involves tasks as 3D scene modeling, multi-view camera geometry, structure-from-motion, stereo correspondence, point cloud processing, motion estimation and more, where machine learning is not a key element.",
      "question": "Is computer vision part of machine learning"
    },
    {
      "answer": "A false positive is an outcome where the model incorrectly predicts the positive class. And a false negative is an outcome where the model incorrectly predicts the negative class. In the following sections, we'll look at how to evaluate classification models using metrics derived from these four outcomes.",
      "question": "What is false negative in a classification table"
    },
    {
      "answer": "Use Regression to Analyze a Wide Variety of Relationships Include continuous and categorical variables. Use polynomial terms to model curvature. Assess interaction terms to determine whether the effect of one independent variable depends on the value of another variable.",
      "question": "When should regression analysis be performed"
    },
    {
      "answer": "The sample mean is a consistent estimator for the population mean. A consistent estimate has insignificant errors (variations) as sample sizes grow larger.  In other words, the more data you collect, a consistent estimator will be close to the real population parameter you're trying to measure.",
      "question": "Why is the definition of a consistent estimator the way it is"
    },
    {
      "answer": "A Correlation of 0 means that there is no linear relationship between the two variables. We already know that if two random variables are independent, the Covariance is 0. We can see that if we plug in 0 for the Covariance to the equation for Correlation, we will get a 0 for the Correlation.",
      "question": "What does a covariance of 0 mean"
    },
    {
      "answer": "At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional to the square of the \u03b2 values, while the L1 norm is proportional the absolute value of the values in \u03b2.",
      "question": "What is the difference between l1 and l2 norms"
    },
    {
      "answer": "The Rabin-Karp algorithm makes use of hash functions and the rolling hash technique. A hash function is essentially a function that maps one thing to a value. In particular, hashing can map data of arbitrary size to a value of fixed size.",
      "question": "Which technique is used in Rabin Karp algorithm"
    },
    {
      "answer": "\u201cCandidate Sampling\u201d training methods involve constructing a training task in which for each. training example. , we only need to evaluate. for a small set of candidate classes.",
      "question": "What is candidate sampling in machine learning"
    },
    {
      "answer": "Static final variables 2) The variable MY_VAR is public which means any class can use it. It is a static variable so you won't need any object of class in order to access it. It's final so the value of this variable can never be changed in the current or in any class.",
      "question": "Can we change the value of static variable"
    },
    {
      "answer": "The Poisson distribution is used to model the number of events occurring within a given time interval. \u03bb is the shape parameter which indicates the average number of events in the given time interval. The following is the plot of the Poisson probability density function for four values of \u03bb.",
      "question": "What is the parameter of the Poisson distribution"
    },
    {
      "answer": "Use the hypergeometric distribution with populations that are so small that the outcome of a trial has a large effect on the probability that the next outcome is an event or non-event. For example, in a population of 10 people, 7 people have O+ blood.",
      "question": "When would you use a hypergeometric distribution"
    },
    {
      "answer": "A training dataset is a dataset of examples used during the learning process and is used to fit the parameters (e.g., weights) of, for example, a classifier.",
      "question": "What is training set in machine learning"
    },
    {
      "answer": "Just as correlation measures the extent of a linear relationship between two variables, autocorrelation measures the linear relationship between lagged values of a time series. There are several autocorrelation coefficients, corresponding to each panel in the lag plot.",
      "question": "What is the autocorrelation for a time series"
    },
    {
      "answer": "Association Rule Mining, as the name suggests, association rules are simple If/Then statements that help discover relationships between seemingly independent relational databases or other data repositories. Most machine learning algorithms work with numeric datasets and hence tend to be mathematical.",
      "question": "What are association rules in data mining"
    },
    {
      "answer": "Generally, you're evidently not an AI, if we are talking about the computers and algorithms and codes. You cannot prove this topic unless you definitely define what is artificial intelligence and what you are. Generally, you're evidently not an AI, if we are talking about the computers and algorithms and codes.",
      "question": "How do you prove that you are not an artificial intelligence"
    },
    {
      "answer": "As far as i read in the manual, stream length is simply the number (n) of the sequent number of the random number sample. The bitstream is likely a number of sample size.",
      "question": "What does Stream length in NIST randomness test mean"
    },
    {
      "answer": "The Central limit Theorem states that when sample size tends to infinity, the sample mean will be normally distributed. The Law of Large Number states that when sample size tends to infinity, the sample mean equals to population mean.",
      "question": "What is the difference between law of large numbers and central limit theorem"
    },
    {
      "answer": "TL; DR: The naive Bayes classifier is an approximation to the Bayes classifier, in which we assume that the features are conditionally independent given the class instead of modeling their full conditional distribution given the class. A Bayes classifier is best interpreted as a decision rule.",
      "question": "What is the difference between the Naive Bayes Classifier and the Bayes classifier"
    },
    {
      "answer": "A histogram is drawn like a bar chart, but often has bars of unequal width. It is the area of the bar that tells us the frequency in a histogram, not its height. Instead of plotting frequency on the y-axis, we plot the frequency density. To calculate this, you divide the frequency of a group by the width of it.",
      "question": "What does density mean in histogram"
    },
    {
      "answer": "Plot a symbol at the median and draw a box between the lower and upper quartiles. Calculate the interquartile range (the difference between the upper and lower quartile) and call it IQ. The line from the lower quartile to the minimum is now drawn from the lower quartile to the smallest point that is greater than L1.",
      "question": "How do you calculate a box plot"
    },
    {
      "answer": "We shall look at 5 popular clustering algorithms that every data scientist should be aware of.K-means Clustering Algorithm.  Mean-Shift Clustering Algorithm.  DBSCAN \u2013 Density-Based Spatial Clustering of Applications with Noise.  EM using GMM \u2013 Expectation-Maximization (EM) Clustering using Gaussian Mixture Models (GMM)More items\u2022",
      "question": "What are the most popular clustering algorithms"
    },
    {
      "answer": "According to this link LDA is a generative classifier. Also, the motto of LDA is to model a discriminant function to classify.",
      "question": "Is linear discriminant analysis a generative model"
    },
    {
      "answer": "Supervised Learning deals with two main tasks Regression and Classification. Unsupervised Learning deals with clustering and associative rule mining problems. Whereas Reinforcement Learning deals with exploitation or exploration, Markov's decision processes, Policy Learning, Deep Learning and value learning.",
      "question": "What is the difference between supervised unsupervised and reinforcement learning"
    },
    {
      "answer": "A finite population is a collection of objects or individuals that are objects of research that occupy a certain area. It clear boundaries that distinguish these population groups from other populations.",
      "question": "What is a finite population in statistics"
    },
    {
      "answer": "Overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data.  Specifically, underfitting occurs if the model or algorithm shows low variance but high bias. Underfitting is often a result of an excessively simple model.",
      "question": "What is Overfitting and Underfitting in learning"
    },
    {
      "answer": "A simple random sample is a subset of a statistical population in which each member of the subset has an equal probability of being chosen. A simple random sample is meant to be an unbiased representation of a group.",
      "question": "What is a simple random sample in statistics"
    },
    {
      "answer": "This variance represents what the regression line cannot predict. It's equal to the sum of squared deviations of data points around predicted points, divided by N minus two. N is the number of data points in the scatterplot. Regression variance is based on differences between predicted data points and the mean of Y.",
      "question": "How do you find the variance of a regression model"
    },
    {
      "answer": "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data.",
      "question": "What is data science and where it is used"
    },
    {
      "answer": "Common examples of algorithms with coefficients that can be optimized using gradient descent are Linear Regression and Logistic Regression.",
      "question": "What algorithms use gradient descent"
    },
    {
      "answer": "It is acknowledged that current tests do not measure IQ to a level of accuracy of one point: there is a margin of error, usually considered to be about five points either side of the obtained IQ, which should be taken into account when making a diagnosis of ID (The American Association on Mental Retardation 2002).",
      "question": "What is the margin of error of IQ tests"
    },
    {
      "answer": "Appropriate Problems for Decision Tree LearningInstances are represented by attribute-value pairs.  The target function has discrete output values.  Disjunctive descriptions may be required.  The training data may contain errors.  The training data may contain missing attribute values.",
      "question": "What are the issues in decision tree learning"
    },
    {
      "answer": "Testing approach: The answers lie in the data set. In order to test a machine learning algorithm, tester defines three different datasets viz. Training dataset, validation dataset and a test dataset (a subset of training dataset).",
      "question": "How do you test machine learning models"
    },
    {
      "answer": "The standard deviation formula may look confusing, but it will make sense after we break it down.  Step 1: Find the mean.Step 2: For each data point, find the square of its distance to the mean.Step 3: Sum the values from Step 2.Step 4: Divide by the number of data points.Step 5: Take the square root.",
      "question": "How do you find the standard deviation between two sets of data"
    },
    {
      "answer": "One way that we calculate the predicted probability of such binary events (drop out or not drop out) is using logistic regression. Unlike regular regression, the outcome calculates the predicted probability of mutually exclusive event occuring based on multiple external factors.",
      "question": "What is predicted probability in logistic regression"
    },
    {
      "answer": "Cluster cohesion: Measures the closeness of the objects within the same cluster. A \u201clower within-cluster\u201d variation indicates good compactness or good clustering. The separation method is implied to measure how well a cluster is separated from other clusters.",
      "question": "Which measures the goodness of a cluster"
    },
    {
      "answer": "Artificial intelligence can dramatically improve the efficiencies of our workplaces and can augment the work humans can do. When AI takes over repetitive or dangerous tasks, it frees up the human workforce to do work they are better equipped for\u2014tasks that involve creativity and empathy among others.",
      "question": "What is the impact of AI"
    },
    {
      "answer": "An Expert system shell is a software development environment. It contains the basic components of expert systems. A shell is associated with a prescribed method for building applications by configuring and instantiating these components.",
      "question": "What is Expert System Shell in artificial intelligence"
    },
    {
      "answer": "In probability theory and statistics, a collection of random variables is independent and identically distributed if each random variable has the same probability distribution as the others and all are mutually independent. This property is usually abbreviated as i.i.d. or iid or IID.",
      "question": "What does independently and identically distributed mean"
    },
    {
      "answer": "In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge.",
      "question": "What is convolutional filter"
    },
    {
      "answer": "The value of a dependent variable depends on an independent variable, so a variable cannot be both independent and dependent at the same time. It must be either the cause or the effect, not both!",
      "question": "Can the same variable be used as the dependent and Independent variable after a time lapse"
    },
    {
      "answer": "As mentioned in the context of the gradient theorem, a vector field F is conservative if and only if it has a potential function f with F=\u2207f. Therefore, if you are given a potential function f or if you can find one, and that potential function is defined everywhere, then there is nothing more to do.",
      "question": "How do you know if F is conservative vector field"
    },
    {
      "answer": "How to Calculate VarianceFind the mean of the data set. Add all data values and divide by the sample size n.Find the squared difference from the mean for each data value. Subtract the mean from each data value and square the result.Find the sum of all the squared differences.  Calculate the variance.",
      "question": "How do I calculate the variance"
    },
    {
      "answer": "To recap, Logistic regression is a binary classification method. It can be modelled as a function that can take in any number of inputs and constrain the output to be between 0 and 1. This means, we can think of Logistic Regression as a one-layer neural network.",
      "question": "Is logistic regression a neural network"
    },
    {
      "answer": "Multiple regression formula is used in the analysis of relationship between dependent and multiple independent variables and formula is represented by the equation Y is equal to a plus bX1 plus cX2 plus dX3 plus E where Y is dependent variable, X1, X2, X3 are independent variables, a is intercept, b, c, d are slopes,",
      "question": "What is the formula for multiple regression"
    },
    {
      "answer": "Quantum fields are matter.  The simplest \u201cpractical\u201d quantum field theory is quantum electromagnetism. In it, two fields exist: the electromagnetic field and the \u201celectron field\u201d. These two fields continuously interact with each other, energy and momentum are transferred, and excitations are created or destroyed.",
      "question": "What is a field in QFT"
    },
    {
      "answer": "For example, if the distribution of raw scores if normally distributed, so is the distribution of z-scores. The mean of any SND always = 0. The standard deviation of any SND always = 1. Therefore, one standard deviation of the raw score (whatever raw value this is) converts into 1 z-score unit.",
      "question": "Why does az score have a mean of 0 and standard deviation of 1"
    },
    {
      "answer": "In this case, convergence in distribution implies convergence in probability. We can state the following theorem: Theorem If Xn d\u2192 c, where c is a constant, then Xn p\u2192 c. Since Xn d\u2192 c, we conclude that for any \u03f5>0, we have limn\u2192\u221eFXn(c\u2212\u03f5)=0,limn\u2192\u221eFXn(c+\u03f52)=1.",
      "question": "How do you prove probability convergence"
    },
    {
      "answer": "Visualping is the newest, easiest and most convenient tool to monitor websites changes. Our Chrome app allows to monitor pages with only 1 click directly from the page you wish to monitor. Users receive an email when changes are detected but can also set up a Slack integration for team notifications.",
      "question": "What is Visualping"
    },
    {
      "answer": "Word vectors are simply vectors of numbers that represent the meaning of a word.  In simpler terms, a word vector is a row of real-valued numbers (as opposed to dummy numbers) where each point captures a dimension of the word's meaning and where semantically similar words have similar vectors.",
      "question": "What is vector representation of words"
    },
    {
      "answer": "When the two options are available, lemmatization will always be a better option than stemming.  But if you can apply a lemmatizer, it will always give you a better result, because lemmatizers rely on correct language data (dictionaries) to identify a word with its lemma.",
      "question": "Is it advisable to choose lemmatization over stemming in NLP"
    },
    {
      "answer": "If a confusion matrix threshold is at disposal, instead, we recommend the usage of the Matthews correlation coefficient over F1 score, and accuracy.  We decided to focus on accuracy and F1 score because they are the most common metrics used for binary classification in machine learning.",
      "question": "Is the Matthews correlation coefficient widely used in binary classifier quality assessment"
    },
    {
      "answer": "Calculate bias by finding the difference between an estimate and the actual value. To find the bias of a method, perform many estimates, and add up the errors in each estimate compared to the real value. Dividing by the number of estimates gives the bias of the method.",
      "question": "How do you calculate bias"
    },
    {
      "answer": "The probability of committing a type II error is equal to one minus the power of the test, also known as beta. The power of the test could be increased by increasing the sample size, which decreases the risk of committing a type II error.",
      "question": "What is the probability of a Type II error"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.",
      "question": "What is bootstrap in machine learning"
    },
    {
      "answer": "To take your first steps down the artificial intelligence career path, hiring managers will likely require that you hold at least a bachelor's degree in mathematics and basic computer technology. However, for the most part, bachelor's degrees will only get you into entry-level positions.",
      "question": "What degree do I need to work with artificial intelligence"
    },
    {
      "answer": "Experimental probability is the actual result of an experiment, which may be different from the theoretical probability. Example: you conduct an experiment where you flip a coin 100 times. The theoretical probability is 50% heads, 50% tails. The actual outcome of your experiment may be 47 heads, 53 tails.",
      "question": "What are some examples of experimental probability"
    },
    {
      "answer": "Train Generative Adversarial Network (GAN)Load Training Data.Define Generator Network.Define Discriminator Network.Define Model Gradients, Loss Functions and Scores.Specify Training Options.Train Model.Generate New Images.More items",
      "question": "How do you train a generative adversarial network"
    },
    {
      "answer": "Gradient descent is an optimization algorithm that finds the optimal weights (a,b) that reduces prediction error. Step 2: Calculate the gradient i.e. change in SSE when the weights (a & b) are changed by a very small value from their original randomly initialized value.",
      "question": "What are the steps for using a gradient descent algorithm"
    },
    {
      "answer": "The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.",
      "question": "What is attention mechanism in NLP"
    },
    {
      "answer": "A Bernouilli distribution is a discrete probability distribution for a Bernouilli trial \u2014 a random experiment that has only two outcomes (usually called a \u201cSuccess\u201d or a \u201cFailure\u201d).  The expected value for a random variable, X, from a Bernoulli distribution is: E[X] = p. For example, if p = . 04, then E[X] = 0.4.",
      "question": "What is the mean of a Bernoulli distribution"
    },
    {
      "answer": "In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function ( ) that expresses how the shape of one is modified by the other. The term convolution refers to both the result function and to the process of computing it.",
      "question": "What is the convolution of two functions"
    },
    {
      "answer": "Tensorflow is the most used library used in development of Deep Learning models.  Keras, on the other end, is a high-level API that is built on top of TensorFlow. It is extremely user-friendly and comparatively easier than TensorFlow.",
      "question": "What is the difference between keras and tensorflow"
    },
    {
      "answer": "Gaussian random variables and Gaussian random vectors (vectors whose components are jointly Gaussian, as defined later) play a central role in detection and estimation.  Jointly Gaussian random variables are completely described by their means and covariances, which is part of the simplicity of working with them.",
      "question": "What is a Gaussian vector"
    },
    {
      "answer": "Order Statistics Definition Order statistics are sample values placed in ascending order. The study of order statistics deals with the applications of these ordered values and their functions. Let's say you had three weights: X1 = 22 kg, X2 = 44 kg, and X3 = 12 kg.",
      "question": "What is order statistics and why do we use it"
    },
    {
      "answer": "1:085:00Suggested clip \u00b7 93 secondsInterpreting Hazard Ratios - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you interpret hazard ratios"
    },
    {
      "answer": "An estimator of a given parameter is said to be unbiased if its expected value is equal to the true value of the parameter. In other words, an estimator is unbiased if it produces parameter estimates that are on average correct.",
      "question": "How do you show an estimator is unbiased"
    },
    {
      "answer": "Returns the inverse, or critical value, of the cumulative standard normal distribution. This function computes the critical value so that the cumulative distribution is greater than or equal to a pre-specified value.",
      "question": "What is the inverse of the standard normal cumulative distribution"
    },
    {
      "answer": "This term is used in statistics in its ordinary sense, but most frequently occurs in connection with samples from different populations which may or may not be identical. If the populations are identical they are said to be homogeneous, and by extension, the sample data are also said to be homogeneous.",
      "question": "What is a homogeneous group in statistics"
    },
    {
      "answer": "Bayesian analysis, a method of statistical inference (named for English mathematician Thomas Bayes) that allows one to combine prior information about a population parameter with evidence from information contained in a sample to guide the statistical inference process.",
      "question": "What is Bayesian analysis used for"
    },
    {
      "answer": "Ordinal YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do regression on Likert scale data"
    },
    {
      "answer": "A spectrum is simply a chart or a graph that shows the intensity of light being emitted over a range of energies.  Spectra can be produced for any energy of light, from low-energy radio waves to very high-energy gamma rays. Each spectrum holds a wide variety of information.",
      "question": "What is a spectral"
    },
    {
      "answer": "Alternatively, general dimensionality reduction techniques are used such as:Independent component analysis.Isomap.Kernel PCA.Latent semantic analysis.Partial least squares.Principal component analysis.Multifactor dimensionality reduction.Nonlinear dimensionality reduction.More items",
      "question": "What are the different feature extraction techniques"
    },
    {
      "answer": "In the context of CNN, a filter is a set of learnable weights which are learned using the backpropagation algorithm. You can think of each filter as storing a single template/pattern.  Filter is referred to as a set of shared weights on the input.",
      "question": "What is a filter in a CNN"
    },
    {
      "answer": "Pros: It is easy and fast to predict class of test data set. It also perform well in multi class prediction. When assumption of independence holds, a Naive Bayes classifier performs better compare to other models like logistic regression and you need less training data.",
      "question": "Can naive Bayes be used for multiclass classification"
    },
    {
      "answer": "Filters typically are applied to data in the data processing stage or the preprocessing stage. Filters enhance the clarity of the signal that's used for machine learning.",
      "question": "What is filtering in machine learning"
    },
    {
      "answer": "The difference between the hypergeometric and the binomial distributions.  For the binomial distribution, the probability is the same for every trial. For the hypergeometric distribution, each trial changes the probability for each subsequent trial because there is no replacement.",
      "question": "What is the difference between binomial and hypergeometric distribution"
    },
    {
      "answer": "Inverse transform sampling is a method for generating random numbers from any probability distribution by using its inverse cumulative distribution F\u22121(x). Recall that the cumulative distribution for a random variable X is FX(x)=P(X\u2264x).",
      "question": "How do you do inverse transformation"
    },
    {
      "answer": "From Wikipedia, the free encyclopedia. In mathematical optimization, constrained optimization (in some contexts called constraint optimization) is the process of optimizing an objective function with respect to some variables in the presence of constraints on those variables.",
      "question": "What is meant by constrained optimization"
    },
    {
      "answer": "You calculate the mean, say it's 10. You calculate the standard deviation: it's 12. That means that any number from 10 to 22 is within one standard deviation away from the mean. Now if your data are symmetric (say normal), any number from -2 to 10 is also within a standard deviation from the mean.",
      "question": "How do you find how many standard deviations away from the mean"
    },
    {
      "answer": "A moving average is a technique that calculates the overall trend in a data set. In operations management, the data set is sales volume from historical data of the company. This technique is very useful for forecasting short-term trends. It is simply the average of a select set of time periods.",
      "question": "What is moving average method of forecasting"
    },
    {
      "answer": "The normal distribution can be used as an approximation to the binomial distribution, under certain circumstances, namely: If X ~ B(n, p) and if n is large and/or p is close to \u00bd, then X is approximately N(np, npq)",
      "question": "Can the binomial distribution be approximated by a normal distribution"
    },
    {
      "answer": "Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors.",
      "question": "What are tensors used for"
    },
    {
      "answer": "1. A pattern recognition technique that is used to categorize a huge number of data into different classes.",
      "question": "What is feature classification"
    },
    {
      "answer": "One assumption of Poisson Models is that the mean and the variance are equal, but this assumption is often violated. This can be dealt with by using a dispersion parameter if the difference is small or a negative binomial regression model if the difference is large.",
      "question": "What can we do if our modelling assumption are violated in Poisson Regression Modelling"
    },
    {
      "answer": "There are a number of equations that can generate an S curve, the most common is logistics function with the equation (in Excel notation): S(x) = (1/(1+exp(-kx))^a is the simple form of the equation, where the minimum value is 0 and the maximum value is 1, k and a both >0 and control the shape.",
      "question": "How do you calculate S curve"
    },
    {
      "answer": "Now, every textbook on linear algebra gives the following definition of a linear operator: an operator T: V\u2014> W between two vector spaces V and W over the same field ! F is said to be linear if it satisfies the conditions of additivity, viz. T(u + v)=T(u)+T(v)",
      "question": "What makes an operator linear"
    },
    {
      "answer": "The binomial is a type of distribution that has two possible outcomes (the prefix \u201cbi\u201d means two, or twice). For example, a coin toss has only two possible outcomes: heads or tails and taking a test could have two possible outcomes: pass or fail. A Binomial Distribution shows either (S)uccess or (F)ailure.",
      "question": "What is binomial distribution with example"
    },
    {
      "answer": "Detection accuracy as discussed in this section refers to the agreement between the emotional states detected by different sets of emotion measurement equipment (e.g., multiple modalities), one of which is being used as the \u201cgrounded truth\u201d (i.e., standard) for determining the correct emotion.",
      "question": "What is detection accuracy"
    },
    {
      "answer": "The basic strength of inductive reasoning is its use in predicting what might happen in the future or in establishing the possibility of what you will encounter. The main weakness of inductive reasoning is that it is incomplete, and you may reach false conclusions even with accurate observations.",
      "question": "What are the advantages and disadvantages of using inductive reasoning"
    },
    {
      "answer": "Discriminant analysis is statistical technique used to classify observations into non-overlapping groups, based on scores on one or more quantitative predictor variables. For example, a doctor could perform a discriminant analysis to identify patients at high or low risk for stroke.",
      "question": "What is discriminant analysis example"
    },
    {
      "answer": "Now, for the differences\u2026 The Mann-Whitney U is a very simple test that makes almost no assumptions about any underlying distribution.  Because the K-S test can assume interval or higher level data, it is a more powerful statistical test than the MW-U, assuming that assumption is valid.",
      "question": "What are the differences between the Kolmogorov Smirnov test and the Mann Whitney U test"
    },
    {
      "answer": "(mathematics) A symbol representing a product over a set of terms.",
      "question": "What does \u220f mean"
    },
    {
      "answer": "The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems.",
      "question": "Is artificial intelligence a technology"
    },
    {
      "answer": "A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process).",
      "question": "What is a null hypothesis in laymans terms"
    },
    {
      "answer": "In a 2-by-2 table with cells a, b, c, and d (see figure), the odds ratio is odds of the event in the exposure group (a/b) divided by the odds of the event in the control or non-exposure group (c/d). Thus the odds ratio is (a/b) / (c/d) which simplifies to ad/bc.",
      "question": "How do you calculate odds ratio"
    },
    {
      "answer": "Action words, or action verbs, simply express an action. The action is something the subject of the sentence or clause is doing and includes sleeping, sitting, and napping-so even though there is no movement, there is still an action.",
      "question": "What are the action words"
    },
    {
      "answer": "Decision trees use multiple algorithms to decide to split a node in two or more sub-nodes.  Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes. The algorithm selection is also based on type of target variables.",
      "question": "How does a tree decide where to split"
    },
    {
      "answer": "There are two possible objectives in a discriminant analysis: finding a predictive equation for classifying new individuals or interpreting the predictive equation to better understand the relationships that may exist among the variables. In many ways, discriminant analysis parallels multiple regression analysis.",
      "question": "What are the objectives of discriminant analysis"
    },
    {
      "answer": "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the",
      "question": "Is Random Forest ensemble learning"
    },
    {
      "answer": "Here are some important considerations while choosing an algorithm.Size of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.",
      "question": "How do I find the best machine learning algorithm"
    },
    {
      "answer": "For a good regression model, you want to include the variables that you are specifically testing along with other variables that affect the response in order to avoid biased results.  Cross-validation determines how well your model generalizes to other data sets by partitioning your data.",
      "question": "What makes a good regression model"
    },
    {
      "answer": "Artificial Intelligence enhances the speed, precision and effectiveness of human efforts. In financial institutions, AI techniques can be used to identify which transactions are likely to be fraudulent, adopt fast and accurate credit scoring, as well as automate manually intense data management tasks.",
      "question": "Why do we use AI"
    },
    {
      "answer": "If you have outliers, the best way is to use a clustering algorithm that can handle them. For example DBSCAN clustering is robust against outliers when you choose minpts large enough. Don't use k-means: the squared error approach is sensitive to outliers. But there are variants such as k-means-- for handling outliers.",
      "question": "How do clusters deal with outliers"
    },
    {
      "answer": "T = (X \u2013 \u03bc) / [ \u03c3/\u221a(n) ]. This makes the equation identical to the one for the z-score; the only difference is you're looking up the result in the T table, not the Z-table. For sample sizes over 30, you'll get the same result.",
      "question": "What is the similarity between a Z score and a T score"
    },
    {
      "answer": "The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X \u2264 x, Y \u2264 y),where X and Y are continuous or discrete. For example, the probability.  P(x1 \u2264 X \u2264 x2,y1 \u2264 Y \u2264 y2) = F(x2,y2) \u2212 F(x2,y1) \u2212 F(x1,y2) + F(x1,y1).",
      "question": "How do you find the joint pdf of two random variables"
    },
    {
      "answer": "Machine Learning is a set of algorithms that parse data and learns from the parsed data and use those learnings to discover patterns of interest. Neural Network or Artificial Neural Network is one set of algorithms used in machine learning for modeling the data using graphs of Neurons.",
      "question": "What is the difference between machine learning and neural networks"
    },
    {
      "answer": "Use imputation for the missing values. When the response is missing, we can use a predictive model to predict the missing response, then create a new fully-observed dataset containing the predictions instead of the missing values, and finally re-estimate the predictive model in this expanded dataset.",
      "question": "How can I deal with missing values in a predictive model"
    },
    {
      "answer": "Particle filtering uses a set of particles (also called samples) to represent the posterior distribution of some stochastic process given noisy and/or partial observations.  The state-space model can be nonlinear and the initial state and noise distributions can take any form required.",
      "question": "What is filtered in particle filtering"
    },
    {
      "answer": "Pooled data occur when we have a \u201ctime series of cross sections,\u201d but the observations in each cross section do not necessarily refer to the same unit. Panel data refers to samples of the same cross-sectional units observed at multiple points in time.",
      "question": "How is panel data different from cross sectional data"
    },
    {
      "answer": "Alpha sets the standard for how extreme the data must be before we can reject the null hypothesis. The p-value indicates how extreme the data are.  If the p-value is greater than alpha (p > . 05), then we fail to reject the null hypothesis, and we say that the result is statistically nonsignificant (n.s.).",
      "question": "Are alpha level and P value the same"
    },
    {
      "answer": "Compressed sensing addresses the issue of high scan time by enabling faster acquisition by measuring fewer Fourier coefficients. This produces a high-quality image with relatively lower scan time.",
      "question": "How does compressed sensing work"
    },
    {
      "answer": "Post-pruning (or just pruning) is the most common way of simplifying trees. Here, nodes and subtrees are replaced with leaves to improve complexity. Pruning can not only significantly reduce the size but also improve the classification accuracy of unseen objects.",
      "question": "What is pruning in decision trees Why is it important"
    },
    {
      "answer": "The latent space is simply a representation of compressed data in which similar data points are closer together in space. Latent space is useful for learning data features and for finding simpler representations of data for analysis.",
      "question": "What are latent spaces in representation learning"
    },
    {
      "answer": "Log-loss measures the accuracy of a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class. Log-loss measures the accuracy of a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class.",
      "question": "Why do we use log loss"
    },
    {
      "answer": "The Bayesian approach permits the use of objective data or subjective opinion in specifying a prior distribution. With the Bayesian approach, different individuals might specify different prior distributions.  Bayesian methods have been used extensively in statistical decision theory (see statistics: Decision analysis).",
      "question": "How is Bayesian analysis used"
    },
    {
      "answer": "Most recent answer One way to compare the two different size data sets is to divide the large set into an N number of equal size sets. The comparison can be based on absolute sum of of difference. THis will measure how many sets from the Nset are in close match with the single 4 sample set.",
      "question": "How do you compare data with different sample sizes"
    },
    {
      "answer": "14:3826:41Suggested clip \u00b7 115 secondsCanonical correlation using SPSS - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you interpret canonical correlation in SPSS"
    },
    {
      "answer": "Conclusion. Cross-Validation is a very powerful tool. It helps us better use our data, and it gives us much more information about our algorithm performance. In complex machine learning models, it's sometimes easy not pay enough attention and use the same data in different steps of the pipeline.",
      "question": "Why is validation important in machine learning"
    },
    {
      "answer": "Learning statistics means learning to communicate using the statistical language, solving statistical problems, drawing conclusions, and supporting conclusions by explaining the reasoning behind them. There are often different ways to solve a statistical problem.",
      "question": "What is the goal of learning statistics"
    },
    {
      "answer": "Mean Absolute Error (MAE) The MAE is a simple way to measure error magnitude. It consists on the average of the absolute differences between the predictions and the observed values. Th measure goes from 0 to infinite, being 0 the best value you can get.",
      "question": "What is the error measure used in reinforcement learning"
    },
    {
      "answer": "One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.",
      "question": "How do you address a vanishing gradient problem"
    },
    {
      "answer": "In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard error.",
      "question": "Is RMSE the same as standard error"
    },
    {
      "answer": "The marks for a group of students before (pre) and after (post) a teaching intervention are recorded below: Marks are continuous (scale) data. Continuous data are often summarised by giving their average and standard deviation (SD), and the paired t-test is used to compare the means of the two samples of related data.",
      "question": "What statistical test to use to compare pre and post tests"
    },
    {
      "answer": "A feature detector is also referred to as a kernel or a filter. Intuitively, the matrix representation of the input image is multiplied element-wise with the feature detector to produce a feature map, also known as a convolved feature or an activation map.",
      "question": "What is feature detector in CNN"
    },
    {
      "answer": "A sequence of random variables X1, X2, X3, \u22ef converges in probability to a random variable X, shown by Xn p\u2192 X, if limn\u2192\u221eP(|Xn\u2212X|\u2265\u03f5)=0, for all \u03f5>0.",
      "question": "How do you show convergence in probability"
    },
    {
      "answer": "The Kalman filter uses a system's dynamic model (e.g., physical laws of motion), known control inputs to that system, and multiple sequential measurements (such as from sensors) to form an estimate of the system's varying quantities (its state) that is better than the estimate obtained by using only one measurement",
      "question": "How does Kalman filter work"
    },
    {
      "answer": "Fourier Methods in Signal Processing The Fourier transform and discrete-time Fourier transform are mathematical analysis tools and cannot be evaluated exactly in a computer. The Fourier transform is used to analyze problems involving continuous-time signals or mixtures of continuous- and discrete-time signals.",
      "question": "What is the use of Fourier transform in signal processing"
    },
    {
      "answer": "The classic machine learning procedure follows the scientific paradigm of induction and deduction. In the inductive step we learn the model from raw data (so called training set), and in the deductive step the model is applied to predict the behaviour of new data.",
      "question": "Is machine learning inductive or deductive"
    },
    {
      "answer": "Syllabus:Basic Data Structures: Arrays, Strings, Stacks, Queues.Asymptotic analysis (Big-O notation)Basic math operations (addition, subtraction, multiplication, division, exponentiation)Sqrt(n) primality testing.Euclid's GCD Algorithm.Basic Recursion.Greedy Algorithms.Basic Dynamic Programming.More items",
      "question": "What are the topics to be covered in algorithms and data structures"
    },
    {
      "answer": "The power of a hypothesis test is affected by three factors. Sample size (n). Other things being equal, the greater the sample size, the greater the power of the test.  The greater the difference between the \"true\" value of a parameter and the value specified in the null hypothesis, the greater the power of the test.",
      "question": "How does power affect sample size"
    },
    {
      "answer": "Abstract. Network representation learning aims to embed the vertexes in a network into low-dimensional dense representations, in which similar vertices in the network should have \u201cclose\u201d representations (usually measured by cosine similarity or Euclidean distance of their representations).",
      "question": "What are network representations"
    },
    {
      "answer": "Ridge regression does not really select variables in the many predictors situation.  Both ridge regression and the LASSO can outperform OLS regression in some predictive situations \u2013 exploiting the tradeoff between variance and bias in the mean square error.",
      "question": "Can ridge regression be used for variable selection"
    },
    {
      "answer": "The difference is a matter of design. In the test of independence, observational units are collected at random from a population and two categorical variables are observed for each unit.  In the goodness-of-fit test there is only one observed variable.",
      "question": "What is the difference between the chi square goodness of fit and independence tests"
    },
    {
      "answer": "Population variance (\u03c32) tells us how data points in a specific population are spread out.  Here N is the population size and the xi are data points. \u03bc is the population mean.",
      "question": "What is N in population variance"
    },
    {
      "answer": "Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data.",
      "question": "How do you ensemble a model"
    },
    {
      "answer": "Each feature, or column, represents a measurable piece of data that can be used for analysis: Name, Age, Sex, Fare, and so on. Features are also sometimes referred to as \u201cvariables\u201d or \u201cattributes.\u201d Depending on what you're trying to analyze, the features you include in your dataset can vary widely.",
      "question": "What are feature variables"
    },
    {
      "answer": "The function fX(x) gives us the probability density at point x. It is the limit of the probability of the interval (x,x+\u0394] divided by the length of the interval as the length of the interval goes to 0. Remember that P(x<X\u2264x+\u0394)=FX(x+\u0394)\u2212FX(x).",
      "question": "How do you find probability density"
    },
    {
      "answer": "This list of requirements prioritization techniques provides an overview of common techniques that can be used in prioritizing requirements.Ranking.  Numerical Assignment (Grouping)  MoScoW Technique.  Bubble Sort Technique.  Hundred Dollar Method.  Analytic Hierarchy Process (AHP)  Five Whys.",
      "question": "What techniques can be used to prioritize changes"
    },
    {
      "answer": "5 years",
      "question": "How long until AI is smarter than humans"
    },
    {
      "answer": "Given two random variables X and Y, the correlation is scale and location invariant in the sense that cor(X,Y)=cor(XT,YT), if XT=a+bX, and YT=c+dY, and b and d have the same sign (either both positive or both negative).",
      "question": "Are correlation scales invariant"
    },
    {
      "answer": "Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.",
      "question": "What is dimensionality reduction in machine learning"
    },
    {
      "answer": "In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.",
      "question": "What is fixed effect in panel data regression"
    },
    {
      "answer": "The Generative Adversarial Network, or GAN, is an architecture that makes effective use of large, unlabeled datasets to train an image generator model via an image discriminator model. The discriminator model can be used as a starting point for developing a classifier model in some cases.",
      "question": "Can Gan be used for classification"
    },
    {
      "answer": "Generally, a machine learning pipeline describes or models your ML process: writing code, releasing it to production, performing data extractions, creating training models, and tuning the algorithm. An ML pipeline should be a continuous process as a team works on their ML platform.",
      "question": "What is pipeline in machine learning"
    },
    {
      "answer": "Stochastic (from from Greek \u03c3\u03c4\u03cc\u03c7\u03bf\u03c2 (st\u00f3khos) 'aim, guess'.) is any randomly determined process. In mathematics the terms stochastic process and random process are interchangeable.",
      "question": "What is meant by stochastic"
    },
    {
      "answer": "The sum of a square matrix and its conjugate transpose. is Hermitian. The difference of a square matrix and its conjugate transpose. is skew-Hermitian.",
      "question": "What are Hermitian and skew Hermitian matrix"
    },
    {
      "answer": "A random variable is a variable whose value is unknown or a function that assigns values to each of an experiment's outcomes.  Random variables are often used in econometric or regression analysis to determine statistical relationships among one another.",
      "question": "What exactly is a random variable"
    },
    {
      "answer": "Dimensionality reduction refers to techniques for reducing the number of input variables in training data. When dealing with high dimensional data, it is often useful to reduce the dimensionality by projecting the data to a lower dimensional subspace which captures the \u201cessence\u201d of the data.",
      "question": "What is dimensionality reduction and explain why it is required"
    },
    {
      "answer": "When the standard deviation or the mean change, something unusual is happening. To detect such changes, for each upcoming point \u201cp\u201d we create of window from \u201cp\u201d to \u201cp-100\u2033. Then, we calculate the standard deviation and mean of this window. If it changes too much, an anomaly has been detected.",
      "question": "How would you find an anomaly in a distribution"
    },
    {
      "answer": "Pure serial correlation: occurs when the error terms are correlated and the regression equation is correctly specified. The most commonly assumed form of serial correlation is first-order serial correlation, in which one error term is a function of a previous error term.",
      "question": "What is pure serial correlation"
    },
    {
      "answer": "Correlated vs. A correlated subquery can be thought of as a filter on the table that it refers to, as if the subquery were evaluated on each row of the table in the outer query. An uncorrelated subquery has no such external column references.",
      "question": "What is the difference between correlated and uncorrelated subquery"
    },
    {
      "answer": "By Jim Frost 45 Comments. Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.",
      "question": "What is homoscedasticity in linear regression"
    },
    {
      "answer": "2:266:36Suggested clip \u00b7 120 secondsAn Easy Rule to Setting Up the Null & Alternate Hypotheses YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you create a null and alternative hypothesis"
    },
    {
      "answer": "To convert a logit ( glm output) to probability, follow these 3 steps:Take glm output coefficient (logit)compute e-function on the logit using exp() \u201cde-logarithimize\u201d (you'll get odds then)convert odds to probability using this formula prob = odds / (1 + odds) .",
      "question": "How do you convert logit to probability"
    },
    {
      "answer": "The distribution function , also called the cumulative distribution function (CDF) or cumulative frequency function, describes the probability that a variate takes on a value less than or equal to a number . The distribution function is sometimes also denoted. (Evans et al. 2000, p.",
      "question": "What does distribution function mean"
    },
    {
      "answer": "(There are two red fours in a deck of 52, the 4 of hearts and the 4 of diamonds). Conditional probability: p(A|B) is the probability of event A occurring, given that event B occurs.  Joint probability is the probability of two events occurring simultaneously. The probability of event A and event B occurring together.",
      "question": "Can you point out the difference between joint probability and conditional probability"
    },
    {
      "answer": "The normal distribution is a continuous probability distribution that is symmetrical on both sides of the mean, so the right side of the center is a mirror image of the left side.  The normal distribution is often called the bell curve because the graph of its probability density looks like a bell.",
      "question": "What is a normal curve in statistics"
    },
    {
      "answer": "Characteristics of a Poisson Distribution The probability that an event occurs in a given time, distance, area, or volume is the same. Each event is independent of all other events. For example, the number of people who arrive in the first hour is independent of the number who arrive in any other hour.",
      "question": "What are the properties of Poisson distribution"
    },
    {
      "answer": "One of the stages that SIFT uses is to create a pyramid of scales of the image.  The feature detector then works by finding features that have a peak response not only in the image space, but in scale space too. This means that it finds the scale of the image which the feature will produce the highest response.",
      "question": "Why are SIFT descriptors scale invariant"
    },
    {
      "answer": "The difference between multi-task learning and meta-learning is: in multitask learning, your goal would be to try to solve all of the training tasks shown in the gray box (on the left picture); whereas in meta-learning your goal is to use these training tasks in order to solve new tasks with a small amount of data, so",
      "question": "What is the difference between meta learning and multi task learning"
    },
    {
      "answer": "Events A and B are independent if the equation P(A\u2229B) = P(A) \u00b7 P(B) holds true. You can use the equation to check if events are independent; multiply the probabilities of the two events together to see if they equal the probability of them both happening together.",
      "question": "How do you know if an event is independent"
    },
    {
      "answer": "Running the ProcedureClick Transform > Recode into Different Variables.Double-click on variable CommuteTime to move it to the Input Variable -> Output Variable box. In the Output Variable area, give the new variable the name CommuteLength, then click Change.Click the Old and New Values button.  Click OK.",
      "question": "How do you convert continuous variables to categorical in SPSS"
    },
    {
      "answer": "The Q-Q plot, or quantile-quantile plot, is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential.  If both sets of quantiles came from the same distribution, we should see the points forming a line that's roughly straight.",
      "question": "What does a QQ plot help you to test"
    },
    {
      "answer": "Big Data is defined as data that is huge in size. Bigdata is a term used to describe a collection of data that is huge in size and yet growing exponentially with time. Examples of Big Data generation includes stock exchanges, social media sites, jet engines, etc.",
      "question": "What is big data with examples"
    },
    {
      "answer": "The median is a measure of center (location) of a list of numbers.  This will be the median. If there are an even number on the list then average the n/2 and the (N + 2)/2 numbers. In general, the median is at position (n + 1)/2. If this position is a whole number then you have the median at that position in the list.",
      "question": "What is N 2 in median"
    },
    {
      "answer": "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. (",
      "question": "What are gradient boosting models"
    },
    {
      "answer": "The outcome variable is also called the response or dependent variable, and the risk factors and confounders are called the predictors, or explanatory or independent variables. In regression analysis, the dependent variable is denoted \"Y\" and the independent variables are denoted by \"X\".",
      "question": "Is the explanatory variable The dependent variable"
    },
    {
      "answer": "When p is greater than 0.5, the distribution will be positively skewed (the peak will be on the left side of the distribution, with relatively fewer observations on the right).",
      "question": "When binomial distribution is positively skewed"
    },
    {
      "answer": "As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.",
      "question": "How do you calculate a standard score"
    },
    {
      "answer": "RL is an increasingly popular technique for organizations that deal regularly with large complex problem spaces. Because RL models learn by a continuous process of receiving rewards and punishments on every action taken, it is able to train systems to respond to unforeseen environments .",
      "question": "Why is reinforcement important in learning"
    },
    {
      "answer": "There are four basic sequence learning problems: sequence prediction, sequence generation, sequence recognition, and sequential decision making. These \u201cproblems\u201d show how sequences are formulated.",
      "question": "Which of the following is part of the sequence learning problem"
    },
    {
      "answer": "Two events are said to be mutually exclusive when the two events cannot occur at the same time. For instance, when you throw a coin the event that a head appears and the event that a tail appears are mutually exclusive because they cannot occur at the same time, it's either a head appears or a tail appears.",
      "question": "How do you determine if an event is mutually exclusive"
    },
    {
      "answer": "The Spearman correlation is the same as the Pearson correlation, but it is used on data from an ordinal scale. Which situation would be appropriate for obtaining a phi-coefficient with a Pearson test?",
      "question": "What is the difference between the Pearson correlation and the Spearman correlation quizlet"
    },
    {
      "answer": "Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Intuitively, underfitting occurs when the model or the algorithm does not fit the data well enough. Specifically, underfitting occurs if the model or algorithm shows low variance but high bias.",
      "question": "What is underfitting in machine learning"
    },
    {
      "answer": "7 steps to improve your data structure and algorithm skillsStep 1: Understand Depth vs. Breadth.Step 2: Start the Depth-First Approach\u2014make a list of core questions.Step 3: Master each data structure.Step 4: Spaced Repetition.Step 5: Isolate techniques that are reused. Isolate actual code blocks.Step 6: Now, it's time for Breadth.Step 7: Practice on paper.",
      "question": "How do you get really good at algorithms"
    },
    {
      "answer": "The receptive field size of a unit can be increased in a number of ways. One option is to stack more layers to make the network deeper, which increases the receptive field size linearly by theory, as each extra layer increases the receptive field size by the kernel size.",
      "question": "How do you increase receptive fields"
    },
    {
      "answer": "A Neural Network has got non linear activation layers which is what gives the Neural Network a non linear element. The function for relating the input and the output is decided by the neural network and the amount of training it gets.  Similarly, a complex enough neural network can learn any function.",
      "question": "Which gives nonlinearity to a neural network"
    },
    {
      "answer": "Center: The center is not affected by sample size. The mean of the sample means is always approximately the same as the population mean \u00b5 = 3,500. Spread: The spread is smaller for larger samples, so the standard deviation of the sample means decreases as sample size increases.",
      "question": "What effect does the sample size have on the standard deviation of all possible sample means"
    },
    {
      "answer": "After a performing a test, scientists can: Reject the null hypothesis (meaning there is a definite, consequential relationship between the two phenomena), or. Fail to reject the null hypothesis (meaning the test has not identified a consequential relationship between the two phenomena)",
      "question": "What is the meaning of a null hypothesis being rejected"
    },
    {
      "answer": "The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(\u2217). Both functions will take any number and rescale it to fall between 0 and 1.",
      "question": "What is the difference between probit and logistic regression"
    },
    {
      "answer": "There is a layer of input nodes, a layer of output nodes, and one or more intermediate layers. The interior layers are sometimes called \u201chidden layers\u201d because they are not directly observable from the systems inputs and outputs.",
      "question": "Why is it called hidden layer"
    },
    {
      "answer": "Model calibration is the process of adjustment of the model parameters and forcing within the margins of the uncertainties (in model parameters and / or model forcing) to obtain a model representation of the processes of interest that satisfies pre-agreed criteria (Goodness-of-Fit or Cost Function).",
      "question": "What is model calibration"
    },
    {
      "answer": "A GLM consists of three components: A random component, A systematic component, and. A link function.",
      "question": "What are the three components of a generalized linear model"
    },
    {
      "answer": "A p-value that is calculated using an approximation to the true distribution is called an asymptotic p-value.  A p-value calculated using the true distribution is called an exact p-value. For large sample sizes, the exact and asymptotic p-values are very similar.",
      "question": "What is an exact p value"
    },
    {
      "answer": "Empirical Relationship between Mean, Median and Mode In case of a moderately skewed distribution, the difference between mean and mode is almost equal to three times the difference between the mean and median. Thus, the empirical mean median mode relation is given as: Mean \u2013 Mode = 3 (Mean \u2013 Median)",
      "question": "What is the relation between mean mode median"
    },
    {
      "answer": "Correlation is a statistical measure that expresses the extent to which two variables are linearly related (meaning they change together at a constant rate).",
      "question": "What correlation means statistics"
    },
    {
      "answer": "Definition: Stratified sampling is a type of sampling method in which the total population is divided into smaller groups or strata to complete the sampling process. The strata is formed based on some common characteristics in the population data.",
      "question": "What is a stratified sampling method"
    },
    {
      "answer": "ReLU is important because it does not saturate; the gradient is always high (equal to 1) if the neuron activates. As long as it is not a dead neuron, successive updates are fairly effective. ReLU is also very quick to evaluate.",
      "question": "Why do we use ReLU in CNN"
    },
    {
      "answer": "The confidence interval (CI) is a range of values that's likely to include a population value with a certain degree of confidence. It is often expressed a % whereby a population means lies between an upper and lower interval.",
      "question": "What is a confidence interval in statistics"
    },
    {
      "answer": "As a rule of thumb, I'd say that SVMs are great for relatively small data sets with fewer outliers.  Also, deep learning algorithms require much more experience: Setting up a neural network using deep learning algorithms is much more tedious than using an off-the-shelf classifiers such as random forests and SVMs.",
      "question": "Is SVM deep learning"
    },
    {
      "answer": "To minimize or avoid performance bias, investigators can consider cluster stratification of patients, in which all patients having an operation by one surgeon or at one hospital are placed into the same study group, as opposed to placing individual patients into groups.",
      "question": "How can we prevent investigators bias"
    },
    {
      "answer": "Regression is a statistical method used in finance, investing, and other disciplines that attempts to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables).",
      "question": "What does regression explain"
    },
    {
      "answer": "Events A and B are independent if: knowing whether A occured does not change the probability of B. Mathematically, can say in tw. Page 1. Events A and B are independent if: knowing whether A occured does not change the probability of B.",
      "question": "What does it mean for two events A and B to be statistically independent"
    },
    {
      "answer": "An independent random variable is a random variable that doesn't have an effect on the other random variables in your experiment. In other words, it doesn't affect the probability of another event happening.",
      "question": "What does it mean for random variables to be independent"
    },
    {
      "answer": "For example, a collaborative filtering recommendation system for television tastes could make predictions about which television show a user should like given a partial list of that user's tastes (likes or dislikes). Note that these predictions are specific to the user, but use information gleaned from many users.",
      "question": "What are some examples of user information required by recommendation engines that use collaborative filtering"
    },
    {
      "answer": "Selection Sort in CExample of Selection Sort.Algorithm for Selection Sort:Step 1 \u2212 Set min to the first location.Step 2 \u2212 Search the minimum element in the array.Step 3 \u2013 swap the first location with the minimum value in the array.Step 4 \u2013 assign the second element as min.Step 5 \u2212 Repeat the process until we get a sorted array.More items\u2022",
      "question": "How do you write an algorithm for a selection sort"
    },
    {
      "answer": "Activation functions cannot be linear because neural networks with a linear activation function are effective only one layer deep, regardless of how complex their architecture is.  Therefore, nonlinear functions must be continuous and differentiable between this range.",
      "question": "Why activation functions are nonlinear in deep learning"
    },
    {
      "answer": "Precision refers to how close estimates from different samples are to each other. For example, the standard error is a measure of precision. When the standard error is small, estimates from different samples will be close in value; and vice versa.",
      "question": "What is sample precision"
    },
    {
      "answer": "0:3910:15Suggested clip \u00b7 118 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you run a regression with multiple variables"
    },
    {
      "answer": "For the alternative formulation, where X is the number of trials up to and including the first success, the expected value is E(X) = 1/p = 1/0.1 = 10. For example 1 above, with p = 0.6, the mean number of failures before the first success is E(Y) = (1 \u2212 p)/p = (1 \u2212 0.6)/0.6 = 0.67.",
      "question": "What is the expected value of a geometric random variable"
    },
    {
      "answer": "Solve each equation to get a solution to the binomial. For x^2 - 9 = 0, for example, x - 3 = 0 and x + 3 = 0. Solve each equation to get x = 3, -3. If one of the equations is a trinomial, such as x^2 + 2x + 4 = 0, solve it using the quadratic formula, which will result in two solutions (Resource).",
      "question": "How do you solve a binomial equation"
    },
    {
      "answer": "Two classes of digital filters are Finite Impulse Response (FIR) and Infinite Impulse Response (IIR). The term 'Impulse Response' refers to the appearance of the filter in the time domain.  The mathematical difference between the IIR and FIR implementation is that the IIR filter uses some of the filter output as input.",
      "question": "What is FIR and IIR filter"
    },
    {
      "answer": "Discriminant function analysis (DFA) is a statistical procedure that classifies unknown individuals and the probability of their classification into a certain group (such as sex or ancestry group). Discriminant function analysis makes the assumption that the sample is normally distributed for the trait.",
      "question": "What is a discriminant function analysis"
    },
    {
      "answer": "Mentor: Well, if the line is a good fit for the data then the residual plot will be random. However, if the line is a bad fit for the data then the plot of the residuals will have a pattern.",
      "question": "How can you tell if a residual plot is a good fit for the data"
    },
    {
      "answer": "The common application of indicators is the detection of end points of titrations. The colour of an indicator alters when the acidity or the oxidizing strength of the solution, or the concentration of a certain chemical species, reaches a critical range of values.",
      "question": "What is the function of the indicator"
    },
    {
      "answer": "The number of bootstrap samples can be indicated with B (e.g. if you resample 10 times then B = 10). A star next to a statistic, like s* or x\u0304* indicates the statistic was calculated by resampling. A bootstrap statistic is sometimes denoted with a T, where T*b would be the Bth bootstrap sample statistic T.",
      "question": "How does bootstrap determine sample size"
    },
    {
      "answer": "\u201cThe distinction between white label and private label are subtle,\u201d he writes. \u201cThat's why these terms are so easily confused. Private label is a brand sold exclusively in one retailer, for example, Equate (WalMart). White label is a generic product, which is sold to multiple retailers like generic ibuprofen (Advil).\u201d",
      "question": "Whats the difference between private label and white label"
    },
    {
      "answer": "Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters.",
      "question": "What is maximum likelihood hypothesis in machine learning"
    },
    {
      "answer": "Advertisements. Interpolation search is an improved variant of binary search. This search algorithm works on the probing position of the required value. For this algorithm to work properly, the data collection should be in a sorted form and equally distributed.",
      "question": "What is interpolation search in data structure"
    },
    {
      "answer": "The hierarchical cluster analysis follows three basic steps: 1) calculate the distances, 2) link the clusters, and 3) choose a solution by selecting the right number of clusters. First, we have to select the variables upon which we base our clusters.",
      "question": "How do you do a cluster analysis"
    },
    {
      "answer": "Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function.  You start by defining the initial parameter's values and from there gradient descent uses calculus to iteratively adjust the values so they minimize the given cost-function.",
      "question": "How does gradient descent work"
    },
    {
      "answer": "Abnormal BRCA1 and BRCA2 genes are found in 5% to 10% of all breast cancer cases in the United States. A study found that women with an abnormal BRCA1 gene had a worse prognosis than women with an abnormal BRCA2 gene 5 years after diagnosis.",
      "question": "Which is worse brca1 or brca2"
    },
    {
      "answer": "Under the batch processing model, a set of data is collected over time, then fed into an analytics system. In other words, you collect a batch of information, then send it in for processing. Under the streaming model, data is fed into analytics tools piece-by-piece. The processing is usually done in real time.",
      "question": "What is the difference between batch processing and stream processing"
    },
    {
      "answer": "Let A and G be the Arithmetic Means and Geometric Means respectively of two positive numbers a and b. Then, As, a and b are positive numbers, it is obvious that A > G when G = -\u221aab.  This proves that the Arithmetic Mean of two positive numbers can never be less than their Geometric Means.",
      "question": "What is the relation between arithmetic mean and geometric mean"
    },
    {
      "answer": "A dummy variable (aka, an indicator variable) is a numeric variable that represents categorical data, such as gender, race, political affiliation, etc.  For example, suppose we are interested in political affiliation, a categorical variable that might assume three values - Republican, Democrat, or Independent.",
      "question": "What is dummy variable given an example"
    },
    {
      "answer": "In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the",
      "question": "What is probability density function in normal distribution"
    },
    {
      "answer": "The loss given default (LGD) is an important calculation for financial institutions projecting out their expected losses due to borrowers defaulting on loans. The expected loss of a given loan is calculated as the LGD multiplied by both the probability of default and the exposure at default.",
      "question": "What is loss given default formula"
    },
    {
      "answer": "There are numerous applications of integrals. Using technology such as computer software, internet sources, graphing calculators and smartphone apps can make solving integral problems easier. Some applications of integrals are: Displacement, which is the integral of velocity with respect to time.",
      "question": "What are the applications of integral calculus in different fields"
    },
    {
      "answer": "In a dataset a training set is implemented to build up a model, while a test (or validation) set is to validate the model built. Data points in the training set are excluded from the test (validation) set.",
      "question": "What is the difference between training and test dataset"
    },
    {
      "answer": "When your child sits the eleven plus exam, the number of questions answered correctly decides the \"Raw Score\". If there are more than one tests, the score may be the sum of the raw scores.  A standardized test score is calculated by translating the raw score into a completely different scale.",
      "question": "How is 11+ standardized calculated"
    },
    {
      "answer": "Example 1: Draw a box-and-whisker plot for the data set {3, 7, 8, 5, 12, 14, 21, 13, 18}.  The box part represents the interquartile range and represents approximately the middle 50% of all the data. The data is divided into four regions, which each represent approximately 25% of the data.",
      "question": "What is an example of a box plot"
    },
    {
      "answer": "The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count.",
      "question": "How do we find average"
    },
    {
      "answer": "Univariate analysis, looking at single variables, is typically the first procedure one does when examining first time data.  The SPSS tools for looking at single variables include the following procedures: Frequencies, Descriptives and Explore all located under the Analyze menu.",
      "question": "What is univariate analysis in SPSS"
    },
    {
      "answer": "Standardization isn't required for logistic regression. The main goal of standardizing features is to help convergence of the technique used for optimization.  Otherwise, you can run your logistic regression without any standardization treatment on the features.",
      "question": "Does logistic regression require feature scaling"
    },
    {
      "answer": "The law of large numbers is a theorem from probability and statistics that suggests that the average result from repeating an experiment multiple times will better approximate the true or expected underlying result. The law of large numbers explains why casinos always make money in the long run.",
      "question": "Why does the law of large numbers work"
    },
    {
      "answer": "When observed outcome of dependent variable can have multiple possible types then logistic regression will be multinomial.",
      "question": "When the observed outcome of dependent variable can have multiple possible types Then the logistic regression is"
    },
    {
      "answer": "The k-means clustering algorithm attempts to split a given anonymous data set (a set containing no information as to class identity) into a fixed number (k) of clusters.  The resulting classifier is used to classify (using k = 1) the data and thereby produce an initial randomized set of clusters.",
      "question": "How K means algorithm works"
    },
    {
      "answer": "This means when calculating the output of a node, the inputs are multiplied by weights, and a bias value is added to the result. The bias value allows the activation function to be shifted to the left or right, to better fit the data.  You can think of the bias as a measure of how easy it is to get a node to fire.",
      "question": "What is bias value why it is used"
    },
    {
      "answer": "Linear Regression Analysis consists of more than just fitting a linear line through a cloud of data points. It consists of 3 stages \u2013 (1) analyzing the correlation and directionality of the data, (2) estimating the model, i.e., fitting the line, and (3) evaluating the validity and usefulness of the model.",
      "question": "What are the steps in regression analysis"
    },
    {
      "answer": "There are various ways to modify a study design to actively exclude or control confounding variables (3) including Randomization, Restriction and Matching. In randomization the random assignment of study subjects to exposure categories to breaking any links between exposure and confounders.",
      "question": "How do you control a confounding variable in regression"
    },
    {
      "answer": "Analysis of covariance (ANCOVA) is a general linear model which blends ANOVA and regression.  Mathematically, ANCOVA decomposes the variance in the DV into variance explained by the CV(s), variance explained by the categorical IV, and residual variance.",
      "question": "What does analysis of covariance mean"
    },
    {
      "answer": "Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items\u2022",
      "question": "How do you choose the best regression model in R"
    },
    {
      "answer": "There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.",
      "question": "How do you find K for K means"
    },
    {
      "answer": "The normal curve is called Mesokurtic curve. If the curve of a distribution is peaked than a normal or mesokurtic curve then it is referred to as a Leptokurtic curve. If a curve is less peaked than a normal curve, it is called as a Platykurtic curve. That's why kurtosis of normal distribution equal to three.",
      "question": "Why kurtosis of normal distribution is 3"
    },
    {
      "answer": "Spatial mining is the extraction of knowledge/spatial relationship and interesting measures that are not explicitly stored in spatial database. Temporal mining is the extraction of knowledge about occurrence of an event whether they follow Cyclic , Random ,Seasonal variations etc.",
      "question": "What is temporal and spatial data mining"
    },
    {
      "answer": "In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.",
      "question": "What does a parametric test mean"
    },
    {
      "answer": "Ordinary least squares assumes things like equal variance of the noise at every x location. Generalized least squares does not assume a diagonal co-variance matrix.",
      "question": "What is the difference between ordinary least squares and generalized least squares"
    },
    {
      "answer": "Agents can be grouped into four classes based on their degree of perceived intelligence and capability :Simple Reflex Agents.Model-Based Reflex Agents.Goal-Based Agents.Utility-Based Agents.Learning Agent.",
      "question": "What are the different types of agents in artificial intelligence"
    },
    {
      "answer": "The T distribution is similar to the normal distribution, just with fatter tails. Both assume a normally distributed population. T distributions have higher kurtosis than normal distributions. The probability of getting values very far from the mean is larger with a T distribution than a normal distribution.",
      "question": "How is the t distribution related to the normal distribution"
    },
    {
      "answer": "In AI, the study on perception is mostly focused on the reproduction of human perception, especially on the perception of aural and visual signals. However, this is not necessarily the case since the perception mechanism of a computer system does not have to be identical to that of a human being.",
      "question": "What is the perception of AI"
    },
    {
      "answer": "There are multiple ways to select a good starting point for the learning rate. A naive approach is to try a few different values and see which one gives you the best loss without sacrificing speed of training. We might start with a large value like 0.1, then try exponentially lower values: 0.01, 0.001, etc.",
      "question": "How do you determine learning rate"
    },
    {
      "answer": "Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.",
      "question": "What is Overfitting in deep learning"
    },
    {
      "answer": "The normal distribution is a continuous probability distribution. This has several implications for probability. The total area under the normal curve is equal to 1. The probability that a normal random variable X equals any particular value is 0.",
      "question": "Is normal distribution continuous or discrete"
    },
    {
      "answer": "The general regression tree building methodology allows input variables to be a mixture of continuous and categorical variables. A decision tree is generated when each decision node in the tree contains a test on some input variable's value. The terminal nodes of the tree contain the predicted output variable values.",
      "question": "What is regression tree in machine learning"
    },
    {
      "answer": "Improve your model accuracy by Transfer Learning.Loading data using python libraries.Preprocess of data which includes reshaping, one-hot encoding and splitting.Constructing the model layers of CNN followed by model compiling, model training.Evaluating the model on test data.Finally, predicting the correct and incorrect labels.",
      "question": "How can transfer learning improve accuracy"
    },
    {
      "answer": "Steps for Making decision treeGet list of rows (dataset) which are taken into consideration for making decision tree (recursively at each nodes).Calculate uncertanity of our dataset or Gini impurity or how much our data is mixed up etc.Generate list of all question which needs to be asked at that node.More items\u2022",
      "question": "How do you use the decision tree in machine learning"
    },
    {
      "answer": "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability.  By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",
      "question": "What is the difference between AUC and ROC"
    },
    {
      "answer": "Qualities of a Good Sampling FrameInclude all individuals in the target population.Exclude all individuals not in the target population.Includes accurate information that can be used to contact selected individuals.",
      "question": "How do you determine a sampling frame"
    },
    {
      "answer": "Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.",
      "question": "What is Adam Optimiser"
    },
    {
      "answer": "The joint probability is symmetrical, meaning that P(A and B) is the same as P(B and A). The calculation using the conditional probability is also symmetrical, for example: P(A and B) = P(A given B)",
      "question": "How do you find conditional probability from joint probability"
    },
    {
      "answer": "Generally, a machine learning pipeline describes or models your ML process: writing code, releasing it to production, performing data extractions, creating training models, and tuning the algorithm. An ML pipeline should be a continuous process as a team works on their ML platform.",
      "question": "What is a pipeline in machine learning"
    },
    {
      "answer": "A relative frequency distribution shows the proportion of the total number of observations associated with each value or class of values and is related to a probability distribution, which is extensively used in statistics.",
      "question": "How do you describe the relative frequency distribution"
    },
    {
      "answer": "In ideal conditions, facial recognition systems can have near-perfect accuracy. Verification algorithms used to match subjects to clear reference images (like a passport photo or mugshot) can achieve accuracy scores as high as 99.97% on standard assessments like NIST's Facial Recognition Vendor Test (FRVT).",
      "question": "How good is facial recognition"
    },
    {
      "answer": "Blocks and strata are different. Blocking refers to classifying experimental units into blocks whereas stratification refers to classifying individuals of a population into strata. The samples from the strata in a stratified random sample can be the blocks in an experiment.",
      "question": "In Experimental Design what is the difference between blocking and stratified sampling"
    },
    {
      "answer": "People also want to know what professions will be most in demand.  This is known as a reward function that will allow AI platforms to come to conclusions instead of arriving at a prediction. Reward Functions are used for reinforcement learning models. Reward Function Engineering determines the rewards for actions.",
      "question": "What is reward in reinforcement learning"
    },
    {
      "answer": "For a random variable yt, the unconditional mean is simply the expected value, E ( y t ) . In contrast, the conditional mean of yt is the expected value of yt given a conditioning set of variables, \u03a9t. A conditional mean model specifies a functional form for E ( y t | \u03a9 t ) . .",
      "question": "What is a conditional mean in regression"
    },
    {
      "answer": "Exponential beta value is interpreted with the reference category, where the probability of the dependent variable will increase or decrease. In continuous variables, it is interpreted with one unit increase in the independent variable, corresponding to the increase or decrease of the units of the dependent variable.",
      "question": "What is beta in logistic regression"
    },
    {
      "answer": "The three different ways of feature extraction are horizontal direction, vertical direction and diagonal direction. Recognition rate percentage for vertical, horizontal and diagonal based feature extraction using feed forward back propagation neural network as classification phase are 92.69, 93.68, 97.80 respectively.",
      "question": "What are the feature extraction techniques in image processing"
    },
    {
      "answer": "Means and Variances of Random Variables: The mean of a discrete random variable, X, is its weighted average. Each value of X is weighted by its probability. To find the mean of X, multiply each value of X by its probability, then add all the products. The mean of a random variable X is called the expected value of X.",
      "question": "How do you find the discrete random variable"
    },
    {
      "answer": "Prior probability, in Bayesian statistical inference, is the probability of an event before new data is collected. This is the best rational assessment of the probability of an outcome based on the current knowledge before an experiment is performed.",
      "question": "What is prior probability in statistics"
    },
    {
      "answer": "Answer. A negative path loading is basically the same as a negative regression coefficient. I.e., For a path loading from X to Y it is the predicted increase in Y for a one unit increase on X holding all other variables constant. So a negative coefficient just means that as X increases, Y is predicted to decrease.",
      "question": "What does a negative path coefficient mean"
    },
    {
      "answer": "With supervised learning, you have features and labels. The features are the descriptive attributes, and the label is what you're attempting to predict or forecast.  Thus, for training the machine learning classifier, the features are customer attributes, the label is the premium associated with those attributes.",
      "question": "What is feature and label in machine learning"
    },
    {
      "answer": "Get startedPrepare your TensorBoard logs. (or download a sample from here).Upload the logs. Install the latest version of TensorBoard to use the uploader. $ pip install -U tensorboard.  View your experiment on TensorBoard. dev. Follow the link provided to view your experiment, or share it with others.",
      "question": "How do you share a TensorBoard"
    },
    {
      "answer": "General Properties of Probability Distributions The sum of all probabilities for all possible values must equal 1. Furthermore, the probability for a particular value or range of values must be between 0 and 1. Probability distributions describe the dispersion of the values of a random variable.",
      "question": "What are the two properties of a probability distribution"
    },
    {
      "answer": "Sequential minimal optimization (SMO) is an algorithm for solving the quadratic programming (QP) problem that arises during the training of support-vector machines (SVM).  SMO is widely used for training support vector machines and is implemented by the popular LIBSVM tool.",
      "question": "What is SMO in machine learning"
    },
    {
      "answer": "A logarithmic scale (or log scale) is a way of displaying numerical data over a very wide range of values in a compact way\u2014typically the largest numbers in the data are hundreds or even thousands of times larger than the smallest numbers.",
      "question": "What does a logarithmic scale look like"
    },
    {
      "answer": "Explainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution can be understood by humans.",
      "question": "What is explainable machine learning"
    },
    {
      "answer": "is that maximin is in decision theory and game theory etc, a rule to identify the worst outcome of each possible option to find one's best (maximum payoff) play while minimax is in decision theory, game theory, etc a decision rule used for minimizing the maximum possible loss, or maximizing the minimum gain.",
      "question": "What is the difference between Minimax and Maximin"
    },
    {
      "answer": "The normal distribution, commonly known as the bell curve, occurs throughout statistics. It is actually imprecise to say \"the\" bell curve in this case, as there are an infinite number of these types of curves. Above is a formula that can be used to express any bell curve as a function of x.",
      "question": "What is the equation of a bell curve"
    },
    {
      "answer": "At a bare minimum, collect around 1000 examples. For most \"average\" problems, you should have 10,000 - 100,000 examples. For \u201chard\u201d problems like machine translation, high dimensional data generation, or anything requiring deep learning, you should try to get 100,000 - 1,000,000 examples.",
      "question": "How much data do you need for machine learning"
    },
    {
      "answer": "In a skewed distribution, the upper half and the lower half of the data have a different amount of spread, so no single number such as the standard deviation could describe the spread very well.",
      "question": "How does skew affect standard deviation"
    },
    {
      "answer": "For example, a random variable could be the outcome of the roll of a die or the flip of a coin. A probability distribution is a list of all of the possible outcomes of a random variable along with their corresponding probability values.",
      "question": "What is the difference between random variable and probability distribution"
    },
    {
      "answer": "A quantile defines a particular part of a data set, i.e. a quantile determines how many values in a distribution are above or below a certain limit. Special quantiles are the quartile (quarter), the quintile (fifth) and percentiles (hundredth).",
      "question": "What does a quantile mean"
    },
    {
      "answer": "A loss function is used to optimize a machine learning algorithm. The loss is calculated on training and validation and its interpretation is based on how well the model is doing in these two sets.  An accuracy metric is used to measure the algorithm's performance in an interpretable way.",
      "question": "What is validation Loss and Validation accuracy"
    },
    {
      "answer": "The standard normal or z-distribution assumes that you know the population standard deviation. The t-distribution is based on the sample standard deviation.",
      "question": "How does the t distribution differ from the z distribution"
    },
    {
      "answer": "Sanderson points out in her book Social Psychology, confirmation bias also helps form and re-confirm stereotypes we have about people:3\ufeff \"We also ignore information that disputes our expectations.",
      "question": "What role does confirmation bias play in stereotyping"
    },
    {
      "answer": "Logistic regression can be binomial, ordinal or multinomial. Binomial or binary logistic regression deals with situations in which the observed outcome for a dependent variable can have only two possible types, \"0\" and \"1\" (which may represent, for example, \"dead\" vs. \"alive\" or \"win\" vs. \"loss\").",
      "question": "What are the types of logistic regression"
    },
    {
      "answer": "Mini-Max Algorithm in Artificial Intelligence. Mini-max algorithm is a recursive or backtracking algorithm which is used in decision-making and game theory. It provides an optimal move for the player assuming that opponent is also playing optimally.  This Algorithm computes the minimax decision for the current state.",
      "question": "What is Minimax algorithm in AI"
    },
    {
      "answer": "6:3017:57Suggested clip \u00b7 93 secondsSAS - Logistic Regression - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you run a logistic regression in SAS"
    },
    {
      "answer": "Loss functions in neural networks The loss function is what SGD is attempting to minimize by iteratively updating the weights in the network. At the end of each epoch during the training process, the loss will be calculated using the network's output predictions and the true labels for the respective input.",
      "question": "What is loss in neural network training"
    },
    {
      "answer": "It does this by using a means of representing knowledge called, semantic networks. These use graphical methods to describe relationships between concepts and events to describe common sense activities.",
      "question": "How is common sense knowledge represented"
    },
    {
      "answer": "The neuron is the basic working unit of the brain, a specialized cell designed to transmit information to other nerve cells, muscle, or gland cells. Neurons are cells within the nervous system that transmit information to other nerve cells, muscle, or gland cells. Most neurons have a cell body, an axon, and dendrites.",
      "question": "What are the functions of neurons"
    },
    {
      "answer": "Association between two variables means the values of one variable relate in some way to the values of the other. Association is usually measured by correlation for two continuous variables and by cross tabulation and a Chi-square test for two categorical variables.",
      "question": "What is an association between two variables"
    },
    {
      "answer": "The training data is an initial set of data used to help a program understand how to apply technologies like neural networks to learn and produce sophisticated results.  Training data is also known as a training set, training dataset or learning set.",
      "question": "What is a training set in data mining"
    },
    {
      "answer": "The range is the distance from the highest value to the lowest value. The Inter-Quartile Range is quite literally just the range of the quartiles: the distance from the largest quartile to the smallest quartile, which is IQR=Q3-Q1.",
      "question": "How do you compare the interquartile range and range"
    },
    {
      "answer": "The binomial theorem is an algebraic method of expanding a binomial expression. Essentially, it demonstrates what happens when you multiply a binomial by itself (as many times as you want). For example, consider the expression (4x+y)7 ( 4 x + y ) 7 .",
      "question": "What is binomial expansion method"
    },
    {
      "answer": "1.96",
      "question": "What is the z value in Wilcoxon signed rank test"
    },
    {
      "answer": "A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.",
      "question": "Why Max pooling is used in CNN"
    },
    {
      "answer": "Repeating patterns often show serial correlation when the level of a variable affects its future level. In finance, this correlation is used by technical analysts to determine how well the past price of a security predicts the future price. Serial correlation is also known as autocorrelation or lagged correlation.",
      "question": "What does autocorrelation or serial correlation imply"
    },
    {
      "answer": "In unsupervised learning, there is no training data set and outcomes are unknown. Essentially the AI goes into the problem blind \u2013 with only its faultless logical operations to guide it.",
      "question": "Does unsupervised learning need training data"
    },
    {
      "answer": "The normal distribution can be used as an approximation to the binomial distribution, under certain circumstances, namely: If X ~ B(n, p) and if n is large and/or p is close to \u00bd, then X is approximately N(np, npq)",
      "question": "Can the normal distribution be used to approximate this probability"
    },
    {
      "answer": "Improving recall involves adding more accurately tagged text data to the tag in question. In this case, you are looking for the texts that should be in this tag but are not, or were incorrectly predicted (False Negatives). The best way to find these kind of texts is to search for them using keywords.",
      "question": "How do you increase recall in machine learning"
    },
    {
      "answer": "Top 10 Data Analytics toolsR Programming. R is the leading analytics tool in the industry and widely used for statistics and data modeling.  Tableau Public:  SAS:  Apache Spark.  Excel.  RapidMiner:KNIME.  QlikView.More items\u2022",
      "question": "What are the tools used in data analysis"
    },
    {
      "answer": "It is a rate per unit of time similar in meaning to reading a car speedometer at a particular instant and seeing 45 mph.  The failure rate (or hazard rate) is denoted by h(t) and is calculated from h(t) = \\frac{f(t)}{1 - F(t)} = \\frac{f(t)}{R(t)} = \\mbox{the instantaneous (conditional) failure rate.}",
      "question": "How are hazard rates calculated"
    },
    {
      "answer": "The main difference is obviously that, in a first order reaction, the order of reaction is one by nature. A pseudo first-order reaction is second order reaction by nature but has been altered to make it a first order reaction.",
      "question": "What is the difference between first order and pseudo first order reactions"
    },
    {
      "answer": "8:3514:50Suggested clip \u00b7 95 secondsLecture 6.3 \u2014 Logistic Regression | Decision Boundary \u2014 [ Machine YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you determine the decision boundary in logistic regression"
    },
    {
      "answer": "Some of the methods commonly used for binary classification are:Decision trees.Random forests.Bayesian networks.Support vector machines.Neural networks.Logistic regression.Probit model.",
      "question": "What are some binary classification algorithms"
    },
    {
      "answer": "As the name implies, multivariate regression is a technique that estimates a single regression model with more than one outcome variable. When there is more than one predictor variable in a multivariate regression model, the model is a multivariate multiple regression.",
      "question": "What is meant by multivariate regression analysis"
    },
    {
      "answer": "A statistic is biased if it is calculated in such a way that it is systematically different from the population parameter being estimated. The following lists some types of biases, which can overlap. Selection bias involves individuals being more likely to be selected for study than others, biasing the sample.",
      "question": "What does it mean if a statistic is biased"
    },
    {
      "answer": "Cross Entropy is definitely a good loss function for Classification Problems, because it minimizes the distance between two probability distributions - predicted and actual.  So cross entropy make sure we are minimizing the difference between the two probability. This is the reason.",
      "question": "Why do we use cross entropy loss"
    },
    {
      "answer": "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.",
      "question": "Why is SVM used for image classification"
    },
    {
      "answer": "Neural style transfer is trained as a supervised learning task in which the goal is to input two images (x), and train a network to output a new, synthesized image (y).",
      "question": "Is neural style transfer supervised learning"
    },
    {
      "answer": "At a bare minimum, collect around 1000 examples. For most \"average\" problems, you should have 10,000 - 100,000 examples. For \u201chard\u201d problems like machine translation, high dimensional data generation, or anything requiring deep learning, you should try to get 100,000 - 1,000,000 examples.",
      "question": "How many observations do you need for machine learning"
    },
    {
      "answer": "Both skew and kurtosis can be analyzed through descriptive statistics. Acceptable values of skewness fall between \u2212 3 and + 3, and kurtosis is appropriate from a range of \u2212 10 to + 10 when utilizing SEM (Brown, 2006).",
      "question": "What kurtosis is acceptable"
    },
    {
      "answer": "At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional to the square of the \u03b2 values, while the L1 norm is proportional the absolute value of the values in \u03b2.",
      "question": "What is the difference between l1 and l2 norm"
    },
    {
      "answer": "While there are a number of different methods for measuring intelligence, the standard and most widely accepted method is by measuring a person's 'intelligence quotient' or IQ. Based on a series of tests which assess various types of abilities such a mathematical, spatial, verbal, logic and memory.",
      "question": "How do you assess your own level of intelligence"
    },
    {
      "answer": "If a and b are two non-zero numbers, then the harmonic mean of a and b is a number H such that the numbers a, H, b are in H.P. We have H = 1/H = 1/2 (1/a + 1/b) \u21d2 H = 2ab/a+b.",
      "question": "What is harmonic mean of A and B"
    },
    {
      "answer": "A control group is a set of experimental samples or subjects that are kept separate and aren't exposed to the independent variable.  A controlled experiment is one in which every parameter is held constant except for the experimental (independent) variable.",
      "question": "What is the difference between a control variable and a control group"
    },
    {
      "answer": "In behavioral finance, base rate fallacy is the tendency for people to erroneously judge the likelihood of a situation by not taking into account all relevant data. Instead, investors might focus more heavily on new information without acknowledging how this impacts original assumptions.",
      "question": "What is the base rate fallacy and why is it important to avoid it"
    },
    {
      "answer": "The obvious difference between ANOVA and ANCOVA is the the letter \"C\", which stands for 'covariance'. Like ANOVA, \"Analysis of Covariance\" (ANCOVA) has a single continuous response variable. ANCOVA is also commonly used to describe analyses with a single response variable, continuous IVs, and no factors.",
      "question": "What is the difference between Anova and Ancova tests"
    },
    {
      "answer": "1 Answer. In word2vec, you train to find word vectors and then run similarity queries between words. In doc2vec, you tag your text and you also get tag vectors.  If two authors generally use the same words then their vector will be closer.",
      "question": "How is Doc2Vec different from word2vec"
    },
    {
      "answer": "The base rate fallacy occurs when prototypical or stereotypical factors are used for analysis rather than actual data. Because the student is volunteering in a hospital with a stroke center, he sees more patients who have experienced a stroke than would be expected in a hospital without a stroke center.",
      "question": "What is base rate fallacy MCAT"
    },
    {
      "answer": "6 Steps To Write Any Machine Learning Algorithm From Scratch: Perceptron Case StudyGet a basic understanding of the algorithm.Find some different learning sources.Break the algorithm into chunks.Start with a simple example.Validate with a trusted implementation.Write up your process.",
      "question": "How do you create a learning algorithm"
    },
    {
      "answer": "OLS cannot be used because the regression function is not a linear function of the regression coefficients (the coefficients appear inside the nonlinear functions \u03a6 or \u039b).",
      "question": "Why are the coefficients of probit and logit models estimated by maximum likelihood instead of OLS"
    },
    {
      "answer": "0:008:33Suggested clip \u00b7 112 secondsHow to read a log scale. - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you read a log scale"
    },
    {
      "answer": "The Poisson distribution has the following characteristics: It is a discrete distribution. Each occurrence is independent of the other occurrences. It describes discrete occurrences over an interval. The occurrences in each interval can range from zero to infinity.",
      "question": "What is Poisson distribution and its characteristics"
    },
    {
      "answer": "SVM Kernel Functions SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel is to take data as input and transform it into the required form.  For example linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid.",
      "question": "What are SVM kernels"
    },
    {
      "answer": "Parametric tests assume underlying statistical distributions in the data. Nonparametric tests do not rely on any distribution.  They can thus be applied even if parametric conditions of validity are not met.",
      "question": "What is the difference between parametric and nonparametric tests"
    },
    {
      "answer": "In probability theory and statistics, a categorical distribution (also called a generalized Bernoulli distribution, multinoulli distribution) is a discrete probability distribution that describes the possible results of a random variable that can take on one of K possible categories, with the probability of each",
      "question": "How do you describe a categorical distribution"
    },
    {
      "answer": "In addition every algorithm must satisfy the following criteria:input: there are zero or more quantities which are externally supplied;output: at least one quantity is produced;definiteness: each instruction must be clear and unambiguous;More items",
      "question": "What are two important criteria for algorithms"
    },
    {
      "answer": "Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.",
      "question": "What is the use of tokenization in NLP"
    },
    {
      "answer": "Yes, although 'linear regression' refers to any approach to model the relationship between one or more variables, OLS is the method used to find the simple linear regression of a set of data.",
      "question": "Is OLS the same as linear regression"
    },
    {
      "answer": "The Boruta algorithm is a wrapper built around the random forest classification algorithm. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. First, it duplicates the dataset, and shuffle the values in each column.",
      "question": "How does Boruta algorithm work"
    },
    {
      "answer": "Introduction[edit] Shift Invariance simply refers to the 'invariance' that a CNN has to recognising images. It allows the CNN to detect features/objects even if it does not look exactly like the images in it's training period. Shift invariance covers 'small' differences, such as movements shifts of a couple of pixels.",
      "question": "What is spatial invariance in CNN"
    },
    {
      "answer": "fastText is a library for efficient learning of word representations and sentence classification. In this document we present how to use fastText in python.",
      "question": "What is fastText in Python"
    },
    {
      "answer": "The SMD is preferable when the studies in a meta-analysis measure a given outcome using different scales or instruments.",
      "question": "What is the main advantage of the standardized mean difference SMD over the mean difference MD )"
    },
    {
      "answer": "A histogram is a graphical display of data using bars of different heights. In a histogram, each bar groups numbers into ranges. Taller bars show that more data falls in that range. A histogram displays the shape and spread of continuous sample data.",
      "question": "How does a histogram work"
    },
    {
      "answer": "Unsupervised learning is very useful in exploratory analysis because it can automatically identify structure in data.  Dimensionality reduction, which refers to the methods used to represent data using less columns or features, can be accomplished through unsupervised methods.",
      "question": "Why unsupervised learning is important"
    },
    {
      "answer": "1. A numerical value that defines the learning capability of a neural network during training. Learn more in: Voltage Instability Detection Using Neural Networks.",
      "question": "What is learning coefficient"
    },
    {
      "answer": "Output is defined as the act of producing something, the amount of something that is produced or the process in which something is delivered. An example of output is the electricity produced by a power plant. An example of output is producing 1,000 cases of a product.",
      "question": "What output means"
    },
    {
      "answer": "To calculate the learnable parameters here, all we have to do is just multiply the by the shape of width m, height n, previous layer's filters d and account for all such filters k in the current layer. Don't forget the bias term for each of the filter.",
      "question": "How are learnable parameters calculated CNN"
    },
    {
      "answer": "ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or a \"success\" (1).  Your observed outcome in logistic regression can ONLY be 0 or 1. The predicted probabilities from the model can take on all possible values between 0 and 1.",
      "question": "What is ROC in logistic regression"
    },
    {
      "answer": "Image processing is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.",
      "question": "What is image processing used for"
    },
    {
      "answer": "Bayesian neural networks differ from plain neural networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions.",
      "question": "What are Bayesian neural networks"
    },
    {
      "answer": "Precision is a metric that quantifies the number of correct positive predictions made. Precision, therefore, calculates the accuracy for the minority class. It is calculated as the ratio of correctly predicted positive examples divided by the total number of positive examples that were predicted.",
      "question": "How do you find the accuracy of a precision and recall"
    },
    {
      "answer": "In an economic model, an exogenous variable is one whose value is determined outside the model and is imposed on the model, and an exogenous change is a change in an exogenous variable. In contrast, an endogenous variable is a variable whose value is determined by the model.",
      "question": "What is the difference between an exogenous variable and an endogenous variable"
    },
    {
      "answer": "The slope of a least squares regression can be calculated by m = r(SDy/SDx). In this case (where the line is given) you can find the slope by dividing delta y by delta x. So a score difference of 15 (dy) would be divided by a study time of 1 hour (dx), which gives a slope of 15/1 = 15.",
      "question": "How do you interpret the slope of the least squares regression line"
    },
    {
      "answer": "A hierarchical linear regression is a special form of a multiple linear regression analysis in which more variables are added to the model in separate steps called \u201cblocks.\u201d This is often done to statistically \u201ccontrol\u201d for certain variables, to see whether adding variables significantly improves a model's ability to",
      "question": "What is a hierarchical regression analysis"
    },
    {
      "answer": "A non-convex optimization problem is any problem where the objective or any of the constraints are non-convex, as pictured below. Such a problem may have multiple feasible regions and multiple locally optimal points within each region.",
      "question": "What is Nonconvex optimization"
    },
    {
      "answer": "Enneagram test results are very accurate for determining your enneagram type and the MBTI test results are quite accurate for determining your MBTI type. Neither is in competition with the other. That being said, it can be very interesting to have the results for both of these uniquely different typologies.",
      "question": "Which is more accurate MBTI and Enneagram"
    },
    {
      "answer": "The odds ratio tells us how much higher the odds of exposure are among case-patients than among controls. An odds ratio of \u2022 1.0 (or close to 1.0) indicates that the odds of exposure among case-patients are the same as, or similar to, the odds of exposure among controls. The exposure is not associated with the disease.",
      "question": "What does an odds ratio of 1.0 mean"
    },
    {
      "answer": "A statistic is a number that represents a property of the sample. For example, if we consider one math class to be a sample of the population of all math classes, then the average number of points earned by students in that one math class at the end of the term is an example of a statistic.",
      "question": "What is an example of an statistic"
    },
    {
      "answer": "1 Answer. 1. 8. Without math: The delta rule uses gradient descent to minimize the error from a perceptron network's weights. Gradient descent is a general algorithm that gradually changes a vector of parameters in order to minimize an objective function.",
      "question": "What is gradient descent and Delta Rule"
    },
    {
      "answer": "Types of predictive modelsForecast models. A forecast model is one of the most common predictive analytics models.  Classification models.  Outliers Models.  Time series model.  Clustering Model.  The need for massive training datasets.  Properly categorising data.",
      "question": "What are the types of predictive models"
    },
    {
      "answer": "The correct interpretation of a 95% confidence interval is that \"we are 95% confident that the population parameter is between X and X.\"",
      "question": "How do you interpret a confidence interval"
    },
    {
      "answer": "Logarithmic Loss, or simply Log Loss, is a classification loss function often used as an evaluation metric in Kaggle competitions.  Log Loss quantifies the accuracy of a classifier by penalising false classifications.",
      "question": "What is log loss function"
    },
    {
      "answer": "In review, beta-endorphins are proteins that are primarily synthesized by the pituitary gland in response to physiologic stressors such as pain. They function through various mechanisms in both the central and peripheral nervous system to relieve pain when bound to their mu-opioid receptors.",
      "question": "What releases beta endorphins"
    },
    {
      "answer": "Q17. Which of the following is true about \u201cRidge\u201d or \u201cLasso\u201d regression methods in case of feature selection? \u201cRidge regression\u201d will use all predictors in final model whereas \u201cLasso regression\u201d can be used for feature selection because coefficient values can be zero.",
      "question": "Which of the following is true about Ridge or lasso regression methods in case of feature selection"
    },
    {
      "answer": "The optimal number of clusters can be defined as follow: Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters. For each k, calculate the total within-cluster sum of square (wss). Plot the curve of wss according to the number of clusters k.",
      "question": "How do you define K in K means clustering"
    },
    {
      "answer": "5 Most Important Methods For Statistical Data AnalysisMean. The arithmetic mean, more commonly known as \u201cthe average,\u201d is the sum of a list of numbers divided by the number of items on the list.  Standard Deviation.  Regression.  Sample Size Determination.  Hypothesis Testing.",
      "question": "What are some of the statistical methods that are useful for data analyst"
    },
    {
      "answer": "Binary cross-entropy is for multi-label classifications, whereas categorical cross entropy is for multi-class classification where each example belongs to a single class.",
      "question": "What is the difference between binary cross entropy and categorical cross entropy"
    },
    {
      "answer": "The critical value is a factor used to compute the margin of error, as shown in the equations below. When the sampling distribution of the statistic is normal or nearly normal, the critical value can be expressed as a t score or as a z-score.",
      "question": "Is critical value the same as Z score"
    },
    {
      "answer": "Examples of such greedy algorithms are Kruskal's algorithm and Prim's algorithm for finding minimum spanning trees, and the algorithm for finding optimum Huffman trees. Greedy algorithms appear in network routing as well.",
      "question": "What is greedy algorithm example"
    },
    {
      "answer": "False positive rate (FPR) is a measure of accuracy for a test: be it a medical diagnostic test, a machine learning model, or something else. In technical terms, the false positive rate is defined as the probability of falsely rejecting the null hypothesis.",
      "question": "What does false positive rate mean"
    },
    {
      "answer": "The sample variance is an estimator for the population variance. When applied to sample data, the population variance formula is a biased estimator of the population variance: it tends to underestimate the amount of variability.  We are using one fitted value (sample mean) in our estimate of the variance.",
      "question": "Why is the formula for sample variance different from the formula for population variance"
    },
    {
      "answer": "The variance is the average of the squared differences from the mean. Standard deviation is the square root of the variance so that the standard deviation would be about 3.03.  Because of this squaring, the variance is no longer in the same unit of measurement as the original data.",
      "question": "Is sample variance and standard deviation the same"
    },
    {
      "answer": "Unlike the independent-samples t-test, the Mann-Whitney U test allows you to draw different conclusions about your data depending on the assumptions you make about your data's distribution.  These different conclusions hinge on the shape of the distributions of your data, which we explain more about later.",
      "question": "Why use Mann Whitney U test instead of t test"
    },
    {
      "answer": "The cumulative distribution function (CDF) of random variable X is defined as FX(x)=P(X\u2264x), for all x\u2208R.SolutionTo find the CDF, note that.  To find P(2<X\u22645), we can write P(2<X\u22645)=FX(5)\u2212FX(2)=3132\u221234=732.  To find P(X>4), we can write P(X>4)=1\u2212P(X\u22644)=1\u2212FX(4)=1\u22121516=116.",
      "question": "How do you find the CDF of a random variable"
    },
    {
      "answer": "The central limit theorem applies to almost all types of probability distributions, but there are exceptions. For example, the population must have a finite variance. That restriction rules out the Cauchy distribution because it has infinite variance.",
      "question": "Does the central limit theorem apply to variance"
    },
    {
      "answer": "The range containing values that are consistent with the null hypothesis is the \"acceptance region\"; the other range, in which the null hypothesis is rejected, is the rejection region (or critical region).",
      "question": "What is the difference between critical region and acceptance region"
    },
    {
      "answer": "Data Augmentation in play. A convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, a CNN can be invariant to translation, viewpoint, size or illumination (Or a combination of the above).",
      "question": "What is data augmentation in CNN"
    },
    {
      "answer": "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.",
      "question": "What does a convolutional neural network do"
    },
    {
      "answer": "In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training.  Given these hyperparameters, the training algorithm learns the parameters from the data.",
      "question": "What are hyperparameters in machine learning"
    },
    {
      "answer": "There are two stages to prediction. The first stage is training the model\u2014this is where the tree is built, tested, and optimized by using an existing collection of data. In the second stage, you actually use the model to predict an unknown outcome.",
      "question": "How do you make predictions in decision trees"
    },
    {
      "answer": "In two-dimensional signals like digital images, frequencies are rate of change of grey scale value (intensity of pixel) with respect to space. This is also called Spatial frequency .  Convert the cosine values represented by the red dots into greyscale (0-255), such that -1 maps to 0 and 1 maps to 255.",
      "question": "What is frequency of an image"
    },
    {
      "answer": "If p is a probability, then p/(1 \u2212 p) is the corresponding odds; the logit of the probability is the logarithm of the odds, i.e.  For each choice of base, the logit function takes values between negative and positive infinity.",
      "question": "What is the logit function when P refers to probability of occurrence of an event"
    },
    {
      "answer": "Artificial intelligence is probably the most widely-known for its application in the etail/retail industry. Conversation intelligence software helps companies interact with customers and follow up leads by analyzing and segmenting sales calls using speech recognition and natural language processing.",
      "question": "In which field is artificial intelligence used"
    },
    {
      "answer": "Classification and regression tree (CART) analysis recursively partitions observations in a matched data set, consisting of a categorical (for classification trees) or continuous (for regression trees) dependent (response) variable and one or more independent (explanatory) variables, into progressively smaller groups (",
      "question": "What is classification and regression tree analysis"
    },
    {
      "answer": "Systematic sampling involves selecting fixed intervals from the larger population to create the sample. Cluster sampling divides the population into groups, then takes a random sample from each cluster.",
      "question": "What are the differences between systematic random sampling and cluster sampling"
    },
    {
      "answer": "Prior probability, in Bayesian statistical inference, is the probability of an event before new data is collected.",
      "question": "What is prior probability in machine learning"
    },
    {
      "answer": "8 Common Data Structures every Programmer must know. A quick introduction to 8 commonly used data structures.  Arrays. An array is a structure of fixed-size, which can hold items of the same data type.  Linked Lists.  Stacks.  Queues.  Hash Tables.  Trees.  Heaps.More items",
      "question": "What are the topics in data structures"
    },
    {
      "answer": "Technically, all interpreters do the same thing and follow the same basic principles. But since sign languages are visual-manual while spoken languages are based on speaking, hearing and writing/reading, the difference entails several special requirements for interpreting.",
      "question": "In what ways are spoken languages and signed languages the same different"
    },
    {
      "answer": "It is a criterion under which a hypothesis tester decides whether a given hypothesis must be accepted or rejected. The general rule of thumb is that if the value of test statics is greater than the critical value then the null hypothesis is rejected in the favor of the alternate hypothesis.",
      "question": "What is the rejection rule"
    },
    {
      "answer": "The basic premise of transfer learning is simple: take a model trained on a large dataset and transfer its knowledge to a smaller dataset. For object recognition with a CNN, we freeze the early convolutional layers of the network and only train the last few layers which make a prediction.",
      "question": "What is transfer learning in CNN"
    },
    {
      "answer": "A significant advantage of a decision tree is that it forces the consideration of all possible outcomes of a decision and traces each path to a conclusion. It creates a comprehensive analysis of the consequences along each branch and identifies decision nodes that need further analysis.",
      "question": "What are the advantages of decision tree"
    },
    {
      "answer": "Data science is the field of study that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract meaningful insights from data.",
      "question": "What is data science in simple words"
    },
    {
      "answer": "While a frequency distribution gives the exact frequency or the number of times a data point occurs, a probability distribution gives the probability of occurrence of the given data point.",
      "question": "What is the difference between probability distribution and relative frequency distribution"
    },
    {
      "answer": "A feature vector is a vector containing multiple elements about an object. Putting feature vectors for objects together can make up a feature space. The features may represent, as a whole, one mere pixel or an entire image. The granularity depends on what someone is trying to learn or represent about the object.",
      "question": "What features do vectors have"
    },
    {
      "answer": "Based on recent research, we hypothesize that there is a neural network of consciousness in which the paraventricular nucleus formally serves as the control nucleus of arousal, which is closely related to the maintenance of consciousness, and the neurons in the posterior cerebral cortex.",
      "question": "Are neural networks conscious"
    },
    {
      "answer": "Use systematic sampling when there's low risk of data manipulation. Systematic sampling is the preferred method over simple random sampling when a study maintains a low risk of data manipulation.",
      "question": "What is systematic sampling used for"
    },
    {
      "answer": "mAP (mean Average Precision) for Object DetectionPrecision & recall.Precision measures how accurate is your predictions.  Recall measures how good you find all the positives.  IoU (Intersection over union)Precision is the proportion of TP = 2/3 = 0.67.Recall is the proportion of TP out of the possible positives = 2/5 = 0.4.",
      "question": "How do you find the accuracy of an object detection"
    },
    {
      "answer": "Note: a Markov chain (of any order) is a stochastic recursive sequence of finite order, or equivalently an auto-regressive process of finite order (possibly nonlinear). In contrast, the martingale property does not put constraints on the order of recursion, while imposing a linear projection condition.",
      "question": "Is a martingale a Markov process"
    },
    {
      "answer": "Variables that can only take on a finite number of values are called \"discrete variables.\" All qualitative variables are discrete. Some quantitative variables are discrete, such as performance rated as 1,2,3,4, or 5, or temperature rounded to the nearest degree.",
      "question": "Is a discrete variable"
    },
    {
      "answer": "There are several situation in which the variable we want to explain can take only two possible values. This is typically the case when we want to model the choice of an individual.  This is why these models are called binary choice models, because they explain a (0/1) dependent variable.",
      "question": "What is a binary choice model"
    },
    {
      "answer": "The SVM typically tries to use a \"kernel function\" to project the sample points to high dimension space to make them linearly separable, while the perceptron assumes the sample points are linearly separable.",
      "question": "What is the difference between the perceptron learning algorithm and SVM"
    },
    {
      "answer": "Gradient is a vector that is tangent of a function and points in the direction of greatest increase of this function. Gradient is zero at a local maximum or minimum because there is no single direction of increase. In mathematics, gradient is defined as partial derivative for every input variable of function.",
      "question": "What is gradient in data science"
    },
    {
      "answer": "Assuming a double-blind test is not possible, here are some techniques that can help:Standardize everything: the research protocol, the moderator script, the questions etc.  Have a second researcher monitor the first researcher.  Stay out of the participant's line of sight.  Practice.More items\u2022",
      "question": "How do you remove experimenter bias"
    },
    {
      "answer": "Cohen's d is an effect size used to indicate the standardised difference between two means. It can be used, for example, to accompany reporting of t-test and ANOVA results. It is also widely used in meta-analysis. Cohen's d is an appropriate effect size for the comparison between two means.",
      "question": "What is Cohen's d in statistics"
    },
    {
      "answer": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.",
      "question": "What exactly is Artificial Intelligence"
    },
    {
      "answer": "The Poisson parameter Lambda (\u03bb) is the total number of events (k) divided by the number of units (n) in the data (\u03bb = k/n).  In between, or when events are infrequent, the Poisson distribution is used.",
      "question": "What is lambda in Poisson distribution"
    },
    {
      "answer": "Imbalanced data typically refers to a classification problem where the number of observations per class is not equally distributed; often you'll have a large amount of data/observations for one class (referred to as the majority class), and much fewer observations for one or more other classes (referred to as the",
      "question": "What is the problem with imbalanced data"
    },
    {
      "answer": "This implies that bias and variance of an estimator are complementary to each other i.e. an estimator with high bias will vary less(have low variance) and an estimator with high variance will have less bias(as it can vary more to fit/explain/estimate the data points).",
      "question": "What is the difference between the bias and variance of an estimator"
    },
    {
      "answer": "Chisquare Test, Different Types and its Application using RChi-Square Test.Chi-square test of independence.2 x 2 Contingency Table.Chi-square test of significance.Chi-square Test in R.Chi Square Goodness of Fit (One Sample Test)Chi-square Goodness of Test in R.Fisher's exact test.More items\u2022",
      "question": "What are the two types of chi square tests"
    },
    {
      "answer": "The generator is a convolutional neural network and the discriminator is a deconvolutional neural network. The goal of the generator is to artificially manufacture outputs that could easily be mistaken for real data. The goal of the discriminator is to identify which outputs it receives have been artificially created.",
      "question": "What is the goal of a generative adversarial network Gan"
    },
    {
      "answer": "Abstract: The k-Nearest Neighbors (kNN) classifier is one of the most effective methods in supervised learning problems. It classifies unseen cases comparing their similarity with the training data.  Fuzzy-kNN computes a fuzzy degree of membership of each instance to the classes of the problem.",
      "question": "What is fuzzy KNN"
    },
    {
      "answer": "Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items\u2022",
      "question": "How do you know which regression is the best"
    },
    {
      "answer": "Correlation is the concept of linear relationship between two variables.  It is linear relationship nor any other relationship. Whereas correlation coefficient is a measure that measures linear relationship between two variables.",
      "question": "Is there any difference between correlation and correlation coefficient"
    },
    {
      "answer": "RECALL is the ratio of the number of relevant records retrieved to the total number of relevant records in the database. It is usually expressed as a percentage. \u2500\u2500\u2500\u2500\u2500\u2500b\u2022d\u2500\u2500\u2500\u2500\u2500\u2500 Page 2 PRECISION is the ratio of the number of relevant records retrieved to the total number of irrelevant and relevant records retrieved.",
      "question": "What is the relationship between precision and recall"
    },
    {
      "answer": "Under simple random sampling, a sample of items is chosen randomly from a population, and each item has an equal probability of being chosen. Meanwhile, systematic sampling involves selecting items from an ordered population using a skip or sampling interval.",
      "question": "What is the difference between simple random sampling and systematic sampling"
    },
    {
      "answer": "Sets can be used in calculated fields Sets can be used in calculated fields as if they were a field.  Or you can have the calculation return a specific value, or return another field instead, the main point is that they are not very different than normal dimensions in this respect.",
      "question": "Can we use sets in calculated fields"
    },
    {
      "answer": "Concepts in Feature Space Given a set of features for a concept learning problem, we can interpret the feature set as a feature space. Given some data, a feature space is just the set of all possible values for a chosen set of features from that data.",
      "question": "What is concept space in machine learning"
    },
    {
      "answer": "Scales effectively with data: Deep networks scale much better with more data than classical ML algorithms.  With classical ML algorithms this quick and easy fix doesn't work even nearly as well and more complex methods are often required to improve accuracy.",
      "question": "Can deep learning scale better"
    },
    {
      "answer": "In addition, another reason to not initialize everything to zero is so that you get different answers. Some optimization techniques are deterministic, so if you initialize randomly, you'll get different answers each time you run it. This helps you explore the space better and avoid (other) local optima.",
      "question": "Why is zero initialization not a recommended weight initialization technique"
    },
    {
      "answer": "Machine learning is more than neural networks and deep learning. It is a field with a legion of smart algorithms that deduce complex patterns and make predictions about the unknown. The robustness of Random forests is contributed to its collection of distinct decision trees, each trying to solve part of the problem.",
      "question": "What have you learned about machine learning"
    },
    {
      "answer": "Probability RulesEvery probability is between zero and one. In other words, if A is an event, then 0\u2264P(A)\u22641.The sum of the probabilities of all of the outcomes is one. In other words, if all of the outcomes in the sample space are denoted by Ai, then \u2211Ai=1.Impossible events have probability zero.  Certain events have probability one.",
      "question": "What are the probability rules"
    },
    {
      "answer": "A pooling or subsampling layer often immediately follows a convolution layer in CNN. Its role is to downsample the output of a convolution layer along both the spatial dimensions of height and width.",
      "question": "What is subsampling in CNN"
    },
    {
      "answer": "Linear Regression is a machine learning algorithm based on supervised learning. Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).  So, this regression technique finds out a linear relationship between x (input) and y(output).",
      "question": "How does regression algorithm work"
    },
    {
      "answer": "(retrogress) Opposite of to develop gradually. retrogress. diminish. regress.",
      "question": "What is the opposite of evolve"
    },
    {
      "answer": "YOUR preferred learning style is the way in which YOU learn best. Three learning styles that are often identified in students are the Auditory Learning Style, the Visual Learning Style, and theTactile/Kinesthetic Learning Style. Read about each of these learning styles to identify YOUR preferred learning style.",
      "question": "What is your preferred way of learning"
    },
    {
      "answer": "Not usually. SGD tends to perform better than using line search.",
      "question": "Is line search used commonly with SGD while learning the parameters for a deep neural networks"
    },
    {
      "answer": "If r is not between the positive and negative critical values, then the correlation coefficient is significant. If r is significant, then you may want to use the line for prediction. Suppose you computed r=0.801 using n=10 data points. df=n\u22122=10\u22122=8.",
      "question": "Is it possible to determine the statistical significance of a correlation coefficient"
    },
    {
      "answer": "Correlation coefficients are indicators of the strength of the relationship between two different variables. A correlation coefficient that is greater than zero indicates a positive relationship between two variables. A value that is less than zero signifies a negative relationship between two variables.",
      "question": "What do different correlation coefficients mean"
    },
    {
      "answer": "Classification is a supervised machine learning approach, in which the algorithm learns from the data input provided to it \u2014 and then uses this learning to classify new observations.  The name (\"Naive\") derives from the fact that the algorithm assumes that attributes are conditionally independent.",
      "question": "What is classification techniques in machine learning"
    },
    {
      "answer": "Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on. If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)",
      "question": "How does neural network reduce loss"
    },
    {
      "answer": "This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method.",
      "question": "What statistics does cross validation reduce"
    },
    {
      "answer": "High Pass RL Filter An inductor, like a capacitor, is a reactive device.  And this is why this circuit is a high-pass filter circuit. Low frequency signals, however, will go through the inductor, because inductors offer very low resistance to low-frequency, or Dc, signals.",
      "question": "Is inductor high pass filter"
    },
    {
      "answer": "Clustering and Association are two types of Unsupervised learning.  Important clustering types are: 1)Hierarchical clustering 2) K-means clustering 3) K-NN 4) Principal Component Analysis 5) Singular Value Decomposition 6) Independent Component Analysis.",
      "question": "Which of the following is an unsupervised learning algorithm"
    },
    {
      "answer": "Canonical correlation analysis (CCA) is very important in MVL, whose main idea is to map data from different views onto a common space with the maximum correlation. The traditional CCA can only be used to calculate the linear correlation between two views.",
      "question": "What is CCA in machine learning"
    },
    {
      "answer": "In mathematics, a tensor is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors.",
      "question": "How do you define a tensor"
    },
    {
      "answer": "With two-way ANOVA, you have one continuous dependent variable and two categorical grouping variables for the independent variables. MANOVA models several dependent variables simultaneously and you can include a variety of independent variables.",
      "question": "What is the difference between a 2 way ANOVA and a MANOVA"
    },
    {
      "answer": "by Tim Bock. Hierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other.",
      "question": "What is hierarchical clustering algorithm"
    },
    {
      "answer": "In the mathematical field of numerical analysis, interpolation is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points.  It is often required to interpolate, i.e., estimate the value of that function for an intermediate value of the independent variable.",
      "question": "What is interpolation algorithm"
    },
    {
      "answer": "To find \u201cq\u201d or the studentized range statistic, refer to your table on page A-32 of your text. On the table 'k' or the number of groups is found along the top, and degrees of freedom within is down the side.",
      "question": "How do you find q in Tukey's HSD"
    },
    {
      "answer": "Such algorithms are called greedy because while the optimal solution to each smaller instance will provide an immediate output, the algorithm doesn't consider the larger problem as a whole.  Greedy algorithms work by recursively constructing a set of objects from the smallest possible constituent parts.",
      "question": "Why is it called greedy algorithm"
    },
    {
      "answer": "Multi-view data is common in real-world datasets, where different views describe distinct perspec- tives.  Multi-view data is prevalent in many real-world applications. For instance, the same news can be obtained from various language sources; an image can be described by different low level visual features.",
      "question": "What is multi view data"
    },
    {
      "answer": "Perceptron networks have several limitations. First, the output values of a perceptron can take on only one of two values (0 or 1) due to the hard-limit transfer function. Second, perceptrons can only classify linearly separable sets of vectors.",
      "question": "What are the limitations of Perceptron"
    },
    {
      "answer": "A vector space is a space of vectors, ie. each element is a vector. A vector field is, at its core, a function between some space and some vector space, so every point in our base space has a vector assigned to it. A good example would be wind direction maps you see on weather reports.",
      "question": "What is the difference between a vector field and a vector space"
    },
    {
      "answer": "Structural equation models are often used to assess unobservable 'latent' constructs. They often invoke a measurement model that defines latent variables using one or more observed variables, and a structural model that imputes relationships between latent variables.",
      "question": "When would you use a structural equation model"
    },
    {
      "answer": "AREA UNDER THE ROC CURVE In general, an AUC of 0.5 suggests no discrimination (i.e., ability to diagnose patients with and without the disease or condition based on the test), 0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding.",
      "question": "What is a good area under ROC curve"
    },
    {
      "answer": "Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.",
      "question": "What is a grid search and why do we use it in machine learning"
    },
    {
      "answer": "Classification and regression trees are machine-learning methods for constructing. prediction models from data. The models are obtained by recursively partitioning. the data space and fitting a simple prediction model within each partition.",
      "question": "What is classification and regression tree"
    },
    {
      "answer": "A correlation close to -1 or 1 tells us that there is a strong relationship between the variables. It is useful to know this. Strictly speaking, it applies to a linear relationship, but the correlation can be high even for an obviously curvilinear relationship.",
      "question": "What is the advantage of a correlation coefficient"
    },
    {
      "answer": "Step 1: Divide your confidence level by 2: .95/2 = 0.475. Step 2: Look up the value you calculated in Step 1 in the z-table and find the corresponding z-value. The z-value that has an area of .475 is 1.96. Step 3: Divide the number of events by the number of trials to get the \u201cP-hat\u201d value: 24/160 = 0.15.",
      "question": "How do you find confidence intervals"
    },
    {
      "answer": "Computer Vision. Image processing is mainly focused on processing the raw input images to enhance them or preparing them to do other tasks. Computer vision is focused on extracting information from the input images or videos to have a proper understanding of them to predict the visual input like human brain.",
      "question": "What is computer vision and image processing"
    },
    {
      "answer": "Variance plays a major role in interpreting data in statistics. The most common application of variance is in polls. For opinion polls, the data gathering agencies cannot invest in collecting data from the entire population.",
      "question": "How is variance used in real life"
    },
    {
      "answer": "Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters.",
      "question": "What is maximum likelihood estimation in machine learning"
    },
    {
      "answer": "In mathematics, specifically in functional analysis, each bounded linear operator on a complex Hilbert space has a corresponding Hermitian adjoint (or adjoint operator). Adjoints of operators generalize conjugate transposes of square matrices to (possibly) infinite-dimensional situations.",
      "question": "What is the adjoint of a linear operator"
    },
    {
      "answer": "Adding Noise into Neural Network Neural networks are capable of learning output functions that can change wildly with small changes in input. Adding noise to inputs randomly is like telling the network to not change the output in a ball around your exact input.",
      "question": "What is noise in neural network"
    },
    {
      "answer": "They have too few levels of structure: Neurons, Layers, and Whole Nets. We need to group neurons in each layer in 'capsules' that do a lot of internal computation and then output a compact result.\u201d",
      "question": "What is wrong with convolutional neural nets"
    },
    {
      "answer": "Qualities of a Good Sampling Frame Include all individuals in the target population. Exclude all individuals not in the target population. Includes accurate information that can be used to contact selected individuals.",
      "question": "What is a good sampling frame"
    },
    {
      "answer": "The resulting image after applying Canny operator (b). The primary advantages of the Sobel operator lie in its simplicity. The Sobel method provides a approximation to the gradient magnitude. Another advantage of the Sobel operator is it can detect edges and their orientations.",
      "question": "What is the advantage of Sobel operator over Prewitt operator"
    },
    {
      "answer": "We present a freely available open-source toolkit for training recurrent neural network based language models. It can be easily used to improve existing speech recognition and machine translation systems.",
      "question": "Is there a recurrent neural networks toolkit"
    },
    {
      "answer": "Definition. The class intervals are the subsets into which the data is grouped. The width of the class intervals will be a compromise between having intervals short enough so that not all of the observations fall in the same interval, but long enough so that you do not end up with only one observation per interval.",
      "question": "What is class interval in statistics with example"
    },
    {
      "answer": "A feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly.  If you accept most classes of problems can be reduced to functions, this statement implies a neural network can, in theory, solve any problem.",
      "question": "Can neural networks solve any problem"
    },
    {
      "answer": "The dissimilarity matrix, using the euclidean metric, can be calculated with the command: daisy(agriculture, metric = \"euclidean\"). The result the of calculation will be displayed directly in the screen, and if you wanna reuse it you can simply assign it to an object: x <- daisy(agriculture, metric = \"euclidean\").",
      "question": "How do you find the dissimilarity of a matrix"
    },
    {
      "answer": "Face validity: Does the content of the test appear to be suitable to its aims? Criterion validity: Do the results correspond to a different test of the same thing?",
      "question": "What is the difference between content and criterion validity"
    },
    {
      "answer": "In computer science, specifically in algorithms related to pathfinding, a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.",
      "question": "What is admissible heuristic in AI"
    },
    {
      "answer": "In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.  Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex.",
      "question": "What is meant by convolution neural network"
    },
    {
      "answer": "Average (or mean) filtering is a method of 'smoothing' images by reducing the amount of intensity variation between neighbouring pixels. The average filter works by moving through the image pixel by pixel, replacing each value with the average value of neighbouring pixels, including itself.",
      "question": "What is average filtering"
    },
    {
      "answer": "The Elbow Method is more of a decision rule, while the Silhouette is a metric used for validation while clustering. Thus, it can be used in combination with the Elbow Method. Therefore, the Elbow Method and the Silhouette Method are not alternatives to each other for finding the optimal K.",
      "question": "Which method is not used for finding the best K in K means technique"
    },
    {
      "answer": "Normalization: Similarly, the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.  So we normalize the data to bring all the variables to the same range.",
      "question": "Why do we normalize data"
    },
    {
      "answer": "Naive bayes is a Generative model whereas Logistic Regression is a Discriminative model . Generative model is based on the joint probability, p( x, y), of the inputs x and the label y, and make their predictions by using Bayes rules to calculate p(y | x), and then picking the most likely label y.",
      "question": "Is naive Bayes generative or discriminative"
    },
    {
      "answer": "In probability theory and statistics, the multivariate normal distribution, multivariate Gaussian distribution, or joint normal distribution is a generalization of the one-dimensional (univariate) normal distribution to higher dimensions.",
      "question": "What is the multivariate Gaussian distribution"
    },
    {
      "answer": "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.",
      "question": "Why does normalization work in batch"
    },
    {
      "answer": "Summary: \u201cOLS\u201d stands for \u201cordinary least squares\u201d while \u201cMLE\u201d stands for \u201cmaximum likelihood estimation.\u201d  Maximum likelihood estimation, or MLE, is a method used in estimating the parameters of a statistical model and for fitting a statistical model to data.",
      "question": "What is the difference between OLS and Maximum Likelihood"
    },
    {
      "answer": "Ensemble learning helps improve machine learning results by combining several models.  Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).",
      "question": "How does ensemble method work"
    },
    {
      "answer": "Data Preprocessing is a technique that is used to convert the raw data into a clean data set.  In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis.",
      "question": "What is data preprocessing in ML"
    },
    {
      "answer": "In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables.",
      "question": "What is the difference between linear regression and multiple linear regression"
    },
    {
      "answer": "The principal advantage of linear regression is its simplicity, interpretability, scientific acceptance, and widespread availability. Linear regression is the first method to use for many problems. Analysts can use linear regression together with techniques such as variable recoding, transformation, or segmentation.",
      "question": "What is the main advantage of using linear regression"
    },
    {
      "answer": "Consider the normal distribution N(100, 10). To find the percentage of data below 105.3, that is P(x < 105.3), standartize first: P(x < 105.3) = P ( z < 105.3 \u2212 100 10 ) = P(z < 0.53). Then find the proportion corresponding to 0.53 in Table A: look for the intersection of the row labeled 0.5 and the column labeled .",
      "question": "How do you find the standard normal distribution percentage"
    },
    {
      "answer": "ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x). Visually, it looks like the following: ReLU is the most commonly used activation function in neural networks, especially in CNNs.",
      "question": "What is ReLU in machine learning"
    },
    {
      "answer": "You can use regression equations to make predictions. Regression equations are a crucial part of the statistical output after you fit a model.  However, you can also enter values for the independent variables into the equation to predict the mean value of the dependent variable.",
      "question": "Is it appropriate to use the linear regression equation to make predictions"
    },
    {
      "answer": "Explanation: Weight adjustment is proportional to negative gradient of error with respect to weight. 10.",
      "question": "Does backpropagation learning is based on gradient descent along error surface"
    },
    {
      "answer": "Binomial is defined as a math term meaning two expressions connected by a plus or minus sign. An example of a binomial is x \u2013 y.  An example of a binomial is Canis familiaris, the scientific name for dog.",
      "question": "What is binomial example"
    },
    {
      "answer": "Data Collection & Analysis Tools Related TopicsBox & Whisker Plot.Check Sheet.Control Chart.Design of Experiments (DOE)Histogram.Scatter Diagram.Stratification.Survey.",
      "question": "What are the tools for analysis"
    },
    {
      "answer": "In data science, association rules are used to find correlations and co-occurrences between data sets. They are ideally used to explain patterns in data from seemingly independent information repositories, such as relational databases and transactional databases.",
      "question": "What is the applicability of association rules"
    },
    {
      "answer": "Linear Regression, intuitively is a regression algorithm with a Linear approach. We try to predict a continuous value of a given data point by generalizing on the data that we have in hand. The linear part indicates that we are using a linear approach in generalizing over the data.",
      "question": "What is the intuition behind linear regression"
    },
    {
      "answer": "Metrics like accuracy, precision, recall are good ways to evaluate classification models for balanced datasets, but if the data is imbalanced and there's class disparity, then other methods like ROC/AUC perform better in evaluating the model performance.",
      "question": "What are the metrics chosen to evaluate model performance"
    },
    {
      "answer": "The two are different. Stoichiometry looks at balancing equations whereas dimensional analysis is looking at the units particular equations take and allowing you to make a determination of final units (and possibly the correctness of your derivation of units for any equations).",
      "question": "Is dimensional analysis the same thing as stoichiometry"
    },
    {
      "answer": "Examples of sampling bias include self-selection, pre-screening of trial participants, discounting trial subjects/tests that did not run to completion and migration bias by excluding subjects who have recently moved into or out of the study area.",
      "question": "What is selection bias example"
    },
    {
      "answer": "Gradient Boosting Machines vs. XGBoost.  While regular gradient boosting uses the loss function of our base model (e.g. decision tree) as a proxy for minimizing the error of the overall model, XGBoost uses the 2nd order derivative as an approximation.",
      "question": "What's the difference between gradient boosting and XGBoost"
    },
    {
      "answer": "Introduction to K-Means ClusteringStep 1: Choose the number of clusters k.  Step 2: Select k random points from the data as centroids.  Step 3: Assign all the points to the closest cluster centroid.  Step 4: Recompute the centroids of newly formed clusters.  Step 5: Repeat steps 3 and 4.",
      "question": "How do you use K means clustering"
    },
    {
      "answer": "In statistics, a confounder (also confounding variable, confounding factor, or lurking variable) is a variable that influences both the dependent variable and independent variable, causing a spurious association. Confounding is a causal concept, and as such, cannot be described in terms of correlations or associations.",
      "question": "What is meant by confounding in statistics"
    },
    {
      "answer": "Initializers define the way to set the initial random weights of Keras layers. The keyword arguments used for passing initializers to layers depends on the layer. Usually, it is simply kernel_initializer and bias_initializer : from tensorflow.keras import layers from tensorflow.keras import initializers layer = layers.",
      "question": "What is kernel initializer in keras"
    },
    {
      "answer": "The 1\u00d71 filter can be used to create a linear projection of a stack of feature maps. The projection created by a 1\u00d71 can act like channel-wise pooling and be used for dimensionality reduction. The projection created by a 1\u00d71 can also be used directly or be used to increase the number of feature maps in a model.",
      "question": "How are 1x1 convolutions used for dimensionality reduction"
    },
    {
      "answer": "The null hypothesis (H0) for a one tailed test is that the mean is greater (or less) than or equal to \u00b5, and the alternative hypothesis is that the mean is < (or >, respectively) \u00b5.",
      "question": "What is the null hypothesis for a one tailed test"
    },
    {
      "answer": "It's greedy because you always mark the closest vertex. It's dynamic because distances are updated using previously calculated values. I would say it's definitely closer to dynamic programming than to a greedy algorithm. To find the shortest distance from A to B, it does not decide which way to go step by step.",
      "question": "Why is Dijkstra A greedy algorithm"
    },
    {
      "answer": "all provides a way to leverage binary classification. -all solution consists of N separate binary classifiers\u2014one binary classifier for each possible outcome.  During training, the model runs through a sequence of binary classifiers, training each to answer a separate classification question.",
      "question": "What is one vs all classification"
    },
    {
      "answer": "By reversing the words in the source sentence, the average distance between corresponding words in the source and target language is unchanged. However, the first few words in the source language are now very close to the first few words in the target language, so the problem's minimal time lag is greatly reduced.",
      "question": "In the paper Sequence to Sequence Learning with Neural Networks why does reversing the source sentence allow better performance on longer sentences"
    },
    {
      "answer": "The main difference is that ABM typically implement low numbers of highly complex agents, and the main feature they consider are their individual capabilities to face the task. On the opposite, MAS consider (very) large numbers of simpler agents, focusing on the emergence of new phenomena from social interactions.",
      "question": "What is the difference between agent based simulation ABS and multi agent system MAS )"
    },
    {
      "answer": "A box and whisker plot\u2014also called a box plot\u2014displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum.",
      "question": "What values are in a box plot"
    },
    {
      "answer": "Establish face validity.Conduct a pilot test.Enter the pilot test in a spreadsheet.Use principal component analysis (PCA)Check the internal consistency of questions loading onto the same factors.Revise the questionnaire based on information from your PCA and CA.",
      "question": "How do you check for the validity and reliability of a questionnaire"
    },
    {
      "answer": "\"A Bayesian network is a probabilistic graphical model which represents a set of variables and their conditional dependencies using a directed acyclic graph.\"  It is also called a Bayes network, belief network, decision network, or Bayesian model.",
      "question": "What is Bayesian network in AI"
    },
    {
      "answer": "They are basically equivalent: the linear time invariant systems refers to an analog system and shift-invariant system refers to a discrete-time system.  The shift-invariant is the same as time invariant: if we delay the input, the output that we get is the original input to the signal that wasn't delayed.",
      "question": "What is difference between Linear time invariant system and Linear shift invariant system 1"
    },
    {
      "answer": "Java, Python, Lisp, Prolog, and C++ are major AI programming language used for artificial intelligence capable of satisfying different needs in the development and designing of different software.",
      "question": "Which program is used for artificial intelligence"
    },
    {
      "answer": "A random variable is a variable whose value is a numerical outcome of a random phenomenon. A discrete random variable X has a countable number of possible values. Example: Let X represent the sum of two dice.  A continuous random variable X takes all values in a given interval of numbers.",
      "question": "What is the difference between a random variable and a discrete random variable"
    },
    {
      "answer": "Linear Shift-Invariant systems, called LSI systems for short, form a very important class of practical systems, and hence are of interest to us. They are also referred to as Linear Time-Invariant systems, in case the independent variable for the input and output signals is time.",
      "question": "What is linear shift invariant system"
    },
    {
      "answer": "Now we'll check out the proven way to improve the accuracy of a model:Add more data. Having more data is always a good idea.  Treat missing and Outlier values.  Feature Engineering.  Feature Selection.  Multiple algorithms.  Algorithm Tuning.  Ensemble methods.",
      "question": "How can the accuracy of a linear regression model be improved"
    },
    {
      "answer": "Inductive probability refers to the likelihood that an inductive argument with true premises will give a true conclusion.  An argument with low inductive probability is less likely to have a true conclusion even if its premises are true.",
      "question": "What is a probability argument"
    },
    {
      "answer": "The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.",
      "question": "How does Softmax regression work"
    },
    {
      "answer": "Autocorrelation can cause problems in conventional analyses (such as ordinary least squares regression) that assume independence of observations. In a regression analysis, autocorrelation of the regression residuals can also occur if the model is incorrectly specified.",
      "question": "Why is autocorrelation a problem for times series analysis"
    },
    {
      "answer": "First, after looking around on the web, it seems that there is no way to compute a (discrete) Fourier transform through a neural network. You can hack it by hard-coding the thing to include the Fourier constants for the transform and then get a decent result.",
      "question": "Can neural networks learn Fourier Transform"
    },
    {
      "answer": "Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation.",
      "question": "What does tokenization mean in NLP"
    },
    {
      "answer": "A sample survey can be broadly defined as an exercise that involves collecting standardised data from a sample of study units (e.g., persons, households, businesses) designed to represent a larger population of units, in order to make quantitative inferences about the population.",
      "question": "What is sample survey method"
    },
    {
      "answer": "(e.g. if P=1/256, that's 8 bits.) Entropy is just the average of that information bit length, over all the outcomes. The purpose of log(pi) appearing in Shannon's Entropy is that log(pi) is the only function satisfying the basic set of properties that the entropy function, H(p1,\u2026,pN), is held to embody.",
      "question": "Why log is used in entropy"
    },
    {
      "answer": "Regularization is a technique which makes slight modifications to the learning algorithm such that the model generalizes better. This in turn improves the model's performance on the unseen data as well.",
      "question": "What are regularization techniques"
    },
    {
      "answer": "In machine learning, scoring is the process of applying an algorithmic model built from a historical dataset to a new dataset in order to uncover practical insights that will help solve a business problem.  The second stage is scoring, in which you apply the trained model to a new dataset.",
      "question": "What is model scoring in machine learning"
    },
    {
      "answer": "The Matrix represents a system of control that operates completely in the mind. As a complex, machine-driven program, it appropriates any personal, political, or ideological leanings and renders them wholly false. It allows illusions but no action.",
      "question": "What is the Matrix and what does it represent"
    },
    {
      "answer": "Two main statistical methods are used in data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from data that are subject to random variation (e.g., observational errors, sampling variation).",
      "question": "What are statistical methods used for analysis"
    },
    {
      "answer": "The beginnings of modern AI can be traced to classical philosophers' attempts to describe human thinking as a symbolic system. But the field of AI wasn't formally founded until 1956, at a conference at Dartmouth College, in Hanover, New Hampshire, where the term \"artificial intelligence\" was coined.",
      "question": "What is the history of artificial intelligence"
    },
    {
      "answer": "Causation is the relationship between cause and effect. So, when a cause results in an effect, that's a causation.  When we say that correlation does not imply cause, we mean that just because you can see a connection or a mutual relationship between two variables, it doesn't necessarily mean that one causes the other.",
      "question": "Does correlation imply causation Why or why not"
    },
    {
      "answer": "more  A symbol for a value we don't know yet. It is usually a letter like x or y. Example: in x + 2 = 6, x is the variable.",
      "question": "What is variable example"
    },
    {
      "answer": "1. If having conditional independence will highly negative affect classification, you'll want to choose K-NN over Naive Bayes. Naive Bayes can suffer from the zero probability problem; when a particular attribute's conditional probability equals zero, Naive Bayes will completely fail to produce a valid prediction.",
      "question": "Classification machine learning When should I use a K NN classifier over a Naive Bayes classifier"
    },
    {
      "answer": "A time series is a dataset whose unit of analysis is a time period, rather than a person. Regression is an analytic tool that attempts to predict one variable, y as a function of one or more x variables. It can be used to analyze both time-series and static data.",
      "question": "What is the difference between regression and time series"
    },
    {
      "answer": "Inverted Dropout is how Dropout is implemented in practice in the various deep learning frameworks because it helps to define the model once and just change a parameter (the keep/drop probability) to run train and test on the same model.",
      "question": "Why is the dropout inverted"
    },
    {
      "answer": "If exploding gradients are still occurring, you can check for and limit the size of gradients during the training of your network. This is called gradient clipping. Dealing with the exploding gradients has a simple but very effective solution: clipping gradients if their norm exceeds a given threshold.",
      "question": "What technique is followed to deal with the problem of exploding gradients in recurrent neural net works RNN )"
    },
    {
      "answer": "Statistics is generally considered a prerequisite to the field of applied machine learning. We need statistics to help transform observations into information and to answer questions about samples of observations.",
      "question": "How is statistics related to machine learning"
    },
    {
      "answer": "Thus, the SMC counts both mutual presences (when an attribute is present in both sets) and mutual absence (when an attribute is absent in both sets) as matches and compares it to the total number of attributes in the universe, whereas the Jaccard index only counts mutual presence as matches and compares it to the",
      "question": "What is the main difference between simple matching coefficient SMC similarity and Jaccard similarity"
    },
    {
      "answer": "If you use import numpy , all sub-modules and functions in the numpy module can only be accesses in the numpy.  If you use from numpy import * , all functions will be loaded into the local namespace. For example array([1,2,3]) can then be used.",
      "question": "What is the difference between import numpy and from numpy import *"
    },
    {
      "answer": "For independent random variables X and Y, the variance of their sum or difference is the sum of their variances: Variances are added for both the sum and difference of two independent random variables because the variation in each variable contributes to the variation in each case.",
      "question": "How do you find the variance of an independent variable"
    },
    {
      "answer": "The t-value measures the size of the difference relative to the variation in your sample data. Put another way, T is simply the calculated difference represented in units of standard error. The greater the magnitude of T, the greater the evidence against the null hypothesis.",
      "question": "What does the T score tell you"
    },
    {
      "answer": "Loss curves are a standard actuarial technique for helping insurance companies assess the amount of reserve capital they need to keep on hand to cover claims from a line of business. Claims made and reported for a given accounting period are tracked seperately over time.",
      "question": "What is a loss curve"
    },
    {
      "answer": "0:007:21Suggested clip \u00b7 102 secondsBayesian posterior sampling - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you sample a posterior distribution"
    },
    {
      "answer": "This is referred to as the joint probability of X = x and Y = y. If X and Y are discrete random variables, the function given by f (x, y) = P(X = x, Y = y) for each pair of values (x, y) within the range of X is called the joint probability distribution of X and Y .",
      "question": "What is the joint distribution of X and Y"
    },
    {
      "answer": "In addition, scales can be constructed from categorical variables. This is covered in a later section. The Count property returns the number of levels in the scale. The IsOrdered property indicates whether the scale is ordered or unordered.",
      "question": "Can Scaling be applied to categorical variables"
    },
    {
      "answer": "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression).",
      "question": "How does KNN classification work"
    },
    {
      "answer": "A mutually exclusive pair of events are complements to each other. For example: If the desired outcome is heads on a flipped coin, the complement is tails. The Complement Rule states that the sum of the probabilities of an event and its complement must equal 1, or for the event A, P(A) + P(A') = 1.",
      "question": "How is the rule of complement used to calculate probability"
    },
    {
      "answer": "(8) The moment generating function corresponding to the normal probability density function N(x;\u00b5, \u03c32) is the function Mx(t) = exp{\u00b5t + \u03c32t2/2}.",
      "question": "What is the moment generating function of normal distribution"
    },
    {
      "answer": "Step 1 \u2014 Deciding on the network topology (not really considered optimization but is obviously very important)  Step 2 \u2014 Adjusting the learning rate.  Step 3 \u2014 Choosing an optimizer and a loss function.  Step 4 \u2014 Deciding on the batch size and number of epochs.  Step 5 \u2014 Random restarts.",
      "question": "How do I tune Hyperparameters in neural network"
    },
    {
      "answer": "To work out the probability that a discrete random variable X takes a particular value x, we need to identify the event (the set of possible outcomes) that corresponds to \"X=x\". pX(x)=Pr(X=x). In general, the probability function pX(x) may be specified in a variety of ways.",
      "question": "What is the function of probability"
    },
    {
      "answer": "12 Common Logical Fallacies and How to Debunk Them12 Common Logical Fallacies and How to Debunk Them.  Ad Hominem.  Appeal to Authority.  Bandwagon Argument, or ad populum.  The Strawman.  Circular Reasoning.  The Genetic Fallacy.  Anecdotal Evidence.More items\u2022",
      "question": "What are the 12 fallacies"
    },
    {
      "answer": "Five main Component of Natural Language processing are:Morphological and Lexical Analysis.Syntactic Analysis.Semantic Analysis.Discourse Integration.Pragmatic Analysis.",
      "question": "What are the components of NLP"
    },
    {
      "answer": "x\u0304 = ( \u03a3 xi ) / nAdd up the sample items.Divide sum by the number of samples.The result is the mean.Use the mean to find the variance.Use the variance to find the standard deviation.",
      "question": "How do you find the mean of a random sample"
    },
    {
      "answer": "Generalized Linear Models let you express the relation between covariates X and response y in a linear, additive manner.",
      "question": "What is the practical purpose of generalized linear models"
    },
    {
      "answer": "We can use the regression line to predict values of Y given values of X. For any given value of X, we go straight up to the line, and then move horizontally to the left to find the value of Y. The predicted value of Y is called the predicted value of Y, and is denoted Y'.",
      "question": "How do you find the predicted value in a regression equation"
    },
    {
      "answer": "Just as ordinary least square regression is the method used to estimate coefficients for the best fit line in linear regression, logistic regression uses maximum likelihood estimation (MLE) to obtain the model coefficients that relate predictors to the target.",
      "question": "Which method gives the best fit for logistic regression model"
    },
    {
      "answer": "2 Answers. Boosting is based on weak learners (high bias, low variance).  Boosting reduces error mainly by reducing bias (and also to some extent variance, by aggregating the output from many models). On the other hand, Random Forest uses as you said fully grown decision trees (low bias, high variance).",
      "question": "What is the difference in bias and variance in 1 Random Forest 2 gradient boosting Why is there this difference"
    },
    {
      "answer": "Some applications of unsupervised machine learning techniques include: Clustering allows you to automatically split the dataset into groups according to similarity. Often, however, cluster analysis overestimates the similarity between groups and doesn't treat data points as individuals.",
      "question": "What are the application of unsupervised learning"
    },
    {
      "answer": "Because our sample size is greater than 30, the Central Limit Theorem tells us that the sampling distribution will approximate a normal distribution.  Because we know the population standard deviation and the sample size is large, we'll use the normal distribution to find probability.",
      "question": "Why is normal distribution used in sampling distribution"
    },
    {
      "answer": "We find the robust standard deviation estimate by multiplying the MAD by a factor that happens to have a value close to 1.5. This gives us a robust value ('sigma- hat') of B . . If we use this method on data without outliers, it provides estimates that are close to x and s, so no harm is done.",
      "question": "How is robust standard deviation calculated"
    },
    {
      "answer": "A statistical test provides a mechanism for making quantitative decisions about a process or processes. The intent is to determine whether there is enough evidence to \"reject\" a conjecture or hypothesis about the process.  A classic use of a statistical test occurs in process control studies.",
      "question": "What are statistical tests in research"
    },
    {
      "answer": "13. What is the difference between unimodal, bimodal, and multimodal data? Unimodal data has a distribution that is single-peaked (one mode). Bimodal data has two peaks (2 modes) and multimodal data refer to distributions with more than two clear peaks.",
      "question": "What is the difference between unimodal and multimodal"
    },
    {
      "answer": "In project management terms, an s-curve is a mathematical graph that depicts relevant cumulative data for a project\u2014such as cost or man-hours\u2014plotted against time.  An s-curve in project management is typically used to track the progress of a project.",
      "question": "What does an S curve represent"
    },
    {
      "answer": "K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.",
      "question": "What is K nearest Knn data mining algorithm"
    },
    {
      "answer": "Spark is capable of handling large-scale batch and streaming data to figure out when to cache data in memory and processing them up to 100 times faster than Hadoop-based MapReduce.  First, you will learn how to install Spark with all new features from the latest Spark 2.0 release.",
      "question": "Why is Spark efficient for large scale machine learning"
    },
    {
      "answer": "Hello every one, We know that Pearson linear correlation coefficient gives the strength of linear relationship, while Spearman rank correlation coefficient gives the strength of monotonic relationship between two variables.",
      "question": "Is rank correlation coefficient different from Pearson correlation coefficient explain with reason"
    },
    {
      "answer": "It is able to do this by using a novel form of reinforcement learning, in which AlphaGo Zero becomes its own teacher. The system starts off with a neural network that knows nothing about the game of Go. It then plays games against itself, by combining this neural network with a powerful search algorithm.",
      "question": "Does AlphaGo use reinforcement learning"
    },
    {
      "answer": "Classification is a data mining function that assigns items in a collection to target categories or classes. The goal of classification is to accurately predict the target class for each case in the data. For example, a classification model could be used to identify loan applicants as low, medium, or high credit risks.",
      "question": "What is data mining classification"
    },
    {
      "answer": "Matrix Inventory allows you to add and manage product lists that consist of similar items that are available in a variety of attributes, such as size or color.  Each product is defined by a combination of attributes is a unique product with its own price, inventory and/or recipe.",
      "question": "What is Matrix inventory"
    },
    {
      "answer": "Since a Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.",
      "question": "Why is naive Bayes used for text classification"
    },
    {
      "answer": "Standard interpretation of the ordered logit coefficient is that for a one unit increase in the predictor, the response variable level is expected to change by its respective regression coefficient in the ordered log-odds scale while the other variables in the model are held constant.",
      "question": "How do you interpret ordered logit coefficients"
    },
    {
      "answer": "The formula is:P(A|B) = P(A) P(B|A)P(B)P(Man|Pink) = P(Man) P(Pink|Man)P(Pink)P(Man|Pink) = 0.4 \u00d7 0.1250.25 = 0.2.Both ways get the same result of ss+t+u+v.P(A|B) = P(A) P(B|A)P(B)P(Allergy|Yes) = P(Allergy) P(Yes|Allergy)P(Yes)P(Allergy|Yes) = 1% \u00d7 80%10.7% = 7.48%More items",
      "question": "How do you calculate Bayesian probability"
    },
    {
      "answer": "Difference between Z score vs T score. Z score is a conversion of raw data to a standard score, when the conversion is based on the population mean and population standard deviation.  T score is a conversion of raw data to the standard score when the conversion is based on the sample mean and sample standard deviation.",
      "question": "What is the difference between T score and Z score"
    },
    {
      "answer": "He doesn't explicitly betray Kaneki, but it seems like it because someone who seemed like such a nice guy, giving advice to Kaneki and helping retrieve him from Aogiri, ended up being a sadistic and manipulative person.",
      "question": "Did Uta betray kaneki"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What is a variance in statistics"
    },
    {
      "answer": "Put simply: random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction. Random forest has nearly the same hyperparameters as a decision tree or a bagging classifier.  Random forest adds additional randomness to the model, while growing the trees.",
      "question": "How does a Random Forest model work"
    },
    {
      "answer": "We can say that, when we move from RNN to LSTM, we are introducing more & more controlling knobs, which control the flow and mixing of Inputs as per trained Weights. And thus, bringing in more flexibility in controlling the outputs. So, LSTM gives us the most Control-ability and thus, Better Results.",
      "question": "Why is Lstm better than RNN"
    },
    {
      "answer": "When examining the distribution of a quantitative variable, one should describe the overall pattern of the data (shape, center, spread), and any deviations from the pattern (outliers).",
      "question": "How do you describe the distribution"
    },
    {
      "answer": "To find the interquartile range (IQR), \u200bfirst find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.",
      "question": "How do you determine the interquartile range"
    },
    {
      "answer": "Cluster analysis, or clustering, is an unsupervised machine learning task. It involves automatically discovering natural grouping in data. Unlike supervised learning (like predictive modeling), clustering algorithms only interpret the input data and find natural groups or clusters in feature space.",
      "question": "What is a clustering algorithm"
    },
    {
      "answer": "A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input.",
      "question": "What are convolutional neural networks used for"
    },
    {
      "answer": "Entropy is the measure of disorder in a thermodynamic system.Difference Between Enthalpy and EntropyEnthalpy is a kind of energyEntropy is a propertyIt is the sum of internal energy and flows energyIt is the measurement of the randomness of moleculesIt is denoted by symbol HIt is denoted by symbol S5 more rows",
      "question": "What is the difference between entropy and entropy"
    },
    {
      "answer": "The logistic function is the inverse of the natural logit function and so can be used to convert the logarithm of odds into a probability. In mathematical notation the logistic function is sometimes written as expit in the same form as logit.",
      "question": "What is the logistic function used for"
    },
    {
      "answer": "If you want to ingest DynamoDB data into Redshift you have a few options.The Redshift Copy command.Build a Data Pipeline that copies the data using an EMR job to S3.Export the DynamoDB data to a file using the AWS CLI and load the flat file into Redshift.More items",
      "question": "How do I transfer data from DynamoDB to redshift"
    },
    {
      "answer": "An endogenous variable is a variable in a statistical model that's changed or determined by its relationship with other variables within the model.  Therefore, its values may be determined by other variables. Endogenous variables are the opposite of exogenous variables, which are independent variables or outside forces.",
      "question": "What is an endogenous variable in regression"
    },
    {
      "answer": "A continuous random variable takes a range of values, which may be finite or infinite in extent. Here are a few examples of ranges: [0, 1], [0, \u221e), (\u2212\u221e, \u221e), [a, b]. The function f(x) is called the probability density function (pdf).",
      "question": "What is range where X is a continuous random variable"
    },
    {
      "answer": "A mixed model, mixed-effects model or mixed error-component model is a statistical model containing both fixed effects and random effects.  Because of their advantage in dealing with missing values, mixed effects models are often preferred over more traditional approaches such as repeated measures ANOVA.",
      "question": "What is a mixed model in statistics"
    },
    {
      "answer": "ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network. The network uses memistors.  It is based on the McCulloch\u2013Pitts neuron. It consists of a weight, a bias and a summation function.",
      "question": "What is Adaline in neural network"
    },
    {
      "answer": "LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution. Given a dataset of documents, LDA backtracks and tries to figure out what topics would create those documents in the first place. LDA is a matrix factorization technique.",
      "question": "How does LDA modeling work"
    },
    {
      "answer": "Ridge regression is a term used to refer to a linear regression model whose coefficients are not estimated by ordinary least squares (OLS), but by an estimator, called ridge estimator, that is biased but has lower variance than the OLS estimator.",
      "question": "What is the difference between OLS and ridge regression"
    },
    {
      "answer": "The classic approach to the multiple comparison problem is to control the familywise error rate. Instead of setting the critical P level for significance, or alpha, to 0.05, you use a lower critical value.",
      "question": "How do you control multiple comparisons"
    },
    {
      "answer": "Conditional probability is defined as the likelihood of an event or outcome occurring, based on the occurrence of a previous event or outcome. Conditional probability is calculated by multiplying the probability of the preceding event by the updated probability of the succeeding, or conditional, event.",
      "question": "What do you mean by conditional probability"
    },
    {
      "answer": "They are often confused with each other. The 'K' in K-Means Clustering has nothing to do with the 'K' in KNN algorithm. k-Means Clustering is an unsupervised learning algorithm that is used for clustering whereas KNN is a supervised learning algorithm used for classification.",
      "question": "What is the difference between Knn and K means clustering"
    },
    {
      "answer": "Support Vector Machine algorithms are supervised learning models that analyse data used for classification and regression analysis. They essentially filter data into categories, which is achieved by providing a set of training examples, each set marked as belonging to one or the other of the two categories.",
      "question": "What is an algorithm in machine learning"
    },
    {
      "answer": "Boosting differs somewhat from bagging as it does not involve bootstrap sampling. Instead models are generated sequentially and iteratively, meaning that it is necessary to have information about model before iteration is produced. Boosting was motivated by Kearns and Valiant (1989).",
      "question": "Does boosting use bootstrapping"
    },
    {
      "answer": "Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.",
      "question": "What is transfer learning in ML"
    },
    {
      "answer": "Below are the methods to convert a categorical (string) input to numerical nature:Label Encoder: It is used to transform non-numerical labels to numerical labels (or nominal categorical variables).  Convert numeric bins to number: Let's say, bins of a continuous variable are available in the data set (shown below).",
      "question": "How do you deal with categorical variables in machine learning"
    },
    {
      "answer": "There are two types of sampling methods: Probability sampling involves random selection, allowing you to make statistical inferences about the whole group. Non-probability sampling involves non-random selection based on convenience or other criteria, allowing you to easily collect initial data.",
      "question": "What are the types of probability and non probability sampling"
    },
    {
      "answer": "The purpose of statistical inference is to estimate this sample to sample variation or uncertainty.",
      "question": "What is the purpose of statistical inference"
    },
    {
      "answer": "The first component is the definition: Two variables are independent when the distribution of one does not depend on the the other.  If the probabilities of one variable remains fixed, regardless of whether we condition on another variable, then the two variables are independent.",
      "question": "What does it mean if two variables are independent"
    },
    {
      "answer": "Deep Learning is a part of Machine Learning which is applied to larger data-sets and based on ANN (Artificial Neural Networks). The main technology used in NLP (Natural Language Processing) which mainly focuses on teaching natural/human language to computers.  NLP is a part of AI which overlaps with ML & DL.",
      "question": "Does NLP come under deep learning"
    },
    {
      "answer": "CRF is a discriminant model. MEMM is not a generative model, but a model with finite states based on state classification. HMM and MEMM are a directed graph, while CRF is an undirected graph. HMM directly models the transition probability and the phenotype probability, and calculates the probability of co-occurrence.",
      "question": "What is the major difference between CRF Conditional Random Field and HMM hidden Markov model"
    },
    {
      "answer": "5 Answers. The Fourier series is used to represent a periodic function by a discrete sum of complex exponentials, while the Fourier transform is then used to represent a general, nonperiodic function by a continuous superposition or integral of complex exponentials.",
      "question": "What is the relationship between the Fourier transform and Fourier series representation of a continuous function"
    },
    {
      "answer": "A correlation coefficient that is greater than zero indicates a positive relationship between two variables. A value that is less than zero signifies a negative relationship between two variables. Finally, a value of zero indicates no relationship between the two variables that are being compared.",
      "question": "What should the correlation of variable when compared with itself *"
    },
    {
      "answer": "In marketing terms, a multi-armed bandit solution is a 'smarter' or more complex version of A/B testing that uses machine learning algorithms to dynamically allocate traffic to variations that are performing well, while allocating less traffic to variations that are underperforming.",
      "question": "What is a bandit algorithm"
    },
    {
      "answer": "Spatiotemporal data mining refers to the process of discovering patterns and knowledge from spatiotemporal data.  Other examples of moving-object data mining include mining periodic patterns for one or a set of moving objects, and mining trajectory patterns, clusters, models, and outliers.",
      "question": "What is spatio temporal data mining"
    },
    {
      "answer": "ASUS EZ Flash 3 allows you to download and update to the latest BIOS through the Internet without having to use a bootable disk or an OS-based utility.",
      "question": "What is EZ flash"
    },
    {
      "answer": "Hickam's dictum",
      "question": "What's the opposite of Occam's razor"
    },
    {
      "answer": "Random utility theory is based on the hypothesis that every individual is a rational decision-maker, maximizing utility relative to his or her choices. Specifically, the theory is based on the following assumptions.",
      "question": "What is random utility model"
    },
    {
      "answer": "In probability, an outcome is in event \"A and B\" only when the outcome is in both event A and event B. (Intersection) In a Venn Diagram, an element is in the intersection of \"A and B\" only when the element is in BOTH sets. Rule (for AND):",
      "question": "What is the and rule in probability"
    },
    {
      "answer": "Algorithms consist of instructions that are carried out (performed) one after another. Sequencing is the specific order in which instructions are performed in an algorithm. For example, a very simple algorithm for brushing teeth might consist of these steps: put toothpaste on toothbrush.",
      "question": "What is the difference between sequence and algorithm"
    },
    {
      "answer": "XFL teams will have two timeouts per half, one fewer than in the NFL. Halftime is 10 minutes, two minutes less than the NFL. Another attempt to shorten the game is not allowing coaches to challenge an official's ruling. All plays are subject to review by the replay official.",
      "question": "What rules are different in the XFL"
    },
    {
      "answer": "2 Key Challenges of Streaming Data and How to Solve ThemStreaming Data is Very Complex. Streaming data is particularly challenging to handle because it is continuously generated by an array of sources and devices and is delivered in a wide variety of formats.  Business Wants Data, But IT Can't Keep Up.",
      "question": "What are the challenges of data stream processing"
    },
    {
      "answer": "Linear regression is used to find the best fitting line between all the points of your dataset (by computing the minimum of a given distance), it does not, in itself, reduce the dimensionality of your data.",
      "question": "Is dimensionality reduction applicable in simple linear regression"
    },
    {
      "answer": "A paired t-test is used when we are interested in the difference between two variables for the same subject. Often the two variables are separated by time. For example, in the Dixon and Massey data set we have cholesterol levels in 1952 and cholesterol levels in 1962 for each subject.",
      "question": "Why would you use a paired t test"
    },
    {
      "answer": "General linear modeling in SPSS for Windows The general linear model (GLM) is a flexible statistical model that incorporates normally distributed dependent variables and categorical or continuous independent variables.",
      "question": "What is general linear model in SPSS"
    },
    {
      "answer": "The Basics of a One-Tailed Test Hypothesis testing is run to determine whether a claim is true or not, given a population parameter. A test that is conducted to show whether the mean of the sample is significantly greater than and significantly less than the mean of a population is considered a two-tailed test.",
      "question": "What do you mean by one tailed test and two tailed test"
    },
    {
      "answer": "An artificial neural network's learning rule or learning process is a method, mathematical logic or algorithm which improves the network's performance and/or training time.  Depending upon the process to develop the network there are three main models of machine learning: Unsupervised learning. Supervised learning.",
      "question": "What is learning in neural networks"
    },
    {
      "answer": "A moving average term in a time series model is a past error (multiplied by a coefficient). Let w t \u223c i i d N ( 0 , \u03c3 w 2 ) , meaning that the wt are identically, independently distributed, each with a normal distribution having mean 0 and the same variance.",
      "question": "What is moving average model in time series"
    },
    {
      "answer": "A factorial distribution happens when a set of variables are independent events. In other words, the variables don't interact at all; Given two events x and y, the probability of x doesn't change when you factor in y.",
      "question": "What is factorial distribution"
    },
    {
      "answer": "For many continuous random variables, we can define an extremely useful function with which to calculate probabilities of events associated to the random variable. In short, the PDF of a continuous random variable is the derivative of its CDF.",
      "question": "Is the derivative of the probability distribution function PDF just a cumulative distribution function cdf"
    },
    {
      "answer": "Global max pooling = ordinary max pooling layer with pool size equals to the size of the input (minus filter size + 1, to be precise). You can see that MaxPooling1D takes a pool_length argument, whereas GlobalMaxPooling1D does not.",
      "question": "What is Global Max pooling"
    },
    {
      "answer": "Naive Bayes works best when you have small training data set, relatively small features(dimensions). If you have huge feature list, the model may not give you accuracy, because the likelihood would be distributed and may not follow the Gaussian or other distribution.",
      "question": "When should we use naive Bayes"
    },
    {
      "answer": "Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.  Also known as deep neural learning or deep neural network.",
      "question": "What is deep learning in simple words"
    },
    {
      "answer": "At the point of non-differentiability, you can assign the derivative of the function at the point \u201cright next\u201d to the singularity and the algorithm will work fine. For example, in ReLU we can give the derivative of the function at zero as 0.",
      "question": "How do deep learning algorithms use ReLU if it is not differentiable at 0"
    },
    {
      "answer": "In mathematics, a Fourier transform (FT) is a mathematical transform that decomposes a function (often a function of time, or a signal) into its constituent frequencies, such as the expression of a musical chord in terms of the volumes and frequencies of its constituent notes.",
      "question": "What is Fourier transform in signals and systems"
    },
    {
      "answer": "User-Based Collaborative Filtering is a technique used to predict the items that a user might like on the basis of ratings given to that item by the other users who have similar taste with that of the target user. Many websites use collaborative filtering for building their recommendation system.",
      "question": "What is user based collaborative filtering"
    },
    {
      "answer": "In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers.  It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.",
      "question": "What is Perceptron in machine learning"
    },
    {
      "answer": "linear threshold unit (LTU) A linear threshold unit is a simple artificial neuron whose output is its thresholded total net input. That is, an LTU with threshold T calculates the weighted sum of its inputs, and then outputs 0 if this sum is less than T, and 1 if the sum is greater than T.",
      "question": "What is a linear threshold unit"
    },
    {
      "answer": "Communalities \u2013 This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.  They are the reproduced variances from the factors that you have extracted.",
      "question": "What is the meaning of communality in factor analysis"
    },
    {
      "answer": "An autocorrelation plot is designed to show whether the elements of a time series are positively correlated, negatively correlated, or independent of each other. (The prefix auto means \u201cself\u201d\u2014 autocorrelation specifically refers to correlation among the elements of a time series.)",
      "question": "What is an autocorrelation plot"
    },
    {
      "answer": "The main requirements that a clustering algorithm should satisfy are:scalability;dealing with different types of attributes;discovering clusters with arbitrary shape;minimal requirements for domain knowledge to determine input parameters;ability to deal with noise and outliers;More items",
      "question": "What are the requirements of clustering algorithms"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.",
      "question": "What is bootstrapping in machine learning"
    },
    {
      "answer": "While many people use the terms interchangeably, data science and big data analytics are unique fields, with the major difference being the scope.  Data science produces broader insights that concentrate on which questions should be asked, while big data analytics emphasizes discovering answers to questions being asked.",
      "question": "What is the difference between data science and data analytics"
    },
    {
      "answer": "Backpropagation only works during training the model on a dataset.  You run your model with the learned parameters (from Backpropagation) and best hyperparameters (from validation) once on the Test set and report the accuracy. You never learn anything, be it parameters or hyperparameters on the Test set.",
      "question": "How does backpropagation work between training validation and test sets"
    },
    {
      "answer": "Inverted dropout is a variant of the original dropout technique developed by Hinton et al. Just like traditional dropout, inverted dropout randomly keeps some weights and sets others to zero. In contrast, traditional dropout requires scaling to be implemented during the test phase.",
      "question": "What is inverted dropout"
    },
    {
      "answer": "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.",
      "question": "What does a normal distribution tell us"
    },
    {
      "answer": "An environment is everything in the world which surrounds the agent, but it is not a part of an agent itself. An environment can be described as a situation in which an agent is present. The environment is where agent lives, operate and provide the agent with something to sense and act upon it.",
      "question": "What is agent and environment in artificial intelligence"
    },
    {
      "answer": "Data are rarely randomly distributed in high-dimensions and are highly correlated, often with spurious correlations. The distances between a data point and its nearest and farthest neighbours can become equidistant in high dimensions, potentially compromising the accuracy of some distance-based analysis tools.",
      "question": "What are the implications of using highly dimensional data"
    },
    {
      "answer": "Recall that in order for a neural networks to learn, weights associated with neuron connections must be updated after forward passes of data through the network. These weights are adjusted to help reconcile the differences between the actual and predicted outcomes for subsequent forward passes.",
      "question": "How are weights updated in neural network"
    },
    {
      "answer": "Generative modeling is an unsupervised learning task in machine learning that involves automatically discovering and learning the regularities or patterns in input data in such a way that the model can be used to generate or output new examples that plausibly could have been drawn from the original dataset.",
      "question": "Are generative models unsupervised"
    },
    {
      "answer": "Covariance is when two variables vary with each other, whereas Correlation is when the change in one variable results in the change in another variable.Differences between Covariance and Correlation.CovarianceCorrelationCovariance can vary between -\u221e and +\u221eCorrelation ranges between -1 and +17 more rows\u2022",
      "question": "Should I use correlation or covariance"
    },
    {
      "answer": "A metric is a function that is used to judge the performance of your model. Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.",
      "question": "What is metrics in neural network"
    },
    {
      "answer": "Clustering starts by computing a distance between every pair of units that you want to cluster. A distance matrix will be symmetric (because the distance between x and y is the same as the distance between y and x) and will have zeroes on the diagonal (because every item is distance zero from itself).",
      "question": "What is distance matrix in clustering"
    },
    {
      "answer": "load_data function Loads the MNIST dataset. This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the MNIST homepage.",
      "question": "What is Mnist Load_data ()"
    },
    {
      "answer": "Dummy variables (sometimes called indicator variables) are used in regression analysis and Latent Class Analysis. As implied by the name, these variables are artificial attributes, and they are used with two or more categories or levels.",
      "question": "Why is it called a dummy variable"
    },
    {
      "answer": "Probability density function (PDF) is a statistical expression that defines a probability distribution (the likelihood of an outcome) for a discrete random variable (e.g., a stock or ETF) as opposed to a continuous random variable.",
      "question": "What does probability density function mean"
    },
    {
      "answer": "Artificial neural networks are forecasting methods that are based on simple mathematical models of the brain. They allow complex nonlinear relationships between the response variable and its predictors.",
      "question": "What are neural network models"
    },
    {
      "answer": "The short answer is yes\u2014because most regression models will not perfectly fit the data at hand. If you need a more complex model, applying a neural network to the problem can provide much more prediction power compared to a traditional regression.",
      "question": "Can neural networks be used for linear regression"
    },
    {
      "answer": "To predict a continuous value, you need to adjust your model (regardless whether it is Recurrent or Not) to the following conditions:Use a linear activation function for the final layer.Chose an appropriate cost function (square error loss is typically used to measure the error of predicting real values)",
      "question": "How can we make a neural network to predict a continuous variable"
    },
    {
      "answer": "In statistics and probability, quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. There is one fewer quantile than the number of groups created.",
      "question": "What is quantile distribution"
    },
    {
      "answer": "Features: The characteristics that define your problem. These are also called attributes. Parameters: The variables your algorithm is trying to tune to build an accurate model.",
      "question": "What are the features and parameters in machine learning"
    },
    {
      "answer": "Answer : Algorithm is a noun meaning some special process of solving a certain type of problem.  Whereas logarithm, again a noun, is the exponent of that power of a fixed number, called the base, which equals a given number, called the antilogarithm.",
      "question": "What is the difference between a logarithm and an algorithm"
    },
    {
      "answer": "To find the interquartile range (IQR), \u200bfirst find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.",
      "question": "How do you find the interquartile range"
    },
    {
      "answer": "Once you have calculated the decimal values of each percentage for each given sample size, you then add these decimal values together and divide the total number by the total sum of both sample sizes. You then need to multiply this value by 100 to get the average percentage.5 days ago",
      "question": "How do you calculate the median percentage"
    },
    {
      "answer": "Stochastic Gradient Descent (SGD) addresses both of these issues by following the negative gradient of the objective after seeing only a single or a few training examples. The use of SGD In the neural network setting is motivated by the high cost of running back propagation over the full training set.",
      "question": "What is SGD in neural network"
    },
    {
      "answer": "Decision tree learning is generally best suited to problems with the following characteristics: Instances are represented by attribute-value pairs. There is a finite list of attributes (e.g. hair colour) and each instance stores a value for that attribute (e.g. blonde).",
      "question": "What type of problems are best suited for decision tree learning"
    },
    {
      "answer": "1 Answers found. A recursive filter has a system in which the output is directly dependent on one or more of its past outputs. But in a non recursive filter the system followed is the one in which the output is independent of any of the past outputs like, the feed-forward system where the system is having no feedback.",
      "question": "What is the main difference between recursive and non recursive filters in DSP"
    },
    {
      "answer": "The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.  Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level.",
      "question": "What is calibrated probability"
    },
    {
      "answer": "So, assuming a 15% survey response rate, we see that you should send your NPS survey to 1,700 customers. What if you're a smaller company and don't have enough customers to send the recommended number of invitations?",
      "question": "What is a good sample size for NPS"
    },
    {
      "answer": "Fisher's exact test obtains its two-tailed P value by computing the probabilities associated with all possible tables that have the same row and column totals. Then, it identifies the alternative tables with a probability that is less than that of the observed table.",
      "question": "What is an intuitive explanation of the Fisher exact test"
    },
    {
      "answer": "The loss function of SVM is very similar to that of Logistic Regression. Looking at it by y = 1 and y = 0 separately in below plot, the black line is the cost function of Logistic Regression, and the red line is for SVM. Please note that the X axis here is the raw model output, \u03b8\u1d40x.",
      "question": "What is the loss function for SVM"
    },
    {
      "answer": "This task of identifying the best subset of predictors to include in the model, among all possible subsets of predictors, is referred to as variable selection.",
      "question": "What is variable selection in regression"
    },
    {
      "answer": "It's a method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.",
      "question": "What is a loss function machine learning"
    },
    {
      "answer": "Standard Deviation: The Difference. The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean.",
      "question": "Is the standard deviation the error"
    },
    {
      "answer": "Criteria for CausalityStrength: A relationship is more likely to be causal if the correlation coefficient is large and statistically significant.Consistency: A relationship is more likely to be causal if it can be replicated.More items\u2022",
      "question": "How do you know if correlation is causation"
    },
    {
      "answer": "Stride is a parameter of the neural network's filter that modifies the amount of movement over the image or video. For example, if a neural network's stride is set to 1, the filter will move one pixel, or unit, at a time.",
      "question": "What is stride in deep learning"
    },
    {
      "answer": "The hazard rate measures the propensity of an item to fail or die depending on the age it has reached. It is part of a wider branch of statistics called survival analysis, a set of methods for predicting the amount of time until a certain event occurs, such as the death or failure of an engineering system or component.",
      "question": "What is hazard rate in survival analysis"
    },
    {
      "answer": "Linear discriminant function analysis (i.e., discriminant analysis) performs a multivariate test of differences between groups.  In addition, discriminant analysis is used to determine the minimum number of dimensions needed to describe these differences.",
      "question": "What is discriminant analysis in SPSS"
    },
    {
      "answer": "Path analysis is a special case of SEM.  Most of the models that you will see in the literature are SEM rather than path analyses. The main difference between the two types of models is that path analysis assumes that all variables are measured without error. SEM uses latent variables to account for measurement error.",
      "question": "What is the difference between path analysis and SEM"
    },
    {
      "answer": "The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.  The C parameter trades off correct classification of training examples against maximization of the decision function's margin.",
      "question": "What is C and gamma in SVM"
    },
    {
      "answer": "Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.",
      "question": "What is a deep learning model"
    },
    {
      "answer": "Structured data is highly specific and is stored in a predefined format, where unstructured data is a conglomeration of many varied types of data that are stored in their native formats. This means that structured data takes advantage of schema-on-write and unstructured data employs schema-on-read.",
      "question": "What is structured and unstructured data"
    },
    {
      "answer": "Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression.  A Random Forest operates by constructing several decision trees during training time and outputting the mean of the classes as the prediction of all the trees.",
      "question": "What is a Random Forest Regression"
    },
    {
      "answer": "Prior probability represents what is originally believed before new evidence is introduced, and posterior probability takes this new information into account.  A posterior probability can subsequently become a prior for a new updated posterior probability as new information arises and is incorporated into the analysis.",
      "question": "What is the difference between prior and posterior probabilities"
    },
    {
      "answer": "It is the sum of the likelihood residuals. At record level, the natural log of the error (residual) is calculated for each record, multiplied by minus one, and those values are totaled.",
      "question": "What is the log likelihood in logistic regression"
    },
    {
      "answer": "A bias vector is an additional set of weights in a neural network that require no input, and this it corresponds to the output of an artificial neural network when it has zero input. Bias represents an extra neuron included with each pre-output layer and stores the value of \u201c1,\u201d for each action.",
      "question": "What is bias in convolutional neural network"
    },
    {
      "answer": "In information theory, the graph entropy is a measure of the information rate achievable by communicating symbols over a channel in which certain pairs of values may be confused. This measure, first introduced by K\u00f6rner in the 1970s, has since also proven itself useful in other settings, including combinatorics.",
      "question": "What is an entropy of Graph Is it related to concept of entropy in Information Theory"
    },
    {
      "answer": "In spatial analysis, four major problems interfere with an accurate estimation of the statistical parameter: the boundary problem, scale problem, pattern problem (or spatial autocorrelation), and modifiable areal unit problem.  In analysis with area data, statistics should be interpreted based upon the boundary.",
      "question": "What are spatial problems"
    },
    {
      "answer": "The binomial distribution model allows us to compute the probability of observing a specified number of \"successes\" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure.",
      "question": "What are binomial distributions used for"
    },
    {
      "answer": "AUC and accuracy are fairly different things.  For a given choice of threshold, you can compute accuracy, which is the proportion of true positives and negatives in the whole data set. AUC measures how true positive rate (recall) and false positive rate trade off, so in that sense it is already measuring something else.",
      "question": "What is the difference between accuracy and AUC"
    },
    {
      "answer": "SGD is a variant of gradient descent. Instead of performing computations on the whole dataset \u2014 which is redundant and inefficient \u2014 SGD only computes on a small subset or random selection of data examples.  Essentially Adam is an algorithm for gradient-based optimization of stochastic objective functions.",
      "question": "What is the difference between SGD and Adam"
    },
    {
      "answer": "It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance. In this tutorial, you will discover the rectified linear activation function for deep learning neural networks.",
      "question": "Why is the ReLU activation function used the most often in neural networks for computer vision"
    },
    {
      "answer": "StepsStep 1: For each (x,y) point calculate x2 and xy.Step 2: Sum all x, y, x2 and xy, which gives us \u03a3x, \u03a3y, \u03a3x2 and \u03a3xy (\u03a3 means \"sum up\")Step 3: Calculate Slope m:m = N \u03a3(xy) \u2212 \u03a3x \u03a3y N \u03a3(x2) \u2212 (\u03a3x)2Step 4: Calculate Intercept b:b = \u03a3y \u2212 m \u03a3x N.Step 5: Assemble the equation of a line.",
      "question": "What is the least squares regression formula"
    },
    {
      "answer": "The most common evaluation metric that is used in object recognition tasks is 'mAP', which stands for 'mean average precision'. It is a number from 0 to 100 and higher values are typically better, but it's value is different from the accuracy metric in classification.",
      "question": "What is mAP object detection"
    },
    {
      "answer": "To calculate permutations, we use the equation nPr, where n is the total number of choices and r is the amount of items being selected. To solve this equation, use the equation nPr = n! / (n - r)!.",
      "question": "How do you calculate permutations"
    },
    {
      "answer": "Understanding the differences Detection refers to mining insights or information in a data pool when it is being processed.  Prediction or predictive analysis employs probability based on the data analyses and processing.",
      "question": "What is the difference between detection and prediction"
    },
    {
      "answer": "Cluster sampling is best used when the clusters occur naturally in a population, when you don't have access to the entire population, and when the clusters are geographically convenient. However, cluster sampling is not as precise as simple random sampling or stratified random sampling.",
      "question": "When should cluster sampling be used"
    },
    {
      "answer": "The mean value of x is thus the first moment of its distribution, while the fact that the probability distribution is normalized means that the zeroth moment is always 1.  The variance of x is thus the second central moment of the probability distribution when xo is the mean value or first moment.",
      "question": "What are moments prove that first moment is average and second moment is variance"
    },
    {
      "answer": "Here are five ways, but it really all boils down to stretching your brain by learning new things:Become a renaissance man. Or woman.  Play the brain game Dual N-Back. Do this 20 minutes a day.  Do regular high cardio exercise.  Learn an instrument.  Buy the book Boost Your IQ by Carolyn Skitt, and play all the games.",
      "question": "How do you get genius level intelligence"
    },
    {
      "answer": "Mean: the average score, calculated by dividing the sum of scores by the number of examinees.  Median: the middle raw score of the distribution; 50 percent of the obtained raw scores are higher and 50 percent are lower than the median.",
      "question": "What does distribution of scores mean"
    },
    {
      "answer": "The three main metrics used to evaluate a classification model are accuracy, precision, and recall. Accuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.",
      "question": "How do you evaluate machine learning models"
    },
    {
      "answer": "Word sense disambiguation, in natural language processing (NLP), may be defined as the ability to determine which meaning of word is activated by the use of word in a particular context.  Lexical ambiguity, syntactic or semantic, is one of the very first problem that any NLP system faces.",
      "question": "What is word sense disambiguation give example"
    },
    {
      "answer": "Many algorithms have been used in measuring user similarity or item similarity in recommender systems. For example, the k-nearest neighbor (k-NN) approach and the Pearson Correlation as first implemented by Allen.",
      "question": "Which algorithm is used in recommendation system"
    },
    {
      "answer": "If the weights are zero, complexity of the whole deep net would be the same as that of a single neuron and the predictions would be nothing better than random. Nodes that are side-by-side in a hidden layer connected to the same inputs must have different weights for the learning algorithm to update the weights.",
      "question": "Is random weight assignment better than assigning weights to the units in the hidden layer"
    },
    {
      "answer": "Sample variance Concretely, the naive estimator sums the squared deviations and divides by n, which is biased.  The sample mean, on the other hand, is an unbiased estimator of the population mean \u03bc. Note that the usual definition of sample variance is. , and this is an unbiased estimator of the population variance.",
      "question": "Is the sample variance an unbiased estimator"
    },
    {
      "answer": "The significance level, also denoted as alpha or \u03b1, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference.",
      "question": "What is Alpha in statistics significance level"
    },
    {
      "answer": "The main difference between cluster sampling and stratified sampling is that in cluster sampling the cluster is treated as the sampling unit so sampling is done on a population of clusters (at least in the first stage). In stratified sampling, the sampling is done on elements within each stratum.",
      "question": "What is the difference between cluster sampling and stratified sampling"
    },
    {
      "answer": "Train and serve a TensorFlow model with TensorFlow ServingTable of contents.Create your model. Import the Fashion MNIST dataset. Train and evaluate your model.Save your model.Examine your saved model.Serve your model with TensorFlow Serving. Add TensorFlow Serving distribution URI as a package source:  Make a request to your model in TensorFlow Serving. Make REST requests.",
      "question": "How do you use TensorFlow serving"
    },
    {
      "answer": "Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models.",
      "question": "What is data preprocessing in machine learning"
    },
    {
      "answer": "In probability, and statistics, a multivariate random variable or random vector is a list of mathematical variables each of whose value is unknown, either because the value has not yet occurred or because there is imperfect knowledge of its value.  Normally each element of a random vector is a real number.",
      "question": "What is a multivariate variable"
    },
    {
      "answer": "To calculate the variance follow these steps:Work out the Mean (the simple average of the numbers)Then for each number: subtract the Mean and square the result (the squared difference).Then work out the average of those squared differences. (Why Square?)",
      "question": "How do you calculate sample variance"
    },
    {
      "answer": "Poisson regression assumes the response variable Y has a Poisson distribution, and assumes the logarithm of its expected value can be modeled by a linear combination of unknown parameters. A Poisson regression model is sometimes known as a log-linear model, especially when used to model contingency tables.",
      "question": "How does Poisson regression work"
    },
    {
      "answer": "Business Uses The K-means clustering algorithm is used to find groups which have not been explicitly labeled in the data. This can be used to confirm business assumptions about what types of groups exist or to identify unknown groups in complex data sets.",
      "question": "What is K means used for"
    },
    {
      "answer": "Semantic similarity is calculated based on two semantic vectors. An order vector is formed for each sentence which considers the syntactic similarity between the sentences. Finally, semantic similarity is calculated based on semantic vectors and order vectors.",
      "question": "How do you find the semantic similarity between two words"
    },
    {
      "answer": "Batch normalization is a layer that allows every layer of the network to do learning more independently. It is used to normalize the output of the previous layers. The activations scale the input layer in normalization.",
      "question": "What is batch normalization CNN"
    },
    {
      "answer": "SVD, or Singular Value Decomposition, is one of several techniques that can be used to reduce the dimensionality, i.e., the number of columns, of a data set.  SVD is an algorithm that factors an m x n matrix, M, of real or complex values into three component matrices, where the factorization has the form USV*.",
      "question": "How does SVD help in dimensionality reduction"
    },
    {
      "answer": "7.2. Radial basis function (RBF) networks are a commonly used type of artificial neural network for function approximation problems. Radial basis function networks are distinguished from other neural networks due to their universal approximation and faster learning speed.",
      "question": "Which function popularly we used in RBF network"
    },
    {
      "answer": "Frequency is not quantized, and has a continuous spectrum. As such, a photon can have any energy, as E=\u210f\u03c9. However, quantum mechanically, if a particle is restricted by a potential, i.e. for V\u22600, the energy spectrum is discrete.",
      "question": "Is frequency quantized"
    },
    {
      "answer": "- Chad Orzel - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the Uncertainty Principle"
    },
    {
      "answer": "The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution.",
      "question": "Why is distribution important in statistics"
    },
    {
      "answer": "Random field theory (RFT) is a recent body of mathematics defining theo- retical results for smooth statistical maps.  The way that RFT solves this problem is by using results that give the expected Euler characteristic (EC) for a smooth statistical map that has been thresholded.",
      "question": "What is random field theory"
    },
    {
      "answer": "\u201cThe benefit to using a one-tailed test is that it requires fewer subjects to reach significance. A two-tailed test splits your significance level and applies it in both directions. Thus, each direction is only half as strong as a one-tailed test, which puts all the significance in one direction.",
      "question": "What is the primary benefit of conducting a one tailed test instead of a two tailed test"
    },
    {
      "answer": "Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.",
      "question": "What are GANs in machine learning"
    },
    {
      "answer": "Mean, variance, and standard deviation The mean of the sampling distribution of the sample mean will always be the same as the mean of the original non-normal distribution. In other words, the sample mean is equal to the population mean.",
      "question": "Is the sample mean equal to the population mean"
    },
    {
      "answer": "Unconscious racial stereotypes are a major example of implicit bias. In other words, having an automatic preference for one race over another without even being aware of this bias.",
      "question": "What is implicit bias example"
    },
    {
      "answer": "Target Concept Term used in the machine learning literature to denote the Bayes decision rule, or the regression function, depending on the context. The target concept is a member of the concept space. Synonyms: Bayes Decision Rule in classification, Regression Function in regression.",
      "question": "What is the target concept in machine learning"
    },
    {
      "answer": "N-grams are contiguous sequences of n-items in a sentence. N can be 1, 2 or any other positive integers, although usually we do not consider very large N because those n-grams rarely appears in many different places.  This post describes several different ways to generate n-grams quickly from input sentences in Python.",
      "question": "What is N grams Python"
    },
    {
      "answer": "Descriptive studies only describe the current state of a variable, so there are no presumed cause or effects, therefore no independent and dependent variables.  Since neither variable in a correlational design is manipulated, it is impossible to determine which is the cause and which is the effect.",
      "question": "Why are dependent and independent variables not applicable in a descriptive type of research"
    },
    {
      "answer": "Dropout is a regularization technique for neural network models proposed by Srivastava, et al. in their 2014 paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting (download the PDF). Dropout is a technique where randomly selected neurons are ignored during training. They are \u201cdropped-out\u201d randomly.",
      "question": "What is dropout rate in deep learning"
    },
    {
      "answer": "In computational mathematics, an iterative method is a mathematical procedure that uses an initial value to generate a sequence of improving approximate solutions for a class of problems, in which the n-th approximation is derived from the previous ones.",
      "question": "What is the condition for iterative method"
    },
    {
      "answer": "Altman's Z-Score model is a numerical measurement that is used to predict the chances of a business going bankrupt in the next two years. The model was developed by American finance professor Edward Altman in 1968 as a measure of the financial stability of companies.",
      "question": "What is Altman's Z score model"
    },
    {
      "answer": "A feedforward neural network is a biologically inspired classification algorithm. It consist of a (possibly large) number of simple neuron-like processing units, organized in layers. Every unit in a layer is connected with all the units in the previous layer.  This is why they are called feedforward neural networks.",
      "question": "What is meant by feed forward neural network"
    },
    {
      "answer": "The chi-square test is a hypothesis test designed to test for a statistically significant relationship between nominal and ordinal variables organized in a bivariate table. In other words, it tells us whether two variables are independent of one another.  The chi-square test is sensitive to sample size.",
      "question": "Is Chi square bivariate analysis"
    },
    {
      "answer": "For large samples, the sample proportion is approximately normally distributed, with mean \u03bc\u02c6P=p. and standard deviation \u03c3\u02c6P=\u221apqn. A sample is large if the interval [p\u22123\u03c3\u02c6p,p+3\u03c3\u02c6p] lies wholly within the interval [0,1].",
      "question": "How do you find a sample proportion"
    },
    {
      "answer": "The \"Fast Fourier Transform\" (FFT) is an important measurement method in the science of audio and acoustics measurement. It converts a signal into individual spectral components and thereby provides frequency information about the signal.",
      "question": "What is the purpose of FFT"
    },
    {
      "answer": "The weaknesses of decision tree methods : Decision trees are less appropriate for estimation tasks where the goal is to predict the value of a continuous attribute. Decision trees are prone to errors in classification problems with many class and relatively small number of training examples.",
      "question": "What are the issues in decision tree induction"
    },
    {
      "answer": "A one-sided argument (also known as card stacking, stacking the deck, ignoring the counterevidence, slanting, and suppressed evidence) is an informal fallacy that occurs when only the reasons supporting a proposition are supplied, while all reasons opposing it are omitted.",
      "question": "What fallacy involves a deliberate selection of data to support only one side of an issue"
    },
    {
      "answer": "The availability heuristic is a mental shortcut that helps us make a decision based on how easy it is to bring something to mind.  The representativeness heuristic is a mental shortcut that helps us make a decision by comparing information to our mental prototypes.",
      "question": "What is the difference between representative and availability heuristics"
    },
    {
      "answer": "Deep learning neural networks are trained using the stochastic gradient descent optimization algorithm. The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.",
      "question": "Why is learning rate used in gradient descent optimization"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What exactly is variance"
    },
    {
      "answer": "Normal Approximation to the Binomialn is your sample size,p is your given probability.q is just 1 \u2013 p. For example, let's say your probability p is . You would find q by subtracting this probability from 1: q = 1 \u2013 . 6 = .",
      "question": "How do you find the probability of normal approximation"
    },
    {
      "answer": "In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of successes (random draws for which the object drawn has a specified feature) in draws, without replacement, from a finite population of size that contains exactly objects with",
      "question": "What is hypergeometric distribution in statistics"
    },
    {
      "answer": "With binary data the variance is a function of the mean, and in particular is not constant as the mean changes. This violates one of the standard linear regression assumptions that the variance of the residual errors is constant.",
      "question": "Why linear regression is not suitable for modeling binary responses"
    },
    {
      "answer": "Quota sampling is different from stratified sampling, because in a stratified sample individuals within each stratum are selected at random. Quota sampling achieves a representative age distribution, but it isn't a random sample, because the sampling frame is unknown.",
      "question": "Is quota sampling random"
    },
    {
      "answer": "To see the accuracy of clustering process by using K-Means clustering method then calculated the square error value (SE) of each data in cluster 2. The value of square error is calculated by squaring the difference of the quality score or GPA of each student with the value of centroid cluster 2.",
      "question": "How do you find the accuracy of K means clustering"
    },
    {
      "answer": "A disadvantage is when researchers can't classify every member of the population into a subgroup. Stratified random sampling is different from simple random sampling, which involves the random selection of data from the entire population so that each possible sample is equally likely to occur.",
      "question": "What are the disadvantages of stratified sampling"
    },
    {
      "answer": "Bias allows you to shift the activation function by adding a constant (i.e. the given bias) to the input. Bias in Neural Networks can be thought of as analogous to the role of a constant in a linear function, whereby the line is effectively transposed by the constant value.",
      "question": "What are biases in neural network"
    },
    {
      "answer": "Ridge and lasso regression allow you to regularize (\"shrink\") coefficients. This means that the estimated coefficients are pushed towards 0, to make them work better on new data-sets (\"optimized for prediction\"). This allows you to use complex models and avoid over-fitting at the same time.",
      "question": "Why do we use Ridge and lasso regression"
    },
    {
      "answer": "Endogenous variables are used in econometrics and sometimes in linear regression. They are similar to (but not exactly the same as) dependent variables. Endogenous variables have values that are determined by other variables in the system (these \u201cother\u201d variables are called exogenous variables).",
      "question": "How do you find endogenous variables"
    },
    {
      "answer": "The purpose of an inverted index is to allow fast full-text searches, at a cost of increased processing when a document is added to the database. The inverted file may be the database file itself, rather than its index.",
      "question": "What are the uses of an inverted index"
    },
    {
      "answer": "Because it arises from consistency between parts of a test, split-half reliability is an \u201cinternal consistency\u201d approach to estimating reliability. This result is an estimate of the reliability of the test scores, and it provides some support for the quality of the test scores.",
      "question": "Why is split half reliability important"
    },
    {
      "answer": "The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(\u2217). Both functions will take any number and rescale it to fall between 0 and 1.",
      "question": "What is the difference between logit and probit regression"
    },
    {
      "answer": "Here are 11 tips for making the most of your large data sets.Cherish your data. \u201cKeep your raw data raw: don't manipulate it without having a copy,\u201d says Teal.  Visualize the information.Show your workflow.  Use version control.  Record metadata.  Automate, automate, automate.  Make computing time count.  Capture your environment.More items\u2022",
      "question": "How do you handle large datasets"
    },
    {
      "answer": "We call vectorization the general process of turning a collection of text documents into numerical feature vectors.  Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.",
      "question": "What is feature vectorization"
    },
    {
      "answer": "Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel. This is related to a form of mathematical convolution. The matrix operation being performed\u2014convolution\u2014is not traditional matrix multiplication, despite being similarly denoted by *.",
      "question": "What is convolution in an image"
    },
    {
      "answer": "R is a very dynamic and versatile programming language for data science. This article deals with classification in R. Generally classifiers in R are used to predict specific category related information like reviews or ratings such as good, best or worst. Various Classifiers are: Decision Trees.",
      "question": "What is R classification"
    },
    {
      "answer": "Leaky ReLU & Parametric ReLU (PReLU) Leaky ReLU has two benefits: It fixes the \u201cdying ReLU\u201d problem, as it doesn't have zero-slope parts. It speeds up training. There is evidence that having the \u201cmean activation\u201d be close to 0 makes training faster.",
      "question": "What are the advantages of using Leaky Rectified Linear Units Leaky ReLU over normal ReLU in deep learning"
    },
    {
      "answer": "7 Practical Guidelines for Accurate Statistical Model BuildingRemember that regression coefficients are marginal results.  Start with univariate descriptives and graphs.  Next, run bivariate descriptives, again including graphs.  Think about predictors in sets.  Model building and interpreting results go hand-in-hand.More items",
      "question": "How do you develop a statistical model"
    },
    {
      "answer": "A population is called multinomial if its data is categorical and belongs to a collection of discrete non-overlapping classes. The null hypothesis for goodness of fit test for multinomial distribution is that the observed frequency fi is equal to an expected count ei in each category.",
      "question": "What is multinomial population"
    },
    {
      "answer": "The coefficient of variation (CV) is the ratio of the standard deviation to the mean. The higher the coefficient of variation, the greater the level of dispersion around the mean.  The lower the value of the coefficient of variation, the more precise the estimate.",
      "question": "Is it better to have a higher or lower coefficient of variation"
    },
    {
      "answer": "Two determine if two images are rotated versions of each other, one can either exhaustively rotate them in order to find out if the two match up at some angle, or alternatively extract features from the images that can then be compared to make the same decision.",
      "question": "What is rotation invariant in image processing"
    },
    {
      "answer": "Linear models describe a continuous response variable as a function of one or more predictor variables. They can help you understand and predict the behavior of complex systems or analyze experimental, financial, and biological data.",
      "question": "What do you mean by linear model"
    },
    {
      "answer": "Three reasons that you should NOT use deep learning(1) It doesn't work so well with small data. To achieve high performance, deep networks require extremely large datasets.  (2) Deep Learning in practice is hard and expensive. Deep learning is still a very cutting edge technique.  (3) Deep networks are not easily interpreted.",
      "question": "When should you not use deep learning"
    },
    {
      "answer": "Batch processing requires separate programs for input, process and output.  In contrast, real time data processing involves a continual input, process and output of data. Data must be processed in a small time period (or near real time). Radar systems, customer services and bank ATMs are examples.",
      "question": "What is the difference between batch processing and real time processing"
    },
    {
      "answer": "Step 1: Load Python packages.  Step 2: Pre-Process the data.  Step 3: Subset the data.  Step 4: Split the data into train and test sets.  Step 5: Build a Random Forest Classifier.  Step 6: Predict.  Step 7: Check the Accuracy of the Model.  Step 8: Check Feature Importance.",
      "question": "How do you create a classification model"
    },
    {
      "answer": "The \u201ctrick\u201d is that kernel methods represent the data only through a set of pairwise similarity comparisons between the original data observations x (with the original coordinates in the lower dimensional space), instead of explicitly applying the transformations \u03d5(x) and representing the data by these transformed",
      "question": "What is the kernel trick SVM"
    },
    {
      "answer": "If I know a programming language, where is a great place to start practicing algorithms?  Become proficient at written communication.  Learn Functional Programming.  Learn Object Oriented Analysis and Design.  Free Code Camp.More items\u2022",
      "question": "How can I begin to learn algorithms"
    },
    {
      "answer": "For an idea we are all familiar with, randomness is surprisingly hard to formally define. We think of a random process as something that evolves over time but in a way we can't predict.",
      "question": "Can we predict randomness"
    },
    {
      "answer": "The difference between the two norms is that the standard deviation is calculating the square of the difference whereas the mean absolute deviation is only looking at the absolute difference. Hence large outliers will create a higher dispersion when using the standard deviation instead of the other method.",
      "question": "What is the logical difference between mean deviation and standard deviation"
    },
    {
      "answer": "Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks.  Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents.",
      "question": "What does spreading activation mean"
    },
    {
      "answer": "Convolution is used in the mathematics of many fields, such as probability and statistics. In linear systems, convolution is used to describe the relationship between three signals of interest: the input signal, the impulse response, and the output signal.",
      "question": "What is the use of convolution"
    },
    {
      "answer": "In image processing, thresholding is used to split an image into smaller segments, or junks, using at least one color or gray scale value to define their boundary. The advantage of obtaining first a binary image is that it reduces the complexityof the data and simplifies the process of recognition and classification.",
      "question": "Why thresholding is used in image processing"
    },
    {
      "answer": "The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.",
      "question": "What is canny edge detection in image processing"
    },
    {
      "answer": "The geometric distribution would represent the number of people who you had to poll before you found someone who voted independent. You would need to get a certain number of failures before you got your first success. If you had to ask 3 people, then X=3; if you had to ask 4 people, then X=4 and so on.",
      "question": "What does a geometric distribution look like"
    },
    {
      "answer": "Measurement uncertainty is critical to risk assessment and decision making. Organizations make decisions every day based on reports containing quantitative measurement data. If measurement results are not accurate, then decision risks increase. Selecting the wrong suppliers, could result in poor product quality.",
      "question": "Why do statistics and uncertainties matter"
    },
    {
      "answer": "In practical terms, deep learning is just a subset of machine learning. In fact, deep learning technically is machine learning and functions in a similar way (hence why the terms are sometimes loosely interchanged).",
      "question": "Is deep learning a part of machine learning"
    },
    {
      "answer": "Time Series Forecast in RStep 1: Reading data and calculating basic summary.  Step 2: Checking the cycle of Time Series Data and Plotting the Raw Data.  Step 3: Decomposing the time series data.  Step 4: Test the stationarity of data.  Step 5: Fitting the model.  Step 6: Forecasting.",
      "question": "How do you forecast time series data"
    },
    {
      "answer": "Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.",
      "question": "How does machine learning collect data"
    },
    {
      "answer": "The hazard rate refers to the rate of death for an item of a given age (x). It is part of a larger equation called the hazard function, which analyzes the likelihood that an item will survive to a certain point in time based on its survival to an earlier time (t).",
      "question": "What is the hazard rate function"
    },
    {
      "answer": "The normal distribution is a probability function that describes how the values of a variable are distributed. It is a symmetric distribution where most of the observations cluster around the central peak and the probabilities for values further away from the mean taper off equally in both directions.",
      "question": "Which distribution is a normal distribution"
    },
    {
      "answer": "On the other hand, when the normal approximation is used to approximate a discrete distribution, a continuity correction can be employed so that we can approximate the probability of a specific value of the discrete distribution. The continuity correction requires adding or subtracting .",
      "question": "Why is the correction for continuity used when using the normal approximation to the binomial distribution"
    },
    {
      "answer": "It is a particular Monte Carlo method that numerically computes a definite integral. While other algorithms usually evaluate the integrand at a regular grid, Monte Carlo randomly chooses points at which the integrand is evaluated. This method is particularly useful for higher-dimensional integrals.",
      "question": "How does Monte Carlo integration work"
    },
    {
      "answer": "Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor. For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms.",
      "question": "Why is there a Bayesian network"
    },
    {
      "answer": "Although side effects believed to be caused by statins can be annoying, consider the benefits of taking a statin before you decide to stop taking your medication. Remember that statin medications can reduce your risk of a heart attack or stroke, and the risk of life-threatening side effects from statins is very low.",
      "question": "Are statins really worth taking"
    },
    {
      "answer": "2. Why is it important to examine a residual plot even if a scatterplot appears to be linear? An examination of the of the residuals often leads us to discover groups of observations that are different from the rest.",
      "question": "Why is it important to examine a residual plot"
    },
    {
      "answer": "Prediction bias is a quantity that measures how far apart those two averages are. That is: prediction bias = average of predictions \u2212 average of labels in data set. Note: \"Prediction bias\" is a different quantity than bias (the b in wx + b).",
      "question": "What is bias in classification"
    },
    {
      "answer": "The sample proportion, P is an unbiased estimator of the population proportion, . Unbiased estimators determines the tendency , on the average, for the statistics to assume values closed to the parameter of interest.",
      "question": "Is proportion a biased estimator"
    },
    {
      "answer": "Jakob Bernoulli",
      "question": "Who discovered the law of large numbers"
    },
    {
      "answer": "The top 5 AI developments as chosen by our team are as follows:The increased speed of AI-enabled medical research.  Computer vision, image, and video analysis technology is evolving.  Powerful AI-based tools become mainstream.  AI learns increasingly higher-level human functions.More items\u2022",
      "question": "What are the recent developments in AI"
    },
    {
      "answer": "Sampling is done because you usually cannot gather data from the entire population. Even in relatively small populations, the data may be needed urgently, and including everyone in the population in your data collection may take too long.",
      "question": "Why is sample survey done"
    },
    {
      "answer": "Association rule mining is a procedure which aims to observe frequently occurring patterns, correlations, or associations from datasets found in various kinds of databases such as relational databases, transactional databases, and other forms of repositories.",
      "question": "What is an association rule in data mining"
    },
    {
      "answer": "From Wikipedia, the free encyclopedia. Cohen's kappa coefficient (\u03ba) is a statistic that is used to measure inter-rater reliability (and also Intra-rater reliability) for qualitative (categorical) items.",
      "question": "What does Kappa mean in statistics"
    },
    {
      "answer": "Concepts in Machine Learning can be thought of as a boolean-valued function defined over a large set of training data.  We have some attributes/features of the day like, Sky, Air Temperature, Humidity, Wind, Water, Forecast and based on this we have a target Concept named EnjoySport.",
      "question": "What is ML concept"
    },
    {
      "answer": "It is one of the more common descriptive statistics functions used to calculate uncertainty.How to CalculateSubtract each value from the mean.Square each value in step 1.Add all of the values from step 2.Count the number of values and Subtract it by 1.Divide step 3 by step 4.Calculate the Square Root of step 5.",
      "question": "How do you calculate uncertainty in statistics"
    },
    {
      "answer": "One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.",
      "question": "Which of the following were introduced to overcome the vanishing gradient problem"
    },
    {
      "answer": "K-nearest neighbor is also used in retail to detect patterns in credit card usage. Many new transaction-scrutinizing software applications use kNN algorithms to analyze register data and spot unusual patterns that indicate suspicious activity.",
      "question": "What are industry applications of the K nearest neighbor algorithm"
    },
    {
      "answer": "One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.",
      "question": "What is the vanishing gradient problem and how do we overcome that"
    },
    {
      "answer": "Symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high-level \"symbolic\" (human-readable) representations of problems, logic and search.  Production rules connect symbols in a relationship similar to an If-Then statement.",
      "question": "What is symbolic machine learning"
    },
    {
      "answer": "Definition: The trend is the component of a time series that represents variations of low frequency in a time series, the high and medium frequency fluctuations having been filtered out.",
      "question": "What is trend in time series data"
    },
    {
      "answer": "Machine learning can be described in many ways. Perhaps the most useful is as type of optimization.  This is done via what is known as an objective function, with \u201cobjective\u201d used in the sense of a goal. This function, taking data and model parameters as arguments, can be evaluated to return a number.",
      "question": "What is an objective function in machine learning"
    },
    {
      "answer": "However, it is not necessary for you to learn the machine learning algorithms that are not a part of machine learning in order to learn deep learning. Instead, if you want to learn deep learning then you can go straight to learning the deep learning models if you want to.",
      "question": "Can I directly learn deep learning"
    },
    {
      "answer": "Cohen's kappa coefficient (\u03ba) is a statistic that is used to measure inter-rater reliability (and also Intra-rater reliability) for qualitative (categorical) items.",
      "question": "What is Cohen's kappa used for"
    },
    {
      "answer": "Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set.  Based on historical data about earlier outcomes involving the same input criteria, it then scores new cases on their probability of falling into a particular outcome category.",
      "question": "What is logistic regression in data science"
    },
    {
      "answer": "Analysis of variance (ANOVA) is an analysis tool used in statistics that splits an observed aggregate variability found inside a data set into two parts: systematic factors and random factors.  1\ufeff\ufeff2\ufeff ANOVA is also called the Fisher analysis of variance, and it is the extension of the t- and z-tests.",
      "question": "What is the concept of analysis of variance ANOVA in statistics"
    },
    {
      "answer": "The aim of distributional semantics is to learn the meanings of linguistic expressions from a corpus of text. The core idea, known as the distributional hy- pothesis, is that the contexts in which an expression appears give us information about its meaning.",
      "question": "What are the goals of distributional semantics"
    },
    {
      "answer": "Midrange determines the number that is halfway between the minimum and maximum numbers of a data set. It is a statistical tool that identifies a measure of center like median, mean or mode.",
      "question": "What is the mid range in statistics"
    },
    {
      "answer": "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.",
      "question": "What is Adam algorithm"
    },
    {
      "answer": "The least squares approach limits the distance between a function and the data points that the function explains. It is used in regression analysis, often in nonlinear regression modeling in which a curve is fit into a set of data. Mathematicians use the least squares method to arrive at a maximum-likelihood estimate.",
      "question": "Why do we use least square method"
    },
    {
      "answer": "Heuristics are the \"shortcuts\" that humans use to reduce task complexity in judgment and choice, and biases are the resulting gaps between normative behavior and the heuristically determined behavior (Kahneman et al., 1982).",
      "question": "What is the difference between a heuristic and a bias"
    },
    {
      "answer": "The coefficient of determination can also be found with the following formula: R2 = MSS/TSS = (TSS \u2212 RSS)/TSS, where MSS is the model sum of squares (also known as ESS, or explained sum of squares), which is the sum of the squares of the prediction from the linear regression minus the mean for that variable; TSS is the",
      "question": "What is the formula for calculating the coefficient of determination"
    },
    {
      "answer": "Mutual information is a quantity that measures a relationship between two random variables that are sampled simultaneously. In particular, it measures how much information is communicated, on average, in one random variable about another.",
      "question": "How does mutual information work"
    },
    {
      "answer": "The three main methods to perform linear regression analysis in Excel are: Regression tool included with Analysis ToolPak. Scatter chart with a trendline.",
      "question": "What method does Excel use for linear regression"
    },
    {
      "answer": "The Hidden layer of the neural network is the intermediate layer between Input and Output layer. Activation function applies on hidden layer if it is available.  Hidden nodes or hidden neurons are the neurons that are neither in the input layer nor the output layer [3].",
      "question": "What are hidden nodes in neural network"
    },
    {
      "answer": "Linear regression attempts to model the relationship between two variables by fitting a linear equation (= a straight line) to the observed data. One variable is considered to be an explanatory variable (e.g. your income), and the other is considered to be a dependent variable (e.g. your expenses).",
      "question": "How would linear regression be described and explained in laymans terms"
    },
    {
      "answer": "The independent variable is the variable the experimenter changes or controls and is assumed to have a direct effect on the dependent variable.  The dependent variable is the variable being tested and measured in an experiment, and is 'dependent' on the independent variable.",
      "question": "What is the independent variable in an experiment"
    },
    {
      "answer": "A Gaussian filter is a linear filter. It's usually used to blur the image or to reduce noise. If you use two of them and subtract, you can use them for \"unsharp masking\" (edge detection). The Gaussian filter alone will blur edges and reduce contrast.",
      "question": "What does a Gaussian filter do"
    },
    {
      "answer": "If you don't know your population mean (\u03bc) but you do know the standard deviation (\u03c3), you can find a confidence interval for the population mean, with the formula: x\u0304 \u00b1 z* \u03c3 / (\u221an),  Step 1: Subtract the confidence level (Given as 95 percent in the question) from 1 and then divide the result by two.",
      "question": "How are confidence intervals calculated"
    },
    {
      "answer": "\"A discrete variable is one that can take on finitely many, or countably infinitely many values\", whereas a continuous random variable is one that is not discrete, i.e. \"can take on uncountably infinitely many values\", such as a spectrum of real numbers.",
      "question": "What is the difference between discrete and continuous variables"
    },
    {
      "answer": "The sensitivity of the test reflects the probability that the screening test will be positive among those who are diseased. In contrast, the specificity of the test reflects the probability that the screening test will be negative among those who, in fact, do not have the disease.",
      "question": "How do you interpret sensitivity and specificity"
    },
    {
      "answer": "Reinforcement Learning (RL) refers to a kind of Machine Learning method in which the agent receives a delayed reward in the next time step to evaluate its previous action. It was mostly used in games (e.g. Atari, Mario), with performance on par with or even exceeding humans.",
      "question": "What is reinforcement learning algorithms"
    },
    {
      "answer": "For a discrete random variable, the expected value, usually denoted as or , is calculated using: \u03bc = E ( X ) = \u2211 x i f ( x i )",
      "question": "How do you find the expected value of a random variable"
    },
    {
      "answer": "The notation for the uniform distribution is X ~ U(a, b) where a = the lowest value of x and b = the highest value of x. The probability density function is f(x)=1b\u2212a f ( x ) = 1 b \u2212 a for a \u2264 x \u2264 b. For this example, X ~ U(0, 23) and f(x)=123\u22120 f ( x ) = 1 23 \u2212 0 for 0 \u2264 X \u2264 23.",
      "question": "How do you calculate uniform distribution"
    },
    {
      "answer": "A decision boundary is the region of a problem space in which the output label of a classifier is ambiguous. If the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable. Decision boundaries are not always clear cut.",
      "question": "What is decision boundary in SVM"
    },
    {
      "answer": "Propositional Logic converts a complete sentence into a symbol and makes it logical whereas in First-Order Logic relation of a particular sentence will be made that involves relations, constants, functions, and constants.",
      "question": "What is the difference between first order logic and propositional logic"
    },
    {
      "answer": "The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence.",
      "question": "What data is used to train vector space models of words such as word2vec"
    },
    {
      "answer": "4:1213:02Suggested clip \u00b7 101 secondsThe Transition Matrix - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you read a transition matrix"
    },
    {
      "answer": "Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. Improving operations. Many companies use predictive models to forecast inventory and manage resources.",
      "question": "What is predictive analytics used for"
    },
    {
      "answer": "Wilcoxon \u2013 The Wilcoxon signed rank test has the null hypothesis that both samples are from the same population.  Sign \u2013 The sign test has the null hypothesis that both samples are from the same population. The sign test compares the two dependent observations and counts the number of negative and positive differences.",
      "question": "What is the difference between sign test and Wilcoxon signed rank test"
    },
    {
      "answer": "Lasso regression performs L1 regularization, which adds a penalty equal to the absolute value of the magnitude of coefficients.  On the other hand, L2 regularization (e.g. Ridge regression) doesn't result in elimination of coefficients or sparse models. This makes the Lasso far easier to interpret than the Ridge.",
      "question": "How are Lasso and ridge regressions used for regularization"
    },
    {
      "answer": "The degree of freedom is not a property of the distribution, it's the name of the distribution. It refers to the number of degrees of freedom of some variable that has the distribution.",
      "question": "Statistics academic discipline What is an intuitive explanation of degrees of freedom"
    },
    {
      "answer": "Mathematically speaking, a decision tree has low bias and high variance. Averaging the result of many decision trees reduces the variance while maintaining that low bias. Combining trees is known as an 'ensemble method'.",
      "question": "Is decision tree an ensemble method"
    },
    {
      "answer": "Feature Selection. Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones.",
      "question": "What is feature selection and feature extraction"
    },
    {
      "answer": "In neural networks, Convolutional neural network (ConvNets or CNNs) is one of the main categories to do images recognition, images classifications. Objects detections, recognition faces etc., are some of the areas where CNNs are widely used.",
      "question": "What is convolutional neural network in image processing"
    },
    {
      "answer": "Any object, function, or statistic that doesn't change when scales are multiplied by a common factor is scale invariant. In statistics, it can also mean a statistic that tends not to change (i.e. 99% of the time, it will stay the same). Some specific statistics are scale invariant.",
      "question": "What is invariance in statistics"
    },
    {
      "answer": "Linear models describe a continuous response variable as a function of one or more predictor variables. They can help you understand and predict the behavior of complex systems or analyze experimental, financial, and biological data.",
      "question": "What is a linear model used for"
    },
    {
      "answer": "Each class will have a \u201clower class limit\u201d and an \u201cupper class limit\u201d which are the lowest and highest numbers in each class. The \u201cclass width\u201d is the distance between the lower limits of consecutive classes.",
      "question": "What is the difference between class size and class width"
    },
    {
      "answer": "A Binomial Regression model can be used to predict the odds of an event.  The Logistic Regression model is a special case of the Binomial Regression model in the situation where the size of each group of explanatory variables in the data set is one.",
      "question": "Is binomial regression the same as logistic regression"
    },
    {
      "answer": "Any good analysis of survey data from a stratified sample includes the same seven steps:Estimate a population parameter.Compute sample variance within each stratum.Compute standard error.Specify a confidence level.Find the critical value (often a z-score or a t-score).Compute margin of error.More items",
      "question": "How do you analyze stratified random sampling"
    },
    {
      "answer": "In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes\u2013no question, and each with its own Boolean-valued outcome: success/yes/true/one (with probability p)",
      "question": "What are the parameters of binomial distribution"
    },
    {
      "answer": "The name 'exponential smoothing' is attributed to the use of the exponential window function during convolution. It is no longer attributed to Holt, Winters & Brown. , and the weights assigned to previous observations are proportional to the terms of the geometric progression. .",
      "question": "Why is it called exponential smoothing"
    },
    {
      "answer": "The biggest flaw in this machine learning technique, according to Mittu, is that there is a large amount of art to building these networks, which means there are few scientific methods to help understand when they will fail.",
      "question": "What's wrong with deep learning"
    },
    {
      "answer": "This lesson explains how to conduct a chi-square goodness of fit test. The test is applied when you have one categorical variable from a single population. It is used to determine whether sample data are consistent with a hypothesized distribution.",
      "question": "What does the chi square goodness of fit test actually test"
    },
    {
      "answer": "Examples of Discrete Distribution The most common discrete probability distributions include binomial, Poisson, Bernoulli, and multinomial.",
      "question": "Which is an example of a discrete distribution"
    },
    {
      "answer": "Entropy is simply a measure of disorder and affects all aspects of our daily lives. In fact, you can think of it as nature's tax. Left unchecked disorder increases over time. Energy disperses, and systems dissolve into chaos.",
      "question": "What is entropy and why is it important"
    },
    {
      "answer": "In Computer science (especially Machine learning) Pruning means simplifying/compressing and optimizing a Decision tree by removing sections of the tree that are uncritical and redundant to classify instances.",
      "question": "How does pruning work in decision trees"
    },
    {
      "answer": "In such a sequence of trials, the geometric distribution is useful to model the number of failures before the first success. The distribution gives the probability that there are zero failures before the first success, one failure before the first success, two failures before the first success, and so on.",
      "question": "What is geometric distribution used for"
    },
    {
      "answer": "An ordinal variable is a categorical variable for which the possible values are ordered. Ordinal variables can be considered \u201cin between\u201d categorical and quantitative variables. Thus it does not make sense to take a mean of the values.",
      "question": "What type of variable is ordinal"
    },
    {
      "answer": "One of the key methodologies to improve efficiency in computational intensive tasks is to reduce the dimensions after ensuring most of the key information is maintained. It also eliminates features with strong correlation between them and reduces over-fitting.",
      "question": "When would you reduce dimensions in your data in machine learning"
    },
    {
      "answer": "The Antardasha of Mercury with Ketu Mahadasha can be evil and good depending on the placement of both Mercury and Ketu in the birth chart.  The antardasha of Mercury with Mahadasha of Ketu brings very bad results if the planet Mercury is weak, afflicted, aspect by Rahu, Saturn and Mars.",
      "question": "Is Ketu Mahadasha bad"
    },
    {
      "answer": "In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.",
      "question": "What is the mean of exponential distribution"
    },
    {
      "answer": "The main difference between the t-test and f-test is, that t-test is used to test the hypothesis whether the given mean is significantly different from the sample mean or not. On the other hand, an F-test is used to compare the two standard deviations of two samples and check the variability.",
      "question": "What is the difference between F and T test"
    },
    {
      "answer": "The range can also be used to estimate another measure of spread, the standard deviation. Rather than go through a fairly complicated formula to find the standard deviation, we can instead use what is called the range rule. The range is fundamental in this calculation.",
      "question": "What are the uses of the range in statistics and what are the areas that we use range for calculations in statistics"
    },
    {
      "answer": "Grid-searching is the process of scanning the data to configure optimal parameters for a given model.  Grid-searching can be applied across machine learning to calculate the best parameters to use for any given model.",
      "question": "What is grid search in machine learning"
    },
    {
      "answer": "The P-value is the probability that a chi-square statistic having 2 degrees of freedom is more extreme than 19.58. We use the Chi-Square Distribution Calculator to find P(\u03a72 > 19.58) = 0.0001.",
      "question": "What is the relationship between p value and chi square"
    },
    {
      "answer": "Discriminant analysis is a versatile statistical method often used by market researchers to classify observations into two or more groups or categories. In other words, discriminant analysis is used to assign objects to one group among a number of known groups.",
      "question": "What is the purpose of discriminant analysis"
    },
    {
      "answer": "Preventing the error gradients from vanishing The presence of the forget gate's activations allows the LSTM to decide, at each time step, that certain information should not be forgotten and to update the model's parameters accordingly. and the gradient doesn't vanish.",
      "question": "How does LSTM help prevent the vanishing and exploding gradient problem in a recurrent neural network"
    },
    {
      "answer": "Spatiotemporal, or spatial temporal, is used in data analysis when data is collected across both space and time. It describes a phenomenon in a certain location and time \u2014 for example, shipping movements across a geographic area over time (see above example image).",
      "question": "What is spatiotemporal analysis"
    },
    {
      "answer": "The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape).",
      "question": "When would you use a Mann Whitney U test"
    },
    {
      "answer": "How to optimize your meta tags: A checklistCheck whether all your pages and your content have title tags and meta descriptions.Start paying more attention to your headings and how you structure your content.Don't forget to mark up your images with alt text.More items\u2022",
      "question": "How do you optimize meta tags"
    },
    {
      "answer": "In mathematics, the geometric\u2013harmonic mean M(x, y) of two positive real numbers x and y is defined as follows: we form the geometric mean of g0 = x and h0 = y and call it g1, i.e. g1 is the square root of xy.  The geometric\u2013harmonic mean is also designated as the harmonic\u2013geometric mean. (cf. Wolfram MathWorld below.)",
      "question": "What is geometric mean and harmonic mean in statistics"
    },
    {
      "answer": "\uf0b7 Birst employs caching and aggregate awareness to send queries to the cache first, and then data to the user-ready data store. \uf0b7 If data is not cached, Birst generates one or more queries depending on how the data is sourced. \uf0b7 Birst's in-memory caching includes both exact and fuzzy matching.",
      "question": "What are the matching types that birst employs while searching data in cache"
    },
    {
      "answer": "The mean used here is referred to as the arithmetic mean \u2013 the sum of all values divided by the number of cases. When working with grouped data, this mean is sometimes referred to as the weighted mean or, more properly, the weighted arithmetic mean. Ungrouped and group methods.",
      "question": "Is a weighted mean and a grouped data mean the same"
    },
    {
      "answer": "The most used algorithm to train neural networks is gradient descent. We'll define it later, but for now hold on to the following idea: the gradient is a numeric calculation allowing us to know how to adjust the parameters of a network in such a way that its output deviation is minimized.",
      "question": "What is gradient neural network"
    },
    {
      "answer": "7:5214:07Suggested clip \u00b7 100 secondsHow to Select the Correct Predictive Modeling Technique | Machine YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you choose a predictive model"
    },
    {
      "answer": "parameter-list is the list of parameters that the function takes separated by commas. If no parameters are given, then the function does not take any and should be defined with an empty set of parenthesis or with the keyword void. If no variable type is in front of a variable in the paramater list, then int is assumed.",
      "question": "What is the difference between a function with parameters and a functions without parameters"
    },
    {
      "answer": "Each feature, or column, represents a measurable piece of data that can be used for analysis: Name, Age, Sex, Fare, and so on. Features are also sometimes referred to as \u201cvariables\u201d or \u201cattributes.\u201d Depending on what you're trying to analyze, the features you include in your dataset can vary widely.",
      "question": "What is a feature variable"
    },
    {
      "answer": "Statistical knowledge helps you use the proper methods to collect the data, employ the correct analyses, and effectively present the results. Statistics is a crucial process behind how we make discoveries in science, make decisions based on data, and make predictions.",
      "question": "What are the uses of statistics"
    },
    {
      "answer": "Univariate statistics summarize only one variable at a time. Bivariate statistics compare two variables. Multivariate statistics compare more than two variables.",
      "question": "What is the difference between univariate and multivariate analysis"
    },
    {
      "answer": "The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(\u2217). Both functions will take any number and rescale it to fall between 0 and 1.",
      "question": "What is the difference between logit and probit model"
    },
    {
      "answer": "Last Updated on Decem. Cross-entropy is commonly used in machine learning as a loss function. Cross-entropy is a measure from the field of information theory, building upon entropy and generally calculating the difference between two probability distributions.",
      "question": "What is entropy and cross entropy"
    },
    {
      "answer": "A statistical hypothesis is a formal claim about a state of nature structured within the framework of a statistical model. For example, one could claim that the median time to failure from (acce]erated) electromigration of the chip population described in Section 6.1.",
      "question": "What is hypothesis in statistics with example"
    },
    {
      "answer": "Euclidean distance",
      "question": "Which distance metric can be used in Knn"
    },
    {
      "answer": "TL;DR \u2013 The train_test_split function is for splitting a single dataset for two different purposes: training and testing.",
      "question": "Which of the following functions can be used to split the data into train and test"
    },
    {
      "answer": "From Wikipedia, the free encyclopedia. An odds ratio (OR) is a statistic that quantifies the strength of the association between two events, A and B.",
      "question": "What is or in statistics"
    },
    {
      "answer": "Perceptron Learning Rule The Perceptron receives multiple input signals, and if the sum of the input signals exceeds a certain threshold, it either outputs a signal or does not return an output. In the context of supervised learning and classification, this can then be used to predict the class of a sample.",
      "question": "How does a perceptron algorithm work"
    },
    {
      "answer": "A discrete variable is a variable whose value is obtained by counting. A continuous variable is a variable whose value is obtained by measuring.  A discrete random variable X has a countable number of possible values.",
      "question": "What are the differences between continuous and discrete variables"
    },
    {
      "answer": "A box plot (also known as box and whisker plot) is a type of chart often used in explanatory data analysis to visually show the distribution of numerical data and skewness through displaying the data quartiles (or percentiles) and averages.",
      "question": "What is Boxplot used for"
    },
    {
      "answer": "H is the measurement matrix. This matrix influences the Kalman Gain.  R is the sensor noise matrix. This matrix implies the measurement error covariance, based on the amount of sensor noise. In this simulation, Q and R are constants, but some implementations of the Kalman Filter may adjust them throughout execution.",
      "question": "What is H in Kalman filter"
    },
    {
      "answer": "In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment.",
      "question": "What is the purpose of probability distribution functions"
    },
    {
      "answer": "An RNNs is essentially a fully connected neural network that contains a refactoring of some of its layers into a loop.  Among the text usages, the following tasks are among those RNNs perform well at: Sequence labelling. Natural Language Processing (NLP) text classification.",
      "question": "Is NLP neural network"
    },
    {
      "answer": "Chi-Square goodness of fit test is a non-parametric test that is used to find out how the observed value of a given phenomena is significantly different from the expected value.  In Chi-Square goodness of fit test, sample data is divided into intervals.",
      "question": "What is the chi square goodness of fit test used for"
    },
    {
      "answer": "Starting at $99.00 USD per user per month. Single-user, desktop application for Windows and Macs. Includes 12 months of technical support. Pricing information for IBM SPSS Statistics is supplied by the software provider or retrieved from publicly accessible pricing materials.",
      "question": "How much is SPSS for Mac"
    },
    {
      "answer": "From Wikipedia, the free encyclopedia. The control variates method is a variance reduction technique used in Monte Carlo methods. It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity.",
      "question": "What is control variates in variance reduction"
    },
    {
      "answer": "An autoencoder accepts input, compresses it, and then recreates the original input.  A variational autoencoder assumes that the source data has some sort of underlying probability distribution (such as Gaussian) and then attempts to find the parameters of the distribution.",
      "question": "What is the difference between traditional Autoencoder and variational Autoencoder"
    },
    {
      "answer": "Other examples that may follow a Poisson distribution include the number of phone calls received by a call center per hour and the number of decay events per second from a radioactive source.",
      "question": "What is Poisson distribution example"
    },
    {
      "answer": "If a problem is nonlinear and its class boundaries cannot be approximated well with linear hyperplanes, then nonlinear classifiers are often more accurate than linear classifiers. If a problem is linear, it is best to use a simpler linear classifier.",
      "question": "What is linear and nonlinear classifier"
    },
    {
      "answer": "How do I run a Z Test?State the null hypothesis and alternate hypothesis.Choose an alpha level.Find the critical value of z in a z table.Calculate the z test statistic (see below).Compare the test statistic to the critical z value and decide if you should support or reject the null hypothesis.",
      "question": "How do you use Z test"
    },
    {
      "answer": "Probability is the chance of an event occurring. A probability distribution is a table or an equation that links each outcome of a statistical experiment with its probability of occurrence.",
      "question": "What is the difference between probability and probability distribution"
    },
    {
      "answer": "In statistics, the multiple comparisons, multiplicity or multiple testing problem occurs when one considers a set of statistical inferences simultaneously or infers a subset of parameters selected based on the observed values.",
      "question": "What is a multiple hypothesis testing problem in statistics"
    },
    {
      "answer": "The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative. Using the original matrix (A), NMF will give you two matrices (W and H).",
      "question": "How does NMF topic modeling work"
    },
    {
      "answer": "Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply.",
      "question": "What is rule based learning in AI"
    },
    {
      "answer": "It is not rare that the results from a study that uses a convenience sample differ significantly with the results from the entire population.  Since the sample is not representative of the population, the results of the study cannot speak for the entire population. This results to a low external validity of the study.",
      "question": "How does convenience sampling affect results"
    },
    {
      "answer": "If we use non - standard units then we may not be able to express our measurement internationally as mainly standard units are used and accepted internationally. The non- standard units do not have the same dimensions all over the world.",
      "question": "What are the disadvantages of using non standard units"
    },
    {
      "answer": "Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models.",
      "question": "What is preprocessing in machine learning"
    },
    {
      "answer": "Static Rules Approach. The most simple, and maybe the best approach to start with, is using static rules. The Idea is to identify a list of known anomalies and then write rules to detect those anomalies. Rules identification is done by a domain expert, by using pattern mining techniques, or a by combination of both.",
      "question": "How do you do anomaly detection"
    },
    {
      "answer": "Log loss, aka logistic loss or cross-entropy loss. This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true .",
      "question": "What is the log loss function"
    },
    {
      "answer": "In a normal distribution, the mean and the median are the same number while the mean and median in a skewed distribution become different numbers: A left-skewed, negative distribution will have the mean to the left of the median. A right-skewed distribution will have the mean to the right of the median.",
      "question": "What are some ways to distinguish between a skewed and normal distribution"
    },
    {
      "answer": "The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.",
      "question": "What is Z score used for"
    },
    {
      "answer": "The expression double standard originally referred to 18th- and 19th-century economic policies of bimetallism. Bimetallism was a monetary system that was based on two metals\u2014a double standard, in its financial \u201cprescribed value\u201d sense, of gold and silver.",
      "question": "Where do double standards come from"
    },
    {
      "answer": "matrix: A rectangular arrangement of numbers or terms having various uses such as transforming coordinates in geometry, solving systems of linear equations in linear algebra and representing graphs in graph theory.",
      "question": "What does a matrix represent in linear algebra"
    },
    {
      "answer": "Homogeneity of variance is an assumption underlying both t tests and F tests (analyses of variance, ANOVAs) in which the population variances (i.e., the distribution, or \u201cspread,\u201d of scores around the mean) of two or more samples are considered equal.",
      "question": "What is homogeneity of variance in statistics"
    },
    {
      "answer": "To convert a logit ( glm output) to probability, follow these 3 steps:Take glm output coefficient (logit)compute e-function on the logit using exp() \u201cde-logarithimize\u201d (you'll get odds then)convert odds to probability using this formula prob = odds / (1 + odds) .",
      "question": "How do you convert odds ratio to logit"
    },
    {
      "answer": "The recommended reference range of serum TNF-\u03b1 was from nondetectable to 8.1 pg/mL. Among 147 patients with IgAN, 98 patients were with elevated serum TNF-\u03b1 and 49 patients were without elevated serum TNF-\u03b1.",
      "question": "What is normal range of TNF alpha"
    },
    {
      "answer": "Multiclass classification: classification task with more than two classes. Each sample can only be labelled as one class. For example, classification using features extracted from a set of images of fruit, where each image may either be of an orange, an apple, or a pear.",
      "question": "What is multi class classification in machine learning"
    },
    {
      "answer": "When the image goes through them, the important features are kept in the convolution layers, and thanks to the pooling layers, these features are intensified and kept over the network, while discarding all the information that doesn't make a difference for the task.",
      "question": "What is convolution and pooling"
    },
    {
      "answer": "Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.",
      "question": "When should logistic regression be used for data analysis"
    },
    {
      "answer": "Second-Order/Pseudo-Second-Order Reaction For a Pseudo-Second-Order Reaction, the reaction rate constant k is replaced by the apparent reaction rate constant k'. If the reaction is not written out specifically to show a value of \u03bdA, the value is assumed to be 1 and is not shown in these equations.",
      "question": "What is a pseudo second order reaction"
    },
    {
      "answer": "The values of the kernel filters are learned automatically by the neural network through the training process, and the filters kernels which results in the features that are most efficient for the particular classification or the detection are automatically learned.",
      "question": "How are filters chosen in CNN"
    },
    {
      "answer": "The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed.  In general, a lower RMSD is better than a higher one.",
      "question": "What is root mean square error used for"
    },
    {
      "answer": "A recursive system is a system in which current output depends on previous output(s) and input(s) but in non-recursive system current output does not depend on previous output(s).",
      "question": "What is recursive and nonrecursive system"
    },
    {
      "answer": "Fourier analysis is used in electronics, acoustics, and communications. Many waveforms consist of energy at a fundamental frequency and also at harmonic frequencies (multiples of the fundamental). The relative proportions of energy in the fundamental and the harmonics determines the shape of the wave.",
      "question": "What is Fourier analysis used for"
    },
    {
      "answer": "Q-learning is called off-policy because the updated policy is different from the behavior policy, so Q-Learning is off-policy. In other words, it estimates the reward for future actions and appends a value to the new state without actually following any greedy policy.",
      "question": "How is Q learning off policy"
    },
    {
      "answer": "K-nearest neighbors K- nearest neighbor (kNN) is a simple supervised machine learning algorithm that can be used to solve both classification and regression problems. kNN stores available inputs and classifies new inputs based on a similar measure i.e. the distance function.",
      "question": "Which algorithm is used for both classification and regression predictive problems"
    },
    {
      "answer": "The linear, polynomial and RBF or Gaussian kernel are simply different in case of making the hyperplane decision boundary between the classes.  Usually linear and polynomial kernels are less time consuming and provides less accuracy than the rbf or Gaussian kernels.",
      "question": "What is the difference between a Gaussian kernel a polynomial kernel a linear kernel and an RBF based kernel"
    },
    {
      "answer": "Z Score is free of any scale, hence it is used as a transformation technique while we need to make any variable unit free in various statistical techniques. Also, it is used to identifying outliers in a univarite way.  Z-test is a statistical technique to test the Null Hypothesis against the Alternate Hypothesis.",
      "question": "How is the Z test different from Z score analysis"
    },
    {
      "answer": "To help you get started in the field, we've assembled a list of the best Big Data courses available.Simplilearn. Simplilearn's Big Data Course catalogue is known for their large number of courses, in subjects as varied as Hadoop, SAS, Apache Spark, and R.  Cloudera.  Big Data University.  Hortonworks.  Coursera.",
      "question": "How do you learn big data"
    },
    {
      "answer": "An -dimensional vector, i.e., a vector ( , , , ) with components. In dimensions greater than or equal to two, vectors are sometimes considered synonymous with points and so n-tuples ( , , , ) are sometimes called points in n-space.",
      "question": "What is an N dimensional vector"
    },
    {
      "answer": "Stochastic gradient descent (SGD) computes the gradient for each update using a single training data point x_i (chosen at random). The idea is that the gradient calculated this way is a stochastic approximation to the gradient calculated using the entire training data.",
      "question": "What is an intuitive explanation of stochastic gradient descent"
    },
    {
      "answer": "a. it allows us to disregard the size of the sample selected when the population is not normal.  it allows us the disregard the shape of the population when n is large.",
      "question": "Why is the central limit theorem so important to the study of sampling distributions"
    },
    {
      "answer": "Whereas multiple regression predicts a single dependent variable from a set of multiple independent variables, canonical correlation simultaneously predicts multiple dependent variables from multiple independent variables.",
      "question": "When would someone use canonical correlation analysis versus multiple multiple regressions"
    },
    {
      "answer": "In artificial intelligence research, commonsense knowledge consists of facts about the everyday world, such as \"Lemons are sour\", that all humans are expected to know.  Common sense knowledge also helps to solve problems in the face of incomplete information.",
      "question": "What is common sense in artificial intelligence"
    },
    {
      "answer": "The sample variance is not always smaller than the population variance.",
      "question": "Is sample variance always smaller than population variance"
    },
    {
      "answer": "At its core, a loss function is incredibly simple: it's a method of evaluating how well your algorithm models your dataset. If your predictions are totally off, your loss function will output a higher number. If they're pretty good, it'll output a lower number.",
      "question": "What does the equation for the loss function do conceptually"
    },
    {
      "answer": "OLS does not require that the error term follows a normal distribution to produce unbiased estimates with the minimum variance. However, satisfying this assumption allows you to perform statistical hypothesis testing and generate reliable confidence intervals and prediction intervals.",
      "question": "Does OLS require normal distribution"
    },
    {
      "answer": "The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems.",
      "question": "Can Knn be used for classification"
    },
    {
      "answer": "The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases.  Therefore, as a sample size increases, the sample mean and standard deviation will be closer in value to the population mean \u03bc and standard deviation \u03c3 .",
      "question": "Does the mean increase with sample size"
    },
    {
      "answer": "A parametric model is one where we assume the 'shape' of the data, and therefore only have to estimate the coefficients of the model. A non-parametric model is one where we do not assume the 'shape' of the data, and we have to estimate the most suitable form of the model, along with the coefficients.",
      "question": "What is the difference between parametric and non parametric models"
    },
    {
      "answer": "Model calibration is done by adjusting the selected parameters such as growth rates, loss rates in the model to obtain a best fit between the model calculations and the monthly average field data (Set #1) collected during first year (June 18, 2004\u2013June 27, 2005).",
      "question": "How do you calibrate a model"
    },
    {
      "answer": "Class limits are the least and greatest numbers that can belong to the class. Class boundaries are the numbers that separate classes without forming gaps between them.",
      "question": "What is the difference between class limits and class boundaries quizlet"
    },
    {
      "answer": "The term convolution refers to the mathematical combination of two functions to produce a third function. It merges two sets of information. In the case of a CNN, the convolution is performed on the input data with the use of a filter or kernel (these terms are used interchangeably) to then produce a feature map.",
      "question": "What is CNN convolution operation"
    },
    {
      "answer": "In this context, a neural network is one of several machine learning algorithms that can help solve classification problems. Its unique strength is its ability to dynamically create complex prediction functions, and emulate human thinking, in a way that no other algorithm can.",
      "question": "Can neural networks be used for classification"
    },
    {
      "answer": "The problem is we always prefer an output having highest probability or lowest distance from reference as our answer and while we are dealing with it, KNN will always give same output for a given set of input repeatedly tested. That means it is quit deterministic.",
      "question": "Is K nearest neighbors example of deterministic algorithm"
    },
    {
      "answer": "According to my POV model accuracy is more important and its all depends on the training data.  Model performance can be improved using distributed computing and parallelizing over the scored assets, whereas accuracy has to be carefully built during the model training process.",
      "question": "Which is more important to you model accuracy or model performance"
    },
    {
      "answer": "1a : to divide into parts or shares. b : to divide (a place, such as a country) into two or more territorial units having separate political status. 2 : to separate or divide by a partition (such as a wall) \u2014often used with off. Other Words from partition Synonyms More Example Sentences Learn More about partition.",
      "question": "What does partitioning mean"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What is the role of activation function in neural network"
    },
    {
      "answer": "Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks. Tim Salimans, Diederik P. Kingma. Download PDF. We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction.",
      "question": "What is called as weight normalization in machine learning"
    },
    {
      "answer": "Normalization is the process of organizing data into a related table; it also eliminates redundancy and increases the integrity which improves performance of the query. To normalize a database, we divide the database into tables and establish relationships between the tables.",
      "question": "What is normalization and its types"
    },
    {
      "answer": "Here are 13 ways you can naturally increase your eagerness to learn and keep feeding your curiosity to stay on your learning goals.Just Show Your Eagerness.  Stay Updated.  Don't Stop Developing Your Skills.  Look for Challenges.  Learn Lateral Thinking.  Be Open to New Experiences.  Start to Be Interesting.  Gain Initial Knowledge.More items\u2022",
      "question": "In what ways do I become more eager to learn and improve myself"
    },
    {
      "answer": "A z-score measures exactly how many standard deviations above or below the mean a data point is.  A negative z-score says the data point is below average. A z-score close to 0 says the data point is close to average. A data point can be considered unusual if its z-score is above 3 or below \u22123 .",
      "question": "What is a z score in math"
    },
    {
      "answer": "Time series data is data that is collected at different points in time. This is opposed to cross-sectional data which observes individuals, companies, etc. at a single point in time. Because data points in time series are collected at adjacent time periods there is potential for correlation between observations.",
      "question": "How do you collect time series data"
    },
    {
      "answer": "Stochastic vs. In general, stochastic is a synonym for random. For example, a stochastic variable is a random variable. A stochastic process is a random process. Typically, random is used to refer to a lack of dependence between observations in a sequence.",
      "question": "What is the difference between stochastic and random"
    },
    {
      "answer": "Entry level positions require at least a bachelor's degree while positions entailing supervision, leadership or administrative roles frequently require master's or doctoral degrees. Typical coursework involves study of: Various level of math, including probability, statistics, algebra, calculus, logic and algorithms.",
      "question": "What should I study to work with artificial intelligence"
    },
    {
      "answer": "To find the harmonic mean of a set of n numbers, add the reciprocals of the numbers in the set, divide the sum by n, then take the reciprocal of the result.",
      "question": "How do you calculate harmonic mean"
    },
    {
      "answer": "For example, a perfect precision and recall score would result in a perfect F-Measure score:F-Measure = (2 * Precision * Recall) / (Precision + Recall)F-Measure = (2 * 1.0 * 1.0) / (1.0 + 1.0)F-Measure = (2 * 1.0) / 2.0.F-Measure = 1.0.",
      "question": "How do you calculate precision and recall"
    },
    {
      "answer": "How to Perform Systematic Sampling: StepsStep 1: Assign a number to every element in your population.  Step 2: Decide how large your sample size should be.  Step 3: Divide the population by your sample size.  Step 1: Assign a number to every element in your population.Step 2: Decide how large your sample size should be.More items\u2022",
      "question": "What are the steps of systematic sampling"
    },
    {
      "answer": "Using too large a batch size can have a negative effect on the accuracy of your network during training since it reduces the stochasticity of the gradient descent.",
      "question": "How does a larger batch size affect your training accuracy"
    },
    {
      "answer": "Unlike the previous measures of variability, the variance includes all values in the calculation by comparing each value to the mean. To calculate this statistic, you calculate a set of squared differences between the data points and the mean, sum them, and then divide by the number of observations.",
      "question": "How do you compare variability of two data sets"
    },
    {
      "answer": "The median is the middle number in a sorted, ascending or descending, list of numbers and can be more descriptive of that data set than the average.  If there is an odd amount of numbers, the median value is the number that is in the middle, with the same amount of numbers below and above.",
      "question": "What is median value in statistics"
    },
    {
      "answer": "Random errors often have a Gaussian normal distribution (see Fig. 2). In such cases statistical methods may be used to analyze the data. The mean m of a number of measurements of the same quantity is the best estimate of that quantity, and the standard deviation s of the measurements shows the accuracy of the estimate.",
      "question": "Do random errors always have a Gaussian distribution"
    },
    {
      "answer": "Softmax is used for multi-classification in the Logistic Regression model, whereas Sigmoid is used for binary classification in the Logistic Regression model. This is similar to the Sigmoid function. The difference is that, in the denominator, we sum together all of the values.",
      "question": "What is the difference between sigmoid and Softmax"
    },
    {
      "answer": "So while L2 regularization does not perform feature selection the same way as L1 does, it is more useful for feature *interpretation*: a predictive feature will get a non-zero coefficient, which is often not the case with L1.",
      "question": "Can we use l2 regularization for feature selection"
    },
    {
      "answer": "In general, an LSTM can be used for classification or regression; it is essentially just a standard neural network that takes as input, in addition to input from that time step, a hidden state from the previous time step. So, just as a NN can be used for classification or regression, so can an LSTM.",
      "question": "Can Lstm be used for classification"
    },
    {
      "answer": "Multinomial logistic regression is used to predict categorical placement in or the probability of category membership on a dependent variable based on multiple independent variables. The independent variables can be either dichotomous (i.e., binary) or continuous (i.e., interval or ratio in scale).",
      "question": "What is multinomial logistic regression used for"
    },
    {
      "answer": "5 | Problems and Issues of Linear RegressionSpecification.Proxy Variables and Measurement Error.Selection Bias.Multicollinearity.Autocorrelation.Heteroskedasticity.Simultaneous Equations.Limited Dependent Variables.More items",
      "question": "What are some problems that are encountered when creating a regression model"
    },
    {
      "answer": "Factor Analysis in SPSS To conduct a Factor Analysis, start from the \u201cAnalyze\u201d menu.  This dialog allows you to choose a \u201crotation method\u201d for your factor analysis.  This table shows you the actual factors that were extracted.  E.  Finally, the Rotated Component Matrix shows you the factor loadings for each variable.More items",
      "question": "How do you do factor analysis in SPSS"
    },
    {
      "answer": "where Ua is size m \u00d7 n, Ub is size m \u00d7 (m - n), and \u03a3a is of size n \u00d7 n. Then A = Ua\u03a3aVH is called the reduced SVD of the matrix A. In this context the SVD defined in Equation (1) is sometimes referred to as the full SVD for contrast. Notice that Ua is not unitary, but it does have orthogonal columns.",
      "question": "What is reduced SVD"
    },
    {
      "answer": "The data structure which is being used in DFS is stack. The process is similar to BFS algorithm. In DFS, the edges that leads to an unvisited node are called discovery edges while the edges that leads to an already visited node are called block edges.",
      "question": "Which data structure is used by depth first search algorithm"
    },
    {
      "answer": "A supervised learning algorithm takes a known set of input data and known responses to the data (output) and trains a model to generate reasonable predictions for the response to new data.  Supervised learning uses classification and regression techniques to develop predictive models.",
      "question": "How does supervised learning algorithm work"
    },
    {
      "answer": "How to Use K-means Cluster Algorithms in Predictive AnalysisPick k random items from the dataset and label them as cluster representatives.Associate each remaining item in the dataset with the nearest cluster representative, using a Euclidean distance calculated by a similarity function.Recalculate the new clusters' representatives.More items",
      "question": "How do you predict using clustering"
    },
    {
      "answer": "Hold-out is when you split up your dataset into a 'train' and 'test' set. The training set is what the model is trained on, and the test set is used to see how well that model performs on unseen data.",
      "question": "What is hold out in machine learning"
    },
    {
      "answer": "A random process is a time-varying function that assigns the outcome of a random experiment to each time instant: X(t). \u2022 For a fixed (sample path): a random process is a time varying function, e.g., a signal.",
      "question": "What does random processes mean"
    },
    {
      "answer": "Convenience sampling (also known as grab sampling, accidental sampling, or opportunity sampling) is a type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
      "question": "What is a convenience sample in statistics"
    },
    {
      "answer": "Computing accuracy for clustering can be done by reordering the rows (or columns) of the confusion matrix so that the sum of the diagonal values is maximal. The linear assignment problem can be solved in O(n3) instead of O(n!). Coclust library provides an implementation of the accuracy for clustering results.",
      "question": "How do you find the accuracy of a clustering algorithm"
    },
    {
      "answer": "The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions. Factor analysis can be used to simplify data, such as reducing the number of variables in regression models.",
      "question": "What is the purpose of factor analysis"
    },
    {
      "answer": "The equation of a hyperplane is w \u00b7 x + b = 0, where w is a vector normal to the hyperplane and b is an offset.",
      "question": "How do you calculate Hyperplane"
    },
    {
      "answer": "t-test is used to test if two sample have the same mean. The assumptions are that they are samples from normal distribution. f-test is used to test if two sample have the same variance. Same assumptions hold.",
      "question": "What is the difference between t distribution and F distribution"
    },
    {
      "answer": "To analyze this data follow these steps:Open the file KAPPA.SAV.  Select Analyze/Descriptive Statistics/Crosstabs.Select Rater A as Row, Rater B as Col.Click on the Statistics button, select Kappa and Continue.Click OK to display the results for the Kappa test shown here:",
      "question": "How do I report a kappa statistic"
    },
    {
      "answer": "Decision Tree Splitting Method #1: Reduction in VarianceFor each split, individually calculate the variance of each child node.Calculate the variance of each split as the weighted average variance of child nodes.Select the split with the lowest variance.Perform steps 1-3 until completely homogeneous nodes are achieved.",
      "question": "How do you determine the best split in decision tree"
    },
    {
      "answer": "Bayesian networks encode the dependencies and independencies between variables. Under the causal Markov assumption, each variable in a Bayesian network is independent of its ancestors given the values of its parents.",
      "question": "What is the Markov assumption for a dynamic Bayesian network"
    },
    {
      "answer": "value of the Shapiro-Wilk Test is greater than 0.05, the data is normal. If it is below 0.05, the data significantly deviate from a normal distribution. If you need to use skewness and kurtosis values to determine normality, rather the Shapiro-Wilk test, you will find these in our enhanced testing for normality guide.",
      "question": "How do you test for normality"
    },
    {
      "answer": "To overcome this prob- lem, the ResNet incorporates skip-connections between layers (He et al., 2016a,b) and the batch-normalization (BN) normalizes the input of activation functions (Ioffe and Szegedy, 2015). These architectures enable an extreme deep neural network to be trained with high performance.",
      "question": "Does ResNet use batch normalization"
    },
    {
      "answer": "Difference Between Temporal and Spatial Databases A spatial database stores and allows queries of data defined by geometric space. Many spatial databases can represent simple coordinates, points, lines and polygons.  A temporal database stores data relating to time whether past, present or future.",
      "question": "What is the difference between spatial temporal data with other type of data"
    },
    {
      "answer": "All Answers (6) Indeed a common rule of thumb is 10 outcome events per predictor, but sometimes this rule is too conservative and can be relaxed (see Vittinghoff E, McCulloch CE. 2007. Relaxing the rule of ten events per variable in logistic and Cox regression.",
      "question": "How many variables should be in a regression model"
    },
    {
      "answer": "How to Calculate a Confusion MatrixStep 1) First, you need to test dataset with its expected outcome values.Step 2) Predict all the rows in the test dataset.Step 3) Calculate the expected predictions and outcomes:",
      "question": "How do you analyze a confusion matrix"
    },
    {
      "answer": "The mean, or average, IQ is 100. Standard deviations, in most cases, are 15 points. The majority of the population, 68.26%, falls within one standard deviation of the mean (IQ 85-115).",
      "question": "What is IQ standard deviation"
    },
    {
      "answer": "Advantages of Linear Regression Linear regression has a considerably lower time complexity when compared to some of the other machine learning algorithms. The mathematical equations of Linear regression are also fairly easy to understand and interpret. Hence Linear regression is very easy to master.",
      "question": "What are advantages of different regression algorithms"
    },
    {
      "answer": "Parallel analysis is a method for determining the number of components or factors to retain from pca or factor analysis. Essentially, the program works by creating a random dataset with the same numbers of observations and variables as the original data.",
      "question": "What is parallel analysis in factor analysis"
    },
    {
      "answer": "Chunking in NLP is Changing a perception by moving a \u201cchunk\u201d, or a group of bits of information, in the direction of a Deductive or Inductive conclusion through the use of language.  you will start to get smaller pieces of information about a car.",
      "question": "What is chunking in NLP"
    },
    {
      "answer": "The Dirichlet is the multivariate generalization of the beta distribution.  The Dirichlet equals the uniform distribution when all parameters (\u03b11\u2026 \u03b1k) are equal. The Dirichlet distribution is a conjugate prior to the categorical distribution and multinomial distributions. A compound variant is the Dirichlet-multinomial.",
      "question": "What does Dirichlet mean"
    },
    {
      "answer": "Logistic regression is a powerful machine learning algorithm that utilizes a sigmoid function and works best on binary classification problems, although it can be used on multi-class classification problems through the \u201cone vs. all\u201d method. Logistic regression (despite its name) is not fit for regression tasks.",
      "question": "Is logistic regression only for binary classification"
    },
    {
      "answer": "Popular ML algorithms include: linear regression, logistic regression, SVMs, nearest neighbor, decision trees, PCA, naive Bayes classifier, and k-means clustering. Classical machine learning algorithms are used for a wide range of applications.",
      "question": "What are the models in machine learning"
    },
    {
      "answer": "A Classification report is used to measure the quality of predictions from a classification algorithm.  The report shows the main classification metrics precision, recall and f1-score on a per-class basis. The metrics are calculated by using true and false positives, true and false negatives.",
      "question": "What is classification report in machine learning"
    },
    {
      "answer": "Normality: Data have a normal distribution (or at least is symmetric) Homogeneity of variances: Data from multiple groups have the same variance. Linearity: Data have a linear relationship. Independence: Data are independent.",
      "question": "What are four main assumptions for parametric statistics"
    },
    {
      "answer": "If you are working on a classification problem, the best score is 100% accuracy. If you are working on a regression problem, the best score is 0.0 error. These scores are an impossible to achieve upper/lower bound.",
      "question": "What is a good accuracy score in machine learning"
    },
    {
      "answer": "0:007:47Suggested clip \u00b7 116 seconds[Proof] Sequence is divergent - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you prove divergence"
    },
    {
      "answer": "Contrastive Loss: Contrastive refers to the fact that these losses are computed contrasting two or more data points representations. This name is often used for Pairwise Ranking Loss, but I've never seen using it in a setup with triplets. Triplet Loss: Often used as loss name when triplet training pairs are employed.",
      "question": "What is contrastive loss"
    },
    {
      "answer": "The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X \u2264 x, Y \u2264 y),where X and Y are continuous or discrete. For example, the probability.  P(x1 \u2264 X \u2264 x2,y1 \u2264 Y \u2264 y2) = F(x2,y2) \u2212 F(x2,y1) \u2212 F(x1,y2) + F(x1,y1).",
      "question": "How do you find the joint distribution of X and Y"
    },
    {
      "answer": "A P value is also affected by sample size and the magnitude of effect. Generally the larger the sample size, the more likely a study will find a significant relationship if one exists. As the sample size increases the impact of random error is reduced.",
      "question": "Why does P value change with sample size"
    },
    {
      "answer": "DEFINITION: Primary sampling unit refers to Sampling units that are selected in the first (primary) stage of a multi-stage sample ultimately aimed at selecting individual elements.",
      "question": "What is a primary sampling unit"
    },
    {
      "answer": "Harmonic means are often used in averaging things like rates (e.g., the average travel speed given a duration of several trips). The weighted harmonic mean is used in finance to average multiples like the price-earnings ratio because it gives equal weight to each data point.",
      "question": "When should harmonic mean be used"
    },
    {
      "answer": "The null hypothesis is the one to be tested and the alternative is everything else. In our example, The null hypothesis would be: The mean data scientist salary is 113,000 dollars. While the alternative: The mean data scientist salary is not 113,000 dollars.",
      "question": "What is null and alternative hypothesis example"
    },
    {
      "answer": "The independent variable is called the Explanatory variable (or better known as the predictor) - the variable which influences or predicts the values. i.e. if the explanatory variable changes then it affects the response variable. Here Y is the Dependent variable or response variable.",
      "question": "Which variable is the explanatory variable"
    },
    {
      "answer": "Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.  Tokenization can be done to either separate words or sentences.",
      "question": "Why tokenization is important in NLP"
    },
    {
      "answer": "2. What is the area under a conditional Cumulative density function? Explanation: Area under any conditional CDF is 1.",
      "question": "What is the area under the conditional C * * * * * * * * * density function"
    },
    {
      "answer": "Each class will have a \u201clower class limit\u201d and an \u201cupper class limit\u201d which are the lowest and highest numbers in each class. The \u201cclass width\u201d is the distance between the lower limits of consecutive classes. The range is the difference between the maximum and minimum data entries.",
      "question": "What is the difference between class interval and class width in statistics"
    },
    {
      "answer": "Accuracy reflects how close a measurement is to a known or accepted value, while precision reflects how reproducible measurements are, even if they are far from the accepted value. Measurements that are both precise and accurate are repeatable and very close to true values.",
      "question": "What is difference between precision and accuracy"
    },
    {
      "answer": "You do need distributional assumptions about the response variable in order to make inferences (e.g, confidence intervals), but it is not necessary that the response variable be normallhy distributed.",
      "question": "Does dependent variable need to be normally distributed"
    },
    {
      "answer": "Weights are the co-efficients of the equation which you are trying to resolve. Negative weights reduce the value of an output. When a neural network is trained on the training set, it is initialised with a set of weights.  A neuron first computes the weighted sum of the inputs.",
      "question": "How weights are calculated in neural networks"
    },
    {
      "answer": "Calculating the distance of various points in the scene relative to the position of the camera is one of the important tasks for a computer vision system.",
      "question": "What is depth computer vision"
    },
    {
      "answer": "Abstract. This work centers on a novel data mining technique we term supervised clustering. Unlike traditional clustering, supervised clustering assumes that the examples are classified. The goal of supervised clustering is to identify class-uniform clusters that have high probability densities.",
      "question": "What is supervised clustering"
    },
    {
      "answer": "Random forest (RF) missing data algorithms are an attractive approach for imputing missing data. They have the desirable properties of being able to handle mixed types of missing data, they are adaptive to interactions and nonlinearity, and they have the potential to scale to big data settings.",
      "question": "Can random forest handle missing data"
    },
    {
      "answer": "A mathematical function with symbol \u03b5ijk defined to switch between the discrete values of +1, 0, and -1, depending on the values of the three indices i, j, and k: It is one of the tools used in Einstein's summation notation to handle operations equivalent to cross products in vector notation.",
      "question": "What is alternating tensor"
    },
    {
      "answer": "They are continuous vs discrete distributions. A first difference is that multinomial distribution M(N,p) is discrete (it generalises binomial disrtibution) whereas Dirichlet distribution is continuous (it generalizes Beta distribution).",
      "question": "What makes the Dirichlet distribution different from a multinomial distribution"
    },
    {
      "answer": "The convolutional neural networks (CNNs) have proven to be a powerful tool for discriminative learning. Recently researchers have also started to show interest in the generative aspects of CNNs in order to gain a deeper understanding of what they have learned and how to further improve them.",
      "question": "Is CNN generative or discriminative"
    },
    {
      "answer": "Statistical Machine Translation. Machine translation (MT) is automated translation. It is the process by which computer software is used to translate a text from one natural language (such as English) to another (such as Spanish).",
      "question": "What is machine translation in AI"
    },
    {
      "answer": "The value of the z-score tells you how many standard deviations you are away from the mean.  A positive z-score indicates the raw score is higher than the mean average. For example, if a z-score is equal to +1, it is 1 standard deviation above the mean. A negative z-score reveals the raw score is below the mean average.",
      "question": "What does the Z score represent"
    },
    {
      "answer": "Deep-learning software by nameSoftwareCreatorInterfacePlaidMLVertex.AI, IntelPython, C++PyTorchAdam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan (Facebook)Python, C++, JuliaApache SINGAApache Software FoundationPython, C++, JavaTensorFlowGoogle BrainPython (Keras), C/C++, Java, Go, JavaScript, R, Julia, Swift18 rivi\u00e4 lis\u00e4\u00e4",
      "question": "Which software is used for deep learning"
    },
    {
      "answer": "Model-based collaborative filtering algorithms provide item recommendation by first developing a model of user ratings. Algorithms in this category take a probabilistic approach and envision the collaborative filtering process as computing the expected value of a user prediction, given his/her ratings on other items.",
      "question": "What is model based collaborative filtering"
    },
    {
      "answer": "Any quantity that has both magnitude and direction is called a vector.  The only difference is that tensor is the generalized form of scalars and vectors . Means scalars and vectors are the special cases of tensor quantities. Scalar is a tensor of rank 0 and vector is a tensor of rank 1.",
      "question": "What is difference between tensor and vector"
    },
    {
      "answer": "The tensor of inertia gives us an idea about how the mass is distributed in a rigid body. Analogously, we can define the tensor of inertia about point O, by writing equation(4) in matrix form.  It follows from the definition of the products of inertia, that the tensors of inertia are always symmetric.",
      "question": "What do you mean by inertia tensor"
    },
    {
      "answer": "We have compiled a list of best practices and strategies that you can use to improve your TensorFlow Lite model performance.Choose the best model for the task.  Profile your model.  Profile and optimize operators in the graph.  Optimize your model.  Tweak the number of threads.  Eliminate redundant copies.More items",
      "question": "How can I improve my TensorFlow performance"
    },
    {
      "answer": "In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.",
      "question": "What is meant by the term instance based learning"
    },
    {
      "answer": "Hypothesis Tests with the Repeated-Measures t (cont.) In words, the null hypothesis says that there is no consistent or systematic difference between the two treatment conditions. Note that the null hypothesis does not say that each individual will have a difference score equal to zero.",
      "question": "What is the null hypothesis for a repeated measures test"
    },
    {
      "answer": "The traditional method of training AI models involves setting up servers where models are trained on data, often through the use of a cloud-based computing platform.  Federated learning brings machine learning models to the data source, rather than bringing the data to the model.",
      "question": "What is Federated AI"
    },
    {
      "answer": "Latent semantic indexing (LSI) is a concept used by search engines to discover how a term and content work together to mean the same thing, even if they do not share keywords or synonyms.  Basically, though, you often need specific keywords on your pages to boost your website traffic.",
      "question": "What is latent semantic indexing and where can it be applied"
    },
    {
      "answer": "split testing",
      "question": "What does AB testing stand for"
    },
    {
      "answer": "Neural networks take input data, train themselves to recognize patterns found in the data, and then predict the output for a new set of similar data. Therefore, a neural network can be thought of as the functional unit of deep learning, which mimics the behavior of the human brain to solve complex data-driven problems.",
      "question": "What is a neural network in programming"
    },
    {
      "answer": "Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.  The three steps involved in cross-validation are as follows : Reserve some portion of sample data-set.",
      "question": "What is cross validation set in machine learning"
    },
    {
      "answer": "If the hazard ratio is less than 1, then the predictor is protective (i.e., associated with improved survival) and if the hazard ratio is greater than 1, then the predictor is associated with increased risk (or decreased survival).",
      "question": "How do you interpret the hazard ratio in Cox Regression"
    },
    {
      "answer": "Collaborative filtering (CF) is a technique used by recommender systems.  In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating).",
      "question": "What is meant by collaborative filtering"
    },
    {
      "answer": "1 Answer. Transfer learning is when a model developed for one task is reused to work on a second task. Fine tuning is one approach to transfer learning.",
      "question": "What is the difference between transfer learning and fine tuning"
    },
    {
      "answer": "Content validity is different from face validity, which refers not to what the test actually measures, but to what it superficially appears to measure.  In clinical settings, content validity refers to the correspondence between test items and the symptom content of a syndrome.",
      "question": "What is the difference between face and content validity"
    },
    {
      "answer": "A random variable, usually written X, is a variable whose possible values are numerical outcomes of a random phenomenon. There are two types of random variables, discrete and continuous.",
      "question": "What is a random variable What are the various types of random variables"
    },
    {
      "answer": "Brownian motion lies in the intersection of several important classes of processes. It is a Gaussian Markov process, it has continuous paths, it is a process with stationary independent increments (a L\u00e9vy process), and it is a martingale. Several characterizations are known based on these properties.",
      "question": "Is Brownian motion a Markov process"
    },
    {
      "answer": "The anti-Martingale, or reverse Martingale, system is a trading methodology that involves halving a bet each time there is a trade loss and doubling it each time there is a gain. This technique is the opposite of the Martingale system, whereby a trader (or gambler) doubles down on a losing bet and halves a winning bet.",
      "question": "What is reverse Martingale"
    },
    {
      "answer": "deep learning - a name for an algorithm in machine learning (just like SVM, Regression etc.) transfer learning - as you may know, in order to train a Neural network it might take long time. So, we use a Neural Network that is already trained and in this way we can extract some features of new sample.",
      "question": "What is the difference between deep learning and transfer learning"
    },
    {
      "answer": "Interpreting the ROC curve Classifiers that give curves closer to the top-left corner indicate a better performance. As a baseline, a random classifier is expected to give points lying along the diagonal (FPR = TPR). The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.",
      "question": "How do you read ROC curve results"
    },
    {
      "answer": "Sampling Frame Error: A type of nonsampling error in a survey caused by a sampling frame (i.e., a list) that is not a perfect representation of the population or universe. That is, the sample list might contain respondents who do not meet the definition of the population or universe.",
      "question": "What is sample frame error"
    },
    {
      "answer": "The Lorenz Curve is a graph that illustrates the distribution of income in the economy. It suggests that the distribution of income in the United States is unequal.",
      "question": "What is the Lorenz curve and what does it suggest"
    },
    {
      "answer": "The reason that SVMs often outperform ANNs in practice is that they deal with the biggest problem with ANNs, SVMs are less prone to overfitting.",
      "question": "What is one reason we might choose to use support vector machine rather than an artificial neural network"
    },
    {
      "answer": "In the chapter on Human Development Indicators, there should be a table that includes the Gini coefficient. For example, in the 2004 edition, they are in table number 14. See also the \u201cGet Indicators\u201d portion of their web site, where you can download an Excel table with the Gini index.",
      "question": "Where is the Gini coefficient data"
    },
    {
      "answer": "Data labeling, in the context of machine learning, is the process of detecting and tagging data samples. The process can be manual but is usually performed or assisted by software.",
      "question": "What is Labelling in machine learning"
    },
    {
      "answer": "Definition: Distribution means to spread the product throughout the marketplace such that a large number of people can buy it. Distribution involves doing the following things: Tracking the places where the product can be placed such that there is a maximum opportunity to buy it.",
      "question": "What is meant by a distribution"
    },
    {
      "answer": "Heat map is a graphical representation of data where values are depicted by color",
      "question": "What is Heat map"
    },
    {
      "answer": ".Pandas Profiling is the auto EDA library is an open source option that is written in python",
      "question": "What is EDA library"
    },
    {
      "answer": "Mean, median, and mode are closely connected by the following relations called an empirical relationship",
      "question": "How can you define an empirical relationship in dataset"
    },
    {
      "answer": "For row data histograms, bihistograms, probability plots, lag plots, block plots, and Youden plots",
      "question": "Which plots used for Plotting the raw data"
    },
    {
      "answer": ".It gives assessment not exactness",
      "question": "What is the purpose of visualization"
    },
    {
      "answer": "Data aggregation is the process of gathering data and presenting it in a summarized format",
      "question": "what is data aggregation"
    },
    {
      "answer": "Exploratory Data Analysis the process of investigating the dataset to discover patterns and anomalies or outliers",
      "question": "What is EDA"
    },
    {
      "answer": "A function is continuous if its graph is an unbroken curve",
      "question": "Where is a graph continuous"
    },
    {
      "answer": ".A confidence interval displays the probability that a parameter will fall between a pair of values around the mean",
      "question": "what is confidence interval"
    },
    {
      "answer": "Adding all numbers in the data set and then dividing by the number of values in the set",
      "question": "How to find the mean"
    },
    {
      "answer": "An unbiased estimator of a parameter is an estimator whose expected value is equal to the parameter",
      "question": "What is Unbiased estimate"
    },
    {
      "answer": "The median is the middle number in a sorted, ascending or descending.",
      "question": "What is median"
    },
    {
      "answer": "No median does not get influenced by outliers",
      "question": "Does median influenced by outliers"
    },
    {
      "answer": "The threshold parameter defines the minimum value in a lognormal distribution",
      "question": "what is Threshold Parameter"
    },
    {
      "answer": "The mode is the value that appears most often in a set of data values",
      "question": "What is Mode"
    },
    {
      "answer": "There are two statistical methods widely used for analyzing data Descriptive and inferential statistics",
      "question": "which statistical methods widely used for analyzing data"
    },
    {
      "answer": "Catching mistakes and anomalies,Gaining new insights into data,Detecting outliers in data,Understanding relationships",
      "question": "what are the uses of EDA"
    },
    {
      "answer": "Inter Quartile Range is the difference between the third quartile and the first Quartile",
      "question": "Define Inter Quartile Range"
    },
    {
      "answer": "The scale represents the standard deviation of the normally distributed data",
      "question": "what is Scale Parameter"
    },
    {
      "answer": "Scatter plot is used to plot data points on a horizontal and a vertical axis to show how much one variable is affected by anothe",
      "question": "What is Scatter plot"
    },
    {
      "answer": "A distribution plot displays a distribution and range of a set of numeric values plotted against a dimension",
      "question": "What is a distribution plot"
    },
    {
      "answer": ".Noisy data is a meaningless data that cannot be interpreted by machines",
      "question": "what is Noisy data"
    },
    {
      "answer": "This method works on sorted data in order to smooth it",
      "question": "what is Binning Method"
    },
    {
      "answer": "Bubble chart is a data visualization that displays multiple circles in a two-dimensional plot",
      "question": "What is Bubble chart"
    },
    {
      "answer": "Exploratory Data Analysis is important step in data science",
      "question": "Which is the important step in Data science"
    },
    {
      "answer": "Summary statistics for numerical data in the dataset and creating various graphical representations to understand the data better",
      "question": "Which terms comes under the EDA"
    },
    {
      "answer": "Measure of Central Tendency is also called as First Moment Business Decision",
      "question": "What is First moment business decision"
    },
    {
      "answer": "Measure of central Tendency is called as summary statistics",
      "question": "What is Measure of central Tendency"
    },
    {
      "answer": "The sum of the values divided by the number of values",
      "question": "What is mean"
    },
    {
      "answer": "Yes mean influenced by outliers",
      "question": "Does mean influenced by outliers"
    },
    {
      "answer": "Measure of Dispersion also called as Second Moment Business Decision",
      "question": "What is second momemt business decision"
    },
    {
      "answer": "A measure of dispersion indicates the scattering of data",
      "question": "Define the Measure of Dispersion"
    },
    {
      "answer": "The four measure of dispersion are range, interquartile range, standard deviation and variance",
      "question": "What are the four measure of dispersion"
    },
    {
      "answer": "The best measurement for dispersion is standard deviation",
      "question": "What is the best measurement for dispersion"
    },
    {
      "answer": "The term variance refers to a statistical measurement of the spread between numbers in a data set",
      "question": "What a variance means"
    },
    {
      "answer": "In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values",
      "question": "what is the standard deviation"
    },
    {
      "answer": "The range is the simple measurement of the difference between values in a dataset",
      "question": "what is range of the dataset"
    },
    {
      "answer": "The disavantage of the variance is unit get squared",
      "question": "What is disavantage of the variance"
    },
    {
      "answer": "Advantage of standard deviation is we get back the original input from squares units",
      "question": "What is advantage of standard deviation"
    },
    {
      "answer": "Python and R are the tools used for EDA",
      "question": "Which are the tools included in EDA"
    },
    {
      "answer": "Multivariate non-graphical EDA techniques generally show the relationship between two or more variables of the data through cross tabulation or statistics",
      "question": "What is Multivariate nongraphical method"
    },
    {
      "answer": "Scatter plot is used to plot data points on a horizontal and a vertical axis to show how much one variable is affected by another",
      "question": "What is Multivariate graphical method"
    },
    {
      "answer": "Multivariate chart is a graphical representation of the relationships between factors and a response",
      "question": "What is Multivariate chart"
    },
    {
      "answer": "Bubble chart is a data visualization that displays multiple circles in a two-dimensional plot",
      "question": "What is run chart"
    },
    {
      "answer": "s called an empirical relationship",
      "question": "How can you define Histogram"
    },
    {
      "answer": "Mean is known as the mathematical average whereas the median is known as the positional average",
      "question": "What is the difference Between Mean and Median"
    },
    {
      "answer": "In Data Science the next step after EDA is Data Mining",
      "question": "In Data Science which is the next step after EDA"
    },
    {
      "answer": "Exploratory Data Analysis is an approach or philosophy for data analysis that employs a variety of techniques mostly graphical",
      "question": "What is the relation between EDA and statistical graphics"
    },
    {
      "answer": "EDA is not identical to statistical graphics although the two terms are used almost interchangeably",
      "question": "Are EDA and statistical graphics same or different"
    },
    {
      "answer": "Most EDA techniques are graphical in nature with a few quantitative technique",
      "question": "Which techniques are there in EDA"
    },
    {
      "answer": ".Plotting simple statistics such as mean plots, standard deviation plots, box plots are used",
      "question": "Which plots used for simple statistics"
    },
    {
      "answer": "Scatter plots are used to display the relationship between two continuous variables x and y",
      "question": "which plots are used for continuous data"
    },
    {
      "answer": "Histograms are useful for displaying continuous data. Bar graphs, line graphs, and histograms have an x- and y-axis",
      "question": "What graphs use continuous data"
    },
    {
      "answer": "A dot chart or dot plot is a statistical chart consisting of group of data points plotted on a simple scale",
      "question": "Which plotting technique is used for continuous data"
    },
    {
      "answer": "Discrete data is best represented using bar charts",
      "question": "What graphs are best for discrete data"
    },
    {
      "answer": "Description of data,Handling missing data,Handling outliers,Understanding relationships and new insights through plots",
      "question": "What Are The Steps In Exploratory Data Analysis In Python"
    },
    {
      "answer": "Descriptive Analysis is the type of analysis of data that helps describe, show or summarize data points",
      "question": "How to describe Descriptive Analysis"
    },
    {
      "answer": "Descriptive statistics enables us to present the data in a more meaningful way, which allows simpler interpretation of the data",
      "question": "Why is descriptive analysis important"
    },
    {
      "answer": "The study of numerical and graphical ways to describe and display your data is called descriptive statistics",
      "question": "What is Descriptive statistics"
    },
    {
      "answer": "EDA stands for Exploratory Data Analysis",
      "question": "In Data Science what does EDA stands for"
    },
    {
      "answer": "Exploratory data analysis is often a precursor to other kinds of work with statistics and data",
      "question": "Is EDA part of data preprocessing"
    },
    {
      "answer": "If your variable of interest is measured in nominal or ordinal or Categorical level then Mode is the most often used",
      "question": "When the Mode is the most often used"
    },
    {
      "answer": "IQR is preferred over a range as, like a range, IQR does not influence by outliers",
      "question": "why IQR is preferred over a range"
    },
    {
      "answer": "first find the median or middle value of the lower and upper half of the data",
      "question": "How do you find the first quartile range"
    },
    {
      "answer": "find the median of the data and then find the median of the first half",
      "question": "How do you find lower quartile"
    },
    {
      "answer": "The semi interquartile range is one half the difference between the first and third quartiles",
      "question": "what is The semi interquartile range"
    },
    {
      "answer": "The mid quartile range is the numerical value midway between the first and third quartile",
      "question": "what is The mid quartile range"
    },
    {
      "answer": "Covariance is a measured use to determine how much variable change in randomly",
      "question": "What is Covariance"
    },
    {
      "answer": "There are two type of dispersion methods in statistics Absolute Measure of Dispersion Relative Measure of Dispersion",
      "question": "What is significance of variance"
    },
    {
      "answer": "There are two type of dispersion methods in statistics Absolute Measure of Dispersion Relative Measure of Dispersion",
      "question": "How many type of dispersion methods in statistics"
    },
    {
      "answer": "The measures of dispersion are important as it helps in understanding how much a data is spread around a central value",
      "question": "Why Is Dispersion Important in Statistics"
    },
    {
      "answer": "The distribution of a data set is the shape of the graph when all possible values are plotted on a frequency graph ",
      "question": "How can we show distribution in dataset"
    },
    {
      "answer": "A data distribution is a function or a listing which shows all the possible values or interval of the data",
      "question": "What do you mean by distribution of data"
    },
    {
      "answer": "normal distribution, chi square distribution, binomial distribution, and Poisson distribution",
      "question": "What are the four types of distribution in statistics"
    },
    {
      "answer": "The Normal or Gaussian distribution is arguably the most famous distribution",
      "question": "What are the most common distributions"
    },
    {
      "answer": ".Some distributions are symmetrical evenly distributed about the mean Other are skewed with data tending to the left or right of the mean",
      "question": "What do distributions look like"
    },
    {
      "answer": "The three common ways of looking at the center are average also called mean, mode and median",
      "question": "How do you summarize data distribution"
    },
    {
      "answer": "A simple and commonly used plot to quickly check the distribution of a sample of data is the histogram",
      "question": "How do you find the distribution of data in Python"
    },
    {
      "answer": "Matplotlib is an easy to use, low level data visualization library that is built on NumPy arrays",
      "question": "How do you visualize data in Python"
    },
    {
      "answer": ".It gives assessment not exactnes",
      "question": "What are the limitations of visualization"
    },
    {
      "answer": "The main challange is Visual noise Most of the objects in dataset are too relative to each other",
      "question": "What are the challenges of data visualization"
    },
    {
      "answer": "Tableau and Microsoft Power BI is a data visualization tool that can be used by data analysts, scientists, statisticians",
      "question": "For two dimensional which visualization library is used"
    },
    {
      "answer": "Tableau and Microsoft Power BI is a data visualization tool that can be used by data analysts, scientists, statisticians",
      "question": "what are the visualization tools"
    },
    {
      "answer": "The upper quartile, or third quartile, is the value under which seventy five percent of data points are found when arranged in increasing order",
      "question": "what is third quartile range data set"
    },
    {
      "answer": "The two main methods in which data is collected for descriptive analytics are data aggregation and data mining",
      "question": "which are the two main methods in which data is collected for descriptive analytics"
    },
    {
      "answer": "data aggregation used to achieve specific business objectives or conduct process or human analysis at almost any scale",
      "question": "What is data aggregation used for"
    },
    {
      "answer": "Predictive analytics is a branch of advanced analytics that makes predictions about future using historical with statistical modeling, data mining",
      "question": "what is the predictive analytics"
    },
    {
      "answer": "Prescriptive analytics is a type of data analytics the use of technology to help businesses make better decisions through the analysis of raw data",
      "question": "what is Prescriptive analytics"
    },
    {
      "answer": "Prescriptive analytics relies on artificial intelligence techniques, such as machine learning",
      "question": "How the Prescriptive analytics works"
    },
    {
      "answer": "A bell curve is a graph depicting the normal distribution",
      "question": "What is bell curve"
    },
    {
      "answer": "In statistics, a population parameter is a number that describes something about an entire group or population",
      "question": "what is Population parameters"
    },
    {
      "answer": "In statistics, the bias of an estimator is the difference between this estimators expected value and the true value of the parameter",
      "question": "What is Biased estimate"
    },
    {
      "answer": "An estimator of a given parameter is said to be unbiased if its expected value is equal to the true value of the parameter",
      "question": "How do you know if an estimator is unbiased"
    },
    {
      "answer": "The lognormal distribution is a continuous probability distribution that models right-skewed data",
      "question": "What is Lognormal Distribution"
    },
    {
      "answer": "The Lognormal location represents the peak mean, median, and mode of the normally distributed data",
      "question": "what is Lognormal Location Parameter"
    },
    {
      "answer": ".the purpose of Scatter plot to check the direction and strength",
      "question": "What is the primary purpose of Scatter plot"
    },
    {
      "answer": "When one variable increase as the other variable increases, there is a positive correlation",
      "question": "What is Positive Correlation in scatterplot"
    },
    {
      "answer": "negative correlation when the increase of one variable leads to decrease in the other",
      "question": "What is Negative correlation in scatterplot"
    },
    {
      "answer": ".No correlation means there is no relationship between the variables",
      "question": "what is mean by No correlation or zero correlation"
    },
    {
      "answer": "Main advantage of scatter plot it Show a relationship and a trend in the data relationship",
      "question": "what are the Advantages of Scatter plots"
    },
    {
      "answer": "univariate data for a descriptive study on how one characteristic or attribute varies or to examine how each characteristic or attribute varies before including that variable in a study with two or more variables",
      "question": "What is Univaraite analysis used for "
    },
    {
      "answer": "Graphing is a way of visually presenting the data.Purpose of the graph is to present,summarise,describe and explore the data",
      "question": "why graph needed for univariable analysis "
    },
    {
      "answer": ".Bar graphs are used to display the frequency distributions for variables measured at the nominal and ordinal levels",
      "question": "what is the Bar Graph "
    },
    {
      "answer": "Bar graphs use the same width for all the bars on the graph, and there is space between the bars.Label the parts of the graph, including the title, the left Y, right X ",
      "question": "How to represent the Bar graph \n"
    },
    {
      "answer": "histogram is a chart that is similar to a bar chart, but it is used for interval and ratio level variables",
      "question": "what is the Histogram "
    },
    {
      "answer": "With a histogram, the width of the bar is important, since it is the total area under the bar that represents the proportion of the phenomenon accounted for by each category",
      "question": "How to represent the histogram "
    },
    {
      "answer": "Pie chart is another  way to show the relationships between classes or categories of a variable is in a pie or circle chart",
      "question": "what is pie chart "
    },
    {
      "answer": "In a pie chart, each slice represents the proportion of the total phenomenon that is due to each of the classes or groups",
      "question": "How to represent the Pie chart "
    },
    {
      "answer": "The Quantile Quantile plot is a graphical technique for determining if two data sets come from populations with a common distribution",
      "question": "what is the Quantile Quantile Plot"
    },
    {
      "answer": "Quantile Quantile plots are used to find the type of distribution for a random variable whether it be a Gaussian Distribution, Uniform Distribution, Exponential Distribution or even Pareto Distribution, etc. You can tell the type of distribution",
      "question": "What does Quantile Quantile Plot will explain "
    },
    {
      "answer": "If the data is normally distributed, the points in the Quantile Quantile Plot lie on a straight diagonal line",
      "question": "How do we know Quantile Quantile Plot is normal "
    },
    {
      "answer": "The purpose of Quantile Quantile Plot is to find out if two sets of data come from the same distribution",
      "question": "Why do we use Quantile Quantile Plot"
    },
    {
      "answer": "Pairwise plots,Spider Plot,Correlation Analysis,Cluster Analysis,Multivariate Analysis of Variance,Principal Component Analysis and Factor Analysis",
      "question": "What are the multivariate analysis techniques"
    },
    {
      "answer": "frequency distribution depicts the frequency or count of the different outcomes in a data set or sample",
      "question": "What is frequency distribution"
    },
    {
      "answer": "Descriptive statistics allow for the ease of data visualization. It allows for data to be presented in a meaningful and understandable way, which, in turn, allows for a simplified interpretation of the data set in question",
      "question": "What is the importance  of describe  statistics"
    },
    {
      "answer": "There are 100 students enrolled for a particular module. To find the overall performance of the students taking the respective module and the distribution of the marks, descriptive statistics must be used. Getting the marks as raw data would prove the determination of the overall performance and the distribution of the marks to be challenging",
      "question": "What is the imporatance of describe  statistics"
    },
    {
      "answer": "The main purpose of EDA is to detect any errors, outliers as well as to understand different patterns in the data. It allows Analysts to understand the data better before making any assumptions",
      "question": "why do we needs to do EDA"
    },
    {
      "answer": "The primary goal of EDA is to maximize the analysts insight into a data set and into the underlying structure of a data set",
      "question": "What are the goals of EDA"
    },
    {
      "answer": "A dot plot, also known as a strip plot or dot chart, is a simple form of data visualization that consists of data points plotted as dots on a graph with an x and y axis",
      "question": "what is dot plot"
    },
    {
      "answer": "Dot plot  charts are used to graphically depict certain data trends or groupings",
      "question": "Where do we use the dot plot "
    },
    {
      "answer": "A good example of dot plot would be the choice of foods that you and your friends ate for snacks",
      "question": "what is an example for dot plot "
    },
    {
      "answer": "A dot plot is a visual display in which each piece of data is represented by a dot above a number line, showing the frequency of each data value. The total number of dots in the plot is the total number of values in the data set. The data points must all be in the same units",
      "question": "How to represent the dot plot"
    },
    {
      "answer": "Multivariate analysis is a Statistical procedure for analysis of data involving more than one type of measurement or observation",
      "question": "what is Multivariate analysis"
    },
    {
      "answer": "Quartiles are the values that divide a list of numerical data into three quarters.There are three quartiles, first, second and third, denoted by Q1, Q2 and Q3. Here, Q2 is nothing but the median of the given data",
      "question": "what is Quartile value"
    },
    {
      "answer": "he expansion of IQR is Inter Quartile Range ",
      "question": "What do you mean by IQR"
    },
    {
      "answer": "The formula for the interquartile range  is   Q3  upper quartile Minus Lower quartilev Q1",
      "question": "What is the formula for IQR"
    },
    {
      "answer": "The median is the middle value of the distribution of the given data. IQR is the range of values that resides in the middle of the scores. When a distribution is skewed, and the median is used instead of the mean to show a central tendency,",
      "question": "How do you define the median "
    },
    {
      "answer": "We are using box plot to identify the Outlier in the data set ",
      "question": "Where do we use box plot"
    },
    {
      "answer": "we have to import matplotlib.pyplot for any data visulaization in python ",
      "question": "What library will use in python for visual plot representation"
    },
    {
      "answer": ".A time series plot is a graph that displays data collected in a time sequence from any process",
      "question": "What is the time series plot"
    },
    {
      "answer": "The chart can be used to determine how the data is trending over time and if the data points are random or exhibit any pattern",
      "question": "What is the purpose of Time series plot"
    },
    {
      "answer": "A time series plot is also known as a. line chart. The above image, which depicts time series data, is a. line chart",
      "question": "what is line chart"
    },
    {
      "answer": "Time series analysis is a specific way of analyzing a sequence of data points collected over an interval of time",
      "question": "what is the representation of Time series plot"
    },
    {
      "answer": "Multivariate analysis of variance MANOVA is an extension of the univariate analysis of variance ANOVA",
      "question": "Is Anova Multivariate analysis"
    },
    {
      "answer": "In an ANOVA, we examine for statistical differences on one continuous dependent variable by an independent grouping variable",
      "question": "what is Anova"
    },
    {
      "answer": "visualizing multivariate data for multiple attributes together is to use parallel coordinates",
      "question": "How do you visualize multivariate data"
    },
    {
      "answer": "pair plot and interaction plot used for multivariate analysis",
      "question": "which plots used for multivariate data"
    },
    {
      "answer": "Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables",
      "question": "What is the difference between multivariate and univariate"
    },
    {
      "answer": "The chi square test is used for determining the association between categorical variables",
      "question": "what is chi square test"
    },
    {
      "answer": "Chi square test used for Bivariate Analysis of two categorical Variables",
      "question": "which test used for Bivariate Analysis of two categorical Variables"
    },
    {
      "answer": "Z and T tests used for Bivariate Analysis of one numerical and one categorical variable",
      "question": "which method used for Bivariate Analysis of one numerical and one categorical variable"
    },
    {
      "answer": "A t test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups",
      "question": "what is T test"
    },
    {
      "answer": " z test is a statistical test to determine whether two population means are different when the variances are known and the sample size is large ",
      "question": "what is z test"
    },
    {
      "answer": "the secondary purpose of Scatter plot is to identify the outliers and presence of clusters",
      "question": "what is the secondary purpose of Scatter plots\n"
    },
    {
      "answer": "t is the area of the bar that tells us the frequency in a histogram, not its height",
      "question": "What does density mean in histogram"
    },
    {
      "answer": "Undirected graph is directionless This means that the edges have no direction",
      "question": "What are Undirected graph"
    },
    {
      "answer": ".A pairs plot allows us to see both distribution of single variables and relationships between two variables",
      "question": "what is pair plot"
    },
    {
      "answer": "Pairplot Plot pairwise relationships in a dataset",
      "question": "What is Seaborn Pairplot"
    },
    {
      "answer": "Infinite kurtosis can be completely normal or flat with no deviation",
      "question": "what is infinite kurtosis"
    },
    {
      "answer": "Excess kurtosis means the distribution of event outcomes have lots of instances of outlier results, causing fat tails on the bell shaped distribution curve",
      "question": "what is excess kurtosis"
    },
    {
      "answer": "Directed graphs have directions associated with them",
      "question": "what is Directed graph"
    },
    {
      "answer": "An adjacency matrix is a square matrix where the number of rows, columns and nodes are the same",
      "question": "what is adjacency matrix "
    },
    {
      "answer": "An interaction plot displays the levels of one variable on the X axis and has a separate line for the means of each level of the other variable",
      "question": "what is an interaction plot"
    },
    {
      "answer": ".The fouth statistical moment talk about Kurtosis.It focus on the Peakness of distribution in the dataset.",
      "question": "what do you mean by Fouth statistical business moment"
    },
    {
      "answer": "There are two types of skewness.positive skewness or negative skewness",
      "question": "what are types of Skewness"
    },
    {
      "answer": "The sample correlation coefficient r is a measure of the closeness of association of the points in a scatter plot",
      "question": "what is r in correlation"
    },
    {
      "answer": "A density plot is a representation of the distribution of a numeric variable",
      "question": "What is density plot"
    },
    {
      "answer": "A density curve is a graphical representation of a numerical distribution where the outcomes are continuous",
      "question": "What is the density curve"
    },
    {
      "answer": "Univariate analysis is the simplest form of analyzing data. Unimeans one , so in other words your data has only one variable",
      "question": "What is Univariate analysis"
    },
    {
      "answer": ".What is the disavantage of scatter plots Interpretation can be subjective",
      "question": "What is the disavantage of scatter plots"
    },
    {
      "answer": "The relationship between two variables is generally considered strong when their r value is larger than 0.7",
      "question": "What does strong mean in a scatter plot\n"
    },
    {
      "answer": "An outlier for a scatter plot is the point or points that are farthest from the regression line",
      "question": "How do outliers affect scatter plots\n"
    },
    {
      "answer": ".As a rule of thumb, a correlation coefficient between 0.25 and 0.5 is considered to be a weak correlation between two variables",
      "question": "What is a very weak correlation"
    },
    {
      "answer": ".When r is near plus 1 or minus 1, the linear relationship is strong when it is near 0, the linear relationship is weak",
      "question": ".How do you know if a correlation is strong or weak"
    },
    {
      "answer": "covariance does not standardise the but correlation standardise the data",
      "question": "Describe covariance vs correlation\n"
    },
    {
      "answer": ".covariance determine only direction but correlation determine both direction and strength",
      "question": "what is the difference between covariance and correlation\n"
    },
    {
      "answer": ".Pearsons correlation coefficient is the test statistics that measures the statistical relationship, or association, between two continuous variables",
      "question": "What do Pearson correlations mean"
    },
    {
      "answer": ".It uses a kernel density estimate to show the probability density function of the variable",
      "question": "why the density plot is used"
    },
    {
      "answer": "Interaction plots are used to understand the behavior of one variable depends on the value of another variable",
      "question": "what is the significance of Interaction Plots in Statistics"
    },
    {
      "answer": "Bivariate data includes data for two set of variables so two sets of data that might be linked",
      "question": "How do you represent bivariate data"
    },
    {
      "answer": ".Bivariate data is most often displayed using a scatter plot",
      "question": "How do we represent bivariate data graphically and how do we analyze it"
    },
    {
      "answer": ".If a density curve is left skewed, then the mean is less than the median,right skewed, then the Mean is greater than the median,no skew, then the mean is equal to the median",
      "question": "How do you analyze a density plot"
    },
    {
      "answer": "As the area of a bar represents the frequency of its interval, the height of the bar represents the density",
      "question": "Is density same as frequency"
    },
    {
      "answer": "In a density histogram or probability density function, the total occurrences is one",
      "question": "What is the difference between a frequency histogram and a density histogram"
    },
    {
      "answer": "kernel plot is also called as density plot,A Density Plot visualises the distribution of data over a continuous interval or time period",
      "question": "What is a kernel plot"
    },
    {
      "answer": "Quantile Quantile plot is to show if two data sets come from the same distribution",
      "question": "What does a Quantile Quantile plot show"
    },
    {
      "answer": "Quantile Quantile Plots overcomes all the limitations of the Histogram plot",
      "question": "Why Quantile Quantile plot is better than a histogram"
    },
    {
      "answer": ".A Probability plot compares the empirical cumulative distribution function,A Qunatile Qunatile plot compares the quantiles of a data distribution with the quantiles",
      "question": "What is the difference between Probability plot and Quantile Quantile plot"
    },
    {
      "answer": "Unimodal has just one peak",
      "question": "what is unimodal"
    },
    {
      "answer": "The ratio of skewness to its standard error can be used as a test of normality ",
      "question": "what is standard error of skewness"
    },
    {
      "answer": "The standard error is calculated by dividing the standard deviation by the sample sizes square root",
      "question": "How is standard error calculated"
    },
    {
      "answer": "Parsimonious models are simple models with great explanatory predictive power",
      "question": "what is parsimonious model"
    },
    {
      "answer": ".Box plots visually show the distribution of numerical data and skewness through displaying the data quartiles or percentiles and averages",
      "question": "What does a whisker plot tell you"
    },
    {
      "answer": "A vertex or node of a graph is one of the objects that are connected together",
      "question": "what are the vertices or nodes"
    },
    {
      "answer": ".An edge or link of a network or graph is one of the connections between the nodes or vertices of the network",
      "question": "what is edge or link in graph"
    },
    {
      "answer": "Weighted graph indicate real values associated with the edges",
      "question": "what is the weighted graph"
    },
    {
      "answer": "In Graph theory, these networks are called graphs",
      "question": "what are the graphs"
    },
    {
      "answer": "Skewness  which is the Third  Statistical moment measures asymmetry of data about its mean",
      "question": "What is Third business moment"
    },
    {
      "answer": "Symmetrical distribution means In the data set both tails are symmetrical and Skewness is equal to zero.",
      "question": "What is symmetrical distribution"
    },
    {
      "answer": "We can identify the symmetrical distribution when mean,median and mode are equal",
      "question": "How to identify the symmetrical distribution "
    },
    {
      "answer": "Positive skewness means in the dataset when Mode is lesser than Median and Median is lesser than Mean.",
      "question": "what about  positive  skewness"
    },
    {
      "answer": "Negative skewness means in the dataset when Mean  is lesser than Median and Median is lesser than Mode.",
      "question": "What about  negative skewness"
    },
    {
      "answer": "This means that normal distribution may have a kurtosis of 3 or excess kurtosis of 0.",
      "question": "what is the kurtosis of normal distribution"
    },
    {
      "answer": ".If skewness is less than minus 1 or greater than 1 the distribution is highly skewed, it is between minus 1 and minus0.5 or between 0.5 and 1 the distribution is moderately skewed",
      "question": "What is the threshold for skewness"
    },
    {
      "answer": "There are three types of Kurtosis is there.Mesokurtic,leptokurtic and platykurtic",
      "question": "what are the  types of  kurtosis"
    },
    {
      "answer": "Mesokurtic having the kurtosis of 3.This group involves the normal distribution and some specific binomial distributions.",
      "question": "Explain about the mesokurtic"
    },
    {
      "answer": "The kurtosis is greater than 3, or excess kurtosis is greater than 0. This is the distribution with fatter tails and a more narrow peak",
      "question": "Explain about the Leptokurtic"
    },
    {
      "answer": "The kurtosis is smaller than 3 or negative for excess kurtosis. This is a distribution with very thin tails compared to the normal distribution",
      "question": "Explain about the Platykurtic"
    },
    {
      "answer": ".A variable in univariate analysis is just a condition or subset that your data falls into",
      "question": "What is the example for Univariate analysis"
    },
    {
      "answer": "Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables",
      "question": "What is the difference between Univariate analysis and Multivariate analysis"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction",
      "question": "Why we using boosting"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction",
      "question": "Use of boosting"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction.",
      "question": "Why do we use boosting in machine learning"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors.",
      "question": "What is boosting technique"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors.",
      "question": "Describe Boosting technique"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors.",
      "question": "what is boosting"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors",
      "question": "Define boosting"
    },
    {
      "answer": "Ensemble methods reduce the bias and variance of our Machine Learning models.Ensemble methods help increase the stability and performance of machine learning models by eliminating the dependency of a single estimator.",
      "question": "Why is Boosting so effective"
    },
    {
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm",
      "question": "What are different boosting techniques"
    },
    {
      "answer": "The term Boosting refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor",
      "question": "What is the key idea of boosting"
    },
    {
      "answer": "The term Boosting  refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor",
      "question": "Describe idea of Boosting"
    },
    {
      "answer": "The term Boosting  refers to a family of algorithms which converts weak learner to strong learners. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting is to train weak learners sequentially, each trying to correct its predecessor",
      "question": "Define key idea of boosting"
    },
    {
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees are fit and at every step, the goal is to improve the accuracy from the prior tree",
      "question": "Why gradient is boosting"
    },
    {
      "answer": "XGBoost stands for Extreme Gradient Boosting, where the term Gradient Boosting originates from the paper Greedy Function Approximation  A Gradient Boosting Machine, by Friedman. The gradient boosted trees has been around for a while, and there are a lot of materials on the topic",
      "question": "What is boost in XGBoost"
    },
    {
      "answer": "Robert Schapire and Yoav Freund made a huge impact in machine and statistical learning with their invention of boosting, which has survived the test of time",
      "question": "Who invented boosting"
    },
    {
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models",
      "question": "How does boosting reduce bias"
    },
    {
      "answer": "overfitting than AdaBoost Boosting techniques tend to have low bias and high variance For basic linear regression classifiers, there is no effect of using Gradient Boosting",
      "question": "On which technique boosting Cannot be applied"
    },
    {
      "answer": "Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series. Firstly, a model is built from the training data",
      "question": "On which technique boosting can be applied"
    },
    {
      "answer": "Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance. In Bagging, each model receives an equal weight. In Boosting, models are weighed based on their performance",
      "question": "Why is boosting better than bagging"
    },
    {
      "answer": "Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance. In Bagging, each model receives an equal weight. In Boosting, models are weighed based on their performance",
      "question": "Describe why boosting is better than bagging"
    },
    {
      "answer": "Boosting is a popular machine learning algorithm that increases accuracy of your model\n",
      "question": "Does boosting speed up model learning"
    },
    {
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage",
      "question": "What is boosting decision tree"
    },
    {
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage",
      "question": "Define boosting decision tree"
    },
    {
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage",
      "question": "what is ment by boosting decision tree"
    },
    {
      "answer": "Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage",
      "question": "Boosting decision tree"
    },
    {
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model",
      "question": "What is a gradient boosting classifier"
    },
    {
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model",
      "question": "gradient boosting classifier"
    },
    {
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications",
      "question": "What is boosting in stats"
    },
    {
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications",
      "question": "Define boosting in stats"
    },
    {
      "answer": "In predictive modeling, boosting is an iterative ensemble method that starts out by applying a classification algorithm and generating classifications",
      "question": "Describe boosting in stats"
    },
    {
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost",
      "question": "What is the difference between AdaBoost and gradient boosting"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction",
      "question": "Describe use of Boosting"
    },
    {
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost",
      "question": "Diffrentiate AdaBoost and gradient boosting"
    },
    {
      "answer": "Gradient boosting derived from the term gradient boosting machines is a popular supervised machine learning technique for regression and classification problems that aggregates an ensemble of weak individual models to obtain a more accurate final model",
      "question": "Is gradient boosting supervised or unsupervised"
    },
    {
      "answer": "Gradient boosting can be used for regression and classification problems",
      "question": "Can boosting be used for regression"
    },
    {
      "answer": "Compared to the simple base learner,boosting increases variance and reduces bias.If you boost a simple base learner, the resulting model will have lower variance compared to some high variance reference like a too deep decision tree",
      "question": "How does boosting reduce variance"
    },
    {
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially",
      "question": "What is ensemble tree"
    },
    {
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially",
      "question": "Describe ensemble tree"
    },
    {
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially",
      "question": "Define ensemble tree"
    },
    {
      "answer": "An ensemble of trees are built one by one and individual trees are summed sequentially\n",
      "question": "ensemble tree"
    },
    {
      "answer": "The difference between stacking and blending is that Stacking uses out of fold predictions for the train set of the next layer,and Blending uses a validation set to train the next layer",
      "question": "Which option is highlighting the difference between blending and stacking"
    },
    {
      "answer": "The random forest algorithm is actually a bagging algorithm also here, we draw random bootstrap samples from your training set. However, in addition to the bootstrap samples, we also draw random subsets of features for training the individual trees in bagging, we provide each tree with the full set of features",
      "question": "Is Random Forest bagging or boosting"
    },
    {
      "answer": "Random Forest is an boosting algorithm which uses trees as its weak classifiers",
      "question": "Is Random Forest a boosting algorithm"
    },
    {
      "answer": "Gradient Boosting",
      "question": "Which is best boosting algorithm"
    },
    {
      "answer": "Gradient Boosting",
      "question": "best boosting algorithm"
    },
    {
      "answer": "In XGBoost, trees grow depth wise while in LightGBM, trees grow leaf wise which is the fundamental difference between the two frameworks",
      "question": "What is the difference between XGBoost and LightGBM"
    },
    {
      "answer": "In XGBoost, trees grow depth wise while in LightGBM, trees grow leaf wise which is the fundamental difference between the two frameworks",
      "question": "Diffrentiate XGBoost and LightGBM"
    },
    {
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers",
      "question": "Is boosting an ensemble method"
    },
    {
      "answer": "If the classifier is stable and simple high bias then we should apply Boosting. Bagging is extended to Random forest model while Boosting is extended to Gradient boosting\n",
      "question": "Does gradient boosting use bagging"
    },
    {
      "answer": "Boosting also requires bootstrapping",
      "question": "Does boosting use bootstrap"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n",
      "question": "What is gradient boosting regression"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees",
      "question": "gradient boosting regression"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n",
      "question": "What is ment by gradient boosting regression"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n",
      "question": "Define gradient boosting regression"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees\n",
      "question": "Describe gradient boosting regression"
    },
    {
      "answer": "n the context of gradient boosting, the training loss is the function that is optimized using gradient descent",
      "question": "What is loss function in gradient boosting"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent",
      "question": "Describe loss function in gradient boosting"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent",
      "question": "Define loss function in gradient boosting"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent\n",
      "question": "What is ment by loss function in gradient boosting"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent\n",
      "question": "loss function in gradient boosting"
    },
    {
      "answer": "Gradient boosting is a greedy algorithm and can overfit a training dataset quickly",
      "question": "Does gradient boosting Overfit"
    },
    {
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm",
      "question": "type of boosting technique"
    },
    {
      "answer": "AdaBoost Adaptive Boosting algorithm,Gradient Boosting algorithm,XG Boost algorithm",
      "question": "Describe diffrent type of boosting technique"
    },
    {
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "boosted classification trees"
    },
    {
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "Define boosted classification trees"
    },
    {
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "Describe boosted classification trees"
    },
    {
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "What is ment by boosted classification trees"
    },
    {
      "answer": "If you carefully tune parameters, gradient boosting can result in better performance than random forests",
      "question": "Is gradient boosting better than random forest"
    },
    {
      "answer": "Gradient boosting redefines boosting as a numerical optimisation problem where the objective is to minimise the loss function of the model by adding weak learners using gradient descent",
      "question": "Does gradient boosting use gradient descent"
    },
    {
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error.If a small change in the prediction for a case causes no change in error, then next target outcome of the case is zero",
      "question": "How does gradient boosting tree work"
    },
    {
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error.If a small change in the prediction for a case causes no change in error, then next target outcome of the case is zero",
      "question": "Describe working of gradient boosting tree "
    },
    {
      "answer": "Gradient Boosting Trees can be used for both regression and classification",
      "question": "Is gradient boosting used for classification"
    },
    {
      "answer": "Boosting means that each tree is dependent on prior trees\n",
      "question": "Describe boosting decision tree"
    },
    {
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up",
      "question": "What are the limitations of boosting"
    },
    {
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up",
      "question": "Describe limitations of boosting"
    },
    {
      "answer": "One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers. Another disadvantage is that the method is almost impossible to scale up",
      "question": "limitations of boosting"
    },
    {
      "answer": "When gradient boosting is done along with linear regression, it is nothing more than another linear model over the existing linear model",
      "question": "Is gradient boosting linear"
    },
    {
      "answer": "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes Gradient Boosting more flexible than AdaBoost",
      "question": "What is the difference between adaptive boosting and gradient boosting"
    },
    {
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set",
      "question": "Diffrentiate adaptive boosting and gradient boosting"
    },
    {
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set",
      "question": "How does boosting algorithm work"
    },
    {
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set\n",
      "question": "Describe working of boosting algorithm"
    },
    {
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule. These weak rules are generated by applying base Machine Learning algorithms on different distributions of the data set",
      "question": "What is ment by working of boosting algorithm"
    },
    {
      "answer": "The residual is the gradient of loss function and the sign of the residual, , is the gradient of loss function . By adding in approximations to residuals, gradient boosting machines are chasing gradients, hence, the term gradient boosting.",
      "question": "Why is it called gradient boosting"
    },
    {
      "answer": "To calculate the gain in each split, XGBoost uses CPU cache to store calculated gradients and Hessians to make the necessary calculations fast. When data does not fit into the cache and main memory, then it becomes important to use the disk space",
      "question": "Why XGBoost is fast"
    },
    {
      "answer": "In Boosting, fitting of many models on training examples relies on target values for calculating residuals. This leads to shift in target values in test set",
      "question": "How does Boosting make prediction"
    },
    {
      "answer": "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model",
      "question": "What is ment by gradient boosting classifier"
    },
    {
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models. The term Boosting refers to a family of algorithms which converts a weak learner to a strong learner. Boosting gets multiple learners",
      "question": "Why does boosting reduce bias"
    },
    {
      "answer": "Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models. The term Boosting refers to a family of algorithms which converts a weak learner to a strong learner",
      "question": "Does boosting reduce variance or bias"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors",
      "question": "What are boosting models"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors",
      "question": "boosting model"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors",
      "question": "Define boosting models"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors\n",
      "question": "Describe boosting models"
    },
    {
      "answer": "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors",
      "question": "What is ment by boosting models"
    },
    {
      "answer": "The good thing about Bagging is, that it also does not increase the bias again, which we will motivate in the following section. That is why the effect of using Bagging together with Linear Regression is low You can not decrease the bias via Bagging, but with Boosting",
      "question": "Can bagging reduce bias"
    },
    {
      "answer": "That is because bagging allows us to approximate relative complex response surfaces by practically smoothing over the learners decision boundaries. That said, you raise a good point about bagging using less data my understanding is that this is a problem when the learners are potentially weak\n",
      "question": "Why does bagging increase bias"
    },
    {
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification",
      "question": "What the difference between bagging and boosting"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction\n",
      "question": "Why is boosting used"
    },
    {
      "answer": "Boosting is a method of combining many weak learners trees into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "What are boosted classification trees"
    },
    {
      "answer": "Bagging is a method of merging the same type of predictions. Boosting is a method of merging different types of predictions. Bagging decreases variance, not bias, and solves over fitting issues in a model. Boosting decreases bias, not variance",
      "question": "What is the primary difference between bagging and boosting algorithms"
    },
    {
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification",
      "question": "Diffrentiate bagging and boosting"
    },
    {
      "answer": "Boosting grants power to machine learning models to improve their accuracy of prediction",
      "question": "what is boosting used for"
    },
    {
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are How trees are built random forests builds each tree independently while gradient boosting builds one tree at a time.\n",
      "question": "What is the difference between gradient boosting and Random Forest"
    },
    {
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are How trees are built random forests builds each tree independently while gradient boosting builds one tree at a time.",
      "question": "Diffrentiate gradient boosting and Random Forest"
    },
    {
      "answer": "Boosting reduces error mainly by reducing bias . On the other hand, Random Forest uses as you said fully grown decision trees.It tackles the error reduction task in the opposite way by reducing variance\n",
      "question": "Why boosting is better than random forest"
    },
    {
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm",
      "question": "What is extreme gradient boost"
    },
    {
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm",
      "question": "extreme gradient boost"
    },
    {
      "answer": "Extreme Gradient Boosting XGBoost is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm.Extreme Gradient Boosting is an efficient open source implementation of the stochastic gradient boosting ensemble algorithm",
      "question": "What is ment by extreme gradient boost"
    },
    {
      "answer": "Boosting, or boosted regression, is a recent data mining technique. that has shown considerable success in predictive accuracy",
      "question": "What is boosting regression"
    },
    {
      "answer": "Boosting, or boosted regression, is a recent data mining technique. that has shown considerable success in predictive accuracy",
      "question": "boosting regression"
    },
    {
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm",
      "question": "What is light gradient boosting machine"
    },
    {
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm\n",
      "question": "light gradient boosting machine"
    },
    {
      "answer": "Light Gradient Boosted Machine, or LightGBM for short, is an open source library that provides an efficient and effective implementation of the gradient boosting algorithm",
      "question": "what is ment by light gradient boosting machine"
    },
    {
      "answer": "Bootstrap aggregation, or bagging, in machine learning decreases variance through building more advanced models of complex data sets.Since this approach consolidates discovery into more defined boundaries, it decreases variance and helps with overfitting",
      "question": "Does bagging increase variance"
    },
    {
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model",
      "question": "How do boosting techniques work"
    },
    {
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model",
      "question": "How does boosting work"
    },
    {
      "answer": "In the bagging method all the individual models will take the bootstrap samples and create the models in parallel. Whereas in the boosting each model will build sequentially. The output of the first model will be pass along with the bootstrap samples data.",
      "question": "What is the difference between bootstrapping bagging and boosting"
    },
    {
      "answer": "In the bagging method all the individual models will take the bootstrap samples and create the models in parallel. Whereas in the boosting each model will build sequentially. The output of the first model will be pass along with the bootstrap samples data.",
      "question": "Diffrentiate bootstrapping bagging and boosting"
    },
    {
      "answer": "The basic principle behind the working of the boosting algorithm is to generate multiple weak learners and combine their predictions to form one strong rule",
      "question": "How does boost work"
    },
    {
      "answer": "In Boosting, fitting of many models on training examples relies on target values for calculating residuals. This leads to shift in target values in test set, i.e. prediction shift. So, it proposes a method to bypass this problem\n",
      "question": "How does boosting make predictionWhy use weak learners in boosting"
    },
    {
      "answer": "However, there are times when ML models are weak learners. Boosting is a way to take several weak models and combine them into a stronger one. Doing this allows you to eliminate bias, improve model accuracy, and boost performance",
      "question": "Why use weak learners in boosting"
    },
    {
      "answer": "Gradient boosting algorithm is one of the most powerful algorithms in the field of machine learning.Gradient boosting algorithm can be used for predicting not only continuous target variable  but also categorical target variable \n",
      "question": "What is Gradient Boosting algorithm"
    },
    {
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree",
      "question": "what is the main objective of boosting"
    },
    {
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree",
      "question": "Describe main objective of Boosting"
    },
    {
      "answer": "Boosting is used to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analysing data for errors. Consecutive trees random sample are fit and at every step, the goal is to improve the accuracy from the prior tree",
      "question": "Main objective of Boosting"
    },
    {
      "answer": "Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model",
      "question": "How is boosting done"
    },
    {
      "answer": "Boosting means combining a learning algorithm in series to achieve a strong learner from many sequentially connected weak learners.Trees in boosting are weak learners but adding many trees in series and each focusing on the errors from previous one make boosting a highly efficient and accurate model",
      "question": "How do boosted trees work"
    },
    {
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "What boosted trees"
    },
    {
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "What meant by boosted trees"
    },
    {
      "answer": "Boosting is a method of combining many weak learners  into a strong classifier. Common tree parameters. These parameters define the end condition for building a new tree. They are usually tuned to increase accuracy and prevent overfitting",
      "question": "Describe boosted trees"
    },
    {
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results",
      "question": "What is the learning rate in boosting"
    },
    {
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results.\n",
      "question": "Describe learning rate in boosting"
    },
    {
      "answer": "This weighting is called a shrinkage or a learning rate. Using a low learning rate can dramatically improve the perfomance of your gradient boosting model. Usually a learning rate in the range of 0.1 to 0.3 gives the best results",
      "question": "Define learning rate in boosting"
    },
    {
      "answer": "The Gradient Boosting Machine is a powerful ensemble machine learning algorithm that uses decision trees. Boosting is a general ensemble technique that involves sequentially adding models to the ensemble where subsequent models correct the performance of prior models",
      "question": "Is gradient boosting ensemble"
    },
    {
      "answer": "Bagging is a technique for reducing prediction variance by producing additional data for training from a dataset by combining repetitions with combinations to create multi sets of the original data. Boosting is an iterative strategy for adjusting an observations weight based on the previous classification",
      "question": "What is difference between boosting and bagging"
    },
    {
      "answer": "Lots of analyst misinterpret the term boosting used in data science.Boosting grants power to machine learning models to improve their accuracy of prediction. Boosting algorithms are one of the most widely used algorithm in data science competitions",
      "question": "What is boosting data science"
    },
    {
      "answer": "Gradient Boosting is similar to AdaBoost in that they both use an ensemble of decision trees to predict a target label. However, unlike AdaBoost, the Gradient Boost trees have a depth larger than 1. In practice, you will typically see Gradient Boost being used with a maximum number of leaves of between 8 and 32",
      "question": "How many trees are in gradient boosting"
    },
    {
      "answer": "A problem with gradient boosted decision trees is that they are quick to learn and overfit training data. One effective way to slow down learning in the gradient boosting model is to use a learning rate, also called shrinkage",
      "question": "Does gradient boosting use learning rate"
    },
    {
      "answer": "Bagging is usually applied where the classifier is unstable and has a high variance. Boosting is usually applied where the classifier is stable and simple and has high bias.\n",
      "question": "When to Use bagging vs boosting"
    },
    {
      "answer": "AdaBoost is known to be sensitive to outliers and  noise",
      "question": "Is AdaBoost sensitive to outliers"
    },
    {
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model.",
      "question": "What is shrinkage in gradient boosting"
    },
    {
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model.",
      "question": "What is ment by shrinkage in gradient boosting"
    },
    {
      "answer": "Shrinkage is a gradient boosting regularization procedure that helps modify the update rule, which is aided by a parameter known as the learning rate. The use of learning rates below 0.1 produces improvements that are significant in the generalization of a model.",
      "question": "Describe shrinkage in gradient boosting"
    },
    {
      "answer": "Gradient Boosting is similar to AdaBoost in that they both use an ensemble of decision trees to predict a target label. However, unlike AdaBoost, the Gradient Boost trees have a depth larger than 1. In practice, you will typically see Gradient Boost being used with a maximum number of leaves of between 8 and 32",
      "question": "What is Max depth in gradient boosting"
    },
    {
      "answer": "Unlike what mentioned in tdc comment, most of boosting methods are highly sensitive to the labeling noise and may easily overfit in the presence of labeling noise. In datasets where Bayes error rates are far from 0  boosting methods can easily overfit , as well",
      "question": "Why is boosting prone to overfitting"
    },
    {
      "answer": "XGB consists of a number of hyper parameters that can be tuned a primary advantage over gradient boosting machines.XGBoost has an in built capability to handle missing values.It provides various intuitive features, such as parallelisation, distributed computing, cache optimisation, and more. ",
      "question": "What are the advantages of XGBoost"
    },
    {
      "answer": "Like any other boosting method, XGB is sensitive to outliers.Unlike LightGBM, in XGB, one has to manually create dummy variable, label encoding for categorical features before feeding them into the models.",
      "question": "What are the disadvantages of XGBoost"
    },
    {
      "answer": ".In some cases, boosting models are trained with an specific fixed weight for each learner called learning rate and instead of giving each sample an individual weight, the models are trained trying to predict the differences between the previous predictions on the samples and the real values of the objective variable.",
      "question": "How is boosting model trained"
    },
    {
      "answer": "In some cases, boosting models are trained with an specific fixed weight for each learner called learning rate and instead of giving each sample an individual weight, the models are trained trying to predict the differences between the previous predictions on the samples and the real values of the objective variable.",
      "question": "How to train boosting model"
    },
    {
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods\n",
      "question": "What is a strong learner"
    },
    {
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods",
      "question": "Define strong learner"
    },
    {
      "answer": "Strong learners are models that have arbitrarily good accuracy. Weak and strong learners are tools from computational learning theory and provide the basis for the development of the boosting class of ensemble methods",
      "question": "What is ment by strong learner"
    },
    {
      "answer": "Boosting is a sequential ensemble method that iteratively adjusts the weight of observation as per the last classification. If an observation is incorrectly classified, it increases the weight of that observation",
      "question": "Is boost sequential"
    },
    {
      "answer": "There has been an enhancement in the algorithm gradient boosting due to which you no longer have to handle the missing values because it will handle it of itself.Hist Gradient Boosting Regressor, both classification regression now have the power of native support for missing values or nans ",
      "question": "Can gradient boosting handle missing values"
    },
    {
      "answer": "Gradient Boosting Decision Tree Based Method for Predicting Interactions Between Target Genes and Drugs. Determining the target genes that interact with drugs drug target interactions plays an important role in drug discovery",
      "question": "Is gradient boosting a tree based method"
    },
    {
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data",
      "question": "What is boosting XGBoost"
    },
    {
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data",
      "question": "boosting XGBoost"
    },
    {
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data",
      "question": "Describe boosting XGBoost"
    },
    {
      "answer": "XGBoost stands for Extreme Gradient Boosting it is a specific implementation of the Gradient Boosting method which uses more accurate approximations to find the best tree model. It employs a number of nifty tricks that make it exceptionally successful, particularly with structured data",
      "question": "What is ment by boosting XGBoost"
    },
    {
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases",
      "question": "What is booster in XGBoost"
    },
    {
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases\n",
      "question": "booster in XGBoost"
    },
    {
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases",
      "question": "Describe booster in XGBoost"
    },
    {
      "answer": "The booster parameter sets the type of learner.The objective determines the learning task, thus the type of the target variable. The available options include regression, logistic regression, binary and multi classification or rank. This option allows to apply XGBoost models to several different types of use cases",
      "question": "What is ment by booster in XGBoost"
    },
    {
      "answer": "Gradient Boosting for regression. GB builds an additive model in a forward stage wise fashion it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function",
      "question": "What is gradient boosting Regressor"
    },
    {
      "answer": "No more than 32 columns per categorical feature",
      "question": "How many columns can XGBoost handle"
    },
    {
      "answer": "The amount of data you need depends on the problem see this great article on learning curves, but in general xgboost is very data efficient like random forests and has found a lot of use where data is expensive to produce as in medicine",
      "question": "Does XGBoost require a lot of data"
    },
    {
      "answer": ".Boosting means that each tree is dependent on prior trees. The algorithm learns by fitting the residual of the trees that preceded it. Thus, boosting in a decision tree ensemble tends to improve accuracy with some small risk of less coverage",
      "question": "How do boosted decision trees work"
    },
    {
      "answer": "XGBoost is more regularized form of Gradient Boosting. XGBoost uses advanced regularization L1 and L2, which improves model generalization capabilities. XGBoost delivers high performance as compared to Gradient Boosting. Its training is very fast and can be parallelized,distributed across clusters",
      "question": "What is the difference between XGBoost and gradient boost"
    },
    {
      "answer": "XGBoost is more regularized form of Gradient Boosting. XGBoost uses advanced regularization L1 and L2, which improves model generalization capabilities. XGBoost delivers high performance as compared to Gradient Boosting. Its training is very fast and can be parallelized,distributed across clusters",
      "question": "Diffrentiate XGBoost and gradient boost"
    },
    {
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch",
      "question": "What is regression tree"
    },
    {
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch",
      "question": "Describe regression tree"
    },
    {
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch",
      "question": "What is ment by regression tree "
    },
    {
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model",
      "question": "What is a boosted tree model"
    },
    {
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model",
      "question": "Describe boosted tree model"
    },
    {
      "answer": "Boosted Regression Tree BRT models are a combination of two techniques decision tree algorithms and boosting methods. Like Random Forest models, BRTs repeatedly fit many decision trees to improve the accuracy of the model",
      "question": "What is ment by boosted tree model"
    },
    {
      "answer": "Gradient Boosting Algorithm is generally used when we want to decrease the Bias error.Gradient Boosting Algorithm can be used in regression as well as classification problems. In regression problems, the cost function is MSE whereas, in classification problems, the cost function is Log Loss",
      "question": "Why is gradient boosting used"
    },
    {
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned",
      "question": "What is Gamma in XGBoost"
    },
    {
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned",
      "question": "Gamma in XGBoost"
    },
    {
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned",
      "question": "What is ment by Gamma in XGBoost"
    },
    {
      "answer": "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned",
      "question": "Describe Gamma in XGBoost"
    },
    {
      "answer": "The residual is the gradient of loss function and the sign of the residual,is the gradient of loss function.By adding in approximations to residuals, gradient boosting machines are chasing gradients, hence, the term gradient boosting\n",
      "question": "Why is gradient boosting called gradient"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees",
      "question": "What is gradient boosting framework"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees",
      "question": "gradient boosting framework"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees",
      "question": "Describe gradient boosting framework"
    },
    {
      "answer": "Gradient boosting is a machine learning technique used in regression and classification tasks, among others.It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees",
      "question": "What is ment by gradient boosting framework"
    },
    {
      "answer": "Fits an exponential cost function and is linear with respect to the observation. Thus, boosting is seen to be a specific type of linear regression",
      "question": "Is boosting linear"
    },
    {
      "answer": "Learning boosts are a learning program strategy in which learners are sent short pieces of information, activities, or quiz questions to boost retention of a particular topic or subject",
      "question": "What is a learning boost"
    },
    {
      "answer": "Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series",
      "question": "What is boosting in AI"
    },
    {
      "answer": "Step 1 The base learner takes all the distributions and assign equal weight or attention to each observation.Step 2 If there is any prediction error caused by first base learning algorithm, then we pay higher attention to observations having prediction error. Then, we apply the next base learning algorithm",
      "question": "How do you boost an algorithm"
    },
    {
      "answer": "Jerome Friedman",
      "question": "Who invented gradient boosting"
    },
    {
      "answer": "BOOST feedback model is one such popular informal method. It is used to give constructive and continuous feedback about positive behaviour as well as rectifying shortcomings. It has been proven to identify and tackle specific performance issues before they escalate into major problems",
      "question": "What is a boost model"
    },
    {
      "answer": "Histogram based gradient boosting is a technique for training faster decision trees used in the gradient boosting ensemble.",
      "question": "What is histogram based gradient boosting"
    },
    {
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network.",
      "question": "What is average path length"
    },
    {
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges.",
      "question": "Define nodes "
    },
    {
      "answer": "Network analytics is any process where network data is collected and analyzed to improve the performance, reliability, visibility, or security of the network.",
      "question": "What is network analytics"
    },
    {
      "answer": "The DFS algorithm aims to move as far as possible away from the root node.",
      "question": "Describe depth first search"
    },
    {
      "answer": "Among basic network analysis methods include  Method  Critical Path Method  And  Critical Chain Method PERT Method, Program Evaluation and Review Technique",
      "question": "Methods of network analysis"
    },
    {
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops.",
      "question": "Describe distances"
    },
    {
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops.",
      "question": "What is distances"
    },
    {
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes.",
      "question": "What is dyads"
    },
    {
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network.",
      "question": "Average path length"
    },
    {
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network.\n",
      "question": "Define average path length"
    },
    {
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network\n",
      "question": "Types of centrality"
    },
    {
      "answer": "Network analysts are employed by businesses to optimize IT network operations. Their duties include analyzing network requirements, setting up computer networks in one or across multiple locations, and configuring computer hardware and software for optimal network communication.",
      "question": "What does a network analyst do"
    },
    {
      "answer": "Network density is the number of edges divided by the total possible edges.",
      "question": "What is network density"
    },
    {
      "answer": "Point to point analysis. A point to point analysis is the most common routing problem. \nFinding Coverage. \nOptimize Fleet. \nSelect Optimal Site. \nOrigin Destination  OD Cost Matrix.\n",
      "question": "Types of network analysis"
    },
    {
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network",
      "question": "What is centrality"
    },
    {
      "answer": "a.Bidirectional edges\nb.Unidirectional edges",
      "question": "Types of edges"
    },
    {
      "answer": "Network traffic is the amount of data moving across a computer network at any given time. Network traffic, also called data traffic, is broken down into data packets and sent over a network before being reassembled by the receiving device or computer.",
      "question": "Network traffic data"
    },
    {
      "answer": "Origin Destination  matrix describes people movement in a certain area. An OD matrix is necessary for planning a good public transportation system. However, the exact values of OD matrix are difficult to measure.",
      "question": "What is OD Matrix"
    },
    {
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops.",
      "question": "Distances"
    },
    {
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes.\n",
      "question": "Dyads"
    },
    {
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network",
      "question": "Centrality"
    },
    {
      "answer": "PERT and CPM are well known network technology.It is espicially using for planning ,scheduling and executing large time bound project,which involve careful co ordination of a variety of complex and inter related activities and resources.\n",
      "question": "What is network analysis PERT CPM"
    },
    {
      "answer": "Network density is the number of edges divided by the total possible edges.",
      "question": "Network density"
    },
    {
      "answer": "Distance is the number of edges or hops between the starting and ending nodes following the shortest path. Unlike length, the distance between two nodes uses only the shortest path\u200a \u200athe path that requires the least hops.",
      "question": "Define distances"
    },
    {
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network",
      "question": "Define centrality"
    },
    {
      "answer": "Abbrevation of  ccm  is critical chain method",
      "question": "What is abbrevation of CCM"
    },
    {
      "answer": "Abbrevation of  ccm  is critical chain method",
      "question": "Abbrevation of CCM"
    },
    {
      "answer": "Freemans closeness centrality, the total geodesic distance from a given vertex to all other vertices, is the best known example. Note that this classification is independent of the type of walk counted i.e. walk, trail, path, geodesic.",
      "question": "Centrality measure is best"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "What is a Network"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "Define Network"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "Explain Network"
    },
    {
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes.",
      "question": "Describes dyads"
    },
    {
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level",
      "question": "Breadth first search"
    },
    {
      "answer": "One of the most widely used and important conceptual tools for analysing networks. Centrality aims to find the most important nodes in a network",
      "question": "Describe centrality"
    },
    {
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network",
      "question": "Accessibility"
    },
    {
      "answer": "The maximum number of  points who have all possible ties present among themselves",
      "question": "Cliques"
    },
    {
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level",
      "question": "Define breadth first search"
    },
    {
      "answer": "In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network",
      "question": "Describe accessibility"
    },
    {
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network\n",
      "question": "What is edges"
    },
    {
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network",
      "question": "Edges"
    },
    {
      "answer": "CPM for Critical Path Method \n",
      "question": "Abbrevation of CPM"
    },
    {
      "answer": "The ArcGIS Network Analyst extension enables the effective movement of goods, efficient organization and coordination of vehicles, and intelligent transport network analysis. Make smarter decisions by developing strategic routing plans.",
      "question": "Full form of  CCM"
    },
    {
      "answer": "Betweenness centrality quantifies how many times a particular node comes in the shortest chosen path between two other nodes. Eigenvector centrality is a measure of the influence of a node in a network.",
      "question": "What is the difference between eigenvector centrality and betweenness centrality"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "Defination of Network"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "What do you mean by Network"
    },
    {
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops.",
      "question": "What is hops"
    },
    {
      "answer": "The maximum number of  points who have all possible ties present among themselves",
      "question": "Define cliques"
    },
    {
      "answer": "The DFS algorithm aims to move as far as possible away from the root node.",
      "question": "What is depth first search"
    },
    {
      "answer": "An edge or link of a network or graph is one of the connections between the nodes or vertices of the network",
      "question": "Define edges"
    },
    {
      "answer": "If we are studying a social relationship between Facebook users, nodes are target users and edges are relationship such as friendships between users or group memberships.",
      "question": "Example of Network"
    },
    {
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops.",
      "question": "Define hops"
    },
    {
      "answer": "The maximum number of  points who have all possible ties present among themselves",
      "question": "Describe Cliques"
    },
    {
      "answer": "The DFS algorithm aims to move as far as possible away from the root node.",
      "question": "Depth first search"
    },
    {
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges.",
      "question": "What is nodes "
    },
    {
      "answer": "The DFS algorithm aims to move as far as possible away from the root node.",
      "question": "Define depth first search"
    },
    {
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops.",
      "question": "Hops"
    },
    {
      "answer": "The maximum number of  points who have all possible ties present among themselves",
      "question": "What is cliques"
    },
    {
      "answer": "Network analysis represents cities as networks in which identifiable urban elements e.g settlements, locations, and intersections are regarded as nodes in a planar graph, and the connections between pairs of nodes e.g roads and transport lines are represented as edges.",
      "question": "Nodes "
    },
    {
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms.",
      "question": "Why Network Analysis"
    },
    {
      "answer": "Network Analyst provides a vehicle routing problem solver that can be used to determine solutions for such complex fleet management tasks. Consider an example of delivering goods to grocery stores from a central warehouse location. A fleet of three trucks is available at the warehouse and also computational biology, engineering, finance, marketing, neuroscience, political science, and public health",
      "question": "Application of network analyst"
    },
    {
      "answer": "Network density is the number of edges divided by the total possible edges.",
      "question": "Describe network density"
    },
    {
      "answer": "Network density is the number of edges divided by the total possible edges.",
      "question": "What is meant by network density"
    },
    {
      "answer": "Length is the number of edges between the starting and ending nodes, known as hops.",
      "question": "Describe hops"
    },
    {
      "answer": "In the analysis of dyads, only the characteristics of the relationship form the structural effects on outcomes.",
      "question": "Define dyads"
    },
    {
      "answer": "The average of the shortest path lengths for all possible node pairs. Gives a measure of  tightness of the Graph and can be used to understand how quickly easily something flows in this network.",
      "question": "Describe average path length"
    },
    {
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level",
      "question": "What is breadth first search"
    },
    {
      "answer": "Breadth first search is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level",
      "question": "Describe breadth first search"
    },
    {
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network",
      "question": "What is accessibility"
    },
    {
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination.",
      "question": "What is origin destination cost matrix"
    },
    {
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination.",
      "question": "Origin destination cost matrix"
    },
    {
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination.",
      "question": "Define origin destination cost matrix"
    },
    {
      "answer": "An OD cost matrix is a table that contains the network impedance from each origin to each destination. Additionally, it ranks the destinations that each origin connects to in ascending order based on the minimum network impedance required to travel from that origin to each destination.",
      "question": "Describe origin destination cost matrix"
    },
    {
      "answer": "It only capture local information of nodes.In many applications, we need more informative measures that can further distinguish among nodes that have almost equally low degrees, or almost equally high degrees",
      "question": "Disadvantages of degeree centrality"
    },
    {
      "answer": "In degree centrality awards one centrality point for every link a node receives.Eigenvector centrality differs from indegree centrality a node receiving many links does not necessarily have a high eigenvector centrality ,So it might be that all linkers have low or null eigenvector centrality",
      "question": "What is the difference between degree centrality and eigenvector centrality"
    },
    {
      "answer": "In degree centrality awards one centrality point for every link a node receives.Eigenvector centrality differs from indegree centrality a node receiving many links does not necessarily have a high eigenvector centrality ,So it might be that all linkers have low or null eigenvector centrality",
      "question": "Difference between degree centrality and eigenvector centrality"
    },
    {
      "answer": "Degree centrality is measured as the number of direct links that involve a given node. Closeness centrality is the shortest path between a node and all other reachable nodes.",
      "question": "What is the difference between degree centrality and closeness centrality"
    },
    {
      "answer": "Degree centrality is measured as the number of direct links that involve a given node. Closeness centrality is the shortest path between a node and all other reachable nodes.",
      "question": "Difference between degree centrality and closeness centrality"
    },
    {
      "answer": "Edge betweenness\nFast Greedy\nLeading eigenvector",
      "question": "Algorithms used in network analytics"
    },
    {
      "answer": "Centrality measures\neigenvector centrality\npage rank\ndiffusion centrality",
      "question": "Properties of  nodes"
    },
    {
      "answer": "PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website",
      "question": "What is page rank "
    },
    {
      "answer": "PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website",
      "question": "Page rank"
    },
    {
      "answer": "Gephi\nCytoscape\nIgraph",
      "question": "What are network visualization software"
    },
    {
      "answer": "Network analysis is an operation in GIS which analyses the datasets of geographic network or real world network. Network analysis examine the properties of natural and man made network in order to understand the behaviour of flows within and around such networks and locational analysis.",
      "question": "What is network analysis used for in GIS"
    },
    {
      "answer": "Among basic network analysis methods include  Method  Critical Path Method  And  Critical Chain Method PERT Method, Program Evaluation and Review Technique",
      "question": "What are the two methods of network analysis"
    },
    {
      "answer": "An activity represents an action and consumption of resources time, money, energy required to complete a portion of a project. Activity is represented by an arrow.  An event or node will always occur at the beginning and end of an activity.",
      "question": "Network analysis in Quantitative techniques"
    },
    {
      "answer": "An activity represents an action and consumption of resources time, money, energy required to complete a portion of a project. Activity is represented by an arrow.  An event or node will always occur at the beginning and end of an activity.",
      "question": "What is network analysis in quantitative techniques"
    },
    {
      "answer": "Network traffic analysis  is a method of monitoring network availability and activity to identify anomalies, including security and operational issues. Collecting a realtime and historical record of whats happening on your network. Detecting malware such as ransomware activity.",
      "question": "What is network analysis in cyber security"
    },
    {
      "answer": "a.Adjacent and edges matrix\nb.Vertices matrix",
      "question": "Type of matrix used in network analysis"
    },
    {
      "answer": "In page rank recursive algorithms is using",
      "question": "Which algorithm is used in page rank"
    },
    {
      "answer": "Network traffic is the amount of data moving across a computer network at any given time. Network traffic, also called data traffic, is broken down into data packets and sent over a network before being reassembled by the receiving device or computer.",
      "question": "What is network traffic data"
    },
    {
      "answer": "Network traffic analysis is a method of monitoring network availability and activity to identify anomalies, including security and operational issues.\n",
      "question": "What is network traffic analysis "
    },
    {
      "answer": "Origin Destination  matrix describes people movement in a certain area. An OD matrix is necessary for planning a good public transportation system. However, the exact values of OD matrix are difficult to measure.\n",
      "question": "OD Matrix"
    },
    {
      "answer": "Point to point analysis. A point to point analysis is the most common routing problem. \nFinding Coverage. \nOptimize Fleet. \nSelect Optimal Site. \nOrigin Destination  OD Cost Matrix.",
      "question": "What are the types of network analysis"
    },
    {
      "answer": "Rules for constructing network\n1 Each activity is represented by one and only one arrow. i.e only one activity can connect any two nodes. 2 No two activities can be identified by the same head and tail events. 3 Nodes are numbered to identify an activity uniquely",
      "question": "Explain various rules for drawing a network"
    },
    {
      "answer": "PERT is the abbreviated form for Program Evaluation and Review Techniques",
      "question": "What is abbrevation of  PERT "
    },
    {
      "answer": "PERT is the abbreviated form for Program Evaluation and Review Techniques",
      "question": "Abbrevation of  PERT "
    },
    {
      "answer": "CPM for Critical Path Method ",
      "question": "What is abbrevation of CPM"
    },
    {
      "answer": "CPM for Critical Path Method ",
      "question": "Full form of CPM"
    },
    {
      "answer": "PERT is that technique of project management which is used to manage uncertain i.e  time is not known activities of any project. CPM is that technique of project management which is used to manage only certain  i.e time is known activities of any project.",
      "question": "What is difference between CPM and PERT"
    },
    {
      "answer": "PERT is that technique of project management which is used to manage uncertain i.e  time is not known activities of any project. CPM is that technique of project management which is used to manage only certain  i.e time is known activities of any project.",
      "question": "Difference between CPM and PERT"
    },
    {
      "answer": "Network based analytics is critical to managing IoT infrastructure. Network analytics has the power to examine details of the IoT communications patterns made through various protocols and correlate these to data paths traversed throughout the network",
      "question": "What is network analytics in IoT"
    },
    {
      "answer": "Social network analysis , also known as network science, is a field of data analytics that uses networks and graph theory to understand social structures. SNA techniques can also be applied to networks . A common application of SNA techniques is with the internet",
      "question": "What is social network analysis"
    },
    {
      "answer": "This user friendly open source tool is pegged as a cross platform graphical application for analysis and visualisation of social networks. It enables developers to create and modify social networks and change node attributes.",
      "question": "What are network visualization applications"
    },
    {
      "answer": "Engineers create the network system and handle major changes to it. Analysts typically handle the dynamic ads, moves, changes, events, and minor issues. The analyst monitors and responds to issues on an established network system. Engineers create the network system and handle major changes to it",
      "question": "Whats the difference between a network engineer and a network analyst"
    },
    {
      "answer": "Engineers create the network system and handle major changes to it. Analysts typically handle the dynamic ads, moves, changes, events, and minor issues. The analyst monitors and responds to issues on an established network system. Engineers create the network system and handle major changes to it",
      "question": "Difference between a network engineer and a network analyst"
    },
    {
      "answer": "Degree, betweenness, closeness and eigenvector  each with its own strengths and weaknesses",
      "question": "What are the 4 centrality measurements"
    },
    {
      "answer": "Thus, measures of individual network elements such as nodes or links typically quantify connectivity profiles associated with these elements and hence reflect the way in which these elements are embedded in the network.",
      "question": "Network measures are often represented in multiple ways"
    },
    {
      "answer": ".To calculate betweenness centrality, you take every pair of the network and count how many times a node can interrupt the shortest paths geodesic distance between the two nodes of the pair.",
      "question": "How is network centrality measured"
    },
    {
      "answer": "To calculate betweenness centrality, you take every pair of the network and count how many times a node can interrupt the shortest paths geodesic distance between the two nodes of the pair.",
      "question": "Network centrality measured"
    },
    {
      "answer": "Freemans closeness centrality, the total geodesic distance from a given vertex to all other vertices, is the best known example. Note that this classification is independent of the type of walk counted i.e. walk, trail, path, geodesic.",
      "question": "Which centrality measure is best"
    },
    {
      "answer": "Betweenness centrality quantifies how many times a particular node comes in the shortest chosen path between two other nodes. Eigenvector centrality is a measure of the influence of a node in a network.",
      "question": "Difference between eigenvector centrality and betweenness centrality"
    },
    {
      "answer": "The betweenness centrality of a node might change if the graph is augmented with a set of arcs. In particular, adding arcs incident to some nodev can increase the betweenness ofv and its ranking.",
      "question": "How do you increase between centrality"
    },
    {
      "answer": "Network visualization, graph visualization or link analysis is the process of visually presenting networks of connected entities as links and nodes. Nodes represent data points and links represent the connections between them.",
      "question": "What is network graph visualization"
    },
    {
      "answer": "Networks graphs are extremely useful in use cases such as intelligence analysis e.g  one person is an associate of a suspect or known criminal, fraud detection e.g., the same social security number was used by different people, and many others",
      "question": "When would you use a network graph"
    },
    {
      "answer": "Network graph is simply called as graph. It consists of a set of nodes connected by branches. In graphs, a node is a common point of two or more branches.  That means, the line segments in the graph represent the branches corresponding to either passive elements or voltage sources of electric circuit.",
      "question": "What is graph in network analysis"
    },
    {
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms.",
      "question": "What is the use of Network Analysis"
    },
    {
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks,a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms.",
      "question": "Why Analysisng Network is required"
    },
    {
      "answer": "Network density is the number of edges divided by the total possible edges.",
      "question": "Define network density"
    },
    {
      "answer": " In Network Analyst, accessibility can be measured in terms of travel time, distance, or any other impedance on the network",
      "question": "Define Accessibility"
    },
    {
      "answer": "Betweenness centrality measures the extent to which a vertex lies on paths between other vertices. Vertices with high betweenness may have considerable influence within a network by virtue of their control over information passing between others.\n",
      "question": "What does high betweenness mean"
    },
    {
      "answer": "A network refers to a structure representing a group of objects or people and relationships between them. It is also known as a graph in mathematics. A network structure consists of nodes and edges.Here, nodes represent objects we are going to analyze while edges represent the relationships between those objects.",
      "question": "Describe Network"
    },
    {
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality",
      "question": "How many measures are there to identify centrality of a node"
    },
    {
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes.\n",
      "question": "How to calculate Closeness centrality"
    },
    {
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations.",
      "question": "Network analytics  "
    },
    {
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality.",
      "question": "Explain Degree centrality"
    },
    {
      "answer": "Network level analysis focuses on topological properties of networks as a whole.",
      "question": "Network level analysis"
    },
    {
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations.",
      "question": "What are network analytics"
    },
    {
      "answer": "When analytics engines are programmed to reason through logical steps, MR is achieved. This capability can enable an analytics engine to navigate through a number of complex decisions to solve a problem or a complex query. With MR, analytics can compare multiple possible outcomes and solve for an optimal result, using the same process that a human would. This is an important complement to ML.",
      "question": "What is Machine reasoning"
    },
    {
      "answer": "Network analysis is widely used in several scientific areas as for example physics, computer science, linguistics and social sciences. In biology, network analysis was applied for example to food webs, social organization and more recently to molecular networks.",
      "question": "Who uses network analysis"
    },
    {
      "answer": "DPI of select traffic flows is a rich data source for network analytics. An analysis of such traffic using techniques such as Network Based Application Recognition,NBAR and Software Defined Application Visibility and Control can discern the communication protocols being used.Analytics engines can use this information in a variety of ways, such as setting of quality of service parameters automatically or profiling endpoints.\n",
      "question": "Deep packet inspection DPI"
    },
    {
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality.",
      "question": "What is the Degree centrality"
    },
    {
      "answer": "A crucial application of network analysis is identifying the important node in a network.This task is called Measuring Network Centrality. In social network analysis, it can refer to the task of identifying the most influential member, or the representative of the group.",
      "question": "What is the crucial application of network analysis"
    },
    {
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks, a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms. Identifying CM targets.",
      "question": "What is the important role of network analysis"
    },
    {
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality",
      "question": "What are the measures of centrality of a node "
    },
    {
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality",
      "question": "How centrality of a node can be measured"
    },
    {
      "answer": "There are several indicators used to measure the centrality of a node. Those are,\n1. Degree centrality\n2. Closeness centrality\n3. Betweenness centrality \n4. Eigenvector centrality",
      "question": "What are the different measures to identify centrality of a node"
    },
    {
      "answer": "Machine learning can be applied in various ways in security, for instance, in malware analysis, to make predictions, and for clustering security events. It can also be used to detect previously unknown attacks with no established signature.",
      "question": "What is machine learning in security"
    },
    {
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality.",
      "question": "Define Degree centrality"
    },
    {
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality.",
      "question": "Definition of Degree centrality"
    },
    {
      "answer": "Degree centrality of a node refers to the number of edges directly attached to the node. In other words, node with a higher degree has higher centrality.",
      "question": "Describe Degree centrality"
    },
    {
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network.\n",
      "question": "What is the Closeness centrality"
    },
    {
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network.",
      "question": "Define Closeness centrality"
    },
    {
      "answer": "The closeness centrality indicates how close a node is to all other nodes in the network.",
      "question": "Explain Closeness centrality"
    },
    {
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes.",
      "question": "Formula to calculate Closeness centrality"
    },
    {
      "answer": "Closeness centrality calculated as 1 divided by sum of distances to all other nodes.",
      "question": "How Closeness centrality can be calculated"
    },
    {
      "answer": "Normalized closeness calculated as total number of nodes minus 1 multiplied by closeness centrality",
      "question": "How to calculate normalized closeness"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "What is the Betweenness centrality"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "Define Betweenness centrality"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "What do you mean by Betweenness centrality"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "Describe Betweenness centrality"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "Definition of Betweenness centrality"
    },
    {
      "answer": "The number of paths between two nodes that go through the ith node is considered as the ith node betweenness centrality.Betweeness centrality as to calculate for each node ad which ever node is having betweenness centrality, that node is considered  to be crucial or critical node.",
      "question": "Explain Betweenness centrality"
    },
    {
      "answer": "Betweenness centrality is calculated as number of shortest paths between s an t nodes that passes through the node in the question divided by number of shortest path between s and t nodes\nwhere s is source node\nt is target node",
      "question": "Formula to calculate the Betweenness centrality\n"
    },
    {
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network.",
      "question": "What is Eigenvector centrality"
    },
    {
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network.\n",
      "question": "Define Eigenvector centrality"
    },
    {
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network.",
      "question": "Describe Eigenvector centrality"
    },
    {
      "answer": "Adding to the degree of one node, the centralities of neighbor nodes are considered. As a result, the eigenvector corresponding to the highest eigenvalue of the adjacency matrix represents the centrality of nodes in the network.",
      "question": "What do you mean by Eigenvector centrality"
    },
    {
      "answer": "There are 3 levels for network analysis, those are,\n1. Element level analysis\n2. Group level analysis\n3. Network level analysis",
      "question": "What are the levels of network analysis"
    },
    {
      "answer": "Element level analysis involves finding of methods to identify the most important nodes of the network are investigated.",
      "question": "What is Element level analysis"
    },
    {
      "answer": "Group level analysis involves methods for defining and finding cohesive groups of nodes in the network.",
      "question": "What is Group level analysis"
    },
    {
      "answer": "Clustering coefficient is calculated as Number of links that exists among its neighbors divided byNumber of links that could have existed among its neighbor",
      "question": "Formula to calculate cluster coefficient"
    },
    {
      "answer": "We represents nodes and edges in a matrix format which is called adjacency matrix.\n",
      "question": "What is the adjacency matrix"
    },
    {
      "answer": " Network analysis provides the capacity to estimate complex patterns of relationships and the network structure can be analysed to reveal core features of the network.",
      "question": "What is the purpose of network analysis"
    },
    {
      "answer": "Network analytics, in its simplest definition, involves the analysis of network data and statistics to identify trends and patterns. Once identified, operators take the next step of action this data which typically involves a network operation or a set of operations.",
      "question": "Define network analytics"
    },
    {
      "answer": "There are 6 steps in Network Analysis, those are,\nStep 1 Configuring the Network Analyst environment.\nStep 2 Adding a network dataset to ArcMap.\nStep 3 Creating the network analysis layer.\nStep 4 Adding network analysis objects.\nStep 5 Setting network analysis layer properties.\nStep 6 Performing the analysis and displaying the results.",
      "question": "What are the steps in network analysis"
    },
    {
      "answer": "A network analysis diagram is the visual display of how people or other elements in a network are connected.",
      "question": "What is a network analysis diagram"
    },
    {
      "answer": "Network Analytics can be used in different applications as follow, Assembly line scheduling,Research and development,Inventory planning and control,Shifting of manufacturing plant from one site to another,Launching of new products and advertising campaigns,Control of traffic flow in cities,Budget and audit procedures, etc",
      "question": "Where do you apply network analytics "
    },
    {
      "answer": "Network analysis ensures the effective utilization of limited resources. It also ensures the optimal use of resources and help to control the idle resources so that project can be effectively executed within the budgeted costs and scheduled time.\n",
      "question": "Why is network analysis necessary"
    },
    {
      "answer": "The major technologies of network analysis are,\n5G and Wi Fi 6 technology,Artificial Intelligence AI and Machine Learning ML,Augmented reality and virtual reality,Cloud computing,DevOps ,Digital transformation ,Intent based networking IBN,Internet of Things IoT,Data Security,SD WAN ",
      "question": "What are major technologies of network analysis"
    },
    {
      "answer": "Statistical and Machine Learning Approaches for Network Analysis provides an accessible framework  for structurally analyzing graphs by bringing together known and novel approaches on graph classes and graph measures for classification.",
      "question": "What is network analysis in machine learning"
    },
    {
      "answer": "Social network analysis, also known as network science, is a field of data analytics that uses networks and graph theory to understand social structures.",
      "question": "Is network analysis data science"
    },
    {
      "answer": "The objectives of Network Analysis are,\n1. Minimize Production Delay, Interruptions and Conflicts\n2. Minimization of Total Project Cost\n3. Trade off between Time and Cost of Project\n4. Minimization of Total Project Duration\n5. Minimization of Idle Resources",
      "question": "What are the objectives of Network Analysis"
    },
    {
      "answer": "For planning, scheduling and controlling of operations in large and complicated projects network analysis is very important and powerful tool.For evaluating the performance level of actual performance in comparison to planned target network analysis is a very useful tool.",
      "question": "What are the advantages of Network Analysis"
    },
    {
      "answer": " Network construction of complex project is very difficult and time consuming in network analysis.Actual time estimation of various activities is a difficult exercise.Analysis of the project is a very difficult work because a number of resource constraints exist in the project.",
      "question": "What are the disadvantages of Network Analysis"
    },
    {
      "answer": "Network analysis is a technique that uses graph theory to study complex real world problems, such as computational ,biology engineering, finance, marketing, neuroscience, political science, and public health ",
      "question": "What is network analysis in Analytics"
    },
    {
      "answer": "Termilogies in Network analysis are,Node is also called as vertex,Edge is also called as Connection",
      "question": "What are the terminologies in Network Analytics"
    },
    {
      "answer": "The strength of the newtwork can be evaluated by using 4 measures , those are, Degree centrality,Closeness centrality,Betweenness centrality ,Eigenvector centrality",
      "question": "How to evaluate the strength of the node in network analysis"
    },
    {
      "answer": "A network graph or simply a network is a connection of objects that are linked together through a series of nodes representing those objects",
      "question": "What is graph of network"
    },
    {
      "answer": "LAN, MAN, and WAN are the three major types of networks designed to operate over the area they cover.",
      "question": "How many types of networks are there"
    },
    {
      "answer": "In network analytics, a software engine analyzes and extracts intelligence from data collected from various sources,such as network devices switches, routers, and wireless, servers syslog, DHCP, AAA, configuration database, etc. andtraffic flow details wireless congestion, data speeds, latency, etc.Network analytics processes are automated and so are more wide ranging than what can be achieved by manual analysis. ",
      "question": "How does network analytics work"
    },
    {
      "answer": "Network analytics collects data from a variety of sources, including from servers such as DHCP, Active Directory, RADIUS, DNS, and syslog, and from network traffic such as NetFlow, traceroute, and SNMP. It does so by using techniques such as telemetry and deep packet inspection DPI to build a rich database from which contextual information can be derived.",
      "question": "How does network analytics collect data"
    },
    {
      "answer": "The analytics engine, the software program that analyzes data and makes decisions, collects data from around the network and performs the desired analysis. This analysis may compare the current state with a model of optimal performance. Whenever the program identifies a deviation from optimal, it may suggest remediations or present its findings to a higher levelprogram or to the IT staff.The analytics engine may also scrutinize endpoint traffic to help identify the endpoint itself or traffic behavior that may signal malware infection.\n",
      "question": "What is Analytics engine"
    },
    {
      "answer": "Networking engineers often debate whether network analytics should be performed remotely, in the cloud, or locally, at the customer premises. Placing the analytics engine in the cloud offers access to much more processing power, scale, and communication with other networks. Cloud hosted analytics also benefits from up to the minute algorithms and crowd sourced data. ",
      "question": "What is difference between Cloud and Local Analytics"
    },
    {
      "answer": "The analytics engine considers the relationship among variables in the network before offering insights or remediation. The correlation among devices, applications, and services can mean that correcting one problem can lead to problems elsewhere.While correlation greatly increases the number of variables in the decision tree and adds complexity to the system, its essential so that all variables can be evaluated for accurate decisions.",
      "question": "Why we need Correlation in Network engine"
    },
    {
      "answer": "Most analytics engines offer guidance on performance improvement through decision trees. When an analytics engine receives network data indicating subpar performance, the decision tree calculates the best network device adjustment or reconfiguration to improve performance of that parameter.The decision tree grows based on the number of sources for streaming telemetry and the number of options for optimizing performance in each point. Because of the complexity of processing these very large data sets in real time, analytics was previously performed only on supercomputers.",
      "question": "What is the role of Decision trees in Analytic Engine"
    },
    {
      "answer": "Network analytics uses a combination of local and cloud based AI driven analytics engines to make sense of all collected data. Using AI and ML, network analytics customizes the network baseline for alerts, reducing noise and false positives while enabling IT teams to identify issues, trends, anomalies, and root causes accurately. AI,ML techniques along with crowd sourced data are also used to reduce unknowns and improve the level of certainty in decision making.",
      "question": "How does network analytics benefit from AI and ML techniques"
    },
    {
      "answer": "Artificial intelligence simulates intelligent decision making in computers. Many sources confuse artificial intelligence with machine learning ML. Machine learning is a subset of the many types of applications that result from the field of artificial intelligence.",
      "question": "How does network analytics benefit from AI techniques"
    },
    {
      "answer": "Use of ML can improve analytics engines. With ML, the parameters in the decision tree can be improved based on experience,cognitive learning, peer comparison,prescriptive learning, or complex mathematical regressions,baselining.ML offers large increases in the accuracy of insights and remediation, because with it the decision trees are modified to meet the specific conditions of a networks configuration, its installed hardware and software, and its services and applications.",
      "question": "How does network analytics benefit from ML techniques"
    },
    {
      "answer": "Streaming telemetry reduces delays in data collection. Telemetry provides information on anything from simple packet flow numbers to complex, application specific performance parameters. Systems that can stream more telemetry, from more sources and about more network variables, give the analytics engine better context in which to make decisions.",
      "question": "What is Streaming telemetry"
    },
    {
      "answer": "Another important factor an analytics engine considers is context. The context is the specific circumstances in which a network anomaly occurs. The same anomaly in different conditions can require very different remediation, so the analytics engine must be programmed with the many variables for contexts, such as network type, service, and application.Other contexts can include wireless interference, network congestion, service duplication, and device limitations.",
      "question": "What is the importance of Context in Network Analytics"
    },
    {
      "answer": "Graph is a mathematical structures used to study pairwise relationships between objects and entities.",
      "question": "What is graph"
    },
    {
      "answer": "Graphs provide a better way of dealing with abstract concepts like relationships and interactions. They also offer an intuitively visual way of thinking about these concepts. Graphs also form a natural basis for analyzing relationships in a Social context.",
      "question": "Why Graphs is needed"
    },
    {
      "answer": "Types of graphs are,\n1. Undirected Simple Graph\n2. Directed Simple Graph\n3. With Self loops\n4. With Parellel edges.",
      "question": "What are graph types"
    },
    {
      "answer": "Nodes and Edges can be accessed together using the G.nodes function and G.edges function.",
      "question": "What are the methods in python to access nodes and edges in python"
    },
    {
      "answer": "Machine Learning has major applicability in IT automation, turning relevant data into actionable software, and it also can ensure optimal configuration in networking.Briefly, ML achieves this by analyzing the structure of collected data to find patterns you did not know were there.",
      "question": "How is machine learning used in networking"
    },
    {
      "answer": "The purest definition of artificial intelligence is software that performs a task on par with a human expert. AI plays an increasingly critical role in taming complexity for growing IT networks. The proliferation of devices, data, and people has made IT infrastructures more complex than ever to manage.",
      "question": "What is AI in networking"
    },
    {
      "answer": ".Graph Machine Learning provides a new set of tools for processing network data and leveraging the power of the relation between entities that can be used for predictive, modeling, and analytics tasks. ",
      "question": "What is graph machine learning"
    },
    {
      "answer": "Following are the Network analysis components,Route,Service area,Closest facility ,OD cost matrix,Vehicle routing problem,Location allocation,Algorithms used by the ArcGIS Network Analyst extension.",
      "question": "What are the components of network analysis"
    },
    {
      "answer": "Network analysis is one of the most popular techniques used for planning, scheduling, monitoring and coordinating large and complex projects comprising a number of activities. It involves the development of a network to indicate logical sequenceof work content elements of a complex situation",
      "question": "What are the objectives of using network analysis"
    },
    {
      "answer": "Network Analytics gives a deep insight into the IT network and helps the administrators make smart and informed business decisions. It can be particularly useful in preventing, detecting and responding to security threats.",
      "question": "How is network analytics beneficial to businesses"
    },
    {
      "answer": "Network Analysis is useful in many living application tasks. It helps us in deep understanding the structure of a relationship in social networks, a structure or process of change in natural phenomenons, or even the analysis of biological systems of organisms. Identifying CM targets ,etc.",
      "question": "What is network analysis with example"
    },
    {
      "answer": "Performance optimization and capacity planning. When done effectively, network analytics reveals crucial information about hidden bottlenecks and other network design issues that can choke traffic and impede productivity,Credential misuse,Cloud security",
      "question": "What are the top 3 network analytics use cases"
    },
    {
      "answer": "NetworkX is a Python library for studying graphs and networks.",
      "question": "What is the python Library Used for studying Graphs And Networks"
    },
    {
      "answer": "The basic entities required for building a network are nodes and the edges connecting the nodes.",
      "question": "What are the basic entities required to build the network\n"
    },
    {
      "answer": "Network Analytics gives a deep insight into the IT network and helps the administrators make smart and informed business decisions. It can be particularly useful in preventing, detecting and responding to security threats.",
      "question": "Why is network analytics important"
    },
    {
      "answer": "Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.\n\nExample\n\nCheck out the below sentence.\n\nAre you feeling hungry\n\nThe given sentence could be either a question or a formal way of offering food.",
      "question": "What is Pragmatic Ambiguity"
    },
    {
      "answer": "Text summarization is the process of shortening a long piece of text with its meaning and effect intact. Text summarization intends to create a summary of any given piece of text and outlines the main points of the document. This technique has improved in recent times and is capable of summarizing volumes of text successfully. Text summarization has proved to a blessing since machines can summarise large volumes of text in no time which would otherwise be really time consuming. There are two types of text summarization\n Extraction based summarization \n Abstraction based summarization",
      "question": "What is text Summarization"
    },
    {
      "answer": "Natural Language Processing",
      "question": "What is NLP"
    },
    {
      "answer": "Natural language processing helps computers communicate with humans in their own language and scales other language related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.",
      "question": "What is the use of NLP"
    },
    {
      "answer": "It is an automated process to extract required information from data by applying machine learning algorithms. ",
      "question": "Is NLP an automated practice"
    },
    {
      "answer": "Yes, It is an automated process to extract required information from data by applying machine learning algorithms. ",
      "question": "Do we need the help of machine learning algorithms for NLP"
    },
    {
      "answer": "Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.",
      "question": "What is Naive Bayes algorithm, When we can use this algorithm in NLP"
    },
    {
      "answer": "Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence.",
      "question": "Explain Dependency Parsing in NLP"
    },
    {
      "answer": "NLTK or Natural Language Toolkit is a series of libraries and programs that are used for symbolic and statistical natural language processing. This toolkit contains some of the most powerful libraries that can work on different ML techniques to break down and understand human language. NLTK is used for Lemmatization, Punctuation, Character count, Tokenization, and Stemming. The difference between NLTK and Spacey are as follows\n While NLTK has a collection of programs to choose from, Spacey contains only the best suited algorithm for a problem in its toolkit \n NLTK supports a wider range of languages compared to Spacey Spacey supports only 7 languages \nWhile Spacey has an object oriented library, NLTK has a string processing library \n Spacey can support word vectors while NLTK cannot",
      "question": "What is NLTK? How is it different from Spacy"
    },
    {
      "answer": "Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more. \nThe various models of information extraction includes\nTagger Module \n Relation Extraction Module \n Fact Extraction Module \n Entity Extraction Module \n Sentiment Analysis Module \n Network Graph Module \nDocument Classification  Language Modeling Module",
      "question": "What is information extraction"
    },
    {
      "answer": "Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.",
      "question": "What is Bag of Words"
    },
    {
      "answer": "Pragmatic ambiguity refers to those words which have more than one meaning and their use in any sentence can depend entirely on the context. Pragmatic ambiguity can result in multiple interpretations of the same sentence. More often than not, we come across sentences which have words with multiple meanings, making the sentence open to interpretation. This multiple interpretation causes ambiguity and is known as Pragmatic ambiguity in NLP.",
      "question": "What is Pragmatic Ambiguity in NLP"
    },
    {
      "answer": "Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.",
      "question": "What is Masked Language Model"
    },
    {
      "answer": "The difference between NLP and CI is as follows\nNatural Language Processing NLP\nNLP attempts to help machines understand and learn how language concepts work\nNLP uses AI technology to identify, understand, and interpret the requests of users through language.\n Conversational Interface CI.\n CI focuses only on providing users with an interface to interact with. \nCI uses voice, chat, videos, images and more such conversational aid to create the user interface.",
      "question": "What is the difference between NLP and CI(Conversational Interface)"
    },
    {
      "answer": "SpaCy  TextBlob  Textacy  Natural language Toolkit NLTK  Retext  NLP.js Stanford NLP  CogcompNLP",
      "question": "What are the best NLP Tools"
    },
    {
      "answer": "Parts of speech tagging better known as POS tagging refers to the process of identifying specific words in a document and group them as part of speech, based on its context. POS tagging is also known as grammatical tagging since it involves understanding grammatical structures and identifying the respective component. POS tagging is a complicated process since the same word can be different parts of speech depending on the context. The same generic process used for word mapping is quite ineffective for POS tagging because of the same reason.",
      "question": "What is POS tagging"
    },
    {
      "answer": "Name entity recognition is more commonly known as NER is the process of identifying specific entities in a text document which are more informative and have a unique context. These often denote places, people, organisations, and more. Even though it seems like these entities are proper nouns, the NER process is far from identifying just the nouns. In fact, NER involves entity chunking or extraction wherein entities are segmented to categorise them under different predefined classes. This step further helps in extracting information.",
      "question": "What is NES"
    },
    {
      "answer": " Lemmatization helps to get to the base form of a word, e.g. are playing  play, eating  eat, etc..",
      "question": "Which technique can be used for keyword normalization in NLP, the process of converting a keyword into its base form"
    },
    {
      "answer": "A technique used in NLP which is used to get a base form of the word. Eg playing play.",
      "question": "What is Lemmatization"
    },
    {
      "answer": "Distance between two word vectors can be computed using Cosine similarity and Euclidean Distance. Cosine Similarity establishes a cosine angle between the vector of two words. A cosine angle close to each other between two word vectors indicates the words are similar and vice a versa. E.g. cosine angle between two words Football and Cricket will be closer to 1 as compared to angle between the words Football and New Delhi",
      "question": "Which technique can be used to compute the distance between two word vectors in NLP"
    },
    {
      "answer": "True",
      "question": "Is it True that Dissimilarity between words expressed using cosine similarity will have values significantly higher than 0.5"
    },
    {
      "answer": "Named entity recognition",
      "question": "Normalization techniques in NLP"
    },
    {
      "answer": "Text Summarization is an NLP use case.",
      "question": "NLP use cases"
    },
    {
      "answer": "EMLo word embeddings supports same word with multiple embeddings, this helps in \nusing the same word in a different context and thus captures the context than just \nmeaning of the word unlike in GloVe and Word2Vec. Nltk is not a word embedding",
      "question": "What is ELMo"
    },
    {
      "answer": "Sentiment Analysis\n Language Translation \n Document Summarization\n Question Answering\n Sentence Completion\n Attribute extraction \nChatbot interactions\n Topic classification\n Intent extraction\n Grammar or Sentence correction\nImage captioning\n Document Ranking\nNatural Language inference",
      "question": "List 10 use cases to be solved using NLP techniques"
    },
    {
      "answer": "The most important word in Sentence",
      "question": "What does the Transformer model pays attention to "
    },
    {
      "answer": "XLNET",
      "question": "Which NLP model gives the best accuracy"
    },
    {
      "answer": "One of the main reasons why NLP is necessary is because it helps computers \ncommunicate with humans in natural language. It also scales other language related \ntasks. Because of NLP, it is possible for computers to hear speech, interpret this \nspeech, measure it and also determine which parts of the speech are important.",
      "question": "Why do we need NLP"
    },
    {
      "answer": "A natural language program must decide what to say and when to say something.",
      "question": "What must a natural language program decide"
    },
    {
      "answer": "NLP can be useful in communicating with humans in their own language. It helps \nimprove the efficiency of the machine translation and is useful in emotional analysis too. \nIt can be helpful in sentiment analysis too. It also helps in structuring highly unstructured \ndata. It can be helpful in creating chatbots, Text Summarization and virtual assistants.",
      "question": "Where can NLP be useful"
    },
    {
      "answer": "The best way to prepare for an NLP Interview is to be clear about the basic concepts. \nGo through blogs that will help you cover all the key aspects and remember the \nimportant topics. Learn specifically for the interviews and be confident while answering \nall the questions.",
      "question": "How to prepare for an NLP Interview"
    },
    {
      "answer": "Breaking sentences into tokens, Parts of speech tagging, Understanding the context, \nLinking components of a created vocabulary, Extracting semantic meaning are currently \nsome of the main challenges of NLP.",
      "question": "What are the main challenges of NLP"
    },
    {
      "answer": "Translation, named entity recognition, relationship extraction, sentiment analysis, \nspeech recognition, and topic segmentation are few of the major tasks of NLP. Under \nunstructured data, there can be a lot of untapped information that can help an \norganization grow.",
      "question": "What are the major tasks of NLP"
    },
    {
      "answer": "Naive Bayes Algorithm has the highest accuracy when it comes to NLP models.",
      "question": "Explain about NLP and Naive Bayes Algorithm"
    },
    {
      "answer": "Common words that occur in sentences that add weight to the sentence are known as \nstop words. These stop words act as a bridge and ensure that sentences are \ngrammatically correct. In simple terms, words that are filtered out before processing \nnatural language data is known as a stop word and it is a common pre processing \nmethod.\n",
      "question": "What are stop words in NLP"
    },
    {
      "answer": "The process of obtaining the root word from the given word is known as stemming. All \ntokens can be cut down to obtain the root word or the stem with the help of efficient and \nwell generalized rules. It is a rule based process and is well known for its simplicity.",
      "question": "What is stemming in NLP"
    },
    {
      "answer": "There are several factors that make the process of Natural Language Processing \ndifficult. There are hundreds of natural languages all over the world, words can be \nambiguous in their meaning, each natural language has a different script and syntax, \nthe meaning of words can change depending on the context, and so the process of NLP \ncan be difficult. If you choose to upskill and continue learning, the process will become \neasier over time.",
      "question": "Why is NLP so hard"
    },
    {
      "answer": "The overall architecture of an NLP pipeline consists of several layers a user interface \none or several NLP models, depending on the use case a Natural Language \nUnderstanding layer to describe the meaning of words and sentences a preprocessing \nlayer microservices for linking the components together and of course.\n",
      "question": "What does a NLP pipeline consist of star symbol"
    },
    {
      "answer": "The five phases of NLP involve lexical structure analysis, parsing, semantic analysis, \ndiscourse integration, and pragmatic analysis",
      "question": "How many steps of NLP is there"
    },
    {
      "answer": "TFIDF or Term Frequency Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF IDF shows a frequency that helps identify the keywords in a document. The major use of TF IDF in NLP is the extraction of useful information from crucial documents by statistical data. It is ideally used to classify and summarize the text in documents and filter out stop words.",
      "question": "What is TF-IDF"
    },
    {
      "answer": " Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real world data to know the actual meaning of sentences and words.",
      "question": "What is Pragmatic Analysis"
    },
    {
      "answer": " When we parse a sentence one word at a time, then it is called a unigram. The sentence parsed two words at a time is a bigram.\nWhen the sentence is parsed three words at a time, then it is a trigram. Similarly, ngram refers to the parsing of n words at a time.",
      "question": "What are unigrams, bigrams, trigrams, and n-grams in NLP"
    },
    {
      "answer": "Below are the steps involved in solving an NLP problem\n\n1.Gather the text from the available dataset or by web scraping\n2.Apply stemming and lemmatization for text cleaning\n3.Apply feature engineering techniques\n4.Embed using word2vec\n5.Train the built model using neural networks or other Machine Learning techniques\n6.Evaluate the models performance\n7.Make appropriate changes in the model\n8.Deploy the model\n",
      "question": "What are the steps involved in solving an NLP problem"
    },
    {
      "answer": "Features or characteristics of a word help in text or document analysis. They also help in sentiment analysis of a text. Feature extraction is one of the techniques that are used by recommendation systems. Reviews such as excellent, good, or great for a movie are positive reviews, recognized by a recommender system. The recommender system also tries to identify the features of the text that help in describing the context of a word or a sentence. Then, it makes a group or category of the words that have some common characteristics. Now, whenever a new word arrives, the system categorizes it as per the labels of such groups.",
      "question": "What is Feature Extraction in NLP"
    },
    {
      "answer": "Precision is the ratio of true positive instances and the total number of positively predicted instances.\nRecall is the ratio of true positive instances and the total actual positive instances.",
      "question": "What is precision and recall"
    },
    {
      "answer": "F1 score evaluates the weighted average of recall and precision. It considers both false negative and false positive instances while evaluating the model. F1 score is more accountable than accuracy for an NLP model when there is an uneven distribution of class.\n",
      "question": "What is F1 score in NLP"
    },
    {
      "answer": "Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.\n\nWhen the machine parses the text one word at a time, then it is a unigram.\nWhen the text is parsed two words at a time, it is a bigram.\nThe set of words is a trigram when the machine parses three words at a time.",
      "question": "Explain how we can do parsing"
    },
    {
      "answer": "The parts of speech POS tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. The software uses algorithms for the parts of speech tagging. POS tagging is one of the most essential tools in Natural Language Processing. It helps in making the machine understand the meaning of a sentence.",
      "question": "What is Parts-of-speech Tagging"
    },
    {
      "answer": "Named Entity Recognition NER is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text. NER is mostly used in NLP, Artificial Intelligence, and Machine Learning. One of the real life applications of NER is chatbots used for customer support.",
      "question": "Explain Named Entity Recognition"
    },
    {
      "answer": "To find out the similarity among words, we use word similarity. We evaluate the similarity with the help of a number that lies between 0 and 1. We use the spacy library to implement the technique of word similarity.",
      "question": "How to check word similarity using the spacy package"
    },
    {
      "answer": "It is a metric that is used to test the performance of language models. Mathematically, it is defined as a function of the probability that the language model represents a test sample. ",
      "question": "What is perplexity in NLP"
    },
    {
      "answer": "The Masked Language Model is a model that takes a sentence with a few hidden masked words as input and tries to complete the sentence by correctly guessing those hidden words.",
      "question": "What do you know about the Masked Language Model"
    },
    {
      "answer": "N gram model is a model in NLP that predicts the probability of a word in a given sentence using the conditional probability of n minus 1 previous words in the sentence. The basic intuition behind this algorithm is that instead of using all the previous words to predict the next word, we use only a few previous words.\n",
      "question": "Briefly describe the N-gram model in NLP"
    },
    {
      "answer": "The Markov assumption assumes for the bigram model that the probability of a word in a sentence depends only on the previous word in that sentence and not on all the previous words.\n",
      "question": "What is the Markov assumption for the bigram model"
    },
    {
      "answer": "Following are a few methods of word embedding.\n\nEmbedding Layer\nWord2Vec\nGlove",
      "question": "List a few popular methods used for word embedding"
    },
    {
      "answer": "len set text",
      "question": "Write the code to count the number of distinct tokens in a text"
    },
    {
      "answer": "Initially, a smaller dictionary is a better choice because most NLP researchers feared that a giant dictionary would contain rare words that may be similar to misspelled words. However, later it was found Damerau and Mays 1989 that in practice, a more extensive dictionary is better at marking rare words as errors.",
      "question": "For correcting spelling errors in a corpus, which one is a better choice: a giant dictionary or a smaller dictionary, and why"
    },
    {
      "answer": "No, it is not always a good idea to remove punctuation marks from the corpus as they are necessary for certain NLP applications that require the marks to be counted along with words.",
      "question": "Do you always recommend removing punctuation marks from the corpus you\u2019re dealing with"
    },
    {
      "answer": "NLTK, Scikit learn,GenSim, SpaCy, CoreNLP, TextBlob.",
      "question": "List a few libraries that you use for NLP in Python"
    },
    {
      "answer": "Support Vector Machines, Neural Networks, Decision Tree, Bayesian Networks.",
      "question": "Suggest a few machine learning/deep learning models that are used in NLP"
    },
    {
      "answer": "GenSim",
      "question": "Which library contains the Word2Vec model in Python"
    },
    {
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. Each one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton.",
      "question": "What is a hapax/hapax legomenon"
    },
    {
      "answer": "A collocation is a group of two or more words that possess a relationship and provide a classic alternative of saying something. For example, strong breeze, the rich and powerful, weapons of mass destruction.",
      "question": "What is a collocation"
    },
    {
      "answer": "1. Lexical Ambiguity This type of ambiguity is observed because of homonyms and polysemy in a sentence.\n\n\t2. Syntactic Ambiguity A syntactic ambiguity is observed when based on the sentences syntax, more than one meaning is possible.\n\n\t3. Semantic Ambiguity This ambiguity occurs when a sentence contains ambiguous words or phrases that have ambiguous meanings.",
      "question": "List a few types of linguistic ambiguities"
    },
    {
      "answer": " Alan Turing developed a test, called Turing Test, that could differentiate between humans and machines. A computer machine is considered intelligent if it can pass this test through its use of language. Alan believed that if a machine could use language the way humans do, it was sufficient for the machine to prove its intelligence.",
      "question": "What is a Turing Test? Explain with respect to NLP-based systems"
    },
    {
      "answer": "Regular expressions in natural language processing are algebraic notations representing a set of strings. They are mainly used to find or replace strings in a text and can also be used to define a language in a formal way.",
      "question": "What do you understand by regular expressions in NLP"
    },
    {
      "answer": " Parsing refers to the task of generating a linguistic structure for a given input. For example, parsing the word helping will result in verb pass  gerunding.",
      "question": "Define the term parsing concerning NLP"
    },
    {
      "answer": "TFIDF or Term Frequency Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF IDF shows a frequency that helps identify the keywords in a document. The major use of TF IDF in NLP is the extraction of useful information from crucial documents by statistical data. It is ideally used to classify and summarize the text in documents and filter out stop words.",
      "question": "What is meant by TF-IDF"
    },
    {
      "answer": "Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence.",
      "question": "What is Dependency Parsing in NLP"
    },
    {
      "answer": " Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real world data to know the actual meaning of sentences and words.",
      "question": "Explain Pragmatic Analysis"
    },
    {
      "answer": " Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.\n\nExample\n\nCheck out the below sentence.\n\nAre you feeling hungry\n\nThe given sentence could be either a question or a formal way of offering food.",
      "question": "Explain is Pragmatic Ambiguity"
    },
    {
      "answer": "When we parse a sentence one word at a time, then it is called a unigram. The sentence parsed two words at a time is a bigram.\nWhen the sentence is parsed three words at a time, then it is a trigram. Similarly, ngram refers to the parsing of n words at a time.",
      "question": "Explain about unigrams, bigrams, trigrams, and n-grams in NLP"
    },
    {
      "answer": "Below are the steps involved in solving an NLP problem\n\n1.Gather the text from the available dataset or by web scraping\n2.Apply stemming and lemmatization for text cleaning\n3.Apply feature engineering techniques\n4.Embed using word2vec\n5.Train the built model using neural networks or other Machine Learning techniques\n6.Evaluate the models performance\n7.Make appropriate changes in the model\n8.Deploy the model",
      "question": "Explain the steps involved in solving an NLP problem"
    },
    {
      "answer": "Features or characteristics of a word help in text or document analysis. They also help in sentiment analysis of a text. Feature extraction is one of the techniques that are used by recommendation systems. Reviews such as excellent, good, or great for a movie are positive reviews, recognized by a recommender system. The recommender system also tries to identify the features of the text that help in describing the context of a word or a sentence. Then, it makes a group or category of the words that have some common characteristics. Now, whenever a new word arrives, the system categorizes it as per the labels of such groups.",
      "question": "What is meant by Feature Extraction in NLP"
    },
    {
      "answer": "Precision is the ratio of true positive instances and the total number of positively predicted instances.\nRecall is the ratio of true positive instances and the total actual positive instances.",
      "question": "What is meant by precision and recall"
    },
    {
      "answer": "F1 score evaluates the weighted average of recall and precision. It considers both false negative and false positive instances while evaluating the model. F1 score is more accountable than accuracy for an NLP model when there is an uneven distribution of class.",
      "question": "What is meant by F1 score in NLP"
    },
    {
      "answer": "Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.\n\nWhen the machine parses the text one word at a time, then it is a unigram.\nWhen the text is parsed two words at a time, it is a bigram.\nThe set of words is a trigram when the machine parses three words at a time.",
      "question": "How can we do parsing"
    },
    {
      "answer": "Named Entity Recognition NER is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text. NER is mostly used in NLP, Artificial Intelligence, and Machine Learning. One of the real life applications of NER is chatbots used for customer support.",
      "question": "What is Named Entity Recognition"
    },
    {
      "answer": "To find out the similarity among words, we use word similarity. We evaluate the similarity with the help of a number that lies between 0 and 1. We use the spacy library to implement the technique of word similarity.",
      "question": "How can we check word similarity using the spacy package"
    },
    {
      "answer": "It is a metric that is used to test the performance of language models. Mathematically, it is defined as a function of the probability that the language model represents a test sample. ",
      "question": "Explain perplexity in NLP"
    },
    {
      "answer": "The Masked Language Model is a model that takes a sentence with a few hidden masked words as input and tries to complete the sentence by correctly guessing those hidden words.",
      "question": "Explain about the Masked Language Model"
    },
    {
      "answer": "N gram model is a model in NLP that predicts the probability of a word in a given sentence using the conditional probability of n minus 1 previous words in the sentence. The basic intuition behind this algorithm is that instead of using all the previous words to predict the next word, we use only a few previous words.",
      "question": "Describe about the N-gram model in NLP"
    },
    {
      "answer": "The Markov assumption assumes for the bigram model that the probability of a word in a sentence depends only on the previous word in that sentence and not on all the previous words.",
      "question": "What you meant by the Markov assumption for the bigram model"
    },
    {
      "answer": "Following are a few methods of word embedding.\n\nEmbedding Layer\nWord2Vec\nGlove\n",
      "question": "Which are the popular methods used for word embedding"
    },
    {
      "answer": " len set text",
      "question": "What is the code to count the number of distinct tokens in a text"
    },
    {
      "answer": "Initially, a smaller dictionary is a better choice because most NLP researchers feared that a giant dictionary would contain rare words that may be similar to misspelled words. However, later it was found Damerau and Mays 1989 that in practice, a more extensive dictionary is better at marking rare words as errors.",
      "question": "which one is a better choice: a giant dictionary or a smaller dictionary, and why"
    },
    {
      "answer": "NLTK, Scikit learn,GenSim, SpaCy, CoreNLP, TextBlob.",
      "question": "Libraries for doing NLP in Python"
    },
    {
      "answer": "Support Vector Machines, Neural Networks, Decision Tree, Bayesian Networks.",
      "question": "Recommend few machine learning/deep learning models that are used in NLP"
    },
    {
      "answer": "GenSim",
      "question": "Name the library that contains the Word2Vec model in Python"
    },
    {
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. \nEach one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton.",
      "question": "What you meant by a hapax"
    },
    {
      "answer": "The rare words that only occur once in a sample text or corpus are called hapaxes. \nEach one of them is called an hapax or hapax legomenon greek for read only once. It is also called a singleton.",
      "question": "What is meant by hapax legomenon"
    },
    {
      "answer": "A collocation is a group of two or more words that possess a relationship and provide a classic alternative of saying something. For example, strong breeze, the rich and powerful, weapons of mass destruction.",
      "question": "What you meant a collocation"
    },
    {
      "answer": "1. Lexical Ambiguity This type of ambiguity is observed because of homonyms and polysemy in a sentence.\n\n\t2. Syntactic Ambiguity A syntactic ambiguity is observed when based on the sentences syntax, more than one meaning is possible.\n\n\t3. Semantic Ambiguity This ambiguity occurs when a sentence contains ambiguous words or phrases that have ambiguous meanings.",
      "question": "List out linguistic ambiguities"
    },
    {
      "answer": "Alan Turing developed a test, called Turing Test, that could differentiate between humans and machines. A computer machine is considered intelligent if it can pass this test through its use of language. Alan believed that if a machine could use language the way humans do, it was sufficient for the machine to prove its intelligence.",
      "question": "What is a Turing Test"
    },
    {
      "answer": "Regular expressions in natural language processing are algebraic notations representing a set of strings. They are mainly used to find or replace strings in a text and can also be used to define a language in a formal way.",
      "question": "What is regular expressions in NLP"
    },
    {
      "answer": "Parsing refers to the task of generating a linguistic structure for a given input. For example, parsing the word helping will result in verb pass plus gerunding.",
      "question": "Describe the term parsing concerning NLP"
    },
    {
      "answer": "SpaCy  TextBlob  Textacy  Natural language Toolkit NLTK  Retext  NLP.js  Stanford NLP  CogcompNLP",
      "question": "Which are the best NLP Tools"
    },
    {
      "answer": "The inverse error function occurs in the solution of nonlinear heat and diffusion problems. It provides exact solutions when the diffusion coefficient is concentration dependent",
      "question": "What is inverse error function"
    },
    {
      "answer": "Error is the difference between Predicted value and Actual value in the test dataset",
      "question": "What is Error"
    },
    {
      "answer": "Glaisher discovered the Error function",
      "question": "Who discovered Error function"
    },
    {
      "answer": "Integrals of the error function occur in a great variety of applications, usually in problems involving multiple integration where the integrand contains exponentials of the squares of the arguments",
      "question": "Can the error function be integrated"
    },
    {
      "answer": "The Mean Absolute Error is the mean of the sum of absolute differences between predictive values and actual values",
      "question": "What is Mean Absolute Error"
    },
    {
      "answer": "To find the mean square error, take the observed value, subtract the predicted value and square that difference. Repeat that for all observations. Then, sum all of those squared values are divided by the number of observations. Notice that the numerator is the sum of the squared errors, which linear regression minimizes",
      "question": "How to find Mean Squared Error"
    },
    {
      "answer": "An error function measures the deviation of an observable value from a prediction.The word error represents the penalty for failing to achieve the expected output.",
      "question": "What is Error Function"
    },
    {
      "answer": "Errors functions try and minimize error values and hence the name",
      "question": "Why is it called error function"
    },
    {
      "answer": "The error function erf is a special function. It is widely used in statistical computations for instance, where it is also known as the standard normal cumulative probability",
      "question": "Where is Error function used"
    },
    {
      "answer": "The complementary error function represents the area under the two tails of zero mean Gaussian probability density function of variance. The error function gives the probability that the parameter lies outside that range",
      "question": "What is Error function in digital communication"
    },
    {
      "answer": "Yes, the complementary error function is odd function",
      "question": "Is complementary error function odd function"
    },
    {
      "answer": "The python error function is also known as the gauss error function and this function throws an error, if any non number is passed as a parameter",
      "question": "What is Python error function"
    },
    {
      "answer": "The error function at infinity is exactly one",
      "question": "What is the error function of infinity"
    },
    {
      "answer": "No, the Error function is not same as Loss function. An error function measures the deviation of an observable value from a prediction, whereas a loss function operates on the error to quantify the negative consequence of an error",
      "question": "Is Error function same as Loss function"
    },
    {
      "answer": "Error is the difference between single actual value and single predicted value. Loss is the average error over training data",
      "question": "What is the difference between Error and loss in Machine learning"
    },
    {
      "answer": "The Error function in neural network is the function, which you try to minimize",
      "question": "What is Error function in neural network"
    },
    {
      "answer": "Another classic sigmoid is the error function",
      "question": "Is sigmoid an error function"
    },
    {
      "answer": "Zero is the error function of zero",
      "question": "What is the error function of zero"
    },
    {
      "answer": "stated by Laplace, proved by Jacobi and rediscovered by Ramanujan",
      "question": "Who introduced the symbol error function"
    },
    {
      "answer": "The complementary error function represents the area under the two tails of a zero mean",
      "question": "What is complementary Error function"
    },
    {
      "answer": "An integration error refers only to a lead not making it to a third party system",
      "question": "What is integration error"
    },
    {
      "answer": "The most commonly used error function for linear regression is Least Squared Error",
      "question": "Which error function is used by Linear Regression"
    },
    {
      "answer": "The error handling mechanisms force the application to log the user off and shut down the system",
      "question": "Why error handling is required"
    },
    {
      "answer": "A Loss function is for single training sample or input. Loss is calculated for every input,number of times of loss calculation will be equal to number of samples present in training dataset. A Cost function is the average loss over the entire training dataset. Cost will be calculate once over entire training dataset",
      "question": "What is the difference between Loss function and Cost function"
    },
    {
      "answer": "A residual is something left over after being used or removed or subtracted.An example of Residual is the paint remaining after all the rooms in the house have been painted. An Error is simply the measure of true difference between actual and predicted values in a machine learning model",
      "question": "What is the difference between Residual and Error"
    },
    {
      "answer": "If the loss is averaged across the entire training samples, the loss is called a cost function",
      "question": "What is Cost Function"
    },
    {
      "answer": "Other names of Mean Squared Error are Mean Squared Deviation, Quadratic Loss, L2 Loss",
      "question": "What are the other names of Mean Squared Error"
    },
    {
      "answer": "L1 Loss is the other name of Mean Absolute Error",
      "question": "What is the other name of Mean Absolute Error"
    },
    {
      "answer": "The similarity between Mean Squared Error and Mean Absolute Error is direction is not considered, whereas magnitude is only considered",
      "question": "What is the similarity between Mean Squared Error and Mean Absolute Error"
    },
    {
      "answer": "The Mean Percentage Error is the average of percent errors of the differences between predicted and actual values",
      "question": "What is Mean Percentage Error"
    },
    {
      "answer": "The Mean Absolute Percentage Error is a calculation of the average of absolute percent of errors",
      "question": "What is Mean Absolute Percentage Error"
    },
    {
      "answer": "The other name of Mean Absolute Percentage Error is Mean Absolute Percentage Deviation",
      "question": "What is the other name of Mean Absolute Percentage Error"
    },
    {
      "answer": "The advantages of Mean Squared Error are when we plot a quadratic equation,we get a gradient descent with only one global minima,there is no local minima.It penalizes the model for making larger errors by squaring them",
      "question": "What are the advantages of Mean Squared Error"
    },
    {
      "answer": "The disadvantage of Mean Squared Error is Outliers are not handled properly",
      "question": "What are the disadvantages of Mean Squared Error"
    },
    {
      "answer": "The advantages of Mean Absolute Error is Outliers are handled better than Mean Squared Error,as it is not penalizing the model by squaring error value",
      "question": "What are the advantages of Mean Absolute Error"
    },
    {
      "answer": "The disadvantage of Mean Absolute Errors will be they are computationally expensive as they use modulus operator function, they may be a local minima",
      "question": "What are the disadvantages of Mean Absolute Error"
    },
    {
      "answer": "The other names of Error functions are Cost Functions, Loss Functions, Fitted value versus Predicted value, Residual versus Error",
      "question": "What are other names for Error function?"
    },
    {
      "answer": "Residual is the difference between Fitted value and Predicted value in the training dataset",
      "question": "What is Residual"
    },
    {
      "answer": "Mean Squared Error is the mean or average of squared distances between actual and predicted values.Since the difference is squared, the direction of the error is meaningless and only the magnitude matters",
      "question": "What is Mean Squared Error"
    },
    {
      "answer": "No,Mean Squared Error cannot be negative,because it is an expected value of a non negative random variable",
      "question": "Can Mean Squared Error be negative"
    },
    {
      "answer": "To minimize the error with the line,we use gradient descent.The way to descend is to take the gradient of the error function with respect to the weights. This gradient is going to point to a direction where the gradient increases the most",
      "question": "How do you minimize the error function"
    },
    {
      "answer": "A loss function is a measure of how good a prediction model does in terms of being able to predict the expected outcome. If the loss is calculated for a single training example, it is called loss function",
      "question": "What is Loss function"
    },
    {
      "answer": "The loss function is the function that computes the distance between the current output of the algorithm and the expected output",
      "question": "What does loss functions compute"
    },
    {
      "answer": "A loss function is for a single training example. It is also sometimes called an error function. A cost function, on the other hand, is the average loss over the entire training dataset",
      "question": "Is loss function a error"
    },
    {
      "answer": "Gradient descent is used for logistic regression",
      "question": "Which error function is used for Logistic Regression"
    },
    {
      "answer": "Mean Squared Error is metric used to measure error function",
      "question": "which metric is used to measure error function"
    },
    {
      "answer": "Binary cross entropy is commonly used loss function for binary classification problem",
      "question": "Which loss function can be used for classification problem"
    },
    {
      "answer": "A loss function specifies a penalty for an incorrect estimate from a statistical model",
      "question": "What is a loss function in terms of statistics"
    },
    {
      "answer": "The 0 1 loss function is non convex and discontinuous, so gradient methods cannot be applied",
      "question": "Why is 0 1 loss not used frequently"
    },
    {
      "answer": "Mean square error is convex on its input and parameters by itself. But on an arbitrary neural network, it is not always convex due to the presence of non linearities in the form of activation functions",
      "question": "Is Mean squared error a convex function"
    },
    {
      "answer": "It is a complex function of a complex variable. This integral is a special sigmoid function that occurs often in probability,statistics and partial differential equations",
      "question": "Define Error function in context of mathematics"
    },
    {
      "answer": "The inverse error function occurs in the solution of nonlinear heat and diffusion problems. It provides exact solutions when the diffusion coefficient is concentration dependent",
      "question": "Define inverse error function"
    },
    {
      "answer": "The symbol error function was stated by Laplace, proved by Jacobi, and rediscovered by Ramanujan",
      "question": "who discovered symbol error function"
    },
    {
      "answer": "Loss fucntion depends on presence of outliers,choice of machine learning algorithm, time efficiency of gradient descent, ease of finding derivatives, confidence of predictions",
      "question": "What does loss function depend on"
    },
    {
      "answer": "The types of loss functions based on classification are Log loss, Focal loss, Relative Entropy, Exponential loss, Hinge loss",
      "question": "What are the different types of loss functions based on classification"
    },
    {
      "answer": "The types of loss functions based on regression are Mean Squared Error, Mean Absolute Error, Huber loss or Smooth Mean Absolute Error, Log cosh loss, Quantile loss",
      "question": "What are the different types of loss functions based on regression"
    },
    {
      "answer": "The measure of average magnitude of errors in a set of predictions, considering their direction is called Mean Bias Error",
      "question": "What is Mean Bias Error"
    },
    {
      "answer": "Squaring the error in gradient descent, ensures that the error for each training example is positive",
      "question": "Why do we square the error function in gradient descent"
    },
    {
      "answer": "Gradient Descent is an optimization algorithm used for minimizing the cost function in various machine learning algorithms",
      "question": "What is the purpose of gradient descent algorithm"
    },
    {
      "answer": "The squared error is everywhere differentiable, while the absolute error is not, this makes the squared error more better, when compared to the techniques of mathematical optimization",
      "question": "Why is the squared error loss function more convenient than the norm function"
    },
    {
      "answer": "The gradient descent algorithm takes a step in the direction of the negative gradient, in order to reduce loss as quickly as possible",
      "question": "Do gradient descent steps always decrease the loss"
    },
    {
      "answer": "The function we want to minimize or maximize is called the objective function or criterion. Loss function is usually a function defined on a data point, prediction and label, and measures the penalty",
      "question": "What is the difference between loss function and objective function"
    },
    {
      "answer": "Loss is used to calculate the gradients",
      "question": "List one usage of loss function"
    },
    {
      "answer": "Mean Squared Error is the most commonly used Loss function",
      "question": "What is the most commonly used loss function"
    },
    {
      "answer": "Gini Impurity is the loss function used by decision trees",
      "question": "Which loss function is used by Decision trees"
    },
    {
      "answer": "Multi class cross entropy is used in multi class classification loss.This is an extension of the binary cross entropy calculation where the losses for each class are calculated separately added as the result",
      "question": "Which metric is used in multi class classification loss"
    },
    {
      "answer": "Binary cross entropy is the measure of difference between probability distributions for a set of given random variables or events",
      "question": "What is Binary Cross Entropy"
    },
    {
      "answer": "The other name for Binary Cross Entropy is Log Loss",
      "question": "What is other name for Binary Cross Entropy"
    },
    {
      "answer": "Yes Binary cross entropy and log loss are the same. Both terms are used for classification problems,whereas cross entropy is used for multi class classification and log loss is used for binary classification",
      "question": "Is binary cross entropy the same as log loss"
    },
    {
      "answer": "Cross entropy loss increases, if the predicted probability is different from the actual label",
      "question": "When does cross entropy loss increases"
    },
    {
      "answer": "The cost function used in Logistic Regression is Log Loss",
      "question": "Which cost function is used in logistic regression"
    },
    {
      "answer": "Mean squared error is the simplest and most common loss function",
      "question": "Is mean squared error loss function"
    },
    {
      "answer": "It is just the square root of the mean squared erro",
      "question": "Is mean squared error the same as root mean squared error"
    },
    {
      "answer": "For Linear Regression, Mean squared error is nothing but the Cost Function. Mean Squared Error is the sum of the squared differences between the prediction and true value",
      "question": "Is mean squared error a cost function"
    },
    {
      "answer": "Root Mean Squared Error is measure of the average deviation of model predictions from the actual values in the dataset",
      "question": "What is Root Mean Squared Error"
    },
    {
      "answer": "Root Mean Squared Error is a cost function, since it is square root of average of squared errors across samples in the dataset",
      "question": "Is Root Mean Squared Error a cost function or loss function"
    },
    {
      "answer": "Root Mean Squared Error value ranges from zero to infinity",
      "question": "What is the range of Root Mean Squared Error value"
    },
    {
      "answer": "The lower the Root Mean Squared Error, the better a given model is able to fit the dataset",
      "question": "How to interpret Root Mean Squared Error"
    },
    {
      "answer": "We cannot claim any number as good Root Mean Squared Error value, since it is based upon the dependent variable",
      "question": "Can Root Mean Squared Error value be greater than 1"
    },
    {
      "answer": "Based on a rule of thumb, it can be said that Root Mean Squared Error values between 0.2 and 0.5 shows that the model can predict the data accurately",
      "question": "What is good range of Root Mean Squared Error"
    },
    {
      "answer": "Standard deviation is used to measure the spread of data around the mean, while Root Mean Squared Error is used to measure distance between some values and prediction for those values",
      "question": "Is Root Mean Squared Error the same as Standard deviation"
    },
    {
      "answer": "Root Mean Squared Error has the same units as the quantity being estimated",
      "question": "What are the units of Root Mean Squared Error"
    },
    {
      "answer": "Lower values of Root Mean Squared Error indicates a better fit of model on to the data",
      "question": "What does lower values of Root Mean Squared Error indicate"
    },
    {
      "answer": "If the Root Mean Squared Error for the test set is much higher than that of the training set, it describes that you have badly over fit the data",
      "question": "What does higher values of Root Mean Squared Error indicate"
    },
    {
      "answer": "Linear Cost Function, Quadratic Cost Function, Cubic Cost Function",
      "question": "What are the different types of cost functions"
    },
    {
      "answer": "Huber loss approaches Mean Absolute Error when hyperparameter delta is approximately equal to 0 and Huber loss approaches Mean Squared Error when delta is approximately equal to infinity",
      "question": "What is the hyper parameter of Huber loss"
    },
    {
      "answer": "Quantile loss functions are useful, when predicting an interval instead of only point predictions",
      "question": "What is the intuition behind Huber loss"
    },
    {
      "answer": "Binary Cross Entropy loss is the other name of Log loss",
      "question": "When are Quantile loss functions useful"
    },
    {
      "answer": "Hinge loss is a loss function used for training classifiers",
      "question": "What is the other name for Log loss"
    },
    {
      "answer": "For a given problem statement, the solution starts with a Random initialization. These initial parameters are then used to generate the predictions that is the output. Once we have the predicted values we can calculate the error or the cost",
      "question": "How error value is calculated using gradient descent method"
    },
    {
      "answer": "There is no correct value for Mean squared error. Simply put, lower the value will be better and 0 means the model is perfect",
      "question": "Should Mean squared error be high or low"
    },
    {
      "answer": "If the execution is not done properly while using gradient descent, it may lead to problems like vanishing gradient or exploding gradient problems",
      "question": "What are the problems faced by gradient descent"
    },
    {
      "answer": "The goal of gradient descent is to minimize the cost function, or the error between predicted and actual output",
      "question": "What is the goal of gradient descent"
    },
    {
      "answer": "The standard error tells you, how accurate the mean of any given sample from that population is likely to be compared to the true population mean",
      "question": "What standard error tells us"
    },
    {
      "answer": "Calculate error between the actual value and the predicted value, Reiterate until you find the best weights of network, Pass an input through the network and get values from output layer, Initialize random weight and bias",
      "question": "What are the steps for using a gradient descent algorithm to calculate error"
    },
    {
      "answer": "Mini Batch gradient descent works faster than both Batch gradient descent and Stochastic gradient descent",
      "question": "Which is the fastest gradient descent"
    },
    {
      "answer": "The choice of error function depends entirely on how our model will be used. Example is Squared deviation",
      "question": "What is the criteria for choosing error function"
    },
    {
      "answer": "Hinge loss is a loss function used for training classifiers",
      "question": "What is Hinge loss"
    },
    {
      "answer": "when the Mean Squared loss function is plotted with respect to weights of the logistic regression model, the curve obtained is not a convex curve which makes it very difficult to find the global minimum.",
      "question": "Why Mean squared error is not used as a loss function in Binomial Logistic Regression"
    },
    {
      "answer": "Cross entropy is better than Mean squared error for classification, because the decision boundary in a classification task is large in comparison with regression.",
      "question": "Why is cross entropy better than Mean squared error"
    },
    {
      "answer": "The deviation of an observable value is measured by using error function.",
      "question": "How do you measure the deviation of an observable value"
    },
    {
      "answer": "Yes loss function is same as Objective function, loss function is a part of a cost function which is a type of an objective function.",
      "question": "Is loss function same as objective function"
    },
    {
      "answer": "The Mean Squared Error, or MSE loss is the default loss to use for regression problems. Mathematically, it is the preferred loss function under the inference framework of maximum likelihood if the distribution of the target variable is Gaussian.",
      "question": "Is Mean square error a good loss function"
    },
    {
      "answer": "The exponential loss is convex and grows exponentially for negative values which makes it more sensitive to outliers. The exponential loss is used in the AdaBoost algorithm.",
      "question": "What is exponential loss"
    },
    {
      "answer": "Contrastive loss is used to map vectors that model the similarity of input items. These mappings can support many tasks, like unsupervised learning, one shot learning, and other distance metric learning tasks.",
      "question": "What is contrastive loss used for"
    },
    {
      "answer": "If we want to indicate the uncertainty around the estimate of the mean measurement, we quote the standard error of the mean. The standard error is most useful as a means of calculating a confidence interval.",
      "question": "Why do we use Standard Error"
    },
    {
      "answer": "The smaller the standard error, the less the spread and the more likely it is that any sample mean is close to the population mean. A small standard error is thus a Good Thing.",
      "question": "Is a low standard error Good"
    },
    {
      "answer": "Standard Error value of 0.8 to 0.9 are acceptable.",
      "question": "How much standard error is acceptable"
    },
    {
      "answer": "Type 1 errors are false positives. They happen when the tester validates a statistically significant difference even though there is not one.",
      "question": "What is Type I error"
    },
    {
      "answer": "Type II error are false negatives. A type II error is defined as the probability of incorrectly failing to reject the null hypothesis, when in fact it is not applicable to the entire population.",
      "question": "What is Type II error"
    },
    {
      "answer": "Type III error occurs when you get the right answer to the wrong question. Type III error occurs when you correctly conclude that the two groups are statistically different, but you are wrong about the direction of the difference.",
      "question": "What is Type III error"
    },
    {
      "answer": "A type IV error was defined as the incorrect interpretation of a correctly rejected null hypothesis. Statistically significant interactions were classified in any of the categories such as correct interpretation or cell mean interpretation or main effect interpretation or no interpretation.",
      "question": "What is Type IV error"
    },
    {
      "answer": "Type I error is rejecting the null hypothesis when it is true, Type II error is probability of incorrectly failing to reject the null hypothesis, Type III error is getting the right answer to the wrong question, Type IV error is incorrect interpretation of a correctly rejected null hypothesis.",
      "question": "What is the difference between Type I error, Type II error, Type III error and Type IV error"
    },
    {
      "answer": "Alpha error occurs when the null hypothesis is erroneously rejected.",
      "question": "What is Alpha Error"
    },
    {
      "answer": "Beta error occurs when the null hypothesis is wrongly retained.",
      "question": "What is Beta Error"
    },
    {
      "answer": "The other name of type I error is Alpha Error.",
      "question": "What is the other name of type I error"
    },
    {
      "answer": "the other name of type II error is Beta Error.",
      "question": "What is the other name of type II error"
    },
    {
      "answer": "The significance level of Type I Error is set as 0.05, which is 5 percentage.",
      "question": "What is the significance level of Type I Error"
    },
    {
      "answer": "Type 1 errors can result from two sources such as random chance and improper research techniques.",
      "question": "What can cause Type I errors"
    },
    {
      "answer": "We can control the likelihood of a Type I error by changing the level of significance. The probability of a Type I error is equal to alpha, so if you want to avoid them, lower your significance level maybe from 5 percent down to 1 percent.",
      "question": "How to prevent Type I errors"
    },
    {
      "answer": "The significance level, also denoted as alpha, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5 percent risk of concluding that a difference exists when there is no actual difference.",
      "question": "Why do we use 0.05 level of significance"
    },
    {
      "answer": "Type II errors can be avoided by increasing the sample size, increasing the significance level.",
      "question": "How to avoid Type II Error"
    },
    {
      "answer": "To decide worst type of error, errors depends upon situation, in some cases, a Type I error is preferable to a Type II error, but in other applications, a Type I error is more dangerous to make than a Type II error.",
      "question": "Is Type I error or Type II error worst"
    },
    {
      "answer": "There are two types of statistical errors such as Sampling error and Non sampling error.",
      "question": "What are the types of statistical errors Class 11"
    },
    {
      "answer": "Bias is the amount that a model prediction differs from the target value, compared to the training data. Bias error results from simplifying the assumptions used in a model so the target functions are easier to approximate.",
      "question": "What is Bias Error"
    },
    {
      "answer": "The other names of Bias Error are Error due, Squared Bias.",
      "question": "What are the other names of Bias Error"
    },
    {
      "answer": "To calculate the bias of a method used for many estimates, find the errors by subtracting each estimate from the actual or observed value. Add up all the errors and divide by the number of estimates to get the bias.",
      "question": "How do you calculate Bias error"
    },
    {
      "answer": "Random error is a chance difference between the observed and true values of something. For example, a researcher misreading a weighing scale records an incorrect measurement.",
      "question": "What is Random error"
    },
    {
      "answer": "If you measure a sample from a wider population, then the average or mean of the sample will be an approximation of the population mean. Thus 68 percent of all sample means will be within one standard error of the population mean and 95 percent within two standard errors.",
      "question": "What does standard error of 1 mean"
    },
    {
      "answer": "High Bias can be solved by adding more features to the hypothesis function, if new features are not available, we create new features by combining two or more existing features or by taking a square, cube, etc of the existing feature.",
      "question": "How do you fix high bias"
    },
    {
      "answer": "If the experimental value is less than the accepted value, the error is negative.",
      "question": "What is a negative error"
    },
    {
      "answer": "Error variance is the statistical variability of scores caused by the influence of variables other than the independent variable.",
      "question": "What is Variance error"
    },
    {
      "answer": "The standard error is calculated by dividing the standard deviation by the square root of sample size.",
      "question": "How standard error is calculated"
    },
    {
      "answer": "Standard error and standard deviation are both measures of variability. The standard deviation reflects variability within a sample, while the standard error estimates the variability across samples of a population.",
      "question": "What is the difference between standard error and standard deviation"
    },
    {
      "answer": "Sampling error is the difference in size between a sample estimate and the population parameter. The standard error of the mean, sometimes shortened to standard error, provided a measure of the accuracy of the sample mean as an estimate of the population parameter.",
      "question": "What is the difference between standard error and Sampling error"
    },
    {
      "answer": "When the standard error is large relative to the statistic, the statistic will typically be non significant. However, if the sample size is very large, for example, sample sizes greater than 1000, then virtually any statistical result calculated on that sample will be statistically significant.",
      "question": "How do you know if standard error is significant"
    },
    {
      "answer": "Standard error is used to estimate the efficiency, accuracy, and consistency of a sample",
      "question": "What are the uses of Standard error"
    },
    {
      "answer": "The sampling error is calculated by dividing the standard deviation of the population by the square root of the size of the sample, and then multiplying the resultant with the Z score value, which is based on the confidence interval.",
      "question": "How do you calculate sampling error"
    },
    {
      "answer": "Sampling errors may be positive or negative.",
      "question": "Can sampling error be negative"
    },
    {
      "answer": "The standard error of the mean is the standard deviation of the sampling distribution of the mean. It is therefore the square root of the variance of the sampling distribution of the mean. ",
      "question": "What is the standard error for a sampling distribution of the mean"
    },
    {
      "answer": "Margin of error can be calculated by multiplying critical value with standard deviation of population or sample.",
      "question": "How do you find margin of error"
    },
    {
      "answer": "Sampling error is affected by a number of factors including sample size, sample design, the sampling fraction and the variability within the population.",
      "question": "What are the causes of sampling errors"
    },
    {
      "answer": "Standard deviation is an essential part of calculating the margin of error for your data. If you do not have the value for your sample data proportion, you can use standard deviation to determine the margin of error.",
      "question": "Is standard deviation margin of error"
    },
    {
      "answer": "Uncertainty is measured with a variance or its square root, which is a standard deviation. The standard deviation of a statistic is also called standard error. Uncertainty emerges because of variability.",
      "question": "Is standard error the same as uncertainty"
    },
    {
      "answer": "The sampling errors can be eliminated by increasing the sample size or the number of samples.",
      "question": "Can sampling error be eliminated"
    },
    {
      "answer": "Sampling error is the difference between a population parameter and a sample statistic used to estimate it. For example, the difference between a population mean and a sample mean is sampling error.",
      "question": "What is Sampling error"
    },
    {
      "answer": "Non sampling error refers to all sources of error that are unrelated to sampling. Non sampling errors are present in all types of survey, including censuses and administrative data.",
      "question": "What is non sampling error"
    },
    {
      "answer": "In general, larger sample sizes decrease the sampling error, however this decrease is not directly proportional.",
      "question": "How do you interpret sampling error"
    },
    {
      "answer": "Sampling error is a statistical error happens due to the sample selected does not perfectly represents the population of interest. Non sampling error occurs due to sources other than sampling, while conducting survey activities is known as non sampling error.",
      "question": "What is the difference between sampling error and non sampling error"
    },
    {
      "answer": "Nonsampling errors, arise mainly due to misleading definitions and concepts, inadequate frames, unsatisfactory questionnaires, defective methods of data collection, tabulation, coding, incomplete coverage of sample units.",
      "question": "What are the sources of non sampling errors"
    },
    {
      "answer": "Techniques to avoid non sampling error are randomizing the selection, training your team, performing external record checks, completing consistency checks, checking your wording, randomizing question order and sticking to the facts.",
      "question": "How can we reduce or avoid non sampling error"
    },
    {
      "answer": "Undercoverage occurs when the sampling frame does not include all members of the target population",
      "question": "What is Undercoverage error"
    },
    {
      "answer": "Coverage error, Measurement error, Nonresponse error and Processing error.",
      "question": "What are the types of non sampling errors"
    },
    {
      "answer": "Sampling errors can be reduced by increasing sample size, splitting population into smaller groups and by using random sampling.",
      "question": "How can sampling errors be prevented"
    },
    {
      "answer": "Yes, the Standard error could be greater than its mean and this might indicates high variation between values and abnormal distribution for data. in such case, it is advisable to use median and range instead of Mean and standard deviation to describe your data.",
      "question": "Can standard error be greater than mean"
    },
    {
      "answer": "Generally, sampling error is the difference in size between a sample estimate and the population parameter. The standard error of the mean, sometimes shortened to standard error, provided a measure of the accuracy of the sample mean as an estimate of the population parameter.",
      "question": "How does standard error relate to sampling error"
    },
    {
      "answer": "Sampling error is important in creating estimates of the population value of a particular variable, how much these estimates can be expected to vary across samples, and the level of confidence that can be placed in the results.",
      "question": "Why is Sampling error important"
    },
    {
      "answer": "Non response errors result from a failure to collect complete information on all units in the selected sample.",
      "question": "What is non response error"
    },
    {
      "answer": "The risk of sampling error is, they may create distortions in the results, leading users to draw incorrect conclusions.",
      "question": "What are the risks of sampling errors"
    },
    {
      "answer": "The risk of sampling errors can be prevented, if the analysts select subsets or samples of data to represent the whole population effectively.",
      "question": "How can we prevent the risk of sampling errors"
    },
    {
      "answer": "Total and Partial are 2 types of non response errors.",
      "question": "What are the types of non response errors"
    },
    {
      "answer": "Total nonresponse error occurs when all or almost all data for a sampling unit are missing.",
      "question": "When does total non response error occur"
    },
    {
      "answer": "Partial nonresponse error occurs when respondents provide incomplete information.",
      "question": "When does partial non response error occur"
    },
    {
      "answer": "Response errors represent a lack of accuracy in responses to questions.",
      "question": "What is response error"
    },
    {
      "answer": "They different factors of response error are, including a questionnaire that requires improvements, misinterpretation of questions by interviewers or respondents, and errors in respondent statements.",
      "question": "What are different factors of response error"
    },
    {
      "answer": "The ways to control response errors include using aided recall, replacing open questions with specific questions, using more appropriate time periods, employing bounded recall and records, using diaries, etc.",
      "question": "What are the possible ways to control response errors"
    },
    {
      "answer": "False positive error and False negative error are two types of selection errors.",
      "question": "What are the major errors of selection"
    },
    {
      "answer": "unit non response error and item non response error are two categories of non response errors.",
      "question": "What are categories of non response errors"
    },
    {
      "answer": "Magnet loss is a type of loss function used in distance metric learning of machine learning problems.",
      "question": "What is Magnet loss function"
    },
    {
      "answer": "Chance Error or chance Variation is the other name of random error.",
      "question": "What is the other name of random error"
    },
    {
      "answer": "Chance variation or chance error or random error is the inherent error in any predictive statistical model.",
      "question": "What are chance errors"
    },
    {
      "answer": "The Absolute error is the difference between the measured value and the actual value. Relative error is the ratio of the absolute error of the measurement to the accepted measurement.",
      "question": "What is absolute error and relative error"
    },
    {
      "answer": "Huber loss is a smooth approximation to absolute value.",
      "question": "Is Huber loss smooth"
    },
    {
      "answer": "Huber loss is more robust to outliers than Mean Squared Error.",
      "question": "Which loss function is robust to outliers"
    },
    {
      "answer": "Yes, Huber loss function is convex.",
      "question": "Is Huber loss function convex"
    },
    {
      "answer": "The statistician Peter Huber invented Huber loss.",
      "question": "Who invented Huber loss"
    },
    {
      "answer": "Smooth L1 loss can be interpreted as a combination of L1 loss and L2 loss. It behaves as L1 loss when the absolute value of the argument is high, and it behaves like L2 loss when the absolute value of the argument is close to zero.",
      "question": "What is smooth L1 loss"
    },
    {
      "answer": "The logistic loss is convex and grows linearly for negative values which make it less sensitive to outliers. The logistic loss is used in the LogitBoost algorithm.",
      "question": "Is logistic loss convex"
    },
    {
      "answer": "We should always use a convex loss function so that gradient descent can converge to the global minima.",
      "question": "Why are losses convex"
    },
    {
      "answer": "In multilabel classification, the zero one loss function corresponds to the subset zero one loss, for each sample the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.",
      "question": "What is Zeroone error"
    },
    {
      "answer": "The logarithm of sigmoid function is not convex.",
      "question": "Is sigmoid loss convex"
    },
    {
      "answer": "The quadratic loss function gives a measure of how accurate a predictive model is. It works by taking the difference between the predicted probability and the actual value, so it is used on classification schemes which produce probabilities",
      "question": "What is quadratic loss function"
    },
    {
      "answer": "Naive Bayes classifier is an example of quadratic loss function",
      "question": "State an example of quadratic loss function"
    },
    {
      "answer": "Squared Hinge loss is an extension of the hinge loss and it is the square of the hinge loss function.",
      "question": "What is Squared hinge Loss"
    },
    {
      "answer": "Gini Impurity is a measure of the likelihood that an instance of a random variable is incorrectly classified per the classes in the data provided the classification is random.",
      "question": "What is Gini impurity"
    },
    {
      "answer": "Hellinger Distance is a cost function that satisfies the triangle inequality.",
      "question": "Mention the cost function that satisfies triangle inequality"
    },
    {
      "answer": "The Hellinger distance forms a bounded metric on the space of probability distributions over a given probability space.",
      "question": "Is Hellinger distance bounded"
    },
    {
      "answer": "Yes Hellinger distance is symmetric. The Hellinger distance metric gives an output in the range of 0 to 1 for two probability distributions, with values closer to 0 meaning they are more similar. ",
      "question": "Is Hellinger distance symmetric"
    },
    {
      "answer": "Hinge loss function typically works best when the values of the output variable are in the set of minus 1 to plus 1.",
      "question": "Mention range of values for which hinge loss works best"
    },
    {
      "answer": "Squared Hinge loss is perfectly suitable for Yes or No type of questions, where the deviation in probability is not a concern.",
      "question": "For which type of questions, Squared Hinge loss is suitable"
    },
    {
      "answer": "The lower bound for Gini impurity function is 0",
      "question": "What is the lower bound for gini impurity"
    },
    {
      "answer": "The other name of cross entropy loss function is logarithmic loss.",
      "question": "What is the other name of cross entropy loss function"
    },
    {
      "answer": "The weighted Cross Entropy loss function is used to solve the problem that the accuracy of the deep learning model overfitting on the test set due to the imbalance of the convergence speed of the loss function decreases.",
      "question": "What is weighted cross entropy loss"
    },
    {
      "answer": "Mathematically, if your label is 1 and your predicted probability is low like 0.1, the cross entropy can be greater than 1, like losses",
      "question": "Can cross entropy be more than 1"
    },
    {
      "answer": "The weighted loss function  is calculated based on the predicted value and error obtained for each instance. This method is applicable to both prognostic and diagnostic tasks.",
      "question": "What is weighted loss function"
    },
    {
      "answer": "Categorical cross entropy is a loss function that is used in multi class classification tasks. These are tasks where an example can only belong to one out of many possible categories and the model must decide which one.",
      "question": "What is categorical cross entropy loss"
    },
    {
      "answer": "Zero entropy means perfect knowledge of a state, no motion, no temperature, no uncertainty. ",
      "question": "What does it mean if entropy is zero"
    },
    {
      "answer": "For logistic regression, this cross entropy loss function is conveniently convex. A convex function has just one minimum, there are no local minima, so gradient descent starting from any point is guaranteed to find the minimum.",
      "question": "Is Cross Entropy loss convex"
    },
    {
      "answer": "An ordinal superiority measure summarizes the probability that an observation from one distribution falls above an independent observation from the other distribution, adjusted for explanatory variables in a model.",
      "question": "Define ordinal probability"
    },
    {
      "answer": "An ordinal superiority measure summarizes the probability that an observation from one distribution falls above an independent observation from the other distribution, adjusted for explanatory variables in a model.",
      "question": "What is ordinal probability"
    },
    {
      "answer": "The ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered as in between the qualitative data and quantitative data. The ordinal data only shows the sequences and cannot use for statistical analysis",
      "question": "Is ordinal data qualitative"
    },
    {
      "answer": ".No. The pairs of ordinal numbers 1 and 4 and, 2 and 3 both sum to 5",
      "question": "Can you sum ordinal data"
    },
    {
      "answer": "You want to use one variable in a prediction of another, or you want to quantify the numerical relationship between two variables\nThe variable you want to predict your dependent variable is an ordered categorical ordinal variable",
      "question": "When to use Ordinal Logistic Regression"
    },
    {
      "answer": "In ordinal encoding, each unique category value is assigned an integer value.\n\nFor example, red is 1, green is 2, and blue is 3.\n\nThis is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used.",
      "question": "Define ordinal encoding"
    },
    {
      "answer": "This means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model. The two most popular techniques are an Ordinal Encoding and a One Hot Encoding",
      "question": "What kind of encoding techniques can you use for categorical variables"
    },
    {
      "answer": "Nominal data is classified without a natural order or rank, whereas ordinal data has a predetermined or natural order.On the other hand, numerical or quantitative data will always be a number that can be measured",
      "question": "What is ordinal and nominal"
    },
    {
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them. Ordinal level of measurement is the second of the four measurement scales. Ordinal indicates order",
      "question": "What is ordinal level"
    },
    {
      "answer": "Ordinal data is frequently skewed or multi modal so violates the assumption of normal distribution. Thus the distribution is not appropriate for analysis as metric data",
      "question": "Can ordinal data be skewed"
    },
    {
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them. Ordinal level of measurement is the second of the four measurement scales. Ordinal indicates order",
      "question": "define ordinal level"
    },
    {
      "answer": "Examples of ordinal variables include socio economic status low income,middle income,high income, education level high school,BS,MS,PhD, income level less than 50K, 50K to 100K, over 100K, satisfaction rating extremely dislike, dislike, neutral, like, extremely like",
      "question": "What are example of ordinal"
    },
    {
      "answer": "Ordinal numbers tell the order of how things are set, they show the position or the rank of something.",
      "question": "What is ordinal numbers"
    },
    {
      "answer": "Ordinal Numbers are those numerals which are used in identifying the position of objects or persons. They are also called as positioning numbers.The ordinal numbers can be written using numerals as prefix and adjectives as a suffix, for example, 1st, 2nd, 3rd, 4th, 5th, 6th and so on.",
      "question": "Define  ordinal numbers"
    },
    {
      "answer": "The package scikit learn is a widely used Python library for machine learning, built on top of NumPy and some other packages. It provides the means for preprocessing data, reducing dimensionality, implementing regression, classification, clustering, and more. Like NumPy, scikit learn is also open source.",
      "question": "Which Python library is used for regression"
    },
    {
      "answer": "Ordinal refers to quantities that have a natural ordering.Interval data is like ordinal except we can say the intervals between each value are equally split. The most common example is temperature in degrees Fahrenheit.",
      "question": "Is temperature an ordinal variable"
    },
    {
      "answer": "In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree is ordinal.",
      "question": "Is ordinal scale continuous"
    },
    {
      "answer": "Ordinal numbers tell the order of how things are set, they show the position or the rank of something.",
      "question": "Define ordinal numbers"
    },
    {
      "answer": "Ordinal regression seeks class label predictions when the penalty incurred for mistakes increases according to an ordering over the labels.The absolute error, between label prediction  and actual label is a canonical ordinal regression loss function.",
      "question": "Define ordinal loss"
    },
    {
      "answer": "Ordinal responses include Likert scales for agreement with attitude statements e.g., disagree, neither agree nor disagree, and agree and reported frequencies of doing something such as helping children with homework e.g., daily, several times per week, occasionally, and never.",
      "question": "What is ordinal response"
    },
    {
      "answer": "Likert scales fall within the ordinal level of measurement the categories of response have directionality, but the intervals between them cannot be presumed equal.\n",
      "question": "Is Likert scale ordinal"
    },
    {
      "answer": "In ordinal encoding, each unique category value is assigned an integer value.\n\nFor example, red is 1, green is 2, and blue is 3.\n\nThis is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used.",
      "question": "what is ordinal encoding"
    },
    {
      "answer": "Age can be both nominal and ordinal data depending on the question types. I.e How old are you is used to collect nominal data while Are you the firstborn or What position are you in your family is used to collect ordinal data. Age becomes ordinal data when there some sort of order to it.",
      "question": "Is age ordinal or nominal"
    },
    {
      "answer": "Linear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression",
      "question": "What are the types of Regressions"
    },
    {
      "answer": "Linear Regression is used to handle regression problems whereas Logistic regression is used to handle the classification problems. Linear regression provides a continuous output but Logistic regression provides discreet output",
      "question": "What is the main difference between linear regression and logistic regression"
    },
    {
      "answer": "Now you can usually use linear regression with an ordinal dependent variable but you will see that the diagnostic plots do not look good.",
      "question": "Can you use linear regression for ordinal data"
    },
    {
      "answer": "Ordinal data can be visualized in several different ways. Common visualizations are the bar chart or a pie chart. Tables can also be useful for displaying ordinal data and frequencies. Mosaic plots can be used to show the relationship between an ordinal variable and a nominal or ordinal variable.\n",
      "question": "How do you display ordinal data"
    },
    {
      "answer": " Assumptions The dependent variable is measured on an ordinal level One or more of the independent variables are either continious categorical or ordinal No Multi collinearity  that is when two or more independent variables are highly correlated with each other.",
      "question": "What are the assumptions for ordinal regression"
    },
    {
      "answer": "Interpret the key results for Binary Logistic Regression\nStep 1 Determine whether the association between the response and the term is statistically significant.\nStep 2 Understand the effects of the predictors.\nStep 3 Determine how well the model fits your data.\nStep 4 Determine whether the model does not fit the data.",
      "question": "How do you interpret logistic regression"
    },
    {
      "answer": "Interpret the key results for Binary Logistic Regression\nStep 1 Determine whether the association between the response and the term is statistically significant.\nStep 2 Understand the effects of the predictors.\nStep 3 Determine how well the model fits your data.\nStep 4 Determine whether the model does not fit the data.",
      "question": "what is interpretation of logistic regression"
    },
    {
      "answer": "R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.",
      "question": "What does beta mean in logistic regression"
    },
    {
      "answer": "ordinal regression also called ordinal classification is a type of regression analysis used for predicting an ordinal variable that is a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant.",
      "question": " What is ordinal regression in machine learning"
    },
    {
      "answer": " ordinal regression also called ordinal classification is a type of regression analysis used for predicting an ordinal variable that is a variable whose value exists on an arbitrary scale where only the relative ordering between different values is significant.",
      "question": "Define ordinal regression "
    },
    {
      "answer": "Bayesian non parametric ordinal regression under a monotonicity constraint Herein the considered models are non parametric and the only condition imposed is that the effects of the covariates on the outcome categories are stochastically monotone according to the ordinal scale.",
      "question": "Is ordinal regression nonparametric"
    },
    {
      "answer": "The assumptions for Ordinal Logistic Regression include Linearity, No Outliers, Independence.",
      "question": "Is ordinal logistic regression linear"
    },
    {
      "answer": "Ordinal data is a kind of categorical data with a set order or scale to it For example ordinal data is said to have been collected when a responder inputs his or her financial happiness level on a scale of 1 10.",
      "question": "What is ordinal data example"
    },
    {
      "answer": "To find out relationship between ordinal variables, you can use Spearman rank correlation or Kendalls Tau c In the same way for graphical representation you can use multiple bar chart. check whether there is a positive or negative relationship between two variable.",
      "question": "How do you correlate ordinal data"
    },
    {
      "answer": "The logistic regression coefficient beta associated with a predictor X is the expected change in log odds of having the outcome per unit change in X.",
      "question": "define beta means in logistic regression"
    },
    {
      "answer": "R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.",
      "question": "What is r squared in logistic regression"
    },
    {
      "answer": " R squared is a goodness of fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.",
      "question": "Define r squared in logistic regressio"
    },
    {
      "answer": "At a very high level, the main difference ordinal regression and linear regression is that with linear regression the dependent variable is continuous and ordinal the dependent variable is ordinal.",
      "question": "What is the difference between linear and ordinal regression"
    },
    {
      "answer": "Logistic regression is usually taken to mean binary logistic regression for a two valued dependent variable Y. Ordinal regression is a general term for any model dedicated to ordinal Y whether Y is discrete or continuous.",
      "question": "What is the difference between logistic regression and ordinal regression"
    },
    {
      "answer": "The best model was deemed to be the linear model, because it has the highest AIC, and a fairly low R square adjusted in fact, it is within 1 percent of that of model poly31 which has the highest R square adjusted.\n",
      "question": "Which is the best regression model"
    },
    {
      "answer": " In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand.",
      "question": "Can ordinal variables be used in regression"
    },
    {
      "answer": "The simplest way to analyze ordinal data is to use visualization tools. For instance, the data may be presented in a table in which each row indicates a distinct category. In addition, they can also be visualized using various charts. The most commonly used chart for representing such types of data is the bar chart.",
      "question": "How do you measure ordinal data"
    },
    {
      "answer": "Both multinomial and ordinal models are used for categorical outcomes with more than two categories. The simplest decision criterion is whether that outcome is nominali.e., no ordering to the categories or ordinal i.e., the categories have an order.",
      "question": "Is multinomial the same as ordinal"
    },
    {
      "answer": "Ordinal regression is used to predict the dependent variable with ordered multiple categories and independent variables. In other words, it is used to facilitate the interaction of dependent variables having multiple ordered levels with one or more independent variables",
      "question": "Why do we use ordinal regression"
    },
    {
      "answer": "Ordinal scale has all its variables in a specific order, beyond just naming them. Ratio scale bears all the characteristics of an interval scale, in addition to that, it can also accommodate the value of zero on any of its variables.\n",
      "question": "What is the difference between ordinal scale and ratio scale"
    },
    {
      "answer": "The mean cannot be computed with ordinal data. Finding the mean requires you to perform arithmetic operations like addition and division on the values in the data set. Since the differences between adjacent scores are unknown with ordinal data, these operations cannot be performed for meaningful results.",
      "question": "Can you calculate mean for ordinal data"
    },
    {
      "answer": "Values on 5 point ordinal scales are never normally distributed",
      "question": "Can ordinal data be normally distributed"
    },
    {
      "answer": "If the variable is ordinal, the median is probably your best bet because it provides more information about the sample than the mode does. But if the variable is interval or ratio, you will need to determine if the distribution is symmetrical or skewed.",
      "question": "Why is median used for ordinal data"
    },
    {
      "answer": "A stronger reason for not using the mean with ordinal data is that its value depends on conventions on coding. Numerical codes such as 1, 2, 3, 4 are usually just chosen for simplicity or convenience, but in principle they could equally well be 1, 23, 456, 7890 as far as corresponding to a defined order as concerned.",
      "question": "Why not use mean for ordinal data"
    },
    {
      "answer": "An ordinal variable is similar to a categorical variable. The difference between the two is that there is a clear ordering of the categories. For example, suppose you have a variable, economic status, with three categories low, medium and high.",
      "question": "Is ordinal data categorical or continuous"
    },
    {
      "answer": "Religion. There are many different religions, but again these are just different ways of categorizing the religious preferences of people. Consequently religion has only a nominal scale of measurement",
      "question": "Is religion nominal or ordinal"
    },
    {
      "answer": "If a variable is ordinal and has at least five categories, making a normality assumption can work well, and then it can make sense to check normality.To check normality, compute skewness or kurtosis. Do not rely on significance tests for normality, because these are strongly sample size dependent",
      "question": "Do you test for normality with ordinal data"
    },
    {
      "answer": "The mode is most useful when used with categorical nominal, or ordinal variables and when there is a relatively small sample size. The mode can be used with categorical variables because it does not require the data to be in a meaningful order. With large samples, it becomes very tedious to determine the mode.",
      "question": "Why is mode used for ordinal data"
    },
    {
      "answer": "The median is usually preferred to other measures of central tendency when your data set is skewed i.e., forms a skewed distribution or you are dealing with ordinal data. However, the mode can also be appropriate in these situations, but is not as commonly used as the median.",
      "question": "Is median preferred for ordinal scale"
    },
    {
      "answer": "Although a t test or ANOVA will work with ordinal data, such an analysis is incorrect because there is no information on the distance between measurements, only their order. Fortunately, easy to use freeware is available for nonparametric analyses of ordinal data to draw robust conclusions.",
      "question": "Can you run an Anova with ordinal data"
    },
    {
      "answer": "The most suitable statistical tests for ordinal data e.g., Likert scale are non parametric tests, such as Mann Whitney U test one variable, no assumption on distribution, Wilcoxon signed rank sum test two variables, normal distribution, Kruskal Wallis test two or more groups, no assumption on distribution.",
      "question": "Which test is best for ordinal data"
    },
    {
      "answer": "The ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered as in between the qualitative data and quantitative data. The ordinal data only shows the sequences and cannot use for statistical analysis",
      "question": "Can ordinal data be qualitative"
    },
    {
      "answer": "Ordinal regression is used to predict the dependent variable with ordered multiple categories and independent variables. In other words, it is used to facilitate the interaction of dependent variables having multiple ordered levels with one or more independent variables. For example Let us assume a survey is done.",
      "question": "What is the main characteristic of ordinal regression algorithm"
    },
    {
      "answer": "Actually, it is not appropriate to treat ordinal data as if it were continuous interval data.",
      "question": "Can ordinal data be treated as interval data"
    },
    {
      "answer": "The purpose of using ordinal numbers is to indicate position, or order of things or objects.Since the counting process requires labeling of things with numbering, when objects or things are placed in an order, ordinal numbers tell their exact position, or they help to put things in an order in a collection.",
      "question": "Why are ordinal numbers important"
    },
    {
      "answer": "one to first.\ntwo to second.\nthree to third.\nfive to fifth.\neight to eighth.\nnine to ninth.\ntwelve to twelfth",
      "question": "How do you write 12 in ordinal numbers"
    },
    {
      "answer": "An ordinal scale is a scale of measurement that uses labels to classify cases measurements into ordered classes.Some examples of variables that use ordinal scales would be movie ratings, political affiliation, military rank, etc. Example. One example of an ordinal scale could be movie ratings.",
      "question": "What is an example of a ordinal scale"
    },
    {
      "answer": "The assumptions of the Chi square include The data in the cells should be frequencies, or counts of cases rather than percentages or some other transformation of the data.However, data may be ordinal data. Interval or ratio data that have been collapsed into ordinal categories may also be used.\n",
      "question": "Can I use Chi Square to test ordinal data"
    },
    {
      "answer": "An ordinal variable is a categorical variable for which the possible values are ordered. Ordinal variables can be considered in between categorical and quantitative variables. Thus it does not make sense to take a mean of the values",
      "question": "What type of variable is ordinal"
    },
    {
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale.",
      "question": "What is ordinal scale in research"
    },
    {
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale.",
      "question": "Define ordinal scale in research"
    },
    {
      "answer": "Military ranks can be considered ordinal measurements. A General is greater in military rank than a Captain who is greater in rank than a Sergeant. Moh's scale of hardness is another good example of measurement at the ordinal level.",
      "question": "Is military rank nominal or ordinal"
    },
    {
      "answer": "Specify a value greater than or equal to 0 and less than 100.",
      "question": "what is confidence interval of ordinal regression"
    },
    {
      "answer": "All continuous data has a median, mode and mean. However, strictly speaking, ordinal data has a median and mode only, and nominal data has only a mode.",
      "question": "Is ordinal mean median or mode"
    },
    {
      "answer": "ORCA Ordinal Regression and Classification Algorithms is an Octave/MATLAB framework including a wide set of ordinal regression methods.",
      "question": "which software is used for ordinal regression"
    },
    {
      "answer": "Ordinal regression seeks class label predictions when the penalty incurred for mistakes increases according to an ordering over the labels.The absolute error, between label prediction  and actual label is a canonical ordinal regression loss function.",
      "question": "What is ordinal loss"
    },
    {
      "answer": "Regression analysis is a form of predictive modelling technique which investigates the relationship between a dependent target and independent variable s predictor. This technique is used for forecasting, time series modelling and finding the causal effect relationship between the variables. For example, relationship between rash driving and number of road accidents by a driver is best studied through regression.",
      "question": "What is Regression Analysis"
    },
    {
      "answer": "regression analysis estimates the relationship between two or more variables. Lets understand this with an easy example\n\nLets say, you want to estimate growth in sales of a company based on current economic conditions. You have the recent company data which indicates that the growth in sales is around two and a half times the growth in the economy. Using this insight, we can predict future sales of the company based on current and past information.",
      "question": "Why do we use Regression Analysis"
    },
    {
      "answer": "Linear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression",
      "question": "Types of Regressions"
    },
    {
      "answer": ".For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature.",
      "question": "Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model"
    },
    {
      "answer": "An odds ratio in an ordinal response model is interpreted the same as in a binary model it gives the change in odds for a unit increase in a continuous predictor or when changing levels of a categorical CLASS predictor\n",
      "question": "How do you interpret ordinal logistic regression odds ratio"
    },
    {
      "answer": "Life is usually simple, when you know only one or two techniques. One of the training institutes I know of tells their students  if the outcome is continuous apply linear regression. If it is binary  use logistic regression However, higher the number of options available at our disposal, more difficult it becomes to choose the right one. A similar case happens with regression models.",
      "question": "How to select the right Regression Model"
    },
    {
      "answer": "Logistic regression fits a logistic curve to binary data. This logistic curve can be interpreted as the probability associated with each outcome across independent variable values. Logistic regression assumes that the relationship between the natural log of these probabilities when expressed as odds and your predictor variable is linear.",
      "question": "what is linearity does in ordinal regression"
    },
    {
      "answer": "Logistic regression fits a logistic curve to binary data. This logistic curve can be interpreted as the probability associated with each outcome across independent variable values. Logistic regression assumes that the relationship between the natural log of these probabilities when expressed as odds and your predictor variable is linear.",
      "question": "Define linearity in ordinal regression"
    },
    {
      "answer": "SPSS ordinal regression procedure works with the data, because it differs from logistic regression. First, for the dependent outcome variable, SPSS actually models the probability of achieving each level or below rather than each level or above",
      "question": "How do I run Ordinal Logistic Regression in SPSS"
    },
    {
      "answer": "Ordinal variables have at least three categories and the categories have a natural order. The categories are ranked but the differences between ranks may not be equal. For example, first, second, and third in a race are ordinal data",
      "question": "Do ordinal variables have natural ordering"
    },
    {
      "answer": "Ordinal variables are fundamentally categorical. One simple option is to ignore the order in the variables categories and treat it as nominal",
      "question": "How do you deal with ordinal categorical variables"
    },
    {
      "answer": "Binary Encoding\n\nIn this encoding scheme, the categorical feature is first converted into numerical using an ordinal encoder. Then the numbers are transformed in the binary number. After that binary value is split into different columns. Binary encoding works really well when there are a high number of categories.",
      "question": "Which encoding is best for categorical data"
    },
    {
      "answer": "An ordinal variable is similar to a categorical variable. The difference between the two is that there is a clear ordering of the categories.Even though we can order these from lowest to highest, the spacing between the values may not be the same across the levels of the variables.",
      "question": "Are ordinal variables categorical"
    },
    {
      "answer": "Encoding of categorical variables with high cardinality\nLabel Encoding scikit learn i.e. mapping integers to classes.\nOne Hot  Dummy Encoding scikit learn i.e. expanding the categorical feature into lots of dummy columns taking values in 0,1",
      "question": "How do you encoding categorical data with high cardinality"
    },
    {
      "answer": "You can put them on a scale with respect to some other, dependent, variable. So there is no correlation with ordinal variables or nominal variables because correlation is a measure of association between scale variables",
      "question": "Can you correlate ordinal scale variables"
    },
    {
      "answer": "In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree is ordinal.",
      "question": "Is strongly agree ordinal"
    },
    {
      "answer": "developed by Eibe Frank and Mark Hal.",
      "question": "who invented ordinal regression"
    },
    {
      "answer": "Ordinal Numbers are those numerals which are used in identifying the position of objects or persons. They are also called as positioning numbers.The ordinal numbers can be written using numerals as prefix and adjectives as a suffix, for example, 1st, 2nd, 3rd, 4th, 5th, 6th and so on.",
      "question": "what is ordinal numbers"
    },
    {
      "answer": "Ordinal classification is a form of multiclass classification for which there is an inherent order between the classes, but not a meaningful numeric difference between them. The performance of such classifiers is usually assessed by measures appropriate for nominal classes or for regression",
      "question": "What is ordinal classification"
    },
    {
      "answer": "Ordinal classification is a form of multiclass classification for which there is an inherent order between the classes, but not a meaningful numeric difference between them. The performance of such classifiers is usually assessed by measures appropriate for nominal classes or for regression.",
      "question": "Define ordinal classification"
    },
    {
      "answer": "Ordinal logistic regression often just called ordinal regression is used to predict an ordinal dependent variable given one or more independent variables.As with other types of regression, ordinal regression can also use interactions between independent variables to predict the dependent variable.",
      "question": "Can you run a regression with ordinal data"
    },
    {
      "answer": "Ordinal variables have two are more categories that can be ordered or ranked. Keep in mind that researchers may sometimes treat ordinal variables as continuous if they have more than five categories. To remember this variable type, think ordinal order.",
      "question": "Can ordinal data be continuous"
    },
    {
      "answer": "Dichotomous variables those with only two values are a special case, and may sometimes be treated as nominal, ordinal, or interval.Whether it is better to treat a dichotomous variable as nominal or ordinal depends on how we think of the underlying concept being measured",
      "question": "Can dichotomous variables be ordinal"
    },
    {
      "answer": "Binary data is discrete data that can be in only one of two categories  either yes or no, 1 or 0, off or on, etc. Binary can be thought of as a special case of ordinal, nominal, count, or interval data.",
      "question": "Can binary be ordinal"
    },
    {
      "answer": "An ordinal encoding involves mapping each unique label to an integer value. This type of encoding is really only appropriate if there is a known relationship between the categories. This relationship does exist for some of the variables in our dataset, and ideally, this should be harnessed when preparing the data.",
      "question": "How does machine learning deal with ordinal data"
    },
    {
      "answer": "Depending on what you want to model, hours and many other attributes like seasons are actually ordinal cyclic variables. In case of seasons you can consider them to be more or less categorical, and in case of hours you can model them as continuous as well.",
      "question": "Are hours ordinal or not"
    },
    {
      "answer": "Ordinal responses include Likert scales for agreement with attitude statements e.g., disagree, neither agree nor disagree, and agree and reported frequencies of doing something such as helping children with homework e.g., daily, several times per week, occasionally, and never.",
      "question": "Define ordinal response"
    },
    {
      "answer": "Von Neumann definition of ordinals",
      "question": "Who invented ordinal numbers"
    },
    {
      "answer": "The empty set  is an ordinal and as ordinal is denoted by 0",
      "question": "Is the empty set an ordinal\n"
    },
    {
      "answer": "The Ordinal scale includes statistical data type where variables are in order or rank but without a degree of difference between categories. The ordinal scale contains qualitative data ordinal meaning order. It places variables in order or rank, only permitting to measure the value as higher or lower in scale.",
      "question": "Is a scale ordinal"
    },
    {
      "answer": "The standard approach to ordinal classification converts the class value into a numeric quantity and applies a regression learner to the transformed data, translating the output back into a discrete class value in a post processing step.",
      "question": "What are ordinal classifications based on"
    },
    {
      "answer": "First, identify your thresholds estimates. You will have one for each possible increase in the outcome variable. For example, if your outcome has a low, medium, and high category, you have two thresholds.one is for the increase from low to medium, and one is for the increase from medium to high.",
      "question": "What is threshold in ordinal regression"
    },
    {
      "answer": "First, identify your thresholds estimates. You will have one for each possible increase in the outcome variable. For example, if your outcome has a low, medium, and high category, you have two thresholds.one is for the increase from low to medium, and one is for the increase from medium to high.",
      "question": "Define threshold in ordinal regression"
    },
    {
      "answer": ".In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand.",
      "question": "What is ordinal dependent variable"
    },
    {
      "answer": "In ordinal regression analysis, the dependent variable is ordinal statistically it is polytomous ordinal and the independent variables are ordinal or continuous level ratio or interval. Sometimes the dependent variable is also called response, endogenous variable, prognostic variable or regressand.",
      "question": "Define ordinal dependent variable"
    },
    {
      "answer": "The most appropriate statistical tests for ordinal data focus on the rankings of your measurements. These are non parametric tests. Parametric tests are used when your data fulfils certain criteria, like a normal distribution. While parametric tests assess means, non parametric tests often assess medians or ranks.",
      "question": "What test is used for ordinal data"
    },
    {
      "answer": "Treat ordinal variables as numeric\n\nBecause the ordering of the categories often is central to the research question, many data analysts do the opposite ignore the fact that the ordinal variable really is not numerical and treat the numerals that designate each category as actual numbers.",
      "question": "How do you handle ordinal data"
    },
    {
      "answer": "Ordinal numbers can be written out as words second, third or as numerals followed by abbreviations 2nd,3rd\n",
      "question": "How are ordinal numbers written"
    },
    {
      "answer": "To perform ordinal regression, we need to expand the targets list into a batch size, num labels tensor, according to our previous encoding, and return the mean squared error loss between predictions and the expanded target Code for the loss function, which first encodes the target label and then calculates MSE",
      "question": "How do you do ordinal regression Pytorch"
    },
    {
      "answer": "Regression analysis is a form of predictive modelling technique which investigates the relationship between a dependent target and independent variable s predictor. This technique is used for forecasting, time series modelling and finding the causal effect relationship between the variables. For example, relationship between rash driving and number of road accidents by a driver is best studied through regression.",
      "question": "Define Regression Analysis"
    },
    {
      "answer": "These tests include an ordinal\n        version of the Hosmer Lemeshow test the Pulkstenis Robinson chi squared and\n        deviance tests and the Lipsitz likelihood ratio test",
      "question": "How to test for goodness of fit in ordinal regression models"
    },
    {
      "answer": "the explanatory variables",
      "question": "Which of them may be suitable as an outcome variable for ordinal regression"
    },
    {
      "answer": "Simple linear regression is a technique that is appropriate \n          to understand the association between one independent\n          variable and one continuous dependent",
      "question": "The regression technique to the appropriate type of outcome variable"
    },
    {
      "answer": "They let me to check and rethink the paradox of significant interactions \n          between the log odds model and the probability on dependent variable",
      "question": "How many interaction effects could be explored in this regression model"
    },
    {
      "answer": "The odds for each explanatory variable must be the same",
      "question": "The assumption of proportional odds states that in regression technique"
    },
    {
      "answer": "Ordinal outcomes are polytomous or multilevel outcomes whose levels can be ordered by for example their clinical significance",
      "question": "Describes an ordinal outcome variable"
    },
    {
      "answer": "It is currently not possible to change the reference category in the Ordinal Regression module",
      "question": "when compared to the reference group for the relevant variable for ordinal regression"
    },
    {
      "answer": "A statistically significant result isnt attributed to chance and depends on two key variables sample size and effect size",
      "question": "Contribute to the model to a statistically significant degree"
    },
    {
      "answer": "If this assumption is violated we cannot reduce the coefficients of the model to a single set across all outcome categories and this modeling approach fails",
      "question": "What should be done if the proportional odds assumption is violated during an ordinal regression"
    },
    {
      "answer": "It could be argued that it is easier to split ordinal outcome variables down in to multiple binary variables and model the data using a series of logistic regression analyses rather than a single ordinal regression analysis",
      "question": "It could be argued that it is easier to split ordinal outcome variables down in to multiple binary variables"
    },
    {
      "answer": "Ordinal regression is a general term for any model dedicated to ordinal Y whether Y is discrete or continuous",
      "question": "Model the data using a series of logistic regression analyses rather than a single ordinal regression analysis"
    },
    {
      "answer": "the test of the P assumption has been described as anti conservative that is it nearly always results in rejection of the proportional odds assumption particularly when the number of explanatory variables is large",
      "question": "Is the assumption of Proportional Odds met for this final version of the model"
    },
    {
      "answer": "Linear regression and logistic regression are two types of regression analysis",
      "question": "However there are other approaches to ordinal regression"
    },
    {
      "answer": "Ordinal logistic regression often just called ordinal regression is used to predict an ordinal dependent variable given one or more independent variables",
      "question": "ordinal regression using spss"
    },
    {
      "answer": "the two groups deteriorate at about the same rate hence the difference between groups is about the same across occasions",
      "question": "Are there differences in the outcome between the groups"
    },
    {
      "answer": "Ordinal regression is a member of the family of regression analyses as a predictive analysis",
      "question": "Are the symptoms more severe in one group"
    },
    {
      "answer": "All continuous data has a median mode and mean However strictly speaking ordinal data has a median and mode only and nominal data has only a mode",
      "question": "are the ordinal data has alternative modelling method"
    },
    {
      "answer": "Ordinal regression is a statistical technique that is used to predict behavior of ordinal level dependent variables",
      "question": "ordinal regression is done when we have dependent variable"
    },
    {
      "answer": "Ordinal regression is a statistical technique that is used to predict behavior of ordinal level dependent variables with a set of independent variables",
      "question": "ordinal regression is done when we have independent variable"
    },
    {
      "answer": "Ordinal Scale is defined as a variable measurement scale used to simply depict the order of variables and not the difference between each of the variables",
      "question": "what are the ordinal measurement scale in ordinal regression"
    },
    {
      "answer": "Nominal scale is a naming scale where variables are simply named or labeled with no specific order",
      "question": "what are the nominal measurement scale in ordinal regression"
    },
    {
      "answer": "In statistics ordinal and nominal variables are both considered categorical variables Even though ordinal data can sometimes be numerical not all mathematical operations can be performed on them",
      "question": "if ordinal regression is categorical data which field it is"
    },
    {
      "answer": "Scales of measurement is how variables are defined and categorised",
      "question": "if ordinal regression is scale data which filed it is"
    },
    {
      "answer": "A parallel slopes model is the result of a multiple linear regression model that has both one numeric explanatory variable and one categorical explanatory variable",
      "question": "To define test parallel lines on ordinal regression"
    },
    {
      "answer": "Cross tabulation also known as cross tab or contingency table is a statistical tool used for categorical data",
      "question": "Describes crosstabulation level in ordinal regression"
    },
    {
      "answer": "A significance level of 0.05 indicates a 5 percentage risk of concluding that an association exists when there is no actual association",
      "question": "Define significant value in ordinal regression"
    },
    {
      "answer": "R squared R2 is a statistical measure that represents the proportion of the variance for a dependent variable thats explained by an independent variable or variables in a regression model",
      "question": "Describes R Square in the regression model"
    },
    {
      "answer": "Now let us start this ordinal regression analysis click analyze in this regression and in this ordinal Now dependent variable is satisfaction And independent variable is factor",
      "question": "How to do Regression Analysis for Likert Scale Data"
    },
    {
      "answer": "Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained",
      "question": "what problem at hand and an assessment of model fit"
    },
    {
      "answer": "If the slope of the line is positive then there is a positive linear relationship i.e as one increases the other increases",
      "question": "how do interpretation of the slope parameters"
    },
    {
      "answer": "A link function transforms the probabilities of the levels of a categorical response variable to a continuous scale that is unbounded",
      "question": "will choice of link function affects the interpretation of the parameters"
    },
    {
      "answer": "In its most general sense Covariates are simply the X variables in a statistical model and An interaction model is a design model that binds an application together in a way that supports the conceptual models of its target users",
      "question": "ordinal regression models with covariates and interactions"
    },
    {
      "answer": "The parallel trend assumption is the most critical of the above the four assumptions to ensure internal validity of DID models",
      "question": "what if parallel assumption is not satisfied"
    },
    {
      "answer": "This issue is more common with binary outcomes but given that ordinal regression is an extension of logistic regression it is plausible to see it occur here as well The problem is likely a result of empty cells for a given outcome level conditional on the covariates",
      "question": "what if there is a high propartion of empty cells"
    },
    {
      "answer": "Regression predictions are for the mean of the dependent variable",
      "question": "How well your ordinal regression model predicts the dependent variable"
    },
    {
      "answer": "Like all IRT models it is seeking to predict the probability of a certain response based on examinee ability trait level and some parameters which describe the performance of the item With the 3PL those parameters are a discrimination b difficulty or location and c pseudo guessing",
      "question": "The three models differ in which response categories are compared and how"
    },
    {
      "answer": "So the Hosmer lemma so test the way it works is it divides the data set into a number of groups according to the fitted probabilities that the binary outcome is a 1 And then it compares",
      "question": "How to calculate an ordinal version of the HL test"
    },
    {
      "answer": "In other words falls in assigned score when the latent variable falls in the th interval of values",
      "question": "How can be assigned an ordinal score"
    },
    {
      "answer": "Analyzing the Homogeneity of a Dataset\n        Calculate the median\n        Subtract the median from each value in the dataset\n        Count how many times the data will make a run above or below the median i.e persistance of positive or negative values\n        Use significance tables to determine thresholds for homogeneity",
      "question": "How heterogeneity calculate in ordinal regression"
    },
    {
      "answer": "The probability that a particular Chi Square test statistic is as extreme as or more so than what has been observed under the null hypothesis is defined by Pr ChiSq",
      "question": "How dose PR test calculate in ordinal regression"
    },
    {
      "answer": "The Lipsitz test is a goodness of fit test for ordinal response logistic regression models",
      "question": "How Lipsitz test calculate in ordinal regression"
    },
    {
      "answer": "The ordered probit and logit models have a dependent variable that are ordered categories Examples include rating systems poor fair good excellent opinion surveys from strongly disagree to strongly agree grades and bond ratings",
      "question": "what if probit model used in ordinal regression"
    },
    {
      "answer": "Regression coefficients are estimates of the unknown population parameters and describe the relationship between a predictor variable and the response In linear regression coefficients are the values that multiply the predictor values",
      "question": "How coefficients involved in ordinal regression"
    },
    {
      "answer": "Logistic regression is a powerful machine learning algorithm that utilizes a sigmoid function and works best on binary classification problems although it can be used on multi class classification problems through the one vs all method",
      "question": "Which type of problems are best for logistic regression"
    },
    {
      "answer": "We implement the trick described above by creating OrdinalClassifier class that will train k minus 1 binary classifier when fit is called and will return predicted class if predict is called",
      "question": "Which ordinal classifier class used for implement"
    },
    {
      "answer": "We can take advantage of the ordered class value by transforming a k class",
      "question": "How to take predicated class"
    },
    {
      "answer": "to get predicted probability of each class first we get all prediction probability from all of our classifiers that stored on clfs after that simply enumerate all possible class label and append its prediction to our predicted list after that return it as a numpy array",
      "question": "What if predict proba in ordinal regression"
    },
    {
      "answer": "we store each unique label available then for first k minus 1 value for each iteration we transform its label to a binary label that represents the test A multiply Vi binary y equal to y greater than self.unique class i.astypenp.uint8 then we fit a new classifier on the transformed label binary y finally store our classifier to the clfs dictionary with i as its key",
      "question": "How K minus 1  Values fits in ordinal regression"
    },
    {
      "answer": "Well a predicted probability is essentially in its most basic form the probability of an event that is calculated from available data",
      "question": "How predicted category probability classified"
    },
    {
      "answer": "The Pearsons correlation coefficient measures linear correlation between two continuous variables Values obtained using an ordinal scale are NOT continuous but their corresponding ranks are Hence you can still use the Pearsons correlation coefficient on those ranks",
      "question": "How correlation involved in ordinal regression"
    },
    {
      "answer": "The model depends on the main effects and interaction effects that you select",
      "question": "How Location model classified in ordinal regression"
    },
    {
      "answer": "A confidence interval displays the probability that a parameter will fall between a pair of values around the mean Confidence intervals measure the degree of uncertainty or certainty in a sampling method They are most often constructed using confidence levels of 95 percentage or 99 percentage",
      "question": "How confidence interval specified"
    },
    {
      "answer": "Used for checking for highly dependent predictors Select a value from the list of options",
      "question": "what if there is an Singularity tolerance"
    },
    {
      "answer": "Load dataset from the source\n        Split the dataset into training and test data\n        Train Decision tree SVM and KNN classifiers on the training data\n        Use the above classifiers to predict labels for the test data\n        Measure accuracy and visualize classification",
      "question": "How do predict multi class ordered variable which technique"
    },
    {
      "answer": "The intercepts indicate where the latent variable is cut to make the three groups that we observe in our data",
      "question": "define intercepts of ordinal regression"
    },
    {
      "answer": "Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable",
      "question": "Why we use logistic regression in Machine Learning"
    },
    {
      "answer": "Logistic regression is basically a supervised classification algorithm",
      "question": "How does logistic regression algorithm work"
    },
    {
      "answer": "Logistic regression is a statistical analysis method to predict a binary outcome such as yes or no based on prior observations of a data set Based on historical data about earlier outcomes involving the same input criteria it then scores new cases on their probability of falling into one of two outcome categories",
      "question": "What is logistic regression in machine learning with example"
    },
    {
      "answer": "Logistic regression transforms its output using the logistic sigmoid function to return a probability value",
      "question": "Which function is used in logistic regression"
    },
    {
      "answer": "denotes the corresponding value but for the null model the model with only an intercept and no covariates",
      "question": "What is McFadden pseudo R2"
    },
    {
      "answer": "Logistic regression and more generally GLM does NOT belong to Machine Learning Rather these methods belongs to parametric modeling Both parametric and algorithmic ML models use the data but in different ways",
      "question": "Is Machine Learning just logistic regression"
    },
    {
      "answer": "Logistic regression is used for binary or multi class classification and the target variable always has to be categorical",
      "question": "Which type of dataset is used for logistic regression"
    },
    {
      "answer": "Logistic regression is a statistical analysis method to predict a binary outcome such as yes or no based on prior observations of a data set A logistic regression model predicts a dependent data variable by analyzing the relationship between one or more existing independent variables",
      "question": "What is logistic regression in simple terms"
    },
    {
      "answer": "Logistic regression is easier to implement interpret and very efficient to train If the number of observations is lesser than the number of features Logistic Regression should not be used, otherwise it may lead to overfitting It makes no assumptions about distributions of classes in feature space",
      "question": "What is the advantage of logistic regression"
    },
    {
      "answer": "A neural network is more complex than logistic regression In practice a neural network model for binary classification can be worse than a logistic regression model because neural networks are more difficult to train and are more prone to overfitting than logistic regression",
      "question": "Why is DNN better than logistic regression"
    },
    {
      "answer": "logistic regression cannot be used for classification tasks that have more than two class labels so called multi class classification A logistic regression model that is adapted to learn and predict a multinomial probability distribution is referred to as Multinomial Logistic Regression",
      "question": "Can logistic regression use for more than 2 classes"
    },
    {
      "answer": "With chi square contingency analysis the independent variable is dichotomous and the dependent variable is dichotomous Logistic regression is a more general analysis however because the independent variable i.e the predictor is not restricted to a dichotomous variable",
      "question": "What is the difference between chi square and logistic regression"
    },
    {
      "answer": "Originally a perceptron was only referring to neural networks with a step function as the transfer function In that case of course the difference is that the logistic regression uses a logistic function and the perceptron uses a step function",
      "question": "How logistic regression is different from Perceptron"
    },
    {
      "answer": "The p value for each term tests the null hypothesis that the coefficient is equal to zero no effect",
      "question": "What does P value mean in logistic regression"
    },
    {
      "answer": "Logistic regression LR is a statistical method similar to linear regression since LR finds an equation that predicts an outcome for a binary variable Y from one or more response variables X",
      "question": "Is logistic regression A statistical test"
    },
    {
      "answer": "The most common form of error for logistic regression perceptron and support vector models is mean squared error",
      "question": "What is common to logistic regression perceptron and support vector machines"
    },
    {
      "answer": "The output from the logistic regression analysis gives a p value of which is based on the Wald z score",
      "question": "What is output of logistic regression"
    },
    {
      "answer": "Logistic regression has two phases training we train the system specifically the weights w and b using stochastic gradient descent and the cross entropy loss",
      "question": "How is logistic regression trained"
    },
    {
      "answer": "An F statistic of at least 3.95 is needed to reject the null hypothesis at an alpha level of 0.1",
      "question": "What is a good f value in regression"
    },
    {
      "answer": "Like other regression techniques logistic regression involves the use of two hypotheses",
      "question": "Is logistic regression a hypothesis test"
    },
    {
      "answer": "Lets start by defining the logistic regression cost function for the two points of interest y equal to 1 and y equal to 0 that is when the hypothesis function predicts Male or Female",
      "question": "How do you conduct a logistic regression"
    },
    {
      "answer": "Odds ratios are one of those concepts in statistics that are just really hard to wrap your head around For example, in logistic regression the odds ratio represents the constant effect of a predictor X on the likelihood that one outcome will occur",
      "question": "What is the odds ratio in logistic regression"
    },
    {
      "answer": "The major limitation of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables",
      "question": "What are the limitations of logistic regression"
    },
    {
      "answer": "SVM works well with unstructured and semi structured data like text and images while logistic regression works with already identified independent variables",
      "question": "What is difference between SVM and logistic regression"
    },
    {
      "answer": "Logistic Regression is a popular algorithm as it converts the values of the log of odds which can range from  minus inf to plus inf to a range between 0 and 1 Since logistic functions output the probability of occurrence of an event they can be applied to many real life scenarios therefore these models are very popular",
      "question": "Why logistic regression is very popular"
    },
    {
      "answer": "Analysis of Variance ANOVA is a statistical analysis to test the degree of differences between two or more groups of an experiment",
      "question": "What is Anova table"
    },
    {
      "answer": "Probability is the probability an event happens For example there might be an 80 percentage chance of rain today Odds more technically the odds of success is defined as probability of success or probability of failure Log odds is the logarithm of the odds",
      "question": "What are odds and log odds"
    },
    {
      "answer": "True Logistic regression is a supervised learning algorithm because it uses true labels for training Supervised learning algorithm should have input variables x and an target variable Y when you train the model",
      "question": "Is logistic regression a supervised machine learning algorithm"
    },
    {
      "answer": "Logistic Regression is a supervised learning algorithm that is used when the target variable is categorica",
      "question": "How logistic regression is implemented"
    },
    {
      "answer": "Summary We need to perform Feature Scaling when we are dealing with Gradient Descent Based algorithms Linear and Logistic Regression Neural Network and Distance based algorithms KNN K means SVM as these are very sensitive to the range of the data points",
      "question": "Do we need to scale data for logistic regression"
    },
    {
      "answer": "Parameter estimates also called coefficients are the log odds ratio associated with a one unit change of the predictor all other predictors being held constant The unknown model parameters are estimated using maximum likelihood estimation",
      "question": "What are the parameters in logistic regression"
    },
    {
      "answer": "Variables that are measured at different scales do not contribute equally to the model fitting model learned function and might end up creating a bias Thus to deal with this potential problem feature wise normalization such as MinMax Scaling is usually used prior to model fitting",
      "question": "What is MIN MAX scaling"
    },
    {
      "answer": "In regression analysis you need to standardize the independent variables when your model contains polynomial terms to model curvature or interaction terms",
      "question": "Should you standardize before regression"
    },
    {
      "answer": "In 1944 Joseph Berkson used log of odds and called this function logit abbreviation for logistic unit following the analogy for probit",
      "question": "What does logit stand for"
    },
    {
      "answer": "One of the way to improve accuracy for logistic regression models is by optimising the prediction probability cutoff scores generated by your logit model",
      "question": "How can logistic regression improve accuracy"
    },
    {
      "answer": "Penalized logistic regression imposes a penalty to the logistic model for having too many variables",
      "question": "What is penalty in logistic regression"
    },
    {
      "answer": "The z score enables a data administrator to compare two different scores that are from different normal distributions of the data",
      "question": "Why is z score normalized"
    },
    {
      "answer": "Yes you do need to scale the target variable I will quote this reference A target variable with a large spread of values in turn may result in large error gradient values causing weight values to change dramatically making the learning process unstable",
      "question": "Should I scale target variable"
    },
    {
      "answer": "So more generally this indicates that a scores increase on an independent variable Theres an increased probability of falling at a higher level on the dependent",
      "question": "Explain what you need to interpret and report to carry out  ordinal regression"
    },
    {
      "answer": "In SPSS Statistics an ordinal regression can be carried out using one of two procedures PLUM and GENLIN Whilst GENLIN has a number of advantages over PLUM including being easier and quicker to carry out it is only available if you have SPSS Statistics Advanced Module",
      "question": "How to carry out ordinal regression using SPSS Statistics"
    },
    {
      "answer": "Ordinal scale is the 2nd level of measurement that reports the ranking and ordering of the data without actually establishing the degree of variation between them",
      "question": "How should be measured at the ordinal level"
    },
    {
      "answer": "Multicollinearity occurs when you have two or more independent variables that are highly correlated with each other",
      "question": "what if multicollinearity occurs in ordinal regression"
    },
    {
      "answer": "The Output Management System OMS provides the ability to automatically write selected categories of output to different output files in different formats",
      "question": "how to use the OMS in ordinal regression"
    },
    {
      "answer": "Ordinal Regression allows you to model the dependence of a polytomous ordinal response on a set of predictors which can be factors or covariates The design of Ordinal Regression is based on the methodology of McCullagh 1980 1998 and the procedure is referred to as PLUM in the syntax",
      "question": "what if PLUM procedure in ordinal regression"
    },
    {
      "answer": "The Parameter estimates table is the core of the output telling us specifically about the relationship between our explanatory variables and the outcome",
      "question": "what is parameter estimates tables information in ordinal regression"
    },
    {
      "answer": "Factor analysis is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.  Factor analysis aims to find independent latent variables.",
      "question": "What does a factor analysis tell you"
    },
    {
      "answer": "In qualitative research no hypotheses or relationships of variables are tested. Because variables must be defined numerically in hypothesis-testing research, they cannot reflect subjective experience. This leads to hypothesis-generating research using the grounded theory method to study subjective experience directly.",
      "question": "Does a qualitative study have variables"
    },
    {
      "answer": "Explain the difference between descriptive and inferential statistics. Descriptive statistics describes sets of data. Inferential statistics draws conclusions about the sets of data based on sampling.  A population is a set of units of interest to a study.",
      "question": "What is the difference between descriptive and inferential statistics quizlet"
    },
    {
      "answer": "Exponential Smoothing is one of the more popular smoothing techniques due to its flexibility, ease in calculation, and good performance. Exponential Smoothing uses a simple average calculation to assign exponentially decreasing weights starting with the most recent observations.",
      "question": "Which method is best for smoothing of data"
    },
    {
      "answer": "Basically, there are three methods to solve a multi-label classification problem, namely: Problem Transformation. Adapted Algorithm.1 Binary Relevance. This is the simplest technique, which basically treats each label as a separate single class classification problem.  2 Classifier Chains.  3 Label Powerset.",
      "question": "How do you handle multi label classification"
    },
    {
      "answer": "Five Common Types of Sampling ErrorsPopulation Specification Error\u2014This error occurs when the researcher does not understand who they should survey.  Sample Frame Error\u2014A frame error occurs when the wrong sub-population is used to select a sample.More items",
      "question": "What are the types of sampling errors"
    },
    {
      "answer": "The Word2Vec Model This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity.",
      "question": "Is Word2Vec deep learning"
    },
    {
      "answer": "The law of averages is not a mathematical principle, whereas the law of large numbers is.  According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.",
      "question": "What is the difference between the law of large numbers and the law of averages"
    },
    {
      "answer": "Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.",
      "question": "Why AI algorithms are biased"
    },
    {
      "answer": ": to aim an attack at someone or something. : to direct an action, message, etc., at someone or something.",
      "question": "What does it mean to target someone"
    },
    {
      "answer": "1: The number of observations n is fixed. 2: Each observation is independent. 3: Each observation represents one of two outcomes (\"success\" or \"failure\"). 4: The probability of \"success\" p is the same for each outcome.",
      "question": "What are the 4 characteristics of a binomial distribution"
    },
    {
      "answer": "The number of neurons in the input layer equals the number of input variables in the data being processed. The number of neurons in the output layer equals the number of outputs associated with each input.",
      "question": "How do you determine the number of neurons in the input layer"
    },
    {
      "answer": "If two random variables X and Y are independent, then their covariance Cov(X, Y) = E(XY) \u2212 E(X)E(Y) = 0, that is, they are uncorrelated.",
      "question": "When X and Y are statistically independent then I xy is"
    },
    {
      "answer": "Artificial intelligence is imparting a cognitive ability to a machine.  The idea behind machine learning is that the machine can learn without human intervention. The machine needs to find a way to learn how to solve a task given the data. Deep learning is the breakthrough in the field of artificial intelligence.",
      "question": "What is artificial intelligence machine learning and deep learning"
    },
    {
      "answer": "Counterintuitive as it may be, supervised algorithms (particularly logistic regression and random forest) tend to outperform unsupervised ones on discrete classification and categorization tasks, where data is relatively structured and well-labeled.",
      "question": "Is it possible for unsupervised learning algorithms to outperform supervised ones"
    },
    {
      "answer": "You should put it after the non-linearity (eg. relu layer). If you are using dropout remember to use it before.",
      "question": "Where should I insert batch normalization"
    },
    {
      "answer": "For example, if n = 100 and p = 0.25 then we are justified in using the normal approximation. This is because np = 25 and n(1 - p) = 75. Since both of these numbers are greater than 10, the appropriate normal distribution will do a fairly good job of estimating binomial probabilities.",
      "question": "What is an example of the normal approximation of the binomial distribution"
    },
    {
      "answer": "Hierarchical clustering outputs a hierarchy, ie a structure that is more informa ve than the unstructured set of flat clusters returned by k-\u2010means. Therefore, it is easier to decide on the number of clusters by looking at the dendrogram (see sugges on on how to cut a dendrogram in lab8).",
      "question": "What are the benefits of hierarchical clustering over K means clustering"
    },
    {
      "answer": "The monty hall problem has 3 doors instead of 100. It is still more likely that you pick a goat.  If a person picks door 1 which is wrong the Monty Hall will close door 3 and give you chance to switch to the right answer, so it means they want always people win the prize.",
      "question": "How does the Monty Hall problem work"
    },
    {
      "answer": "To calculate how much weight you need, divide the known population percentage by the percent in the sample. For this example: Known population females (51) / Sample Females (41) = 51/41 = 1.24. Known population males (49) / Sample males (59) = 49/59 = .",
      "question": "How do you do weightage to a variable"
    },
    {
      "answer": "A variable is said to be continuous if it can assume an infinite number of real values. Examples of a continuous variable are distance, age and temperature. The measurement of a continuous variable is restricted by the methods used, or by the accuracy of the measuring instruments.",
      "question": "Is age a continuous variable"
    },
    {
      "answer": "The lower quartile, or first quartile, is denoted as Q1 and is the middle number that falls between the smallest value of the dataset and the median. The second quartile, Q2, is also the median.",
      "question": "Is median the same with second quartile"
    },
    {
      "answer": "Residual analysis is used to assess the appropriateness of a linear regression model by defining residuals and examining the residual plot graphs.",
      "question": "What is residual analysis used for"
    },
    {
      "answer": "If you want a representative sample of a particular population, you need to ensure that:The sample source includes all the target population.The selected data collection method (online, phone, paper, in person) can reach individuals that represent that target population.More items\u2022",
      "question": "How do you know if a sample size is representative"
    },
    {
      "answer": "The main difference between stratified sampling and cluster sampling is that with cluster sampling, you have natural groups separating your population.  With stratified random sampling, these breaks may not exist*, so you divide your target population into groups (more formally called \"strata\").",
      "question": "What is the difference between stratified random sampling and cluster sampling"
    },
    {
      "answer": "The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.",
      "question": "In what setting are z scores useful"
    },
    {
      "answer": "CONCLUSION. There are three primary goals of survival analysis, to estimate and interpret survival and / or hazard functions from the survival data; to compare survival and / or hazard functions, and to assess the relationship of explanatory variables to survival time.",
      "question": "Why is survival analysis used"
    },
    {
      "answer": "Every parametric test has the assumption that the sample means are following a normal distribution. This is the case if the sample itself is normal distributed or if approximately if the sample size is big enough.",
      "question": "Why does data need to be normally distributed in parametric tests"
    },
    {
      "answer": "A Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.  The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence.",
      "question": "What is Seq2Seq model"
    },
    {
      "answer": "Divide the number of subjects by 2, and round down. In the example 5 \u00f7 2 = 2.5 and rounding down gives 2. Find the first-ordered survival time that is greater than this number. This is the median survival time.",
      "question": "How do you find the median in survival time"
    },
    {
      "answer": "While regular gradient boosting uses the loss function of our base model (e.g. decision tree) as a proxy for minimizing the error of the overall model, XGBoost uses the 2nd order derivative as an approximation.",
      "question": "How is XGBoost different from gradient boosting"
    },
    {
      "answer": "The reason n-1 is used is because that is the number of degrees of freedom in the sample. The sum of each value in a sample minus the mean must equal 0, so if you know what all the values except one are, you can calculate the value of the final one.",
      "question": "Why is there a degree of freedom of n 1 for sample standard deviation"
    },
    {
      "answer": "Statistical knowledge helps you use the proper methods to collect the data, employ the correct analyses, and effectively present the results. Statistics is a crucial process behind how we make discoveries in science, make decisions based on data, and make predictions.",
      "question": "What are the advantages of statistics"
    },
    {
      "answer": "Linear regression can only be used when one has two continuous variables\u2014an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.",
      "question": "What data is used for multiple linear regression"
    },
    {
      "answer": "The four elements of a descriptive statistics problem include population/sample, tables/graphs, identifying patterns, and A. data.",
      "question": "What are the four elements of a descriptive statistics problem"
    },
    {
      "answer": "The mass density (\u03c1) of a substance is the mass of one unit volume of the substance.  The relative density is the ratio of the mass of the substance in air at 20 \u00b0C to that of an equal volume of water at the same temperature.",
      "question": "What is density and relative density"
    },
    {
      "answer": "The Paired Samples t Test compares two means that are from the same individual, object, or related units. The two means can represent things like: A measurement taken at two different times (e.g., pre-test and post-test with an intervention administered between the two time points)5 p\u00e4iv\u00e4\u00e4 sitten",
      "question": "What is the comparison mean for a paired sample t test"
    },
    {
      "answer": "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",
      "question": "What is a gradient in deep learning"
    },
    {
      "answer": "The prior distribution is a distribution for the parameters whereas the prior predictive distribution is a distribution for the observations.  The last line is based on the assumption that the upcoming observation is independent of X given \u03b8.",
      "question": "Differences between prior distribution and prior predictive distribution"
    },
    {
      "answer": "Decision trees: Are popular among non-statisticians as they produce a model that is very easy to interpret. Each leaf node is presented as an if/then rule.",
      "question": "Is a decision tree a model"
    },
    {
      "answer": "Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data.  Models and algorithms based on the principle of competitive learning include vector quantization and self-organizing maps (Kohonen maps).",
      "question": "What is competitive learning algorithm in neural network"
    },
    {
      "answer": "Answer. True is the answer of Restricted Boltzmann Machine expect data to be labeled for Training as because there are two process for training one which is called as pre-training and training. In pre-training one don't need labeled data.",
      "question": "Does Restricted Boltzmann Machine expect the data to be labeled for training"
    },
    {
      "answer": "Sampling is a statistical procedure that is concerned with the selection of the individual observation; it helps us to make statistical inferences about the population. In sampling, we assume that samples are drawn from the population and sample means and population means are equal.",
      "question": "What are the importance of sampling in statistics"
    },
    {
      "answer": "AI programs can provide automation for low-value tasks freeing up engineers to perform higher-value tasks. By using machine learning to discover patterns in the data, machines will be incredibly important to help with engineering judgment.",
      "question": "How is AI used in engineering"
    },
    {
      "answer": "Bootstrap aggregating, also called bagging (from bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.",
      "question": "Is bootstrapping the same as bagging"
    },
    {
      "answer": "Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.",
      "question": "What is NLP used for"
    },
    {
      "answer": "Fundamentally, classification is about predicting a label and regression is about predicting a quantity.  That classification is the problem of predicting a discrete class label output for an example. That regression is the problem of predicting a continuous quantity output for an example.",
      "question": "What is regression and classification"
    },
    {
      "answer": "A) (ii) Disadvantages of Mohr Method \uf0a7 Mohr's method is suitable only for titration of chloride, bromide and cyanide alone. \uf0a7 Errors can be introduced due to the need of excess titrant before the endpoint colour is visible.",
      "question": "What are the limitations of Mohr's method"
    },
    {
      "answer": "This article lists out 10 comprehensive data mining tools widely used in the big data industry.Rapid Miner.  Oracle Data Mining.  IBM SPSS Modeler.  KNIME.  Python.  Orange.  Kaggle.  Rattle.More items\u2022",
      "question": "What are the data mining tools"
    },
    {
      "answer": "We can compute the p-value corresponding to the absolute value of the t-test statistics (|t|) for the degrees of freedom (df): df=n\u22121. If the p-value is inferior or equal to 0.05, we can conclude that the difference between the two paired samples are significantly different.",
      "question": "How do you find the degrees of freedom for a t test"
    },
    {
      "answer": "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.  Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks.",
      "question": "What does batch normalization do"
    },
    {
      "answer": "Robust statistics are statistics with good performance for data drawn from a wide range of probability distributions, especially for distributions that are not normal. Robust statistical methods have been developed for many common problems, such as estimating location, scale, and regression parameters.",
      "question": "What does it mean robust in statistics"
    },
    {
      "answer": "So, for 10% error, you need 100 hash functions. For 1% error, you need 10,000 hash functions. Yick. That's friggin expensive, and if that's all there were to MinHash, I'd simply go with the O(n log(n)) algorithm.",
      "question": "How many hash functions are required in a minhash algorithm"
    },
    {
      "answer": "Genetic algorithms are important in machine learning for three reasons. First, they act on discrete spaces, where gradient-based methods cannot be used. They can be used to search rule sets, neural network architectures, cellular automata computers, and so forth.",
      "question": "Are genetic algorithms machine learning"
    },
    {
      "answer": "Given an image or a video stream, an object detection model can identify which of a known set of objects might be present and provide information about their positions within the image.",
      "question": "What is an object detection model"
    },
    {
      "answer": "Here are applications of Reinforcement Learning:Robotics for industrial automation.Business strategy planning.Machine learning and data processing.It helps you to create training systems that provide custom instruction and materials according to the requirement of students.Aircraft control and robot motion control.",
      "question": "What are the applications of reinforcement learning"
    },
    {
      "answer": "Definition: Stratified sampling is a type of sampling method in which the total population is divided into smaller groups or strata to complete the sampling process.  Stratified sampling is used when the researcher wants to understand the existing relationship between two groups.",
      "question": "What is meant by stratified sampling"
    },
    {
      "answer": "Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate (\"backtracks\") as soon as it determines that the candidate cannot possibly be completed to a",
      "question": "What is backtracking algorithm"
    },
    {
      "answer": "Micro-level adaptive instruction: The main feature of this approach is to utilize on-task rather than pre-task measurement to diagnose the students' learning behaviors and performance so as to adapt the instruction at the micro-level. Typical examples include one-on-one tutoring and intelligent tutoring systems.",
      "question": "Which is an example of adaptive instruction"
    },
    {
      "answer": "The distributional hypothesis in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings. The underlying idea that \"a word is characterized by the company it keeps\" was popularized by Firth in the 1950s.",
      "question": "What is distributional information"
    },
    {
      "answer": "The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.",
      "question": "How do you calculate false positives and negatives"
    },
    {
      "answer": "The input() function accepts an optional string argument called prompt and returns a string. Note that the input() function always returns a string even if you entered a number. To convert it to an integer you can use int() or eval() functions.",
      "question": "What is the datatype of the output for the function input ()"
    },
    {
      "answer": "Time series regression is a statistical method for predicting a future response based on the response history (known as autoregressive dynamics) and the transfer of dynamics from relevant predictors.  Time series regression is commonly used for modeling and forecasting of economic, financial, and biological systems.",
      "question": "What are some methods of time series regression analysis"
    },
    {
      "answer": "Bayesian hyperparameter tuning allows us to do so by building a probabilistic model for the objective function we are trying to minimize/maximize in order to train our machine learning model. Examples of such objective functions are not scary - accuracy, root mean squared error and so on.",
      "question": "What is Bayesian Hyperparameter optimization"
    },
    {
      "answer": "Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities.",
      "question": "What is modality in machine learning"
    },
    {
      "answer": "An operating system (OS) is a set of functions or programs that coordinate a user program's access to the computer's resources (i.e. memory and CPU).  These functions are called the MicroStamp11's kernel functions.",
      "question": "How kernel functions are called"
    },
    {
      "answer": "As regards the normality of group data, the one-way ANOVA can tolerate data that is non-normal (skewed or kurtotic distributions) with only a small effect on the Type I error rate. However, platykurtosis can have a profound effect when your group sizes are small.",
      "question": "Can you use Anova if data is not normally distributed"
    },
    {
      "answer": "Sample size refers to the number of participants or observations included in a study. This number is usually represented by n. The size of a sample influences two statistical properties: 1) the precision of our estimates and 2) the power of the study to draw conclusions.",
      "question": "What is sample and sample size"
    },
    {
      "answer": "Analysis of variance (ANOVA) is a statistical technique that is used to check if the means of two or more groups are significantly different from each other. ANOVA checks the impact of one or more factors by comparing the means of different samples.  Another measure to compare the samples is called a t-test.",
      "question": "How does Anova work in statistics"
    },
    {
      "answer": "\u2022 Model capacity is ability to fit variety of functions. \u2013 Model with Low capacity struggles to fit training set. \u2013 A High capacity model can overfit by memorizing. properties of training set not useful on test set. \u2022 When model has higher capacity, it overfits.",
      "question": "What is model capacity in machine learning"
    },
    {
      "answer": "A marginal distribution is the percentages out of totals, and conditional distribution is the percentages out of some column.  Conditional distribution, on the other hand, is the probability distribution of certain values in the table expressed as percentages out of sums (or local totals) of certain rows or columns.",
      "question": "What is marginal and conditional distribution"
    },
    {
      "answer": "communalities is calculated sum of square factor loadings. Generally, an item factor loading is recommended higher than 0.30 or 0.33 cut value. So if an item load only one factor its communality will be 0.30*0.30 = 0.09.",
      "question": "What is the cutoff for loading factors using factor analysis"
    },
    {
      "answer": "5. Image Processing Using Machine LearningFeature mapping using the scale-invariant feature transform (SIFT) algorithm.Image registration using the random sample consensus (RANSAC) algorithm.Image Classification using artificial neural networks.Image classification using convolutional neural networks (CNNs)Image Classification using machine learning.More items",
      "question": "How is image processing used in machine learning"
    },
    {
      "answer": "As the df increase, the chi square distribution approaches a normal distribution. The mean of a chi square distribution is its df. The mode is df - 2 and the median is approximately df - 0 .",
      "question": "How do you find the mode of a chi square distribution"
    },
    {
      "answer": "Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.",
      "question": "Which algorithm falls under unsupervised learning"
    },
    {
      "answer": "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.",
      "question": "Is matrix factorization collaborative filtering"
    },
    {
      "answer": "The theorem and its generalizations can be used to prove results and solve problems in combinatorics, algebra, calculus, and many other areas of mathematics. The binomial theorem also helps explore probability in an organized way: A friend says that she will flip a coin 5 times.",
      "question": "Why is the binomial theorem useful"
    },
    {
      "answer": "Linear least squares regression is by far the most widely used modeling method. It is what most people mean when they say they have used \"regression\", \"linear regression\" or \"least squares\" to fit a model to their data.",
      "question": "Is linear regression A least squares"
    },
    {
      "answer": "0:1110:28\u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u062d \u00b7 110 \u062b\u0627\u0646\u064a\u0629Lambda Measure of Association for Two Nominal Variables in SPSS YouTube\u0628\u062f\u0627\u064a\u0629 \u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u064e\u062d\u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0645\u0642\u0637\u0639 \u0627\u0644\u0645\u0642\u062a\u0631\u064e\u062d",
      "question": "How do you interpret lambda in SPSS"
    },
    {
      "answer": "A random variable can be either discrete (having specific values) or continuous (any value in a continuous range). The use of random variables is most common in probability and statistics, where they are used to quantify outcomes of random occurrences.",
      "question": "Why are statistics random variables"
    },
    {
      "answer": "KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.",
      "question": "Why do we use KNN algorithm"
    },
    {
      "answer": "A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process). For example, a gambler may be interested in whether a game of chance is fair.",
      "question": "What is a null hypothesis example"
    },
    {
      "answer": "Non-hierarchical clustering is frequently referred to as k-means clustering. This type of clustering does not require all possible distances to be computed in a large data set. This technique is primarily used for the analysis of clusters in data mining.",
      "question": "Is frequently referred to as K means clustering"
    },
    {
      "answer": "Artificial intelligence is generally divided into two types \u2013 narrow (or weak) AI and general AI, also known as AGI or strong AI.",
      "question": "What are the 2 types of AI"
    },
    {
      "answer": "The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero.",
      "question": "What is the purpose of Lasso regression"
    },
    {
      "answer": "In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.",
      "question": "When should we use hierarchical linear models"
    },
    {
      "answer": "The chief difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias problem, while CRFs are globally renormalized.",
      "question": "How do Conditional Random Fields CRF compare to Maximum Entropy Models and Hidden Markov Models"
    },
    {
      "answer": "Two different learning models were introduced that can be used as part of the word2vec approach to learn the word embedding; they are: Continuous Bag-of-Words, or CBOW model. Continuous Skip-Gram Model.",
      "question": "Which is the best model used in Word2Vec algorithm for word embedding"
    },
    {
      "answer": "Artificial intelligence (AI) is the attempt to let computers perform services for which humans need intelligence. However, this is still not possible today. AI systems are capable of recognizing patterns, learning and making decisions.",
      "question": "Is artificial intelligence intelligent"
    },
    {
      "answer": "A random effect model is a model all of whose factors represent random effects. (See Random Effects.) Such models are also called variance component models. Random effect models are often hierarchical models. A model that contains both fixed and random effects is called a mixed model.",
      "question": "What is random effect in mixed model"
    },
    {
      "answer": "Introduction Statistical discrete processes \u2013 for example, the number of accidents per driver, the number of insects per leaf in an orchard, the number of thunderstorms per year, the number of earthquakes per year, the number of patients visit emergency room in a certain hospital per day - often occur in real life.",
      "question": "What are uses of discrete distributions in real life"
    },
    {
      "answer": "Artificial Intelligence ExamplesManufacturing robots.Smart assistants.Proactive healthcare management.Disease mapping.Automated financial investing.Virtual travel booking agent.Social media monitoring.Inter-team chat tool.More items",
      "question": "What products use artificial intelligence"
    },
    {
      "answer": "The Kruskal-Wallis H test (sometimes also called the \"one-way ANOVA on ranks\") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable.",
      "question": "When Kruskal Wallis test is used"
    },
    {
      "answer": "R-squared is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.  After fitting a linear regression model, you need to determine how well the model fits the data.",
      "question": "What is r squared change in regression"
    },
    {
      "answer": "Perceptron Learning Rule states that the algorithm would automatically learn the optimal weight coefficients. The input features are then multiplied with these weights to determine if a neuron fires or not.",
      "question": "What do you mean by Perceptron and its learning rule"
    },
    {
      "answer": "Unlike the independent-samples t-test, the Mann-Whitney U test allows you to draw different conclusions about your data depending on the assumptions you make about your data's distribution.  These different conclusions hinge on the shape of the distributions of your data, which we explain more about later.",
      "question": "What is the difference between t test and Mann Whitney test"
    },
    {
      "answer": "Two disjoint events can never be independent, except in the case that one of the events is null.  Events are considered disjoint if they never occur at the same time. For example, being a freshman and being a sophomore would be considered disjoint events. Independent events are unrelated events.",
      "question": "Can two events be independent and disjoint"
    },
    {
      "answer": "Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.",
      "question": "What is the difference between interpolation and extrapolation"
    },
    {
      "answer": "The most popular is definitely KMP, if you need fast string matching without any particular usecase in mind it's what you should use. Here are your options(with time complexity): Brute Force O(nm) Knuth\u2013Morris\u2013Pratt algorithm - O(n)",
      "question": "Which is the best algorithm for checking string similarity metric"
    },
    {
      "answer": "To visualize a small data set containing multiple categorical (or qualitative) variables, you can create either a bar plot, a balloon plot or a mosaic plot.  These methods make it possible to analyze and visualize the association (i.e. correlation) between a large number of qualitative variables.",
      "question": "What is a recommended way to visualize categorical data"
    },
    {
      "answer": "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability.  By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",
      "question": "What is ROC AUC score"
    },
    {
      "answer": "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.",
      "question": "What is gradient boosting used for"
    },
    {
      "answer": "Random forest (RF) is a machine-learning method that generally works well with high-dimensional problems and allows for nonlinear relationships between predictors; however, the presence of correlated predictors has been shown to impact its ability to identify strong predictors.",
      "question": "Can random forest handle correlated variables"
    },
    {
      "answer": "So regression performance is measured by how close it fits an expected line/curve, while machine learning is measured by how good it can solve a certain problem, with whatever means necessary. I'll argue that the distinction between machine learning and statistical inference is clear.",
      "question": "What is the difference between machine learning and regression"
    },
    {
      "answer": "Abstract. Markov chain Monte Carlo (MCMC) is a simulation technique that can be used to find the posterior distribution and to sample from it. Thus, it is used to fit a model and to draw samples from the joint posterior distribution of the model parameters.  The software OpenBUGS and Stan are MCMC samplers.",
      "question": "What is Markov Chain Monte Carlo and why it matters"
    },
    {
      "answer": "When comparing two groups, you need to decide whether to use a paired test. When comparing three or more groups, the term paired is not apt and the term repeated measures is used instead. Use an unpaired test to compare groups when the individual values are not paired or matched with one another.",
      "question": "What statistical analysis should I use to compare two groups"
    },
    {
      "answer": "The Cox (proportional hazards or PH) model (Cox, 1972) is the most commonly used multivariate approach for analysing survival time data in medical research. It is a survival analysis regression model, which describes the relation between the event incidence, as expressed by the hazard function and a set of covariates.",
      "question": "What is multivariate Cox regression analysis"
    },
    {
      "answer": "To reduce variability we perform multiple rounds of cross-validation with different subsets from the same data. We combine the validation results from these multiple rounds to come up with an estimate of the model's predictive performance. Cross-validation will give us a more accurate estimate of a model's performance.",
      "question": "What does cross validation reduce"
    },
    {
      "answer": "It is a Markov random field. It was translated from statistical physics for use in cognitive science. The Boltzmann machine is based on stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model that is a stochastic Ising Model and applied to machine learning.",
      "question": "Is there a relation between Boltzmann machines and Markov random fields"
    },
    {
      "answer": "The null hypothesis is a general statement that states that there is no relationship between two phenomenons under consideration or that there is no association between two groups. An alternative hypothesis is a statement that describes that there is a relationship between two selected variables in a study.",
      "question": "What is the difference between null and alternative hypothesis"
    },
    {
      "answer": "In mathematics, a Fourier transform (FT) is a mathematical transform that decomposes a function (often a function of time, or a signal) into its constituent frequencies, such as the expression of a musical chord in terms of the volumes and frequencies of its constituent notes.",
      "question": "What does Fourier mean"
    },
    {
      "answer": "A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.",
      "question": "What is a probability distribution explain your answer"
    },
    {
      "answer": "The t-distribution cannot be calculated without a known standard deviation, while the standard normal distribution can be.",
      "question": "Which of the following is a difference between the T distribution and the standard normal Z distribution group of answer choices"
    },
    {
      "answer": "8:3417:13Suggested clip \u00b7 72 secondsStepwise regression procedures in SPSS (new, 2018) - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you interpret a stepwise regression analysis"
    },
    {
      "answer": "Abstract. Hidden Markov Models (HMMs) provide a simple and effective frame- work for modelling time-varying spectral vector sequences. As a con- sequence, almost all present day large vocabulary continuous speech recognition (LVCSR) systems are based on HMMs.",
      "question": "What is hidden Markov in speech recognition"
    },
    {
      "answer": "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error. The key idea is to set the target outcomes for this next model in order to minimize the error.",
      "question": "What is an intuitive explanation of Gradient Boosting"
    },
    {
      "answer": "k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.",
      "question": "What is the point of K means clustering"
    },
    {
      "answer": "Depending on the skill being taught, backward chaining has a distinct advantage: It directly links the independent completion of a task to the immediate reward or reinforcement. Once the child can complete the last step independently, he or she can work on also completing the next-to-last step independently.",
      "question": "What is an advantage of backward chaining"
    },
    {
      "answer": "For more tips, read 10 Best Practices for Effective Dashboards.Choose the right charts and graphs for the job.  Use predictable patterns for layouts.  Tell data stories quickly with clear color cues.  Incorporate contextual clues with shapes and designs.  Strategically use size to visualize values.More items",
      "question": "How do you visualize data effectively"
    },
    {
      "answer": "By using these midpoints as the categorical response values, the researcher can easily calculate averages. Granted, this average will only be an estimate or a \u201cballpark\u201d value but is still extremely useful for the purpose of data analysis.",
      "question": "Can you average categorical data"
    },
    {
      "answer": "The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.",
      "question": "What is back propagation in machine learning"
    },
    {
      "answer": "In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of successes (random draws for which the object drawn has a specified feature) in draws, without replacement, from a finite population of size that contains exactly objects with",
      "question": "What is a hypergeometric probability distribution"
    },
    {
      "answer": "Definition of outliers. An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.",
      "question": "What defines an outlier"
    },
    {
      "answer": "A statistic d is called an unbiased estimator for a function of the parameter g(\u03b8) provided that for every choice of \u03b8, E\u03b8d(X) = g(\u03b8). Any estimator that not unbiased is called biased. The bias is the difference bd(\u03b8) = E\u03b8d(X) \u2212 g(\u03b8). We can assess the quality of an estimator by computing its mean square error.",
      "question": "How do you calculate an unbiased estimator"
    },
    {
      "answer": "Standardized effect size statistics remove the units of the variables in the effect. The second type is simple. These statistics describe the size of the effect, but remain in the original units of the variables. So for example, say you're comparing the mean temperature of soil under two different conditions.",
      "question": "What is standardized effect"
    },
    {
      "answer": "A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is zero.  Non-square matrices (m-by-n matrices for which m \u2260 n) do not have an inverse. However, in some cases such a matrix may have a left inverse or right inverse.",
      "question": "What is non invertible matrix"
    },
    {
      "answer": "A data set can also be presented by means of a data frequency table, a table in which each distinct value is listed in the first row and its frequency, which is the number of times the value appears in the data set, is listed below it in the second row.",
      "question": "What is data frequency table"
    },
    {
      "answer": "Factor Analysis (FA) is an exploratory technique applied to a set of outcome variables that seeks to find the underlying factors (or subsets of variables) from which the observed variables were generated.",
      "question": "What is factor analysis in multivariate analysis"
    },
    {
      "answer": "There are different types of mean, viz. arithmetic mean, weighted mean, geometric mean (GM) and harmonic mean (HM). If mentioned without an adjective (as mean), it generally refers to the arithmetic mean.",
      "question": "How many types of mean in statistics"
    },
    {
      "answer": "The squared error has some nice properties: It is symmetrical. That means, if the actual value is and you predict or , you get the same error measure.",
      "question": "Why we take SSE sum of square error and RMSE root mean square error"
    },
    {
      "answer": "Low-shot learning deep learning is based on the concept that reliable algorithms can be created to make predictions from minimalist datasets.",
      "question": "What is low shot learning"
    },
    {
      "answer": "Weights(Parameters) \u2014 A weight represent the strength of the connection between units. If the weight from node 1 to node 2 has greater magnitude, it means that neuron 1 has greater influence over neuron 2. A weight brings down the importance of the input value.",
      "question": "Why weight is used in neural network"
    },
    {
      "answer": "Multi-class Classification using Decision Tree, Random Forest and Extra Trees Algorithm in Python: An End-To-End Data Science Recipe \u2014 016. a) Different types of Machine Learning problems.  i) How to implement Decision Tree, Random Forest and Extra Tree Algorithms for Multiclass Classification in Python.",
      "question": "Can random forest be used for multiclass classification"
    },
    {
      "answer": "Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.",
      "question": "What are decision trees commonly used for"
    },
    {
      "answer": "This is the basis of the Breusch\u2013Pagan test. It is a chi-squared test: the test statistic is distributed n\u03c72 with k degrees of freedom. If the test statistic has a p-value below an appropriate threshold (e.g. p < 0.05) then the null hypothesis of homoskedasticity is rejected and heteroskedasticity assumed.",
      "question": "What is the null hypothesis for Heteroskedasticity"
    },
    {
      "answer": "There are various ways to modify a study design to actively exclude or control confounding variables (3) including Randomization, Restriction and Matching. In randomization the random assignment of study subjects to exposure categories to breaking any links between exposure and confounders.",
      "question": "How do you deal with confounders within a statistical study"
    },
    {
      "answer": "In an upper-tailed test the decision rule has investigators reject H0 if the test statistic is larger than the critical value. In a lower-tailed test the decision rule has investigators reject H0 if the test statistic is smaller than the critical value.",
      "question": "How do you know if its a lower or upper tailed test"
    },
    {
      "answer": "The quality loss function as defined by Taguchi is the loss imparted to the society by the product from the time the product is designed to the time it is shipped to the customer. In fact, he defined quality as the conformity around a target value with a lower standard deviation in the outputs.",
      "question": "What is Taguchi quality loss function"
    },
    {
      "answer": "A mode of a continuous probability distribution is often considered to be any value x at which its probability density function has a locally maximum value, so any peak is a mode. In symmetric unimodal distributions, such as the normal distribution, the mean (if defined), median and mode all coincide.",
      "question": "What is the mode of a continuous random variable"
    },
    {
      "answer": "Achieving translation invariance in Convolutional NNs: Then the max pooling layer takes the output from the convolutional layer and reduces its resolution and complexity. It does so by outputting only the max value from a grid.So the information about the exact position of the max value in the grid is discarded.",
      "question": "How exactly does max pooling create translation invariance"
    },
    {
      "answer": "7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.",
      "question": "How do you handle an unbalanced data set"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean.  SD is the dispersion of individual data values.",
      "question": "What does standard deviation of the mean represent"
    },
    {
      "answer": "How to Handle Imbalanced DatasetChange the evaluation matrix. If we apply the wrong evaluation matrix on the imbalanced dataset, it can give us misleading results.  Resample the dataset. Resample means to change the distribution of the imbalance classes in the dataset.  Change the algorithm and approach to the problem.",
      "question": "How do you handle an imbalanced data set"
    },
    {
      "answer": "The cumulative distribution function (CDF) calculates the cumulative probability for a given x-value. Use the CDF to determine the probability that a random observation that is taken from the population will be less than or equal to a certain value.",
      "question": "What is the use of cumulative distribution function"
    },
    {
      "answer": "So, for example, if our random variable were the number obtained by rolling a fair 3-sided die, the expected value would be (1 * 1/3) + (2 * 1/3) + (3 * 1/3) = 2.",
      "question": "How do you find the expected value example"
    },
    {
      "answer": "Decision theory is the science of making optimal decisions in the face of uncertainty. Statistical decision theory is concerned with the making of decisions when in the presence of statistical knowledge (data) which sheds light on some of the uncertainties involved in the decision problem.",
      "question": "What is decision theory in statistics"
    },
    {
      "answer": "The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data.",
      "question": "What does Akaike information criterion mean"
    },
    {
      "answer": "Though the name is a mouthful, the concept behind this is very simple. To tell briefly, LDA imagines a fixed set of topics. Each topic represents a set of words. And the goal of LDA is to map all the documents to the topics in a way, such that the words in each document are mostly captured by those imaginary topics.",
      "question": "How does LDA algorithm work"
    },
    {
      "answer": "Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.",
      "question": "What is validation machine learning"
    },
    {
      "answer": "Cost function(J) of Linear Regression is the Root Mean Squared Error (RMSE) between predicted y value (pred) and true y value (y). Gradient Descent: To update \u03b81 and \u03b82 values in order to reduce Cost function (minimizing RMSE value) and achieving the best fit line the model uses Gradient Descent.",
      "question": "What is a cost function in linear regression"
    },
    {
      "answer": "Vector space model or term vector model is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, such as, for example, index terms.  The model is used to represent documents in an n-dimensional space. But a \u201cdocument\u201d can mean any object you're trying to model.",
      "question": "What is vector space in machine learning"
    },
    {
      "answer": "Decision Tree - Overfitting There are several approaches to avoiding overfitting in building decision trees. Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set. Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree.",
      "question": "What is pre pruning and post pruning in decision tree"
    },
    {
      "answer": "The 7 Steps of Machine Learning1 - Data Collection.2 - Data Preparation.3 - Choose a Model.4 - Train the Model.5 - Evaluate the Model.6 - Parameter Tuning.7 - Make Predictions.More items",
      "question": "What are the correct steps of a machine learning process"
    },
    {
      "answer": "gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set gammas = [0.1, 1, 10, 100]for gamma in gammas: svc = svm.SVC(kernel='rbf', gamma=gamma).fit(X, y)",
      "question": "What is Gamma in SVC"
    },
    {
      "answer": "The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.",
      "question": "When should I use weighted kappa"
    },
    {
      "answer": "Taking the square root of the variance gives us the units used in the original scale and this is the standard deviation. Standard deviation is the measure of spread most commonly used in statistical practice when the mean is used to calculate central tendency. Thus, it measures spread around the mean.",
      "question": "Where do we use standard deviation and variance"
    },
    {
      "answer": "The generator is a convolutional neural network and the discriminator is a deconvolutional neural network. The goal of the generator is to artificially manufacture outputs that could easily be mistaken for real data. The goal of the discriminator is to identify which outputs it receives have been artificially created.",
      "question": "What is the goal of a generative adversarial network GAN )"
    },
    {
      "answer": "If the outcomes are mutually independent, then yes the method is valid. If the outcomes are mutually exclusive, then no, the method is not valid. It's easy to see why this is the case. If you have three binary models, then the sum of the outcomes do not necessarily sum to one.",
      "question": "Can you split a multinomial logistic regression model into separate binary logistic regression models"
    },
    {
      "answer": "Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them.",
      "question": "What is correlation and autocorrelation"
    },
    {
      "answer": "Choosing the right Activation FunctionSigmoid functions and their combinations generally work better in the case of classifiers.Sigmoids and tanh functions are sometimes avoided due to the vanishing gradient problem.ReLU function is a general activation function and is used in most cases these days.More items\u2022",
      "question": "What is the activation function used for"
    },
    {
      "answer": "Information provides a way to quantify the amount of surprise for an event measured in bits. Entropy provides a measure of the average amount of information needed to represent an event drawn from a probability distribution for a random variable.",
      "question": "Why is information entropy"
    },
    {
      "answer": "While the returns for stocks usually have a normal distribution, the stock price itself is often log-normally distributed. This is because extreme moves become less likely as the stock's price approaches zero.",
      "question": "Why do prices and income follow a log normal distribution"
    },
    {
      "answer": "Response bias can be defined as the difference between the true values of variables in a study's net sample group and the values of variables obtained in the results of the same study.  Nonresponse bias occurs when some respondents included in the sample do not respond.",
      "question": "What is the difference between nonresponse and response bias"
    },
    {
      "answer": "Linear means something related to a line.  A non-linear equation is such which does not form a straight line. It looks like a curve in a graph and has a variable slope value. The major difference between linear and nonlinear equations is given here for the students to understand it in a more natural way.",
      "question": "What is the difference between linear and nonlinear association"
    },
    {
      "answer": "The 5 main steps to create word clouds in RStep 1: Create a text file.  Step 2 : Install and load the required packages.  Step 3 : Text mining.  Step 4 : Build a term-document matrix.  Step 5 : Generate the Word cloud.",
      "question": "How do I use text mining in R"
    },
    {
      "answer": "5 Most Important Methods For Statistical Data AnalysisMean. The arithmetic mean, more commonly known as \u201cthe average,\u201d is the sum of a list of numbers divided by the number of items on the list.  Standard Deviation.  Regression.  Sample Size Determination.  Hypothesis Testing.",
      "question": "What is the best statistical analysis technique"
    },
    {
      "answer": "Big data is a big deal. From reducing their costs and making better decisions, to creating products and services that are in demand by customers, businesses will increasingly benefit by using big-data analytics.",
      "question": "What's the big deal about Big Data"
    },
    {
      "answer": "recursion",
      "question": "Which search method is used in Minimax algorithm"
    },
    {
      "answer": "Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels.  A non-linear filtering is one that cannot be done with convolution or Fourier multiplication. A sliding median filter is a simple example of a non-linear filter.",
      "question": "What is the difference between linear and nonlinear filters"
    },
    {
      "answer": "Linear regression quantifies the relationship between one or more predictor variable(s) and one outcome variable.  For example, it can be used to quantify the relative impacts of age, gender, and diet (the predictor variables) on height (the outcome variable).",
      "question": "What is regression example"
    },
    {
      "answer": "For skewed distributions, it is quite common to have one tail of the distribution considerably longer or drawn out relative to the other tail. A \"skewed right\" distribution is one in which the tail is on the right side. A \"skewed left\" distribution is one in which the tail is on the left side.",
      "question": "What does a left skewed distribution mean"
    },
    {
      "answer": "Pearson's product moment correlation coefficient (r) is given as a measure of linear association between the two variables: r\u00b2 is the proportion of the total variance (s\u00b2) of Y that can be explained by the linear regression of Y on x. 1-r\u00b2 is the proportion that is not explained by the regression.",
      "question": "What is the correlation coefficient in a linear regression"
    },
    {
      "answer": "Investment risk is the idea that an investment will not perform as expected, that its actual return will deviate from the expected return. Risk is measured by the amount of volatility, that is, the difference between actual returns and average (expected) returns.",
      "question": "How do you measure risk and return"
    },
    {
      "answer": "The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.",
      "question": "What is an example of probability distribution"
    },
    {
      "answer": "Binary Search: Search a sorted array by repeatedly dividing the search interval in half. Begin with an interval covering the whole array. If the value of the search key is less than the item in the middle of the interval, narrow the interval to the lower half.",
      "question": "How do you perform a binary search"
    },
    {
      "answer": "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.",
      "question": "What s so special about rectified linear units ReLU activation function"
    },
    {
      "answer": "Typically, a regression analysis is done for one of two purposes: In order to predict the value of the dependent variable for individuals for whom some information concerning the explanatory variables is available, or in order to estimate the effect of some explanatory variable on the dependent variable.",
      "question": "What is the purpose of a regression model"
    },
    {
      "answer": "T-test. A t-test is used to compare the mean of two given samples. Like a z-test, a t-test also assumes a normal distribution of the sample. A t-test is used when the population parameters (mean and standard deviation) are not known.",
      "question": "Is at test a statistical test"
    },
    {
      "answer": "Replaces an image by the norm of its gradient, as estimated by discrete filters. The Raw filter of the detail panel designates two filters that correspond to the two components of the gradient in the principal directions.",
      "question": "What is a gradient norm"
    },
    {
      "answer": "The amount that the weights are updated during training is referred to as the step size or the \u201clearning rate.\u201d Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0.",
      "question": "What is step size in machine learning"
    },
    {
      "answer": "Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron.",
      "question": "What is the role of the activation function in a neural network How does this function in a human neural network system"
    },
    {
      "answer": "Dimensionality reduction is the process of reducing the number of random variables or attributes under consideration. High-dimensionality data reduction, as part of a data pre-processing-step, is extremely important in many real-world applications.",
      "question": "What is the need of dimensionality reduction in data mining"
    },
    {
      "answer": "Your classifier would have learned an equal an opposite rule, with the same performance and same AUC / ROC curve.",
      "question": "What will happen to AUC if I switch the positive and negative classes in the test data"
    },
    {
      "answer": "Posterior probability = prior probability + new evidence (called likelihood). For example, historical data suggests that around 60% of students who start college will graduate within 6 years. This is the prior probability. However, you think that figure is actually much lower, so set out to collect new data.",
      "question": "What is posterior probability example"
    },
    {
      "answer": "It depends on the data you want and the project you're doing. You could use even your twitter data for sentiment analysis. Request your archive in twitter -> download -> analyse sentiment through supervised learning techniques.",
      "question": "Where can one find a training set for sentiment analysis"
    },
    {
      "answer": "Random assignment helps reduce the chances of systematic differences between the groups at the start of an experiment and, thereby, mitigates the threats of confounding variables and alternative explanations. However, the process does not always equalize all of the confounding variables.",
      "question": "How does random assignment control for confounding variables"
    },
    {
      "answer": "In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.",
      "question": "What is map in ML"
    },
    {
      "answer": "The size of the sample space is the total number of possible outcomes. For example, when you roll 1 die, the sample space is 1, 2, 3, 4, 5, or 6. So the size of the sample space is 6.",
      "question": "How do you find the sample space"
    },
    {
      "answer": "Some of my suggestions to you would be:Feature Scaling and/or Normalization - Check the scales of your gre and gpa features.  Class Imbalance - Look for class imbalance in your data.  Optimize other scores - You can optimize on other metrics also such as Log Loss and F1-Score.More items",
      "question": "How can you improve the accuracy of a logistic regression model in python"
    },
    {
      "answer": "The k-means problem is finding the least-squares assignment to centroids. There are multiple algorithms for finding a solution. There is an obvious approach to find the global optimum: enumerating all k^n possible assignments - that will yield a global minimum, but in exponential runtime.",
      "question": "How do you get global minima in K means algorithm"
    },
    {
      "answer": "If a p-value is lower than our significance level, we reject the null hypothesis. If not, we fail to reject the null hypothesis.",
      "question": "What happens when the p value is lower than the level of significance"
    },
    {
      "answer": "1:314:30Suggested clip \u00b7 120 secondsCumulative Frequency Distribution (Less than and More than YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you construct a less than cumulative frequency distribution"
    },
    {
      "answer": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.",
      "question": "Is AI all about simulating human intelligence"
    },
    {
      "answer": "For the vanishing gradient problem, the further you go through the network, the lower your gradient is and the harder it is to train the weights, which has a domino effect on all of the further weights throughout the network. That was the main roadblock to using Recurrent Neural Networks.",
      "question": "What is vanishing gradient problem in RNN"
    },
    {
      "answer": "Hypothesis Tests of the Mean and MedianParametric tests (means)Nonparametric tests (medians)1-sample t test1-sample Sign, 1-sample Wilcoxon2-sample t testMann-Whitney testOne-Way ANOVAKruskal-Wallis, Mood's median testFactorial DOE with one factor and one blocking variableFriedman test",
      "question": "What are the different types of parametric tests"
    },
    {
      "answer": "Simple linear regression relates X to Y through an equation of the form Y = a + bX. Both quantify the direction and strength of the relationship between two numeric variables.  The correlation squared (r2 or R2) has special meaning in simple linear regression.",
      "question": "Does linear regression show correlation"
    },
    {
      "answer": "In statistics, the likelihood function (often simply called the likelihood) measures the goodness of fit of a statistical model to a sample of data for given values of the unknown parameters.",
      "question": "What does likelihood mean in statistics"
    },
    {
      "answer": "If you're given the probability (percent) greater than x and you need to find x, you translate this as: Find b where p(X > b) = p (and p is given). Rewrite this as a percentile (less-than) problem: Find b where p(X < b) = 1 \u2013 p. This means find the (1 \u2013 p)th percentile for X.",
      "question": "How do you find the percentile under the normal curve"
    },
    {
      "answer": "Two examples of common independent variables are age and time.  They're independent of everything else. The dependent variable (sometimes known as the responding variable) is what is being studied and measured in the experiment. It's what changes as a result of the changes to the independent variable.",
      "question": "What is an independent variable example"
    },
    {
      "answer": "A decision tree is a flowchart-like diagram that shows the various outcomes from a series of decisions. It can be used as a decision-making tool, for research analysis, or for planning strategy. A primary advantage for using a decision tree is that it is easy to follow and understand.",
      "question": "What is decision tree diagram"
    },
    {
      "answer": "Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.",
      "question": "What is Homoscedasticity in regression analysis"
    },
    {
      "answer": "The universe is considered an isolated system because the energy of the universe is constant. This matches with the definition of an isolated system, which is that energy is not exchanged with the surroundings, thus staying constant.",
      "question": "Is the universe an isolated system"
    },
    {
      "answer": "Simple Linear Regression Math by HandCalculate average of your X variable.Calculate the difference between each X and the average X.Square the differences and add it all up.  Calculate average of your Y variable.Multiply the differences (of X and Y from their respective averages) and add them all together.More items",
      "question": "How do you calculate linear regression by hand"
    },
    {
      "answer": "Bayesian analysis is a statistical paradigm that answers research questions about unknown parameters using probability statements.",
      "question": "What is the purpose of Bayesian analysis"
    },
    {
      "answer": "Reliability refers to the extent that the instrument yields the same results over multiple trials. Validity refers to the extent that the instrument measures what it was designed to measure.  Construct validity uses statistical analyses, such as correlations, to verify the relevance of the questions.",
      "question": "What is validity and reliability in statistics"
    },
    {
      "answer": "1:246:12Suggested clip \u00b7 104 secondsBuilding Statistical Models - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you make a statistical model"
    },
    {
      "answer": "Naive Bayes classifier (Russell, & Norvig, 1995) is another feature-based supervised learning algorithm. It was originally intended to be used for classification tasks, but with some modifications it can be used for regression as well (Frank, Trigg, Holmes, & Witten, 2000) .",
      "question": "Can naive Bayes be used for regression"
    },
    {
      "answer": "As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.",
      "question": "How do you find the standardized score"
    },
    {
      "answer": "12 Tips to boost your multitasking skillsAccept your limits. To better manage task organization, be aware of your limits, especially those you can't control.  Distinguish urgent from important.  Learn to concentrate.  Avoid distractions.  Work in blocks of time.  Work on related tasks together.  Learn to supervise.  Plan ahead.More items\u2022",
      "question": "How can I learn multitasking"
    },
    {
      "answer": "How to conduct a multivariate testIdentify a problem.  Formulate a hypothesis.  Create variations.  Determine your sample size.  Test your tools.  Start driving traffic.  Analyze your results.  Learn from your results.",
      "question": "How do you do a multivariate test"
    },
    {
      "answer": "A subquery is a select statement that is embedded in a clause of another select statement.  A Correlated subquery is a subquery that is evaluated once for each row processed by the outer query or main query.",
      "question": "What is the difference between subquery and correlated query"
    },
    {
      "answer": "Look at normality plots of the data. \u201cNormal Q-Q Plot\u201d provides a graphical way to determine the level of normality. The black line indicates the values your sample should adhere to if the distribution was normal.  If the dots fall exactly on the black line, then your data are normal.",
      "question": "How do you know if your data is normally distributed"
    },
    {
      "answer": "A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.",
      "question": "Why is the pooling layer used in CNN"
    },
    {
      "answer": "How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "How does logistic regression deal with Multicollinearity"
    },
    {
      "answer": "Derivative RulesCommon FunctionsFunctionDerivativeSquarex22xSquare Root\u221ax(\u00bd)x-\u00bdExponentialexexaxln(a) ax24 more rows",
      "question": "What is the derivative of E X"
    },
    {
      "answer": "In exploratory studies, p-values enable the recognition of any statistically noteworthy findings. Confidence intervals provide information about a range in which the true value lies with a certain degree of probability, as well as about the direction and strength of the demonstrated effect.",
      "question": "What is the difference between P value and confidence interval"
    },
    {
      "answer": "In the design of experiments and analysis of variance, a main effect is the effect of an independent variable on a dependent variable averaged across the levels of any other independent variables.  Main effects are essentially the overall effect of a factor.",
      "question": "What do main effects mean in Anova"
    },
    {
      "answer": "A function that represents a discrete probability distribution is called a probability mass function. A function that represents a continuous probability distribution is called a probability density function. Functions that represent probability distributions still have to obey the rules of probability.",
      "question": "What is the difference between probability density function and probability distribution function"
    },
    {
      "answer": "Similar to the distinction in philosophy between a priori and a posteriori, in Bayesian inference a priori denotes general knowledge about the data distribution before making an inference, while a posteriori denotes knowledge that incorporates the results of making an inference.",
      "question": "What is the difference between a priori and a posteriori probability"
    },
    {
      "answer": "This learning process is independent.  During the training of ANN under unsupervised learning, the input vectors of similar type are combined to form clusters. When a new input pattern is applied, then the neural network gives an output response indicating the class to which input pattern belongs.",
      "question": "What is unsupervised learning in neural network"
    },
    {
      "answer": "Critic Loss: D(x) - D(G(z)) The discriminator tries to maximize this function. In other words, it tries to maximize the difference between its output on real instances and its output on fake instances.",
      "question": "What is discriminator loss"
    },
    {
      "answer": "Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.",
      "question": "What do you mean by tensor"
    },
    {
      "answer": "The task of object localization is to predict the object in an image as well as its boundaries.  Simply, object localization aims to locate the main (or most visible) object in an image while object detection tries to find out all the objects and their boundaries.",
      "question": "What is localization in image processing"
    },
    {
      "answer": "Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph. How sent_tokenize works ? The sent_tokenize function uses an instance of PunktSentenceTokenizer from the nltk.",
      "question": "How does NLTK sentence Tokenizer work"
    },
    {
      "answer": "The best fit line is the one that minimises sum of squared differences between actual and estimated results. Taking average of minimum sum of squared difference is known as Mean Squared Error (MSE). Smaller the value, better the regression model.",
      "question": "How do you tell if a regression model is a good fit"
    },
    {
      "answer": "The cross-entropy compares the model's prediction with the label which is the true probability distribution. The cross-entropy goes down as the prediction gets more and more accurate. It becomes zero if the prediction is perfect. As such, the cross-entropy can be a loss function to train a classification model.",
      "question": "How does cross entropy work"
    },
    {
      "answer": "The Machine Learning algorithms that require the feature scaling are mostly KNN (K-Nearest Neighbours), Neural Networks, Linear Regression, and Logistic Regression.",
      "question": "Which machine learning algorithms require feature scaling"
    },
    {
      "answer": "Definition. Inter-rater reliability is the extent to which two or more raters (or observers, coders, examiners) agree. It addresses the issue of consistency of the implementation of a rating system. Inter-rater reliability can be evaluated by using a number of different statistics.",
      "question": "What does Inter rater mean"
    },
    {
      "answer": "Events A and B are independent if the equation P(A\u2229B) = P(A) \u00b7 P(B) holds true. You can use the equation to check if events are independent; multiply the probabilities of the two events together to see if they equal the probability of them both happening together.",
      "question": "How do you know if something is independent in probability"
    },
    {
      "answer": "An indicator random variable is a special kind of random variable associated with the occurence of an event. The indicator random variable IA associated with event A has value 1 if event A occurs and has value 0 otherwise. In other words, IA maps all outcomes in the set A to 1 and all outcomes outside A to 0.",
      "question": "What is an indicator random variable"
    },
    {
      "answer": "The coefficient of variation is a better risk measure than the standard deviation alone because the CV adjusts for the size of the project. The CV measures the standard deviation divided by the mean and therefore puts the standard deviation into context.",
      "question": "Why is the coefficient of variation a better risk measure to"
    },
    {
      "answer": "1 \u2014 Linear Regression.  2 \u2014 Logistic Regression.  3 \u2014 Linear Discriminant Analysis.  4 \u2014 Classification and Regression Trees.  5 \u2014 Naive Bayes.  6 \u2014 K-Nearest Neighbors.  7 \u2014 Learning Vector Quantization.  8 \u2014 Support Vector Machines.More items\u2022",
      "question": "Which classification algorithms is easiest to start with for prediction"
    },
    {
      "answer": "A feature selection method is proposed to select a subset of variables in principal component analysis (PCA) that preserves as much information present in the complete data as possible. The information is measured by means of the percentage of consensus in generalised Procrustes analysis.",
      "question": "How Principal component analysis is used for feature selection"
    },
    {
      "answer": "The task boils down to computing the distance between two face vectors. As such, appropriate distance metrics are essential for face verification accuracy.  The use of cosine similarity in our method leads to an effective learning algorithm which can improve the generalization ability of any given metric.",
      "question": "Why does face verification identification usally use cosine similarity"
    },
    {
      "answer": "When dealing with Machine Learning models, it is usually recommended that you store them somewhere. At the private sector, you oftentimes train them and store them before production, while in research and for future model tuning it is a good idea to store them locally.",
      "question": "Where are machine learning models stored"
    },
    {
      "answer": "Logistic regression is a classification algorithm traditionally limited to only two-class classification problems. If you have more than two classes then Linear Discriminant Analysis is the preferred linear classification technique.",
      "question": "Is linear discriminant analysis machine learning"
    },
    {
      "answer": "A significant result indicates that your data are significantly heteroscedastic, and thus the assumption of homoscedasticity in the regression residuals is violated. In your case the data violate the assumption of homoscedasticity, as your p value is 8.6\u22c510\u221228. The e is standard scientific notation for powers of 10.",
      "question": "What is E in P value"
    },
    {
      "answer": "A latent variable is a variable that cannot be observed. The presence of latent variables, however, can be detected by their effects on variables that are observable. Most constructs in research are latent variables.  Because measurement error is by definition unique variance, it is not captured in the latent variable.",
      "question": "What is the meaning of latent variable"
    },
    {
      "answer": "ANOVA is used to compare and contrast the means of two or more populations. ANCOVA is used to compare one variable in two or more populations while considering other variables.",
      "question": "Why we use Ancova instead of Anova"
    },
    {
      "answer": "The ith order statistic of a set of n elements is the ith smallest element. For example, the minimum of a set of elements is the first order statistic (i = 1), and the maximum is the nth order statistic (i = n). A median, informally, is the \"halfway point\" of the set.",
      "question": "What is the ith order statistic"
    },
    {
      "answer": "Convolution neural network is a type of neural network which has some or all convolution layers. Feed forward neural network is a network which is not recursive. neurons in this layer were only connected to neurons in the next layer.  neurons in this layer were only connected to neurons in the next layer.",
      "question": "What are the differences between a convolutional network and a feedforward neural network"
    },
    {
      "answer": "Markov chains are an important concept in stochastic processes. They can be used to greatly simplify processes that satisfy the Markov property, namely that the future state of a stochastic variable is only dependent on its present state.",
      "question": "What is the use of Markov chain"
    },
    {
      "answer": "Conditional Random Fields (CRF) CRF is a discriminant model for sequences data similar to MEMM. It models the dependency between each state and the entire input sequences. Unlike MEMM, CRF overcomes the label bias issue by using global normalizer.",
      "question": "What is CRF NLP"
    },
    {
      "answer": "68% of the data is within 1 standard deviation (\u03c3) of the mean (\u03bc), 95% of the data is within 2 standard deviations (\u03c3) of the mean (\u03bc), and 99.7% of the data is within 3 standard deviations (\u03c3) of the mean (\u03bc).",
      "question": "What is 2 standard deviations from the mean"
    },
    {
      "answer": "In scikit-learn we can use the CalibratedClassifierCV class to create well calibrated predicted probabilities using k-fold cross-validation.  In CalibratedClassifierCV the training sets are used to train the model and the test sets is used to calibrate the predicted probabilities.",
      "question": "What is CalibratedClassifierCV"
    },
    {
      "answer": "Different classifiers are then added on top of this feature extractor to classify images.Support Vector Machines. It is a supervised machine learning algorithm used for both regression and classification problems.  Decision Trees.  K Nearest Neighbor.  Artificial Neural Networks.  Convolutional Neural Networks.",
      "question": "How do you classify images in machine learning"
    },
    {
      "answer": "The AUC value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an excellent classifier.",
      "question": "What is a good ROC score"
    },
    {
      "answer": "Data for two variables (usually two types of related data). Example: Ice cream sales versus the temperature on that day. The two variables are Ice Cream Sales and Temperature.",
      "question": "What are some examples of bivariate data"
    },
    {
      "answer": "Statement of the Multiplication Rule In order to use the rule, we need to have the probabilities of each of the independent events. Given these events, the multiplication rule states the probability that both events occur is found by multiplying the probabilities of each event.",
      "question": "Do you multiply independent events probability"
    },
    {
      "answer": "Findings. A fundamental problem with stepwise regression is that some real explanatory variables that have causal effects on the dependent variable may happen to not be statistically significant, while nuisance variables may be coincidentally significant.",
      "question": "What is wrong with stepwise regression"
    },
    {
      "answer": "Gradient Boosting or GBM is another ensemble machine learning algorithm that works for both regression and classification problems. GBM uses the boosting technique, combining a number of weak learners to form a strong learner.  We will use a simple example to understand the GBM algorithm.",
      "question": "What are different ensemble learning algorithms"
    },
    {
      "answer": "The mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or overall IoU thresholds, depending on different detection challenges that exist. In PASCAL VOC2007 challenge, AP for one object class is calculated for an IoU threshold of 0.5.",
      "question": "How do you calculate average precision score"
    },
    {
      "answer": "Interpolation is making an educated guess with the information within a certain data set. It is a \u201cbest guess\u201d using the information you have at hand.",
      "question": "What is interpolation in machine learning"
    },
    {
      "answer": "Unsupervised learning uses the entire dataset for the supervised training process. In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.  In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.",
      "question": "What is the difference between self supervised and unsupervised learning"
    },
    {
      "answer": "A matrix A is symmetric if it is equal to its transpose, i.e., A=AT. A matrix A is symmetric if and only if swapping indices doesn't change its components, i.e., aij=aji.",
      "question": "What makes a matrix symmetric"
    },
    {
      "answer": "A kind of average sometimes used in statistics and engineering, often abbreviated as RMS. To find the root mean square of a set of numbers, square all the numbers in the set and then find the arithmetic mean of the squares. Take the square root of the result. This is the root mean square.",
      "question": "How is root mean square calculated"
    },
    {
      "answer": "Probit regression, also called a probit model, is used to model dichotomous or binary outcome variables. In the probit model, the inverse standard normal distribution of the probability is modeled as a linear combination of the predictors.",
      "question": "What is probit regression used for"
    },
    {
      "answer": "4.1 Input Layer Input layer in CNN should contain image data. Image data is represented by three dimensional matrix as we saw earlier. You need to reshape it into a single column.  If you have \u201cm\u201d training examples then dimension of input will be (784, m).",
      "question": "What is input layer in CNN"
    },
    {
      "answer": "Because neural networks work internally with numeric data, binary data (such as sex, which can be male or female) and categorical data (such as a community, which can be suburban, city or rural) must be encoded in numeric form.",
      "question": "Can neural network handle categorical data"
    },
    {
      "answer": "Variance of estimator: Variance is one of the most popularly used measures of spread. It is taken into consideration for quantification of the amount of dispersion with respect to set of data values. Variance is defined as the average of the squared deviation of each observation from its mean.",
      "question": "What is the variance of the estimator"
    },
    {
      "answer": "How It Works. Connected component labeling works by scanning an image, pixel-by-pixel (from top to bottom and left to right) in order to identify connected pixel regions, i.e. regions of adjacent pixels which share the same set of intensity values V.",
      "question": "How does connected component image labeling work on colored images"
    },
    {
      "answer": "The variance is the average of the sum of squares (i.e., the sum of squares divided by the number of observations). The standard deviation is the square root of the variance.",
      "question": "How do you find the variance of a sum of squares"
    },
    {
      "answer": "Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. Improving operations. Many companies use predictive models to forecast inventory and manage resources.",
      "question": "How are predictive analytics commonly used"
    },
    {
      "answer": "Machine learning is perhaps the principal technology behind two emerging domains: data science and artificial intelligence. The rise of machine learning is coming about through the availability of data and computation, but machine learning methdologies are fundamentally dependent on models.",
      "question": "What are the domains of machine learning"
    },
    {
      "answer": "The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.",
      "question": "How do you determine the size of a hidden layer"
    },
    {
      "answer": "Blocking refers to classifying experimental units into blocks whereas stratification refers to classifying individuals of a population into strata. The samples from the strata in a stratified random sample can be the blocks in an experiment.",
      "question": "What is the difference between blocking and stratification"
    },
    {
      "answer": "It is well known that maximum likelihood estimators are often biased, and it is of use to estimate the expected bias so that we can reduce the mean square errors of our parameter estimates.  In both problems, the first-order bias is found to be linear in the parameter and the sample size.",
      "question": "Is maximum likelihood estimator biased"
    },
    {
      "answer": "Rather than trying to define a number, instead define what a field of numbers is; instead of defining what a vector is, consider instead all the vectors that make up a vector space. So to understand tensors of a particular type, instead consider all those tensors of the same type together.",
      "question": "What is a good way to understand tensors"
    },
    {
      "answer": "Bayes Theorem for Modeling Hypotheses. Bayes Theorem is a useful tool in applied machine learning. It provides a way of thinking about the relationship between data and a model. A machine learning algorithm or model is a specific way of thinking about the structured relationships in the data.",
      "question": "How Bayes theorem is applied in machine learning"
    },
    {
      "answer": "The WordNet is a part of Python's Natural Language Toolkit. It is a large word database of English Nouns, Adjectives, Adverbs and Verbs. These are grouped into some set of cognitive synonyms, which are called synsets.  In the wordnet, there are some groups of words, whose meaning are same.",
      "question": "What is NLTK WordNet"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What are the differences between supervised and unsupervised classification"
    },
    {
      "answer": "Hypergeometric Formula.. The hypergeometric distribution has the following properties: The mean of the distribution is equal to n * k / N . The variance is n * k * ( N - k ) * ( N - n ) / [ N2 * ( N - 1 ) ] .",
      "question": "What is the formula for hypergeometric distribution"
    },
    {
      "answer": "Finally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset. If the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.",
      "question": "Why is test data set used"
    },
    {
      "answer": "The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.",
      "question": "What is a probability distribution example"
    },
    {
      "answer": "A statistic is biased if the long-term average value of the statistic is not the parameter it is estimating. More formally, a statistic is biased if the mean of the sampling distribution of the statistic is not equal to the parameter.  Therefore the sample mean is an unbiased estimate of \u03bc.",
      "question": "Is mean a biased estimator"
    },
    {
      "answer": "Many everyday data sets typically follow a normal distribution: for example, the heights of adult humans, the scores on a test given to a large class, errors in measurements. The normal distribution is always symmetrical about the mean.",
      "question": "Does the data follow a normal distribution"
    },
    {
      "answer": "Simple linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line. Both variables should be quantitative.",
      "question": "What is a simple linear regression model"
    },
    {
      "answer": "The second reason you may see validation loss lower than training loss is due to how the loss value are measured and reported: Training loss is measured during each epoch. While validation loss is measured after each epoch.",
      "question": "Why is my validation loss lower than training loss"
    },
    {
      "answer": "In other words, discriminative models are used to specify outputs based on inputs (by models such as Logistic regression, Neural networks and Random forests), while generative models generate both inputs and outputs (for example, by Hidden Markov model, Bayesian Networks and Gaussian mixture model).",
      "question": "Is Random Forest generative or discriminative"
    },
    {
      "answer": "The ability to slide the signal is the what gives Engineers a more accurate representation of the signal and therefore a better resolution in time.  So when you use a Wavelet Transform the signal is deconstructed using the same wavelet at different scales, rather than the same sin() wave at different frequencies.",
      "question": "Why do we use wavelet transform"
    },
    {
      "answer": "To create a stratified random sample, there are seven steps: (a) defining the population; (b) choosing the relevant stratification; (c) listing the population; (d) listing the population according to the chosen stratification; (e) choosing your sample size; (f) calculating a proportionate stratification; and (g) using",
      "question": "How do you do stratified sampling"
    },
    {
      "answer": "A method of computing a kind of arithmetic mean of a set of numbers in which some elements of the set carry more importance (weight) than others. Example: Grades are often computed using a weighted average. Suppose that homework counts 10%, quizzes 20%, and tests 70%.",
      "question": "What is weighted average with example"
    },
    {
      "answer": "In probability theory and statistics, the marginal distribution of a subset of a collection of random variables is the probability distribution of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.",
      "question": "What does marginal distribution mean"
    },
    {
      "answer": "Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).",
      "question": "What is conditional probability explain with an example"
    },
    {
      "answer": "Now we'll check out the proven way to improve the performance(Speed and Accuracy both) of neural network models:Increase hidden Layers.  Change Activation function.  Change Activation function in Output layer.  Increase number of neurons.  Weight initialization.  More data.  Normalizing/Scaling data.More items\u2022",
      "question": "How can neural networks be improved"
    },
    {
      "answer": "In probability theory and related fields, a stochastic or random process is a mathematical object usually defined as a family of random variables.  Stochastic processes are widely used as mathematical models of systems and phenomena that appear to vary in a random manner.",
      "question": "What is probability and random process"
    },
    {
      "answer": "The mn Rule Consider an experiment that is performed in two stages. If the first stage can be accomplished in m different ways and for each of these ways, the second stage can be accomplished in n different ways, then there are to- tal mn different ways to accomplish the experiment.",
      "question": "What is the MN rule in statistics"
    },
    {
      "answer": "Recurrent Neural Networks (RNNs) are a form of machine learning algorithm that are ideal for sequential data such as text, time series, financial data, speech, audio, video among others.",
      "question": "Is recurrent neural networks are best suited for text processing"
    },
    {
      "answer": "3.1 . Each bootstrap distribution is centered at the statistic from the corresponding sample rather than at the population mean \u03bc.",
      "question": "Where is a bootstrap distribution centered"
    },
    {
      "answer": "DeepMind",
      "question": "Who has beaten AlphaGo"
    },
    {
      "answer": "Pierre-Simon Laplace",
      "question": "Who proved the central limit theorem"
    },
    {
      "answer": "The estimation of distribution algorithm (EDA) aims to explicitly model the probability distribution of the quality solutions to the underlying problem. By iterative filtering for quality solution from competing ones, the probability model eventually approximates the distribution of global optimum solutions.",
      "question": "Evolutionary Computation Estimation of Distribution Algorithm EDA"
    },
    {
      "answer": "Artificial intelligence can dramatically improve the efficiencies of our workplaces and can augment the work humans can do. When AI takes over repetitive or dangerous tasks, it frees up the human workforce to do work they are better equipped for\u2014tasks that involve creativity and empathy among others.",
      "question": "What is the role of artificial intelligence in the shaping modern society"
    },
    {
      "answer": "Implementing Deep Learning Methods and Feature Engineering for Text Data: FastText. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub.",
      "question": "Is fastText deep learning"
    },
    {
      "answer": "The exponential distribution is often used to model the longevity of an electrical or mechanical device. In Example, the lifetime of a certain computer part has the exponential distribution with a mean of ten years (X\u223cExp(0.1)).",
      "question": "When would you use an exponential distribution"
    },
    {
      "answer": "The definition is: \"Entropy is a measure of how evenly energy is distributed in a system. In a physical system, entropy provides a measure of the amount of energy that cannot be used to do work.\"",
      "question": "What is entropy in layman's terms"
    },
    {
      "answer": "For this, you aim to maximize the Youden's index, which is Maximum=Sensitivity + Specificity - 1. So you choose those value of the ROC-curve as a cut-off, where the term \"Sensitivity + Specificity - 1\" (parameters taken from the output in the same line as the observed value, see attachments) is maximal.",
      "question": "How cut off value is calculated from ROC curve"
    },
    {
      "answer": "The standard error tells you how accurate the mean of any given sample from that population is likely to be compared to the true population mean. When the standard error increases, i.e. the means are more spread out, it becomes more likely that any given mean is an inaccurate representation of the true population mean.",
      "question": "What standard error tells us"
    },
    {
      "answer": "Validity is important because it can help determine what types of tests to use, and help to make sure researchers are using methods that are not only ethical, and cost-effective, but also a method that truly measures the idea or constructs in question.",
      "question": "What is the purpose of measuring the validity of a test"
    },
    {
      "answer": "Standard deviation tells you how spread out the data is. It is a measure of how far each observed value is from the mean. In any distribution, about 95% of values will be within 2 standard deviations of the mean.",
      "question": "What does the standard deviation tell you"
    },
    {
      "answer": "0:0012:40Suggested clip \u00b7 82 secondsCommon Source Amplifiers - Gain Equation - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you calculate gain of common source amplifier"
    },
    {
      "answer": "Use Augmented Dickey-Fuller Test (adf test). A p-Value of less than 0.05 in adf. test() indicates that it is stationary.",
      "question": "How do I check if a time series is stationary in R"
    },
    {
      "answer": "A CNN LSTM can be defined by adding CNN layers on the front end followed by LSTM layers with a Dense layer on the output. It is helpful to think of this architecture as defining two sub-models: the CNN Model for feature extraction and the LSTM Model for interpreting the features across time steps.",
      "question": "How do I combine CNN and Lstm"
    },
    {
      "answer": "Subject 2. Time-series data is a set of observations collected at usually discrete and equally spaced time intervals.  Cross-sectional data are observations that come from different individuals or groups at a single point in time.",
      "question": "What is the difference between trend time series and cross section analysis"
    },
    {
      "answer": "The pre-attention phase is an automatic process which happens unconsciously. The second stage is focused attention in which an individual takes all of the observed features and combines them to make a complete perception. This second stage process occurs if the object doesn't stand out immediately.",
      "question": "What are the two stages of processing in the feature integration theory"
    },
    {
      "answer": "Data is the currency of applied machine learning.  Resampling is a methodology of economically using a data sample to improve the accuracy and quantify the uncertainty of a population parameter. Resampling methods, in fact, make use of a nested resampling method.",
      "question": "What is resampling in machine learning"
    },
    {
      "answer": "Statistical data binning is a way to group numbers of more or less continuous values into a smaller number of \"bins\". For example, if you have data about a group of people, you might want to arrange their ages into a smaller number of age intervals (for example, grouping every five years together).",
      "question": "What is data binning in statistics"
    },
    {
      "answer": "Temporal Difference is an approach to learning how to predict a quantity that depends on future values of a given signal. It can be used to learn both the V-function and the Q-function, whereas Q-learning is a specific TD algorithm used to learn the Q-function.",
      "question": "Is Q learning temporal difference"
    },
    {
      "answer": "The main difference is the one of focus. Data Engineers are focused on building infrastructure and architecture for data generation. In contrast, data scientists are focused on advanced mathematics and statistical analysis on that generated data.  Simply put, data scientists depend on data engineers.",
      "question": "How data engineering is different from data science"
    },
    {
      "answer": "The product moment correlation coefficient (pmcc) can be used to tell us how strong the correlation between two variables is. A positive value indicates a positive correlation and the higher the value, the stronger the correlation.  If there is a perfect negative correlation, then r = -1.",
      "question": "What does product moment correlation coefficient mean"
    },
    {
      "answer": "Key Takeaways. Standard deviation looks at how spread out a group of numbers is from the mean, by looking at the square root of the variance. The variance measures the average degree to which each point differs from the mean\u2014the average of all data points.",
      "question": "What is standard deviation and variance"
    },
    {
      "answer": "In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class.",
      "question": "What is Perceptron learning algorithm"
    },
    {
      "answer": "What is the F-distribution. A probability distribution, like the normal distribution, is means of determining the probability of a set of events occurring. This is true for the F-distribution as well. The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution.",
      "question": "Is F distribution a normal distribution"
    },
    {
      "answer": "6 Answers. Machine learning algorithms use optimization all the time.  Nonetheless, as mentioned in other answers, convex optimization is faster, simpler and less computationally intensive, so it is often easier to \"convexify\" a problem (make it convex optimization friendly), then use non-convex optimization.",
      "question": "Is convex optimization important for machine learning"
    },
    {
      "answer": "A weak classifier is simply a classifier that performs poorly, but performs better than random guessing.  AdaBoost can be applied to any classification algorithm, so it's really a technique that builds on top of other classifiers as opposed to being a classifier itself.",
      "question": "What is weak classifier in AdaBoost"
    },
    {
      "answer": "K-means clustering algorithm computes the centroids and iterates until we it finds optimal centroid.  In this algorithm, the data points are assigned to a cluster in such a manner that the sum of the squared distance between the data points and centroid would be minimum.",
      "question": "What is K means clustering algorithm explain with an example"
    },
    {
      "answer": "TL;DR: Entropy is not quantized. Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.  Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.",
      "question": "Is entropy quantized"
    },
    {
      "answer": "Confusion matrix not only gives you insight into the errors being made by your classifier but also types of errors that are being made. This breakdown helps you to overcomes the limitation of using classification accuracy alone. Every column of the confusion matrix represents the instances of that predicted class.",
      "question": "Why do we need confusion matrix in data mining"
    },
    {
      "answer": "A simple linear regression plot for amount of rainfall. Regression analysis is used in stats to find trends in data. For example, you might guess that there's a connection between how much you eat and how much you weigh; regression analysis can help you quantify that.",
      "question": "What is regression analysis example"
    },
    {
      "answer": "The coefficient of variation (COV) is a measure of relative event dispersion that's equal to the ratio between the standard deviation and the mean. While it is most commonly used to compare relative risk, the COV may be applied to any type of quantitative likelihood or probability distribution.",
      "question": "Where is coefficient variation used"
    },
    {
      "answer": "Cluster analysis divides data into groups (clusters) that are meaningful, useful, or both. If meaningful groups are the goal, then the clusters should capture the natural structure of the data. In some cases, however, cluster analysis is only a useful starting point for other purposes, such as data summarization.",
      "question": "How do you read cluster analysis"
    },
    {
      "answer": "Test method. Use the one-sample z-test to determine whether the hypothesized population proportion differs significantly from the observed sample proportion.",
      "question": "What test statistic is used to test a population proportion"
    },
    {
      "answer": "In the context of AB testing experiments, statistical significance is how likely it is that the difference between your experiment's control version and test version isn't due to error or random chance.  It's commonly used in business to observe how your experiments affect your business's conversion rates.",
      "question": "What is statistical significance in AB testing"
    },
    {
      "answer": "r text-mining natural-language. According the documentation of the removeSparseTerms function from the tm package, this is what sparsity entails: A term-document matrix where those terms from x are removed which have at least a sparse percentage of empty (i.e., terms occurring 0 times in a document) elements.",
      "question": "What is sparsity in document term matrix"
    },
    {
      "answer": "The ground-truth bounding boxes (i.e., the hand labeled bounding boxes from the testing set that specify where in the image our object is).",
      "question": "What is ground truth box"
    },
    {
      "answer": "Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.",
      "question": "What is sentiment analysis in natural language processing"
    },
    {
      "answer": "Simply put, a random sample is a subset of individuals randomly selected by researchers to represent an entire group as a whole. The goal is to get a sample of people that is representative of the larger population.",
      "question": "What is the main purpose of random sampling"
    },
    {
      "answer": "Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution.",
      "question": "What is the shape of the chi square distribution"
    },
    {
      "answer": "Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. In logistic regression we assumed that the labels were binary: y(i)\u2208{0,1} . We used such a classifier to distinguish between two kinds of hand-written digits.",
      "question": "Is Softmax the same as logistic regression"
    },
    {
      "answer": "Definition: A vector space is a set V on which two operations + and \u00b7 are defined, called vector addition and scalar multiplication. The operation + (vector addition) must satisfy the following conditions: Closure: If u and v are any vectors in V, then the sum u + v belongs to V.",
      "question": "How do you define a vector space"
    },
    {
      "answer": "1 : a branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data. 2 : a collection of quantitative data.",
      "question": "What is the simple definition of statistics"
    },
    {
      "answer": "Multicollinearity causes the following two basic types of problems: The coefficient estimates can swing wildly based on which other independent variables are in the model.  Multicollinearity reduces the precision of the estimate coefficients, which weakens the statistical power of your regression model.",
      "question": "How does Multicollinearity affect the regression model"
    },
    {
      "answer": "Key Takeaways. Standard deviation defines the line along which a particular data point lies. Z-score indicates how much a given value differs from the standard deviation. The Z-score, or standard score, is the number of standard deviations a given data point lies above or below mean.",
      "question": "What is the difference between AZ score and standard deviation"
    },
    {
      "answer": "The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(\u2217). Both functions will take any number and rescale it to fall between 0 and 1.",
      "question": "What is logit probit model"
    },
    {
      "answer": "A probability sampling method is any method of sampling that utilizes some form of random selection. In order to have a random selection method, you must set up some process or procedure that assures that the different units in your population have equal probabilities of being chosen.",
      "question": "What is probability sampling technique"
    },
    {
      "answer": "Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients. Implementations may choose to sum the gradient over the mini-batch which further reduces the variance of the gradient.",
      "question": "What is mini batch stochastic gradient descent"
    },
    {
      "answer": "Character N-grams (of at least 3 characters) that are common to words meaning \u201ctransport\u201d in the same texts sample in French, Spanish and Greek and their respective frequency.",
      "question": "What is character N grams"
    },
    {
      "answer": "The Linear Regression Equation The equation has the form Y= a + bX, where Y is the dependent variable (that's the variable that goes on the Y axis), X is the independent variable (i.e. it is plotted on the X axis), b is the slope of the line and a is the y-intercept.",
      "question": "How do you write a regression model"
    },
    {
      "answer": "A Kalman Filter is an algorithm that can predict future positions based on current position. It can also estimate current position better than what the sensor is telling us. It will be used to have better association.",
      "question": "How can a Kalman filter be used in computer vision"
    },
    {
      "answer": "Developers can make use of NLP to perform tasks like speech recognition, sentiment analysis, translation, auto-correct of grammar while typing, and automated answer generation. NLP is a challenging field since it deals with human language, which is extremely diverse and can be spoken in a lot of ways.",
      "question": "What is the scope of NLP"
    },
    {
      "answer": "A continuous variable is one which can take on a value between any other two values, such as: indoor temperature, time spent waiting, water consumed, color wavelength, and direction of travel. A discrete variable corresponds to a digital quantity, while a continuous variable corresponds to an analog quantity.",
      "question": "Is time a discrete variable"
    },
    {
      "answer": "ProcedureFrom the cluster management console, select Workload > Spark > Deep Learning.Select the Datasets tab.Click New.Create a dataset from Images for Object Classification.Provide a dataset name.Specify a Spark instance group.Specify image storage format, either LMDB for Caffe or TFRecords for TensorFlow.More items",
      "question": "How do you create a dataset of an image"
    },
    {
      "answer": "The different types of regression in machine learning techniques are explained below in detail:Linear Regression. Linear regression is one of the most basic types of regression in machine learning.  Logistic Regression.  Ridge Regression.  Lasso Regression.  Polynomial Regression.  Bayesian Linear Regression.",
      "question": "What are the different types of regression"
    },
    {
      "answer": "How to Use K-means Cluster Algorithms in Predictive AnalysisPick k random items from the dataset and label them as cluster representatives.Associate each remaining item in the dataset with the nearest cluster representative, using a Euclidean distance calculated by a similarity function.Recalculate the new clusters' representatives.More items",
      "question": "How is K means clustering used in prediction"
    },
    {
      "answer": "The p-value for each term tests the null hypothesis that the coefficient is equal to zero (no effect). A low p-value (< 0.05) indicates that you can reject the null hypothesis.",
      "question": "How do I interpret p value in logistic regression"
    },
    {
      "answer": "The Monty Hall problem has confused people for decades. In the game show, Let's Make a Deal, Monty Hall asks you to guess which closed door a prize is behind. The answer is so puzzling that people often refuse to accept it! The problem occurs because our statistical assumptions are incorrect.",
      "question": "Why the Monty Hall problem is wrong"
    },
    {
      "answer": "A major difference is in its shape: the normal distribution is symmetrical, whereas the lognormal distribution is not. Because the values in a lognormal distribution are positive, they create a right-skewed curve.  A further distinction is that the values used to derive a lognormal distribution are normally distributed.",
      "question": "What is the difference between normal and lognormal distribution"
    },
    {
      "answer": "If two random variables X and Y are independent, then they are uncorrelated. Proof. Uncorrelated means that their correlation is 0, or, equivalently, that the covariance between them is 0.",
      "question": "How do you prove two variables are uncorrelated"
    },
    {
      "answer": "Advantages of Dimensionality Reduction It helps in data compression, and hence reduced storage space. It reduces computation time. It also helps remove redundant features, if any.",
      "question": "Why dimensionality reduction is important step in machine learning"
    },
    {
      "answer": "Probability theory is the mathematical study of phenomena characterized by randomness or uncertainty. More precisely, probability is used for modelling situations when the result of an experiment, realized under the same circumstances, produces different results (typically throwing a dice or a coin).",
      "question": "What is probability theory used for"
    },
    {
      "answer": "Discriminant analysis is a versatile statistical method often used by market researchers to classify observations into two or more groups or categories. In other words, discriminant analysis is used to assign objects to one group among a number of known groups.",
      "question": "What is discriminant analysis used for"
    },
    {
      "answer": "The level of statistical significance is often expressed as a p-value between 0 and 1. The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.  A p-value higher than 0.05 (> 0.05) is not statistically significant and indicates strong evidence for the null hypothesis.",
      "question": "Is the level of significance the same as the P value"
    },
    {
      "answer": "Sparse coding is the representation of items by the strong activation of a relatively small set of neurons. For each stimulus, this is a different subset of all available neurons.",
      "question": "What is sparse coding in neural network"
    },
    {
      "answer": "NHST is difficult to describe in one sentence, particularly here.",
      "question": "What does Null Hypothesis significance testing NHST mean"
    },
    {
      "answer": "The performance of deep learning neural networks often improves with the amount of data available. Data augmentation is a technique to artificially create new training data from existing training data. This means, variations of the training set images that are likely to be seen by the model.",
      "question": "What is augmentation in deep learning"
    },
    {
      "answer": "If your data contains both numeric and categorical variables, the best way to carry out clustering on the dataset is to create principal components of the dataset and use the principal component scores as input into the clustering.",
      "question": "Can you use categorical variables in clustering"
    },
    {
      "answer": "If all of the values in the sample are identical, the sample standard deviation will be zero. When discussing the sample mean, we found that the sample mean for diastolic blood pressure was 71.3.",
      "question": "Can a sample mean be zero"
    },
    {
      "answer": "There is a good reason why accuracy is not an appropriate measure for information retrieval problems. In almost all circumstances, the data is extremely skewed: normally over 99.9% of the documents are in the nonrelevant category.",
      "question": "Why accuracy is not used as a preferred method for real world IR system evaluation"
    },
    {
      "answer": "Padding is a term relevant to convolutional neural networks as it refers to the amount of pixels added to an image when it is being processed by the kernel of a CNN. For example, if the padding in a CNN is set to zero, then every pixel value that is added will be of value zero.",
      "question": "What is padding in deep learning"
    },
    {
      "answer": "resample Function One resampling application is the conversion of digitized audio signals from one sample rate to another, such as from 48 kHz (the digital audio tape standard) to 44.1 kHz (the compact disc standard).  resample applies a lowpass filter to the input sequence to prevent aliasing during resampling.",
      "question": "What is resampling in signal processing"
    },
    {
      "answer": "In computer science and engineering, a test vector is a set of inputs provided to a system in order to test that system. In software development, test vectors are a methodology of software testing and software verification and validation.",
      "question": "What is input vector"
    },
    {
      "answer": "An easy guide to choose the right Machine Learning algorithmSize of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.",
      "question": "Which algorithm is right for machine learning"
    },
    {
      "answer": "Just multiply the probability of the first event by the second. For example, if the probability of event A is 2/9 and the probability of event B is 3/9 then the probability of both events happening at the same time is (2/9)*(3/9) = 6/81 = 2/27.",
      "question": "How do you find the probability of multiple events"
    },
    {
      "answer": "To format the size of data points in a scatter plot graph, right click any of the data points and select 'format data series' then select marker options and customize for larger or smaller data points.",
      "question": "How do you make the dots on a scatter plot bigger"
    },
    {
      "answer": "A common problem in machine learning is sparse data, which alters the performance of machine learning algorithms and their ability to calculate accurate predictions. Data is considered sparse when certain expected values in a dataset are missing, which is a common phenomenon in general large scaled data analysis.",
      "question": "What is sparse data in machine learning"
    },
    {
      "answer": "Regression: This is a tool used to evaluate the relationship of a dependent variable in relation to multiple independent variables. A regression will analyze the mean of the dependent variable in relation to changes in the independent variables. Time Series: A time series measures data over a specific period of time.",
      "question": "What is the difference between time series and regression"
    },
    {
      "answer": "Consider statistics as a problem-solving process and examine its four components: asking questions, collecting appropriate data, analyzing the data, and interpreting the results. This session investigates the nature of data and its potential sources of variation. Variables, bias, and random sampling are introduced.",
      "question": "What is the statistical problem solving process"
    },
    {
      "answer": "Eigenanalysis is a mathematical operation on a square, symmetric matrix. A square matrix has the same number of rows as columns. A symmetric matrix is the same if you switch rows and columns. Distance and similarity matrices are nearly always square and symmetric.",
      "question": "What is Eigen analysis"
    },
    {
      "answer": "Simply put, homoscedasticity means \u201chaving the same scatter.\u201d For it to exist in a set of data, the points must be about the same distance from the line, as shown in the picture above. The opposite is heteroscedasticity (\u201cdifferent scatter\u201d), where points are at widely varying distances from the regression line.",
      "question": "What does Homoscedasticity mean in regression"
    },
    {
      "answer": "If you have both a response variable and an explanatory variable, the explanatory variable is always plotted on the x-axis (the horizontal axis). The response variable is always plotted on the y-axis (the vertical axis).",
      "question": "How do you know which is the explanatory variable"
    },
    {
      "answer": "Approach \u2013Load dataset from source.Split the dataset into \u201ctraining\u201d and \u201ctest\u201d data.Train Decision tree, SVM, and KNN classifiers on the training data.Use the above classifiers to predict labels for the test data.Measure accuracy and visualise classification.",
      "question": "How do you do multi class classification"
    },
    {
      "answer": "Here are some important considerations while choosing an algorithm.Size of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.",
      "question": "How can I choose among classification algorithms to work with"
    },
    {
      "answer": "Genetic algorithms are stochastic search algorithms which act on a population of possible solutions.  Genetic algorithms are used in artificial intelligence like other search algorithms are used in artificial intelligence \u2014 to search a space of potential solutions to find one which solves the problem.",
      "question": "Are genetic algorithms artificial intelligence"
    },
    {
      "answer": "Taguchi loss function formulaL is the loss function.y is the value of the characteristic you are measuring (e.g. length of product)m is the value you are aiming for (in our example, perfect length for the product)k is a proportionality constant (i.e. just a number)",
      "question": "How is Taguchi quality loss function calculated"
    },
    {
      "answer": "Exploratory Data Analysis is one of the important steps in the data analysis process.  Exploratory Data Analysis is a crucial step before you jump to machine learning or modeling of your data. It provides the context needed to develop an appropriate model \u2013 and interpret the results correctly.",
      "question": "Why do we need to perform exploratory data analysis"
    },
    {
      "answer": "Fortunately, hinge loss, logistic loss and square loss are all convex functions. Convexity ensures global minimum and it's computationally appleaing.",
      "question": "Is squared loss convex"
    },
    {
      "answer": "The input nodes take in information, in the form which can be numerically expressed. The information is presented as activation values, where each node is given a number, the higher the number, the greater the activation.  The output nodes then reflect the input in a meaningful way to the outside world.",
      "question": "What is an activation value *"
    },
    {
      "answer": "Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks.  Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents.",
      "question": "How does activation spread through a semantic network"
    },
    {
      "answer": "Examples of Artificial Intelligence: Work & School1 \u2013 Google's AI-Powered Predictions.  2 \u2013 Ridesharing Apps Like Uber and Lyft.  3 \u2014 Commercial Flights Use an AI Autopilot.1 \u2013 Spam Filters.2 \u2013 Smart Email Categorization.1 \u2013Plagiarism Checkers.  2 \u2013Robo-readers.  1 \u2013 Mobile Check Deposits.More items\u2022",
      "question": "What are some applications of AI in real life"
    },
    {
      "answer": "There are two main ways to access subsets of the elements in a tensor, either of which should work for your example.Use the indexing operator (based on tf. slice() ) to extract a contiguous slice from the tensor. input = tf.  Use the tf. gather() op to select a non-contiguous slice from the tensor. input = tf.",
      "question": "How do I find the value of Tensor"
    },
    {
      "answer": "The sampling distribution of the sample mean can be thought of as \"For a sample of size n, the sample mean will behave according to this distribution.\" Any random draw from that sampling distribution would be interpreted as the mean of a sample of n observations from the original population.",
      "question": "What does a sampling distribution of sample means represent"
    },
    {
      "answer": "The determinant is related to the volume of the space occupied by the swarm of data points represented by standard scores on the measures involved.  When the measures are correlated, the space occupied becomes an ellipsoid whose volume is less than 1.",
      "question": "What does the determinant of the correlation matrix represent"
    },
    {
      "answer": "0:041:23Suggested clip \u00b7 72 secondsQuick Example - Find the Area to the Right Of a Z-Score - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How is technology used to find the area to the right of Z"
    },
    {
      "answer": "\u2022 A random process is a time-varying function that assigns the outcome of a random experiment to each time instant: X(t). \u2022 For a fixed (sample path): a random process is a time varying function, e.g., a signal.",
      "question": "What is random process in communication"
    },
    {
      "answer": "Basically, it takes between 365 days (1 year) to 1,825 days (5 years) to learn artificial intelligence (assuming you put in 4 \u2013 0.5 learning hours a day). And how fast you learn also affects how long it takes you to be an expert.",
      "question": "How long does it take to learn artificial intelligence"
    },
    {
      "answer": "An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.",
      "question": "What are some applications of the Autoregressive integrated moving average ARIMA model"
    },
    {
      "answer": "All descriptive statistics are either measures of central tendency or measures of variability, also known as measures of dispersion.  Range, quartiles, absolute deviation and variance are all examples of measures of variability. Consider the following data set: 5, 19, 24, 62, 91, 100.",
      "question": "What is an example of a descriptive statistic"
    },
    {
      "answer": "The total number of contravariant and covariant indices of a tensor. The rank of a tensor is independent of the number of dimensions. of the underlying space.",
      "question": "What is tensor rank"
    },
    {
      "answer": "Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.",
      "question": "What is meant by a tensor"
    },
    {
      "answer": "Generative adversarial nets can be applied in many fields from generating images to predicting drugs, so don't be afraid of experimenting with them. We believe they help in building a better future for machine learning.",
      "question": "What are generative adversarial networks used for"
    },
    {
      "answer": "the state of being likely or probable; probability. a probability or chance of something: There is a strong likelihood of his being elected.",
      "question": "What is meant by likelihood"
    },
    {
      "answer": "Canonical discriminant analysis is a dimension-reduction technique related to principal component analysis and canonical correlation.  This maximal multiple correlation is called the first canonical correlation. The coefficients of the linear combination are the canonical coefficients or canonical weights.",
      "question": "What is canonical discriminant analysis"
    },
    {
      "answer": "Entropy can be calculated for a random variable X with k in K discrete states as follows: H(X) = -sum(each k in K p(k) * log(p(k)))",
      "question": "How do you calculate entropy of information"
    },
    {
      "answer": "Word2Vec can be used to get actionable metrics from thousands of customers reviews. Businesses don't have enough time and tools to analyze survey responses and act on them thereon. This leads to loss of ROI and brand value. Word embeddings prove invaluable in such cases.",
      "question": "Where is Word2Vec used"
    },
    {
      "answer": "This is the \u201cq-value.\u201d A p-value of 5% means that 5% of all tests will result in false positives. A q-value of 5% means that 5% of significant results will result in false positives.",
      "question": "How do you interpret Q values"
    },
    {
      "answer": "In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.",
      "question": "What does it mean when data is positively skewed"
    },
    {
      "answer": "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization.",
      "question": "Does normalization improve performance machine learning"
    },
    {
      "answer": "2:316:15Suggested clip \u00b7 118 secondsUnit Conversion the Easy Way (Dimensional Analysis) - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you convert dimensional analysis"
    },
    {
      "answer": "Multi-task learning (MTL) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks.  In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly.",
      "question": "What is multi task learning in machine learning"
    },
    {
      "answer": "The MSE is a measure of the quality of an estimator\u2014it is always non-negative, and values closer to zero are better.  For an unbiased estimator, the MSE is the variance of the estimator. Like the variance, MSE has the same units of measurement as the square of the quantity being estimated.",
      "question": "Is MSE equal to variance"
    },
    {
      "answer": "4:026:15Suggested clip \u00b7 93 secondsFinding the Test Statistic for a Wilcoxon Rank Sum Test in  - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you solve the Wilcoxon rank sum test"
    },
    {
      "answer": "if p is a statement variable, the negation of p is \"not p\", denoted by ~p. If p is true, then ~p is false. Conjunction: if p and q are statement variables, the conjunction of p and q is \"p and q\", denoted p q.(p q) ~(p q) p xor qExclusive Orp ~(~p)Double Negation",
      "question": "What is logically equivalent to P or Q"
    },
    {
      "answer": "The difference between combinations and permutations is ordering. With permutations we care about the order of the elements, whereas with combinations we don't. For example, say your locker \u201ccombo\u201d is 5432. If you enter 4325 into your locker it won't open because it is a different ordering (aka permutation).",
      "question": "How do you know when to use a permutation instead of a combination"
    },
    {
      "answer": "to safeguard against the researcher problem of experimenter bias, researchers employ blind observers, single and double blind study, and placebos. to control for ethnocentrism, they use cross cultural sampling.",
      "question": "What are two methods researchers use to avoid experimenter bias"
    },
    {
      "answer": "In ordinary least squares, the relevant assumption of the classical linear regression model is that the error term is uncorrelated with the regressors. The presence of omitted-variable bias violates this particular assumption. The violation causes the OLS estimator to be biased and inconsistent.",
      "question": "Which assumption does omitted variable bias violate"
    },
    {
      "answer": "0:012:32Suggested clip \u00b7 101 secondsMultiple Logistic Regression - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do multiple logistic regression"
    },
    {
      "answer": "Artificial General Intelligence",
      "question": "What does AGI stand for in artificial intelligence"
    },
    {
      "answer": "Cross tabulationCross tabulations require that the two data columns be adjacent. You can drag columns by selecting them, and moving the cursor so it's immediately between two columns.  Once you have the columns adjacent, select both of them including the variable names all the way to the bottom.",
      "question": "How do you do cross tabulation"
    },
    {
      "answer": "Factor analysis is as much of a \"test\" as multiple regression (or statistical tests in general) in that it is used to reveal hidden or latent relationships/groupings in one's dataset.  Multiple regression takes data points in some n-dimensional space and finds the best fit line.",
      "question": "How is factor analysis different from multiple regression"
    },
    {
      "answer": "When someone talks about AR, they are referring to technology that overlays information and virtual objects on real-world scenes in real-time. It uses the existing environment and adds information to it to make a new artificial environment.",
      "question": "What is augmented reality used for"
    },
    {
      "answer": "They provide a natural way to handle missing data, they allow combination of data with domain knowledge, they facilitate learning about causal relationships between variables, they provide a method for avoiding overfitting of data (Heckerman, 1995), they can show good prediction accuracy even with rather small sample",
      "question": "What are the advantages of Bayesian networks"
    },
    {
      "answer": "Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on. If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)",
      "question": "How do neural networks reduce loss"
    },
    {
      "answer": "To put simply, likelihood is \"the likelihood of \u03b8 having generated D\" and posterior is essentially \"the likelihood of \u03b8 having generated D\" further multiplied by the prior distribution of \u03b8.",
      "question": "What is the difference between likelihood function and posterior probability"
    },
    {
      "answer": "Adding more training data.Reducing parameters. We have too many neurons in our hidden layers or too many layers. Let's remove some layers, or reduce the number of hidden neurons.Increase regularization. Either by increasing our. for L1/L2 weight regularization. We can also use dropout the technique.",
      "question": "Why and what to do when neural networks perform poorly on the training set"
    },
    {
      "answer": "Learning involves far more than thinking: it involves the whole personality - senses, feelings, intuition, beliefs, values and will.  Learning occurs when we are able to: Gain a mental or physical grasp of the subject. Make sense of a subject, event or feeling by interpreting it into our own words or actions.",
      "question": "What is learning and how do we learn"
    },
    {
      "answer": "EM is an iterative method which alternates between two steps, expectation (E) and maximization (M). For clustering, EM makes use of the finite Gaussian mixtures model and estimates a set of parameters iteratively until a desired convergence value is achieved.",
      "question": "What is Expectation Maximization clustering"
    },
    {
      "answer": "Simple logistic regression analysis refers to the regression application with one dichotomous outcome and one independent variable; multiple logistic regression analysis applies when there is a single dichotomous outcome and more than one independent variable.",
      "question": "What does multiple logistic regression mean"
    },
    {
      "answer": "Tokenization is one of the most common tasks when it comes to working with text data.  Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.",
      "question": "What is tokenization NLP"
    },
    {
      "answer": "Click on the triangle-shaped icon located at the top right corner of the panel, and then choose \"Save Path\". Next, select \"Clipping Path\" from the same drop-down menu. A new dialog box will appear with a variety of clipping path settings. Make sure your path is selected, and then click OK.",
      "question": "How do you do a clipping path"
    },
    {
      "answer": "It's a form of machine learning and therefore a branch of artificial intelligence. Depending on the complexity of the problem, reinforcement learning algorithms can keep adapting to the environment over time if necessary in order to maximize the reward in the long-term.",
      "question": "Is reinforcement learning AI"
    },
    {
      "answer": "Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.",
      "question": "How do you know if an event is independent or dependent"
    },
    {
      "answer": "While statistical significance relates to whether an effect exists, practical significance refers to the magnitude of the effect. However, no statistical test can tell you whether the effect is large enough to be important in your field of study.  An effect of 4 points or less is too small to care about.",
      "question": "How might a statistical test be statistically significant but not practical"
    },
    {
      "answer": "When there is lack of domain understanding for feature introspection , Deep Learning techniques outshines others as you have to worry less about feature engineering . Deep Learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition.",
      "question": "Why should I learn deep learning"
    },
    {
      "answer": "Linear discriminant analysis (LDA) is one of commonly used supervised subspace learning methods.  The objective optimization is in both the ratio trace and the trace ratio forms, forming a complete framework of a new approach to jointly clustering and unsupervised subspace learning.",
      "question": "Is linear discriminant analysis supervised or unsupervised"
    },
    {
      "answer": "Communalities \u2013 This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.  They are the reproduced variances from the factors that you have extracted.",
      "question": "What does Communalities mean in factor analysis"
    },
    {
      "answer": "Non-linearity in neural networks simply mean that the output at any unit cannot be reproduced from a linear function of the input.",
      "question": "What is nonlinearity in neural networks"
    },
    {
      "answer": "Stochastic Gradient Descent: you would randomly select one of those training samples at each iteration to update your coefficients. Online Gradient Descent: you would use the \"most recent\" sample at each iteration. There is no stochasticity as you deterministically select your sample.",
      "question": "Difference between stochastic gradient descent and online learning"
    },
    {
      "answer": "The first method involves the conditional distribution of a random variable X2 given X1. Therefore, a bivariate normal distribution can be simulated by drawing a random variable from the marginal normal distribution and then drawing a second random variable from the conditional normal distribution.",
      "question": "How do you create a bivariate normal distribution"
    },
    {
      "answer": "In a crossover network, resistors are usually used in combination with other components to control either impedance magnitudes or the relative levels between different drivers in a system.",
      "question": "What does a resistor do in a crossover"
    },
    {
      "answer": "A regression equation is used in stats to find out what relationship, if any, exists between sets of data. For example, if you measure a child's height every year you might find that they grow about 3 inches a year. That trend (growing three inches a year) can be modeled with a regression equation.",
      "question": "What does a regression equation tell you"
    },
    {
      "answer": "Optimal control focuses on a subset of problems, but solves these problems very well, and has a rich history. RL can be thought of as a way of generalizing or extending ideas from optimal control to non-traditional control problems.",
      "question": "What is the difference between optimal control theory and reinforcement learning"
    },
    {
      "answer": "Random forests perform well for multi-class object detection and bioinformatics, which tends to have a lot of statistical noise. Gradient Boosting performs well when you have unbalanced data such as in real time risk assessment.",
      "question": "Why is gradient boosting better than random forest"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is the difference between supervised and unsupervised learning"
    },
    {
      "answer": "PD analysis is a method used by larger institutions to calculate their expected loss. A PD is assigned to each risk measure and represents as a percentage the likelihood of default.  LGD represents the amount unrecovered by the lender after selling the underlying asset if a borrower defaults on a loan.",
      "question": "What is PD and LGD"
    },
    {
      "answer": "Instance-based methods are sometimes referred to as lazy learning methods because they delay processing until a new instance must be classified. The nearest neighbors of an instance are defined in terms of Euclidean distance.",
      "question": "Why instance based learning is called as lazy learning"
    },
    {
      "answer": "Other ways of avoiding experimenter's bias include standardizing methods and procedures to minimize differences in experimenter-subject interactions; using blinded observers or confederates as assistants, further distancing the experimenter from the subjects; and separating the roles of investigator and experimenter.",
      "question": "How do you get rid of experimenter bias"
    },
    {
      "answer": "The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution. It is also known as the Gaussian distribution and the bell curve.",
      "question": "Why data should be normally distributed"
    },
    {
      "answer": "An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value.  The vertical axis represents the size of the area (total number of pixels) that is captured in each one of these zones.",
      "question": "What is a histogram in image processing"
    },
    {
      "answer": "conditions\u2014Random, Normal, and Independent\u2014is. important when constructing a confidence interval.",
      "question": "What are the three conditions for constructing a confidence interval for the population mean"
    },
    {
      "answer": "Regression trees are used in Statistics, Data Mining and Machine learning. It is a very important and powerful technique when it comes to predictive analysis [5] . The goal is to predict the value of target variable on the basis of several input attributes that act as nodes of the regression tree.",
      "question": "Which type of data is often Modelled using regression trees"
    },
    {
      "answer": "The C parameter trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors.",
      "question": "Which parameter in SVM is responsible for tradeoff between misclassification and simplicity of model"
    },
    {
      "answer": "Average-linkage is where the distance between each pair of observations in each cluster are added up and divided by the number of pairs to get an average inter-cluster distance. Average-linkage and complete-linkage are the two most popular distance metrics in hierarchical clustering.",
      "question": "How does Average Linkage work in Hierarchical Agglomerative clustering"
    },
    {
      "answer": "Each is essentially a component of the prior term. That is, machine learning is a subfield of artificial intelligence. Deep learning is a subfield of machine learning, and neural networks make up the backbone of deep learning algorithms.",
      "question": "Is neural network a part of machine learning"
    },
    {
      "answer": "Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e.g., points, lines or bars) contained in graphics. The goal is to communicate information clearly and efficiently to users. It is one of the steps in data analysis or data science.",
      "question": "What is data visualization and its techniques"
    },
    {
      "answer": "A data distribution is a function or a listing which shows all the possible values (or intervals) of the data. It also (and this is important) tells you how often each value occurs.",
      "question": "What does a distribution tell us about a set of data"
    },
    {
      "answer": "The correlation coefficient is a measure of the degree of linear association between two continuous variables, i.e. when plotted together, how close to a straight line is the scatter of points.  Both x and y must be continuous random variables (and Normally distributed if the hypothesis test is to be valid).",
      "question": "For correlation coefficient between two random variables to be a meaningful measure of their linear association do the variables need to be normally distributed"
    },
    {
      "answer": "A stochastic process is a family of random variables {X\u03b8}, where the parameter \u03b8 is drawn from an index set \u0398. For example, let's say the index set is \u201ctime\u201d.  One example of a stochastic process that evolves over time is the number of customers (X) in a checkout line.",
      "question": "What is a stochastic process provide an example"
    },
    {
      "answer": "The covariance between X and Y is defined as Cov(X,Y)=E[(X\u2212EX)(Y\u2212EY)]=E[XY]\u2212(EX)(EY).The covariance has the following properties:Cov(X,X)=Var(X);if X and Y are independent then Cov(X,Y)=0;Cov(X,Y)=Cov(Y,X);Cov(aX,Y)=aCov(X,Y);Cov(X+c,Y)=Cov(X,Y);Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z);more generally,",
      "question": "How do you find the covariance of a random variable"
    },
    {
      "answer": "The chi-square distribution curve is skewed to the right, and its shape depends on the degrees of freedom df. For df > 90, the curve approximates the normal distribution. Test statistics based on the chi-square distribution are always greater than or equal to zero.",
      "question": "What is the basic shape of the chi square distribution"
    },
    {
      "answer": "The Gini coefficient for the entire world has been estimated by various parties to be between 0.61 and 0.68.",
      "question": "What is the average Gini coefficient"
    },
    {
      "answer": "R-squared should accurately reflect the percentage of the dependent variable variation that the linear model explains. Your R2 should not be any higher or lower than this value.  However, if you analyze a physical process and have very good measurements, you might expect R-squared values over 90%.",
      "question": "What is an acceptable R squared value"
    },
    {
      "answer": "The decision rule is: Reject H0 if Z < 1.645. The decision rule is: Reject H0 if Z < -1.960 or if Z > 1.960. The complete table of critical values of Z for upper, lower and two-tailed tests can be found in the table of Z values to the right in \"Other Resources.\"",
      "question": "What is the rule for rejecting Ho in terms of Z"
    },
    {
      "answer": "Suggest Edits. Support Vector Machines (SVMs) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.",
      "question": "What is a linear SVM"
    },
    {
      "answer": "Unsupervised learning is the Holy Grail of Deep Learning. The goal of unsupervised learning is to create general systems that can be trained with little data.  Today Deep Learning models are trained on large supervised datasets. Meaning that for each data, there is a corresponding label.",
      "question": "Can deep learning be unsupervised"
    },
    {
      "answer": "1:1111:18Suggested clip \u00b7 91 secondsLimits of Functions of Two Variables - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the limit of a function with two variables"
    },
    {
      "answer": "Text classification using word embeddings and deep learning in python \u2014 classifying tweets from twitterSplit the data into text (X) and labels (Y)Preprocess X.Create a word embedding matrix from X.Create a tensor input from X.Train a deep learning model using the tensor inputs and labels (Y)More items\u2022",
      "question": "How do I use Word embeds for text classification"
    },
    {
      "answer": "Gaussian Distribution Function The nature of the gaussian gives a probability of 0.683 of being within one standard deviation of the mean. The mean value is a=np where n is the number of events and p the probability of any integer value of x (this expression carries over from the binomial distribution ).",
      "question": "What is the mean of a Gaussian distribution"
    },
    {
      "answer": "Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.",
      "question": "What is dimensional analysis and how do we use it"
    },
    {
      "answer": "Just so, the Poisson distribution deals with the number of occurrences in a fixed period of time, and the exponential distribution deals with the time between occurrences of successive events as time flows by continuously.",
      "question": "What is the relationship between Poisson and exponential distribution"
    },
    {
      "answer": "Regression analysis is used when you want to predict a continuous dependent variable from a number of independent variables. If the dependent variable is dichotomous, then logistic regression should be used.",
      "question": "Which method is used for predicting continuous dependent variable"
    },
    {
      "answer": "The second derivative may be used to determine local extrema of a function under certain conditions. If a function has a critical point for which f\u2032(x) = 0 and the second derivative is positive at this point, then f has a local minimum here.  This technique is called Second Derivative Test for Local Extrema.",
      "question": "Why do you use the second derivative test"
    },
    {
      "answer": "With cluster sampling, in contrast, the sample includes elements only from sampled clusters. Multistage sampling. With multistage sampling, we select a sample by using combinations of different sampling methods. For example, in Stage 1, we might use cluster sampling to choose clusters from a population.",
      "question": "What is the difference between cluster and multistage sampling"
    },
    {
      "answer": "In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.",
      "question": "What is minimum variance of an estimator"
    },
    {
      "answer": "Do not confuse statistical significance with practical importance.  However, a weak correlation can be statistically significant, if the sample size is large enough.",
      "question": "Can a weak correlation be significant"
    },
    {
      "answer": "In active learning teachers are facilitators rather than one way providers of information.  Other examples of active learning techniques include role-playing, case studies, group projects, think-pair-share, peer teaching, debates, Just-in-Time Teaching, and short demonstrations followed by class discussion.",
      "question": "What is an example of active learning"
    },
    {
      "answer": "Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.  Thus, attempting to make the model conform too closely to slightly inaccurate data can infect the model with substantial errors and reduce its predictive power.",
      "question": "What is meant by Overfitting of data"
    },
    {
      "answer": "ELIZA is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum.  As such, ELIZA was one of the first chatterbots and one of the first programs capable of attempting the Turing test.",
      "question": "What is Eliza in artificial intelligence"
    },
    {
      "answer": "The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image. It finds the direction of the largest increase from light to dark and the rate of change in that direction.",
      "question": "How do Sobel filters work"
    },
    {
      "answer": "A term-document matrix represents the processed text from a text analysis as a table or matrix where the rows represent the text responses, or documents, and the columns represent the words or phrases (the terms).  matrix).",
      "question": "What is text Matrix"
    },
    {
      "answer": "Non-probability sampling is often used because the procedures used to select units for inclusion in a sample are much easier, quicker and cheaper when compared with probability sampling. This is especially the case for convenience sampling.",
      "question": "Why do we use non probability sampling"
    },
    {
      "answer": "R is now used by over 50% of data miners. R, Python, and SQL were the most popular programming languages. Python, Lisp/Clojure, and Unix tools showest the highest growth in 2012, while Java and MATLAB slightly declined in popularity.",
      "question": "What language is used for data mining"
    },
    {
      "answer": "A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts. Stress and strain are both tensor quantities.  A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts.",
      "question": "What is tensor quantity"
    },
    {
      "answer": "Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression.",
      "question": "Is stochastic gradient descent linear"
    },
    {
      "answer": "The CAC ratio is calculated by looking at the quarter over quarter increase in gross margin divided by the total sales and marketing expenses for that quarter. Gross margin is the total revenue minus cost of goods sold.",
      "question": "How is CAC ratio calculated"
    },
    {
      "answer": "The experts predict that AI will outperform humans in the next 10 years in tasks such as translating languages (by 2024), writing high school essays (by 2026), and driving trucks (by 2027). But many other tasks will take much longer for machines to master.",
      "question": "Will artificial intelligence supersede human intelligence"
    },
    {
      "answer": "Whereas AI is preprogrammed to carry out a task that a human can but more efficiently, artificial general intelligence (AGI) expects the machine to be just as smart as a human.  A machine that was able to do this would be considered a fine example of AGI.",
      "question": "What is the difference between general artificial intelligence and artificial intelligence"
    },
    {
      "answer": "Any point directly on the y-axis has an X value of 0. Multiple Choice: In a simple Linear regression problem, r and b1. Explanation: r= correlation coefficient and b1= slope. If we have a downward sloping trend-line then that means we have a negative (or inverse) correlation coefficient.",
      "question": "What is the relationship between the linear correlation coefficient r and the slope b 1 of a regression line"
    },
    {
      "answer": "The name tells you how to calculate it. You subtract the regression-predicted values from the actual values, square them (to get rid of directionality), take their average, then take the square root of the average.",
      "question": "How do you evaluate the accuracy of a regression result"
    },
    {
      "answer": "Gradient Descent is the process of minimizing a function by following the gradients of the cost function. This involves knowing the form of the cost as well as the derivative so that from a given point you know the gradient and can move in that direction, e.g. downhill towards the minimum value.",
      "question": "What is gradient descent in logistic regression"
    },
    {
      "answer": "Poisson Formula. Suppose we conduct a Poisson experiment, in which the average number of successes within a given region is \u03bc. Then, the Poisson probability is: P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828.",
      "question": "How do you find the probability of a Poisson distribution"
    },
    {
      "answer": "Advantages of distributed representations Mapping efficiency: a micro-feature-based distributed representation often allows a simple mapping (that uses few connections or weights) to solve a task. For example, suppose we wish to classify 100 different colored shapes as to whether or not they are yellow.",
      "question": "What are the advantages of distributed representations"
    },
    {
      "answer": "As Justin Rising points out, the order statistics are clearly not independent of each other. . If the observations are independent and identically distributed from a continuous distribution, then any ordering of the samples is equally likely.",
      "question": "Are the order statistics independent"
    },
    {
      "answer": "The value to be gained from taking a decision. Net gain is calculated by adding together the expected value of each outcome and deducting the costs associated with the decision.",
      "question": "How do you calculate decision trees"
    },
    {
      "answer": "How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "How can Multicollinearity be reduced"
    },
    {
      "answer": "Each party in a dispute recognises that its own use of the concept is contested by those of other parties. To use an essentially contested concept means to use it against other users. To use such a concept means to use it aggresssively and defensively.",
      "question": "What is contested concept"
    },
    {
      "answer": "Use. Cluster sampling is typically used in market research. It's used when a researcher can't get information about the population as a whole, but they can get information about the clusters.  Cluster sampling is often more economical or more practical than stratified sampling or simple random sampling.",
      "question": "Why do we use cluster sampling"
    },
    {
      "answer": "0:082:33Suggested clip \u00b7 117 secondsHistogram Finding Frequency - Corbettmaths - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you read a relative frequency density histogram"
    },
    {
      "answer": "It is linear if there exists a function H(x) = \u03b20 + \u03b2T x such that h(x) = I(H(x) > 0). H(x) is also called a linear discriminant function. The decision boundary is therefore defined as the set {x \u2208 Rd : H(x)=0}, which corresponds to a (d \u2212 1)-dimensional hyperplane within the d-dimensional input space X.",
      "question": "What are the decision boundaries for linear discriminant analysis"
    },
    {
      "answer": "A good knowledge representation system must have properties such as: Representational Accuracy: It should represent all kinds of required knowledge. Inferential Adequacy: It should be able to manipulate the representational structures to produce new knowledge corresponding to the existing structure.",
      "question": "What are the properties of good knowledge representation techniques"
    },
    {
      "answer": "The example of reinforcement learning is your cat is an agent that is exposed to the environment. The biggest characteristic of this method is that there is no supervisor, only a real number or reward signal. Two types of reinforcement learning are 1) Positive 2) Negative.",
      "question": "What is reinforcement learning example"
    },
    {
      "answer": "Unsupervised Learning is the second type of machine learning, in which unlabeled data are used to train the algorithm, which means it used against data that has no historical labels.",
      "question": "What category of machine learning algorithm finds patterns in the data when the data is not labeled"
    },
    {
      "answer": "Convolutional Neural Networks (CNNs) is the most popular neural network model being used for image classification problem. The big idea behind CNNs is that a local understanding of an image is good enough.",
      "question": "What type of deep learning models are best suited for image recognition"
    },
    {
      "answer": "Pre-Interview PreparationDevelop a deep knowledge of data structures. You should understand and be able to talk about different data structures and their strengths, weaknesses, and how they compare to each other.  Understand Big O notation.  Know the major sorting algorithms.",
      "question": "How do I start preparing for data structures and algorithms"
    },
    {
      "answer": "The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.",
      "question": "Why do we use sigmoid function"
    },
    {
      "answer": "Streaming Data is data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously, and in small sizes (order of Kilobytes).",
      "question": "What does streaming data mean"
    },
    {
      "answer": "- Mode-The most repetitive number! - Median:The number in the MIDDLE when they are IN ORDER! - Mean- The AVERAGE OF ALL NUMBERS: You add up all the numbers then you divide it by the TOTAL NUMBER of NUMBERS! - Range - THE BIGGEST minus the Smallest!",
      "question": "What is the purpose of mean median mode and range"
    },
    {
      "answer": "The standard deviation of the sample mean \u02c9X that we have just computed is the standard deviation of the population divided by the square root of the sample size: \u221a10=\u221a20/\u221a2.",
      "question": "What is the formula for the standard deviation of the sampling distribution of the sample mean X"
    },
    {
      "answer": "Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B. {/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B\u2014but one event doesn't necessarily cause the other event to happen.",
      "question": "How do you tell the difference between correlation and causation"
    },
    {
      "answer": "Categories with a large difference between observed and expected values make a larger contribution to the overall chi-square statistic. In these results, the contribution values from each category sum to the overall chi-square statistic, which is 0.65.",
      "question": "What is the contribution to the chi square statistic"
    },
    {
      "answer": "A statistical hypothesis is a formal claim about a state of nature structured within the framework of a statistical model. For example, one could claim that the median time to failure from (acce]erated) electromigration of the chip population described in Section 6.1.",
      "question": "What is a statistical hypothesis example"
    },
    {
      "answer": "In this blog we will learn what is calibration and why and when we should use it. We calibrate our model when the probability estimate of a data point belonging to a class is very important. Calibration is comparison of the actual output and the expected output given by a system.",
      "question": "Why do we need calibration in machine learning"
    },
    {
      "answer": "Standard deviation (represented by the symbol sigma, \u03c3 ) shows how much variation or dispersion exists from the average (mean), or expected value. More precisely, it is a measure of the average distance between the values of the data in the set and the mean.",
      "question": "How do you explain standard deviation in statistics"
    },
    {
      "answer": "So the difference is in the way the future reward is found. In Q-learning it's simply the highest possible action that can be taken from state 2, and in SARSA it's the value of the actual action that was taken.",
      "question": "What is the difference between Q learning and Sarsa"
    },
    {
      "answer": "Fixed effects are variables that are constant across individuals; these variables, like age, sex, or ethnicity, don't change or change at a constant rate over time. They have fixed effects; in other words, any change they cause to an individual is the same.",
      "question": "What does fixed effect mean in statistics"
    },
    {
      "answer": "The number of outcomes in non-overlapping intervals are independent.   The probability of two or more outcomes in a sufficiently short interval is virtually zero.   The probability of exactly one outcome in a sufficiently short interval or small region is proportional to the length of the interval or region.",
      "question": "How do I know if my data is Poisson distributed"
    },
    {
      "answer": "A Bayesian network (also known as a Bayes network, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG).  Efficient algorithms can perform inference and learning in Bayesian networks.",
      "question": "What does Bayesian networks mean in Machine Learning"
    },
    {
      "answer": "Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.",
      "question": "What is validation in machine learning"
    },
    {
      "answer": "Edge detection is an image processing technique for finding the boundaries of objects within images. It works by detecting discontinuities in brightness. Edge detection is used for image segmentation and data extraction in areas such as image processing, computer vision, and machine vision.",
      "question": "Why do we need edge detection"
    },
    {
      "answer": "Using P values and Significance Levels Together If your P value is less than or equal to your alpha level, reject the null hypothesis. The P value results are consistent with our graphical representation. The P value of 0.03112 is significant at the alpha level of 0.05 but not 0.01.",
      "question": "Is the P value the same as Alpha"
    },
    {
      "answer": "A GLM is absolutely a statistical model, but statistical models and machine learning techniques are not mutually exclusive. In general, statistics is more concerned with inferring parameters, whereas in machine learning, prediction is the ultimate goal.",
      "question": "Are generalized linear models statistical methods or machine learning methods"
    },
    {
      "answer": "We input the data in the learning algorithm as a set of inputs, which is called as Features, denoted by X along with the corresponding outputs, which is indicated by Y, and the algorithm learns by comparing its actual production with correct outputs to find errors. It then modifies the model accordingly.",
      "question": "What data would be used as input to the machine learning algorithms"
    },
    {
      "answer": "Kappa is widely used on Twitch in chats to signal you are being sarcastic or ironic, are trolling, or otherwise playing around with someone. It is usually typed at the end of a string of text, but, as can often the case on Twitch, it is also often used on its own or repeatedly (to spam someone).",
      "question": "What is Kappa used for"
    },
    {
      "answer": "When q-learning is performed we create what's called a q-table or matrix that follows the shape of [state, action] and we initialize our values to zero. We then update and store our q-values after an episode. This q-table becomes a reference table for our agent to select the best action based on the q-value.",
      "question": "What does the Q table in Q learning algorithm represent"
    },
    {
      "answer": "A commonly used rule says that a data point is an outlier if it is more than 1.5 \u22c5 IQR 1.5\\cdot \\text{IQR} 1. 5\u22c5IQR1, point, 5, dot, start text, I, Q, R, end text above the third quartile or below the first quartile.",
      "question": "How do you determine if there are outliers in a data set"
    },
    {
      "answer": "Randomization as a method of experimental control has been extensively used in human clinical trials and other biological experiments. It prevents the selection bias and insures against the accidental bias. It produces the comparable groups and eliminates the source of bias in treatment assignments.",
      "question": "Why is it important to randomise participants in a study"
    },
    {
      "answer": "Two-sample t-test is used when the data of two samples are statistically independent, while the paired t-test is used when data is in the form of matched pairs.  To use the two-sample t-test, we need to assume that the data from both samples are normally distributed and they have the same variances.",
      "question": "What is the difference between at test and a paired t test"
    },
    {
      "answer": "The formula to calculate the test statistic comparing two population means is, Z= ( x - y )/\u221a(\u03c3x2/n1 + \u03c3y2/n2). In order to calculate the statistic, we must calculate the sample means ( x and y ) and sample standard deviations (\u03c3x and \u03c3y) for each sample separately. n1 and n2 represent the two sample sizes.",
      "question": "How do you find the test statistic"
    },
    {
      "answer": "One reason you should consider when using ReLUs is, that they can produce dead neurons. That means that under certain circumstances your network can produce regions in which the network won't update, and the output is always 0.",
      "question": "Why is ReLu used in hidden layers"
    },
    {
      "answer": "The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the \u201cerrors\u201d) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences.",
      "question": "How do you interpret mean square error"
    },
    {
      "answer": "'Learning to learn' is the ability to pursue and persist in learning, to organise one's own learning, including through effective management of time and information, both individually and in groups.",
      "question": "What is the meaning of learning to learn"
    },
    {
      "answer": "Back-propagation is the process of calculating the derivatives and gradient descent is the process of descending through the gradient, i.e. adjusting the parameters of the model to go down through the loss function.",
      "question": "What is the difference between Backpropagation and gradient descent"
    },
    {
      "answer": "To measure the relationship between numeric variable and categorical variable with > 2 levels you should use eta correlation (square root of the R2 of the multifactorial regression). If the categorical variable has 2 levels, point-biserial correlation is used (equivalent to the Pearson correlation).",
      "question": "How do you find the correlation between categorical variables"
    },
    {
      "answer": "A Z-score is a score which indicates how many standard deviations an observation is from the mean of the distribution. Z-scores tend to be used mainly in the context of the normal curve, and their interpretation based on the standard normal table.  Non-normal distributions can also be transformed into sets of Z-scores.",
      "question": "Can z score be used for non normal distribution"
    },
    {
      "answer": "A normal distribution is determined by two parameters the mean and the variance.  Now the standard normal distribution is a specific distribution with mean 0 and variance 1. This is the distribution that is used to construct tables of the normal distribution.",
      "question": "What is the difference between a normal distribution and a standard normal distribution"
    },
    {
      "answer": "The standard error of estimate, Se indicates approximately how much error you make when you use the predicted value for Y (on the least-squares line) instead of the actual value of Y.",
      "question": "What does the standard error of the estimate represent"
    },
    {
      "answer": "The component form of simple exponential smoothing is given by: Forecast equation^yt+h|t=\u2113tSmoothing equation\u2113t=\u03b1yt+(1\u2212\u03b1)\u2113t\u22121, Forecast equation y ^ t + h | t = \u2113 t Smoothing equation \u2113 t = \u03b1 y t + ( 1 \u2212 \u03b1 ) \u2113 t \u2212 1 , where \u2113t is the level (or the smoothed value) of the series at time t .",
      "question": "What is the exponential smoothing formula"
    },
    {
      "answer": "The Agglomerative Hierarchical Clustering is the most common type of hierarchical clustering used to group objects in clusters based on their similarity.",
      "question": "Which type of hierarchical clustering algorithm is more commonly used"
    },
    {
      "answer": "The reasoning is the mental process of deriving logical conclusion and making predictions from available knowledge, facts, and beliefs.  In artificial intelligence, the reasoning is essential so that the machine can also think rationally as a human brain, and can perform like a human.",
      "question": "What is reasoning in artificial intelligence"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "What are the uses of eigenvalues"
    },
    {
      "answer": "The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.  The learning rate may be the most important hyperparameter when configuring your neural network.",
      "question": "What is learning rate in CNN"
    },
    {
      "answer": "The most intuitive way to increase the frequency resolution of an FFT is to increase the size while keeping the sampling frequency constant. Doing this will increase the number of frequency bins that are created, decreasing the frequency difference between each.",
      "question": "How can frequency resolution be improved"
    },
    {
      "answer": "The \"Linear-by-Linear\" test is for ordinal (ordered) categories and assumes equal and ordered intervals. The Linear-by-Linear Association test is a test for trends in a larger-than-2x2 table. Its value is shown to be significant and indicates that income tends to rise with values of \"male\" (i.e., from 0 to 1).",
      "question": "What is linear by linear association chi square test"
    },
    {
      "answer": "In logistic regression, as with any flavour of regression, it is fine, indeed usually better, to have continuous predictors. Given a choice between a continuous variable as a predictor and categorising a continuous variable for predictors, the first is usually to be preferred.",
      "question": "Can you use continuous variables in logistic regression"
    },
    {
      "answer": "From the menus of SPSS choose: Analyze Scale Multidimensional Scaling\u2026 In Distances, select either Data are distances or Create distances from data. If your data are distances, you must select at least four numeric variables for analysis, and you can click Shape to indicate the shape of the distance matrix.",
      "question": "How do you do multidimensional scaling in SPSS"
    },
    {
      "answer": "A local minimum of a function (typically a cost function in machine learning, which is something we want to minimize based on empirical data) is a point in the domain of a function that has the following property: the function evaluates to a greater value at every other point in a neighborhood around the local minimum",
      "question": "What is local minima in machine learning"
    },
    {
      "answer": "There are four types of classification. They are Geographical classification, Chronological classification, Qualitative classification, Quantitative classification.",
      "question": "What are the types of classification in statistics"
    },
    {
      "answer": "TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf. data. Datasets , enabling easy-to-use and high-performance input pipelines. To get started see the guide and our list of datasets.",
      "question": "What is dataset in TensorFlow"
    },
    {
      "answer": "Eigenvectors are a special set of vectors associated with a linear system of equations (i.e., a matrix equation) that are sometimes also known as characteristic vectors, proper vectors, or latent vectors (Marcus and Minc 1988, p.  Each eigenvector is paired with a corresponding so-called eigenvalue.",
      "question": "What are eigenvectors of a matrix"
    },
    {
      "answer": "The standard deviation is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance.  If the data points are further from the mean, there is a higher deviation within the data set; thus, the more spread out the data, the higher the standard deviation.",
      "question": "What mean standard deviation"
    },
    {
      "answer": "The (statistical) design of experiments (DOE) is an efficient procedure for planning experiments so that the data obtained can be analyzed to yield valid and objective conclusions. DOE begins with determining the objectives of an experiment and selecting the process factors for the study.",
      "question": "What is statistical design of experiments"
    },
    {
      "answer": "With the LassoCV, RidgeCV, and Linear Regression machine learning algorithms.Define the problem.Gather the data.Clean & Explore the data.Model the data.Evaluate the model.Answer the problem.",
      "question": "How do you predict using machine learning"
    },
    {
      "answer": "Bootstrapping is a type of resampling where large numbers of smaller samples of the same size are repeatedly drawn, with replacement, from a single original sample. For example, let's say your sample was made up of ten numbers: 49, 34, 21, 18, 10, 8, 6, 5, 2, 1. You randomly draw three numbers 5, 1, and 49.",
      "question": "What is an example of bootstrapping"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.",
      "question": "What is the difference between mean and standard deviation"
    },
    {
      "answer": "A simple definition of a sampling frame is the set of source materials from which the sample is selected. The definition also encompasses the purpose of sampling frames, which is to provide a means for choosing the particular members of the target population that are to be interviewed in the survey.",
      "question": "What is the purpose of sampling frame"
    },
    {
      "answer": "A statistic is a characteristic of a sample. Generally, a statistic is used to estimate the value of a population parameter. For instance, suppose we selected a random sample of 100 students from a school with 1000 students. The average height of the sampled students would be an example of a statistic.",
      "question": "What is an example of a statistic in the study"
    },
    {
      "answer": "A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.",
      "question": "What is a random variable in probability theory"
    },
    {
      "answer": "(When does a random variable have a Poisson YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the Poisson distribution"
    },
    {
      "answer": "Bayesian networks are a type of Probabilistic Graphical Model that can be used to build models from data and/or expert opinion. They can be used for a wide range of tasks including prediction, anomaly detection, diagnostics, automated insight, reasoning, time series prediction and decision making under uncertainty.",
      "question": "How the Bayesian network can be used"
    },
    {
      "answer": "A common pattern is the bell-shaped curve known as the \"normal distribution.\" In a normal or \"typical\" distribution, points are as likely to occur on one side of the average as on the other. Note that other distributions look similar to the normal distribution.",
      "question": "What is a normal distribution in a histogram"
    },
    {
      "answer": "3.1 Comparison MatrixClassification AlgorithmsAccuracyF1-ScoreNa\u00efve Bayes80.11%0.6005Stochastic Gradient Descent82.20%0.5780K-Nearest Neighbours83.56%0.5924Decision Tree84.23%0.63083 more rows\u2022",
      "question": "Which algorithm is best for classification"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "Which is better supervised or unsupervised learning"
    },
    {
      "answer": "Listen to pronunciation. (NOR-mul raynj) In medicine, a set of values that a doctor uses to interpret a patient's test results. The normal range for a given test is based on the results that are seen in 95% of the healthy population.",
      "question": "What does normal range mean"
    },
    {
      "answer": "Now, three variable case it is less clear for me. An intuitive definition for covariance function would be Cov(X,Y,Z)=E[(x\u2212E[X])(y\u2212E[Y])(z\u2212E[Z])], but instead the literature suggests using covariance matrix that is defined as two variable covariance for each pair of variables.",
      "question": "How do you find the covariance of three variables"
    },
    {
      "answer": "The simplest example of a non-linear operator (non-linear functional) is a real-valued function of a real argument other than a linear function.  Under other restrictions on K(t,s,u) an Urysohn operator acts on other spaces, for instance, L2[a,b] or maps one Orlicz space LM1[a,b] into another LM2[a,b].",
      "question": "Which is not a linear operator"
    },
    {
      "answer": "A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.",
      "question": "What is random variables in probability"
    },
    {
      "answer": "Multiple regression estimates how the changes in each predictor variable relate to changes in the response variable.  What does it mean to control for the variables in the model? It means that when you look at the effect of one variable in the model, you are holding constant all of the other predictors in the model.",
      "question": "What does it mean to control for a variable in multiple regression"
    },
    {
      "answer": "In a Data Mining sense, the similarity measure is a distance with dimensions describing object features. That means if the distance among two data points is small then there is a high degree of similarity among the objects and vice versa. The similarity is subjective and depends heavily on the context and application.",
      "question": "What are the measures of similarity in data mining"
    },
    {
      "answer": "Here is step by step on how to compute K-nearest neighbors KNN algorithm:Determine parameter K = number of nearest neighbors.Calculate the distance between the query-instance and all the training samples.Sort the distance and determine nearest neighbors based on the K-th minimum distance.More items",
      "question": "How is KNN algorithm calculated"
    },
    {
      "answer": "2:194:05Suggested clip \u00b7 97 secondsChoosing Intervals for a Histogram - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you determine the intervals for a histogram"
    },
    {
      "answer": "Automatic thresholding Select initial threshold value, typically the mean 8-bit value of the original image. Divide the original image into two portions; Pixel values that are less than or equal to the threshold; background. Pixel values greater than the threshold; foreground.",
      "question": "How is the threshold value calculated in image processing"
    },
    {
      "answer": "Since both drifts involve a statistical change in the data, the best approach to detect them is by monitoring its statistical properties, the model's predictions, and their correlation with other factors.",
      "question": "How do you detect data Drifting"
    },
    {
      "answer": "The process of adjusting the weights and threshold of the ADALINE network is based on a learning algorithm named the Delta rule (Widrow and Hoff 1960) or Widrow-Hoff learning rule, also known as LMS (Least Mean Square ) algorithm or Gradient Descent method.",
      "question": "What is the delta rule of Adaline network"
    },
    {
      "answer": "It's a cost function that is used as loss for machine learning models, telling us how bad it's performing, the lower the better. Also it's much easier to reason about the loss this way, to be consistent with the rule of loss functions approaching 0 as the model gets better.",
      "question": "Why do we use negative log likelihood"
    },
    {
      "answer": "The learning algorithm of the Hopfield network is unsupervised, meaning that there is no \u201cteacher\u201d telling the network what is the correct output for a certain input.",
      "question": "Is Hopfield network supervised or unsupervised"
    },
    {
      "answer": "Recall is the number of relevant documents retrieved by a search divided by the total number of existing relevant documents, while precision is the number of relevant documents retrieved by a search divided by the total number of documents retrieved by that search.",
      "question": "What is the difference between precision and recall"
    },
    {
      "answer": "So that we only have to have one area table, rather than an infinite number of area tables. Of course, technology can find area under any normal curve and so tables of values are a bit archaic.",
      "question": "Why do we Standardise normal distribution"
    },
    {
      "answer": "When working with a measurement variable, the Kruskal\u2013Wallis test starts by substituting the rank in the overall data set for each measurement value. The smallest value gets a rank of 1, the second-smallest gets a rank of 2, etc.",
      "question": "How do you rank data for the Kruskal Wallis test"
    },
    {
      "answer": "The Poisson distribution is used to describe the distribution of rare events in a large population. For example, at any particular time, there is a certain probability that a particular cell within a large population of cells will acquire a mutation.",
      "question": "When should I use Poisson distribution"
    },
    {
      "answer": "In class limit, the upper extreme value of the first class interval and the lower extreme value of the next class interval will not be equal. In class boundary, the upper extreme value of the first class interval and the lower extreme value of the next class interval will be equal.",
      "question": "What is the difference between class interval and class boundary"
    },
    {
      "answer": "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.",
      "question": "What is convolutional neural network algorithm"
    },
    {
      "answer": "Multivariate ANOVA (MANOVA) extends the capabilities of analysis of variance (ANOVA) by assessing multiple dependent variables simultaneously. ANOVA statistically tests the differences between three or more group means.  This statistical procedure tests multiple dependent variables at the same time.",
      "question": "Is Anova Multivariate analysis"
    },
    {
      "answer": "A frequent problem in estimating logistic regression models is a failure of the likelihood maximization algorithm to converge. In most cases, this failure is a consequence of data patterns known as complete or quasi-complete separation.  Log-likelihood as a function of the slope, quasi-complete separation.",
      "question": "Is logistic regression guaranteed to converge"
    },
    {
      "answer": "Group projects, discussions, and writing are examples of active learning, because they involve doing something.",
      "question": "Which of the following are examples of active learning"
    },
    {
      "answer": "As a hypothetical example of systematic sampling, assume that in a population of 10,000 people, a statistician selects every 100th person for sampling. The sampling intervals can also be systematic, such as choosing a new sample to draw from every 12 hours.",
      "question": "What is systematic sampling example"
    },
    {
      "answer": "Mathematically speaking, the regret is expressed as the difference between the payoff (reward or return) of a possible action and the payoff of the action that has been actually taken. If we denote the payoff function as u the formula becomes: regret = u(possible action) - u(action taken)",
      "question": "What is regret in reinforcement learning"
    },
    {
      "answer": "Classification/Recognition: Given an image with an object , find out what that object is.  In other words, classify it in a class from a set of predefined categories. Localization : Find where the object is and draw a bounding box around it.",
      "question": "What is localization in deep learning"
    },
    {
      "answer": "Definition. Data Partitioning is the technique of distributing data across multiple tables, disks, or sites in order to improve query processing performance or increase database manageability.",
      "question": "What is partitioning of data"
    },
    {
      "answer": "Definition: Gamma distribution is a distribution that arises naturally in processes for which the waiting times between events are relevant. It can be thought of as a waiting time between Poisson distributed events.",
      "question": "What does gamma distribution mean"
    },
    {
      "answer": "Partial least squares regression (PLS regression) is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the",
      "question": "What is PLS in statistics"
    },
    {
      "answer": "Writing up resultsFirst, present descriptive statistics in a table.  Organize your results in a table (see Table 3) stating your dependent variable (dependent variable = YES) and state that these are \"logistic regression results.\"  When describing the statistics in the tables, point out the highlights for the reader.More items",
      "question": "How do you write logistic regression results"
    },
    {
      "answer": "A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.",
      "question": "What is a probability distribution in statistics"
    },
    {
      "answer": "The sample variance is an estimator for the population variance. When applied to sample data, the population variance formula is a biased estimator of the population variance: it tends to underestimate the amount of variability.  We are using one fitted value (sample mean) in our estimate of the variance.",
      "question": "Why is the formula of sample variance different from population variance"
    },
    {
      "answer": "Correlation measures linearity between X and Y. If \u03c1(X,Y) = 0 we say that X and Y are \u201cuncorrelated.\u201d If two variables are independent, then their correlation will be 0. However, like with covariance.",
      "question": "What is the correlation between two independent random variables"
    },
    {
      "answer": "Detection theory or signal detection theory is a means to measure the ability to differentiate between information-bearing patterns (called stimulus in living organisms, signal in machines) and random patterns that distract from the information (called noise, consisting of background stimuli and random activity of the",
      "question": "What is noise in signal detection theory"
    },
    {
      "answer": "A histogram shows bars representing numerical values by range of value. A bar chart shows categories, not numbers, with bars indicating the amount of each category. Histogram example: student's ages, with a bar showing the number of students in each year.",
      "question": "What can you tell from a histogram"
    },
    {
      "answer": "Discrete random variables can only take on values from a countable set of numbers such as the integers or some subset of integers. (Usually, they can't be fractions.)",
      "question": "Can a discrete variable take any fractional value"
    },
    {
      "answer": "Softmax Thus sigmoid is widely used for binary classification problems. While building a network for a multiclass problem, the output layer would have as many neurons as the number of classes in the target. For instance if you have three classes, there would be three neurons in the output layer.",
      "question": "Which activation function is used for binary classification"
    },
    {
      "answer": "Best Image Processing Projects CollectionLicense plate recognition.Face Emotion recognition.Face recognition.Cancer detection.Object detection.Pedestrian detection.Lane detection for ADAS.Blind assistance systems.More items",
      "question": "Whatt are best image processing ideas"
    },
    {
      "answer": "A single object of the world from which a model will be learned, or on which a model will be used (e.g., for prediction). In most machine learning work, instances are described by feature vectors; some work uses more complex representations (e.g., containing relations between instances or between parts of instances).",
      "question": "What is an instance in machine learning"
    },
    {
      "answer": "First multiply the critical value by the standard deviation. Then divide this result by the error from Step 1. Now square this result. This result is the sample size.",
      "question": "How do you find the sample size when given the mean and standard deviation"
    },
    {
      "answer": "The coefficient of determination is a measurement used to explain how much variability of one factor can be caused by its relationship to another related factor. This correlation, known as the \"goodness of fit,\" is represented as a value between 0.0 and 1.0.",
      "question": "What does the coefficient of determination tell you"
    },
    {
      "answer": "Box plots divide the data into sections that each contain approximately 25% of the data in that set. Box plots are useful as they provide a visual summary of the data enabling researchers to quickly identify mean values, the dispersion of the data set, and signs of skewness.",
      "question": "What is the point of a box plot"
    },
    {
      "answer": "The general idea is that machine learning, while not always the perfect choice, can be powerful in modeling time series data due to its ability to handle non-linear data. The feature engineering applied to the time series data in a machine learning approach is the key to how successful the model will be.",
      "question": "Data Science Can machine learning be used for time series analysis"
    },
    {
      "answer": "Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them. Bivariate analysis can be helpful in testing simple hypotheses of association.",
      "question": "What is the use of bivariate analysis"
    },
    {
      "answer": "Model specification refers to the determination of which independent variables should be included in or excluded from a regression equation.  A multiple regression model is, in fact, a theoretical statement about the causal relationship between one or more independent variables and a dependent variable.",
      "question": "What is a model in regression analysis"
    },
    {
      "answer": "The steps in grouping may be summarized as follows:Decide on the number of classes.Determine the range, i.e., the difference between the highest and lowest observations in the data.Divide range by the number of classes to estimate approximate size of the interval (h).More items",
      "question": "How do you find the class interval in a frequency table"
    },
    {
      "answer": "A joint probability distribution shows a probability distribution for two (or more) random variables. Instead of events being labeled A and B, the norm is to use X and Y. The formal definition is: f(x,y) = P(X = x, Y = y) The whole point of the joint distribution is to look for a relationship between two variables.",
      "question": "What is joint distribution in statistics"
    },
    {
      "answer": "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed.  Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.",
      "question": "Why is the word deep used in deep learning"
    },
    {
      "answer": "How Change Detection WorksDeveloper updates the data model, e.g. by updating a component binding.Angular detects the change.Change detection checks every component in the component tree from top to bottom to see if the corresponding model has changed.If there is a new value, it will update the component's view (DOM)",
      "question": "How does change detection work in angular"
    },
    {
      "answer": "MLP usually means many layers and can be supervised with labels. RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).  RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).",
      "question": "Whats the difference between Multilayer Perceptron and Restricted Boltzmann Machine"
    },
    {
      "answer": "Poisson Formula. P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to \u03bc . The variance is also equal to \u03bc .",
      "question": "What is mean in Poisson distribution"
    },
    {
      "answer": "Vectors have many real-life applications, including situations involving force or velocity. For example, consider the forces acting on a boat crossing a river. The boat's motor generates a force in one direction, and the current of the river generates a force in another direction. Both forces are vectors.",
      "question": "What are some applications of vectors in real life"
    },
    {
      "answer": "Data quality is important when applying Artificial Intelligence techniques, because the results of these solutions will be as good or bad as the quality of the data used.  The algorithms that feed systems based on Artificial Intelligence can only assume that the data to be analyzed are reliable.",
      "question": "Why is data important in AI"
    },
    {
      "answer": "The number of input variables or features for a dataset is referred to as its dimensionality.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.",
      "question": "What is Dimension machine learning"
    },
    {
      "answer": "The Real World is a term by the redpills to refer to reality, the true physical world and life outside the Matrix.",
      "question": "What is the real world in the Matrix"
    },
    {
      "answer": "Weights and biases (commonly referred to as w and b) are the learnable parameters of a machine learning model.  When the inputs are transmitted between neurons, the weights are applied to the inputs along with the bias. A neuron. Weights control the signal (or the strength of the connection) between two neurons.",
      "question": "What is a weight in machine learning"
    },
    {
      "answer": "First, let's review how to calculate the population standard deviation:Calculate the mean (simple average of the numbers).For each number: Subtract the mean. Square the result.Calculate the mean of those squared differences.  Take the square root of that to obtain the population standard deviation.",
      "question": "How do you find the population standard deviation"
    },
    {
      "answer": "A Convolutional Neural Networks Introduction so to speak.Step 1: Convolution Operation.  Step 1(b): ReLU Layer.  Step 2: Pooling.  Step 3: Flattening.  Step 4: Full Connection.  Step 1 - Convolution Operation.  Step 1(b): The Rectified Linear Unit (ReLU)  Step 2 - Max Pooling.More items\u2022",
      "question": "What are the steps in convolution neural network"
    },
    {
      "answer": "In computational learning theory, probably approximately correct (PAC) learning is a framework for mathematical analysis of machine learning.",
      "question": "What is PAC in machine learning"
    },
    {
      "answer": "The disadvantage of the ANOVA F-test is that if we reject the null hypothesis, we do not know which treatments can be said to be significantly different from the others, nor, if the F-test is performed at level \u03b1, can we state that the treatment pair with the greatest mean difference is significantly different at level",
      "question": "What is the limitation of the F ratio in Anova"
    },
    {
      "answer": "The difference between forward and backward chaining is: Backward chaining starts with a goal and then searches back through inference rules to find the facts that support the goal. Forward chaining starts with facts and searches forward through the rules to find a desired goal.",
      "question": "What is the difference between forward and backward chaining in artificial intelligence"
    },
    {
      "answer": "Hypothesis Testing \u2014 2-tailed testSpecify the Null(H0) and Alternate(H1) hypothesis.Choose the level of Significance(\u03b1)Find Critical Values.Find the test statistic.Draw your conclusion.",
      "question": "How do you do a two sided hypothesis test"
    },
    {
      "answer": "The basic idea behind a neural network is to simulate (copy in a simplified but reasonably faithful way) lots of densely interconnected brain cells inside a computer so you can get it to learn things, recognize patterns, and make decisions in a humanlike way.",
      "question": "How does a neural network function"
    },
    {
      "answer": "We use binary cross-entropy loss for classification models which output a probability p. The range of the sigmoid function is [0, 1] which makes it suitable for calculating probability.",
      "question": "Which loss function is used for binary classification"
    },
    {
      "answer": "The uniform distribution defines equal probability over a given range for a continuous distribution. For this reason, it is important as a reference distribution. One of the most important applications of the uniform distribution is in the generation of random numbers.",
      "question": "What is the use of uniform distribution"
    },
    {
      "answer": "Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample. Thus it gives the probability of getting r events out of n trials.",
      "question": "What is the difference between binomial and normal distribution"
    },
    {
      "answer": "Given that the range can easily be computed with information on the maximum and minimum value of the data set, users requiring only a rough indication of the data may prefer to use this indicator over more sophisticated measures of spread, like the standard deviation.",
      "question": "What are the uses of range in statistics"
    },
    {
      "answer": "Nonparametric tests are also called distribution-free tests because they don't assume that your data follow a specific distribution. You may have heard that you should use nonparametric tests when your data don't meet the assumptions of the parametric test, especially the assumption about normally distributed data.",
      "question": "When should nonparametric statistics be used"
    },
    {
      "answer": "Ground truth is a term used in statistics and machine learning that means checking the results of machine learning for accuracy against the real world. The term is borrowed from meteorology, where \"ground truth\" refers to information obtained on site.",
      "question": "What is ground truth in AI"
    },
    {
      "answer": "The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population. In the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.",
      "question": "What does the law of large numbers mean"
    },
    {
      "answer": "Stochastic vs. For example, a stochastic variable is a random variable. A stochastic process is a random process. Typically, random is used to refer to a lack of dependence between observations in a sequence. For example, the rolls of a fair die are random, so are the flips of a fair coin.",
      "question": "What is the difference between random and stochastic"
    },
    {
      "answer": "Descriptive analytics is a statistical method that is used to search and summarize historical data in order to identify patterns or meaning.",
      "question": "What are descriptive analytics"
    },
    {
      "answer": "8 Examples of Artificial IntelligenceGoogle Maps and Ride-Hailing Applications. One doesn't have to put much thought into traveling to a new destination anymore.  Face Detection and Recognition.  Text Editors or Autocorrect.  Search and Recommendation Algorithms.  Chatbots.  Digital Assistants.  Social Media.  E-Payments.",
      "question": "What are some examples of artificial intelligence"
    },
    {
      "answer": "Shift-invariance: this means that if we shift the input in time (or shift the entries in a vector) then the output is shifted by the same amount.",
      "question": "What is shift invariance in a convolutional neural network CNN"
    },
    {
      "answer": "bucketized_column. Represents discretized dense input bucketed by boundaries .",
      "question": "What do you use the TF Feature_column Bucketized_column function for"
    },
    {
      "answer": "Negative binomial regression \u2013 Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean.",
      "question": "When would you use a negative binomial distribution"
    },
    {
      "answer": "Covariance measures the directional relationship between the returns on two assets. A positive covariance means that asset returns move together while a negative covariance means they move inversely.",
      "question": "How do you explain covariance"
    },
    {
      "answer": "A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.",
      "question": "What is a sampling error in research"
    },
    {
      "answer": "The marketplace for predictive analytics software has ballooned: G2Crowd records 92 results in the category. Pricing varies substantially based on the number of users and, in some cases, amount of data, but generally starts around $1,000 per year, though it can easily scale into six figures.",
      "question": "How much does Predictive Analytics cost"
    },
    {
      "answer": "Denying the antecedent, sometimes also called inverse error or fallacy of the inverse, is a formal fallacy of inferring the inverse from the original statement. It is committed by reasoning in the form: If P, then Q. Therefore, if not P, then not Q.",
      "question": "What is denying the antecedent in relation to a propositional fallacy"
    },
    {
      "answer": "An estimate of a population parameter may be expressed in two ways: Point estimate. A point estimate of a population parameter is a single value of a statistic. For example, the sample mean x is a point estimate of the population mean \u03bc.",
      "question": "What are the methods of estimation in statistics"
    },
    {
      "answer": "4:306:35Suggested clip \u00b7 77 secondsMarginal PDF from Joint PDF - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the marginal density function"
    },
    {
      "answer": "It might take about 2-4 hours of coding and 1-2 hours of training if done in Python and Numpy (assuming sensible parameter initialization and a good set of hyperparameters). No GPU required, your old but gold CPU on a laptop will do the job. Longer training time is expected if the net is deeper than 2 hidden layers.",
      "question": "How long do neural networks take to train"
    },
    {
      "answer": "The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions. Factor analysis can be used to simplify data, such as reducing the number of variables in regression models.",
      "question": "What is the purpose of factor analysis"
    },
    {
      "answer": "Neural network regularization is a technique used to reduce the likelihood of model overfitting. There are several forms of regularization. The most common form is called L2 regularization.  L2 regularization tries to reduce the possibility of overfitting by keeping the values of the weights and biases small.",
      "question": "What is l2 regularization in neural networks"
    },
    {
      "answer": "An Iterator is an object that can be used to loop through collections, like ArrayList and HashSet. It is called an \"iterator\" because \"iterating\" is the technical term for looping. To use an Iterator, you must import it from the java.",
      "question": "What is the use of iterator"
    },
    {
      "answer": "Some additional simple scoring methods include:Counts. Count the number of times each word appears in a document.Frequencies. Calculate the frequency that each word appears in a document out of all the words in the document.",
      "question": "How do you calculate bag words"
    },
    {
      "answer": "LSTMs solve the problem using a unique additive gradient structure that includes direct access to the forget gate's activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process.",
      "question": "How does Lstm overcomes vanishing gradient problem"
    },
    {
      "answer": "In its simplest form, the sigmoid is a representation of time (on the horizontal axis) and activity (on the vertical axis). The wonder of this curve is that it really describes most phenomena, regardless of type.  The phenomenon experiences sharp growth. It hits a maturity phase where growth slows, and then stops.",
      "question": "What does a sigmoid curve mean"
    },
    {
      "answer": "There are two main reasons to use logarithmic scales in charts and graphs. The first is to respond to skewness towards large values; i.e., cases in which one or a few points are much larger than the bulk of the data. The second is to show percent change or multiplicative factors.",
      "question": "Why would you use a logarithmic scale"
    },
    {
      "answer": "Symmetrical distribution occurs when the values of variables occur at regular frequencies and the mean, median and mode occur at the same point. In graph form, symmetrical distribution often appears as a bell curve. If a line were drawn dissecting the middle of the graph, it would show two sides that mirror each other.",
      "question": "What is symmetric data distribution"
    },
    {
      "answer": "(i) The value of dimensionless constants cannot be determined by this method. (ii) This method cannot be applied to equations involving exponential and trigonometric functions. (iii) It cannot be applied to an equation involving more than three physical quantities.",
      "question": "What are the advantages and disadvantages of Dimensional Analysis"
    },
    {
      "answer": "Conclusion. Human intelligence revolves around adapting to the environment using a combination of several cognitive processes. The field of Artificial intelligence focuses on designing machines that can mimic human behavior. However, AI researchers are able to go as far as implementing Weak AI, but not the Strong AI.",
      "question": "What is the difference between intelligence and artificial intelligence"
    },
    {
      "answer": "To write a null hypothesis, first start by asking a question. Rephrase that question in a form that assumes no relationship between the variables. In other words, assume a treatment has no effect. Write your hypothesis in a way that reflects this.",
      "question": "How do you write a hypothesis and null hypothesis"
    },
    {
      "answer": "In simple words, stemming technique only looks at the form of the word whereas lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word.",
      "question": "What is the difference between stemming and Lemmatization"
    },
    {
      "answer": "Coefficients of linear discriminants: Shows the linear combination of predictor variables that are used to form the LDA decision rule. for example, LD1 = 0.91*Sepal.",
      "question": "What is coefficients of linear Discriminants"
    },
    {
      "answer": "The higher the number of features, the harder it gets to visualize the training set and then work on it.  Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables. It can be divided into feature selection and feature extraction.",
      "question": "How does dimensionality reduction work"
    },
    {
      "answer": "Both indices take values from zero to one. In a similarity index, a value of 1 means that the two communities you are comparing share all their species, while a value of 0 means they share none. In a dissimilarity index the interpretation is the opposite: 1 means that the communities are totally different.",
      "question": "How do you interpret Sorensen index of similarity"
    },
    {
      "answer": "In short, the problem with neural networks is that a number of parameter have to be set before any training can begin. However, there are no clear rules how to set these parameters.  By combining genetic algorithms with neural networks (GANN), the genetic algorithm is used to find these parameters.",
      "question": "Can we incorporate genetic algorithm concept to artificial neural network"
    },
    {
      "answer": "Probability distributions are a fundamental concept in statistics. They are used both on a theoretical level and a practical level. Some practical uses of probability distributions are: To calculate confidence intervals for parameters and to calculate critical regions for hypothesis tests.",
      "question": "What is the use of probability distribution"
    },
    {
      "answer": "The short answer is: Logistic regression is considered a generalized linear model because the outcome always depends on the sum of the inputs and parameters. Or in other words, the output cannot depend on the product (or quotient, etc.)",
      "question": "Is logistic regression a generalized linear model"
    },
    {
      "answer": "Statistical power, or the power of a hypothesis test is the probability that the test correctly rejects the null hypothesis. That is, the probability of a true positive result.  statistical power is the probability that a test will correctly reject a false null hypothesis.",
      "question": "What is statistical power in research"
    },
    {
      "answer": "Statistical inference involves hypothesis testing (evaluating some idea about a population using a sample) and estimation (estimating the value or potential range of values of some characteristic of the population based on that of a sample).",
      "question": "What does statistical inference take into account"
    },
    {
      "answer": "In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.  In the adaptive control literature, the learning rate is commonly referred to as gain.",
      "question": "What is meant by learning rate"
    },
    {
      "answer": "5 Ways to Avoid Being Fooled By Statistics.  Do A Little Bit of Math and apply Common Sense.  Always Look for the Source and check the authority of the source.  Question if the statistics are biased or statistically insignificant.  Question if the statistics are skewed purposely or Misinterpreted.More items\u2022",
      "question": "How can we avoid misleading statistics"
    },
    {
      "answer": "Multinomial logistic regression (often just called 'multinomial regression') is used to predict a nominal dependent variable given one or more independent variables. It is sometimes considered an extension of binomial logistic regression to allow for a dependent variable with more than two categories.",
      "question": "When would you use multinomial regression"
    },
    {
      "answer": "Getting Familiar with ML Pipelines A machine learning pipeline is used to help automate machine learning workflows. They operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated to achieve an outcome, whether positive or negative.",
      "question": "What do you think is important in a machine learning Pipeline"
    },
    {
      "answer": "In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard error.",
      "question": "Is RMSE and standard error same"
    },
    {
      "answer": "Preference learning is a subfield in machine learning, which is a classification method based on observed preference information. In the view of supervised learning, preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.",
      "question": "What is preference Learning And how is it different from machine learning"
    },
    {
      "answer": "Normalization basically means bringing all the values to once scale and there is nothing wrong using percentage but there must be a base value for normalizing the data and if you are asking about 100 as a base value and then converting everything as % it will not be equal to normalization as in normalization the base",
      "question": "What is normalized percentage"
    },
    {
      "answer": "Consider a binomial distribution with parameters (n, p). When n is large and p is small , approximate the probability using Poisson distribution. When n is large and p is close to 0.5, use normal approximation.",
      "question": "When do I approximate Binomial Distribution with Normal vs Poisson"
    },
    {
      "answer": "Which intuitively says that the probability of has to be \u201creally high\u201d. In other words, if your value is smaller than E[X], then the upper bound of it taking that value is 1 (basically sort of an uninteresting statement, since you already knew the upper bound was 1 or greater).",
      "question": "What is an intuitive explanation of Markovs inequality"
    },
    {
      "answer": "Some Disadvantages of KNNAccuracy depends on the quality of the data.With large data, the prediction stage might be slow.Sensitive to the scale of the data and irrelevant features.Require high memory \u2013 need to store all of the training data.Given that it stores all of the training, it can be computationally expensive.",
      "question": "Which of the following are the disadvantages of using Knn"
    },
    {
      "answer": "Let's GO!Step 0 : Pre-requisites. It is recommended that before jumping on to Deep Learning, you should know the basics of Machine Learning.  Step 1 : Setup your Machine.  Step 2 : A Shallow Dive.  Step 3 : Choose your own Adventure!  Step 4 : Deep Dive into Deep Learning.",
      "question": "How do you implement deep learning"
    },
    {
      "answer": "The disadvantages: Convenience samples do not produce representative results. If you need to extrapolate to the target population, convenience samples aren't going to get you there.",
      "question": "What is the problem with convenience sampling"
    },
    {
      "answer": "Techniques to reduce underfitting :Increase model complexity.Increase number of features, performing feature engineering.Remove noise from the data.Increase the number of epochs or increase the duration of training to get better results.",
      "question": "How do you prevent Underfitting in machine learning"
    },
    {
      "answer": "Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).",
      "question": "What is discrete and continuous distribution"
    },
    {
      "answer": "In regression analysis, the dependent variable is denoted Y and the independent variable is denoted X. So, in this case, Y=total cholesterol and X=BMI. When there is a single continuous dependent variable and a single independent variable, the analysis is called a simple linear regression analysis .",
      "question": "How do you find x and y variables in regression"
    },
    {
      "answer": "So standard deviation gives you more deviation than mean deviation whem there are certain data points that are too far from its mean.",
      "question": "Which is larger average deviation or standard deviation"
    },
    {
      "answer": "Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.",
      "question": "What is a gradient machine learning"
    },
    {
      "answer": "Order of training data during training a neural network matters a great deal. If you are training with a mini batch you may see large fluctuations in accuracy (and cost function) and may end up over fitting correlated portions of your mini batch.",
      "question": "Does the order of training examples within a minibatch matter when training a neural network"
    },
    {
      "answer": "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.",
      "question": "How do you calculate classification accuracy"
    },
    {
      "answer": "SVM tries to finds the \u201cbest\u201d margin (distance between the line and the support vectors) that separates the classes and this reduces the risk of error on the data, while logistic regression does not, instead it can have different decision boundaries with different weights that are near the optimal point.",
      "question": "Is SVM better than logistic regression"
    },
    {
      "answer": "An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.",
      "question": "What is Arima model used for"
    },
    {
      "answer": "In statistics, the kth order statistic of a statistical sample is equal to its kth-smallest value. Together with rank statistics, order statistics are among the most fundamental tools in non-parametric statistics and inference.",
      "question": "What is KTH in statistics"
    },
    {
      "answer": "In simple terms, deep learning is when ANNs learn from large amounts of data. Similar to how humans learn from experience, a deep learning algorithm performs a task repeatedly, each time tweaking it slightly to improve the outcome.",
      "question": "How does a deep neural network learn"
    },
    {
      "answer": "Sampling errors can be reduced by the following methods: (1) by increasing the size of the sample (2) by stratification. Increasing the size of the sample: The sampling error can be reduced by increasing the sample size. If the sample size n is equal to the population size N, then the sampling error is zero.",
      "question": "What is sampling error and how can it be reduced"
    },
    {
      "answer": "The Kruskal-Wallis H test (sometimes also called the \"one-way ANOVA on ranks\") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable.",
      "question": "What is Kruskal Wallis test used for"
    },
    {
      "answer": "3 Answers. Attempts to find an average value of AC would directly provide you the answer zero Hence, RMS values are used. They help to find the effective value of AC (voltage or current). This RMS is a mathematical quantity (used in many math fields) used to compare both alternating and direct currents (or voltage).",
      "question": "Why use root mean square instead of average"
    },
    {
      "answer": "A p-value less than 0.05 (typically \u2264 0.05) is statistically significant. It indicates strong evidence against the null hypothesis, as there is less than a 5% probability the null is correct (and the results are random). Therefore, we reject the null hypothesis, and accept the alternative hypothesis.",
      "question": "Why is the standard p value 0 05"
    },
    {
      "answer": "The most used algorithm to train neural networks is gradient descent. We'll define it later, but for now hold on to the following idea: the gradient is a numeric calculation allowing us to know how to adjust the parameters of a network in such a way that its output deviation is minimized.",
      "question": "What is a gradient in neural network"
    },
    {
      "answer": "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.",
      "question": "What is meant by supervised machine learning"
    },
    {
      "answer": "Definition: Quota sampling is a sampling methodology wherein data is collected from a homogeneous group. It involves a two-step process where two variables can be used to filter information from the population. It can easily be administered and helps in quick comparison.",
      "question": "What is meant by quota sampling"
    },
    {
      "answer": "International communication (also referred to as the study of global communication or transnational communication) is the communication practice that occurs across international borders.  International communication \"encompasses political, economic, social, cultural and military concerns\".",
      "question": "What is the meaning of international communication"
    },
    {
      "answer": "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.  In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible.",
      "question": "What is K means algorithm in machine learning"
    },
    {
      "answer": "The purpose of a neural network is to learn to recognize patterns in your data. Once the neural network has been trained on samples of your data, it can make predictions by detecting similar patterns in future data. Software that learns is truly \"Artificial Intelligence\".",
      "question": "What is the purpose of a neural network"
    },
    {
      "answer": "Object is a copy of the class. Instance is a variable that holds the memory address of the object. You can also have multiple objects of the same class and then multiple instances of each of those objects. In these cases, each object's set of instances are equivalent in value, but the instances between objects are not.",
      "question": "What is the difference between object and instance"
    },
    {
      "answer": "GAN Training Step 1 \u2014 Select a number of real images from the training set. Step 2 \u2014 Generate a number of fake images. This is done by sampling random noise vectors and creating images from them using the generator. Step 3 \u2014 Train the discriminator for one or more epochs using both fake and real images.",
      "question": "How do you create a generative adversarial network"
    },
    {
      "answer": "In implementing most of the machine learning algorithms, we represent each data point with a feature vector as the input. A vector is basically an array of numerics, or in physics, an object with magnitude and direction.",
      "question": "What is data representation in machine learning"
    },
    {
      "answer": "In other words, accuracy describes the difference between the measurement and the part's actual value, while precision describes the variation you see when you measure the same part repeatedly with the same device.",
      "question": "What is the relationship between precision and accuracy"
    },
    {
      "answer": "To find the average, add them together and divide by the number of values (10 in this case). When repeated measurements give different results, we want to know how widely spread the readings are. The spread of values tells us something about the uncertainty of a measurement.",
      "question": "How do you find the uncertainty of a measurement"
    },
    {
      "answer": "The maximum entropy principle is defined as modeling a given set of data by finding the highest entropy to satisfy the constraints of our prior knowledge.  The maximum entropy model is a conditional probability model p(y|x) that allows us to predict class labels given a set of features for a given data point.",
      "question": "What is maximum entropy model in NLP"
    },
    {
      "answer": "Now living under the identity of Scarecrow, Hide helped Koutarou Amon flee from Akihiro Kanou after he was turned into a one-eyed ghoul.",
      "question": "Did hide become a ghoul"
    },
    {
      "answer": "In Semantic networks, we can represent our knowledge in the form of graphical networks. This network consists of nodes representing objects and arcs which describe the relationship between those objects. Semantic networks can categorize the object in different forms and can also link those objects.",
      "question": "How knowledge is represented using semantic network"
    },
    {
      "answer": "For example RSA Encryption padding is randomized, ensuring that the same message encrypted multiple times looks different each time. It also avoids other weaknesses, such as encrypting the same message using different RSA keys leaking the message, or an attacker creating messages derived from some other ciphertexts.",
      "question": "What is padding in RSA encryption"
    },
    {
      "answer": "Predicting Google's Stock Price using Linear RegressionTake a value of x (say x=0)Find the corresponding value of y by putting x=0 in the equation.Store the (x,y) value pair in a table.Repeat the process once or twice or as many times as we want.Plot the points on the graph to obtain the straight line.",
      "question": "How do you use linear regression to predict stock prices"
    },
    {
      "answer": "Truncated Backpropagation Through Time (truncated BPTT) is a widespread method for learning recurrent computational graphs. Truncated BPTT keeps the computational benefits of Backpropagation Through Time (BPTT) while relieving the need for a complete backtrack through the whole data sequence at every step.",
      "question": "What is truncated Bptt"
    },
    {
      "answer": "In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.",
      "question": "What is meant by Hyperplane"
    },
    {
      "answer": "HMMs is the Hidden Markov Models library for Python. It is easy to use, general purpose library, implementing all the important submethods, needed for the training, examining and experimenting with the data models.",
      "question": "What is the best Python library for Hidden Markov Models"
    },
    {
      "answer": "For example, a p-value of 0.01 would mean there is a 1% chance of committing a Type I error. However, using a lower value for alpha means that you will be less likely to detect a true difference if one really exists (thus risking a type II error).",
      "question": "What is the relationship between the p value of a t test and the Type I and Type II errors"
    },
    {
      "answer": "It's O(V+E) because each visit to v of V must visit each e of E where |e| <= V-1. Since there are V visits to v of V then that is O(V).  So total time complexity is O(V + E).",
      "question": "Why is the complexity of DFS o v e"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is supervised and unsupervised learning explain with the examples"
    },
    {
      "answer": "Best Practices of Data CleaningSetting up a Quality Plan. RELATED BLOG.  Fill-out missing values. One of the first steps of fixing errors in your dataset is to find incomplete values and fill them out.  Removing rows with missing values.  Fixing errors in the structure.  Reducing data for proper data handling.",
      "question": "How does machine learning clean data"
    },
    {
      "answer": "In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression.  Such models are called linear models.",
      "question": "How do you explain linear regression"
    },
    {
      "answer": "Some business analysts at claim that AI is a game changer for the personal device market. By 2020, about 60 percent of personal-device technology vendors will depend on AI-enabled Cloud platforms to deliver enhanced functionality and personalized services. AI technology will deliver an \u201cemotional user experience.\u201d",
      "question": "What is the future of AI and machine learning"
    },
    {
      "answer": "Linear models, generalized linear models, and nonlinear models are examples of parametric regression models because we know the function that describes the relationship between the response and explanatory variables.  If the relationship is unknown and nonlinear, nonparametric regression models should be used.",
      "question": "Is linear regression non parametric"
    },
    {
      "answer": "Definition: Given data the maximum likelihood estimate (MLE) for the parameter p is the value of p that maximizes the likelihood P(data |p). That is, the MLE is the value of p for which the data is most likely. 100 P(55 heads|p) = ( 55 ) p55(1 \u2212 p)45.",
      "question": "How do you find the maximum likelihood estimator"
    },
    {
      "answer": "How to Find the Mean. The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count.",
      "question": "How do you find the mean in statistics"
    },
    {
      "answer": "Exponential smoothing is a way to smooth out data for presentations or to make forecasts. It's usually used for finance and economics. If you have a time series with a clear pattern, you could use moving averages \u2014 but if you don't have a clear pattern you can use exponential smoothing to forecast.",
      "question": "When would you use exponential smoothing"
    },
    {
      "answer": "Improving the PF can maximize current-carrying capacity, improve voltage to equipment, reduce power losses, and lower electric bills. The simplest way to improve power factor is to add PF correction capacitors to the electrical system. PF correction capacitors act as reactive current generators.",
      "question": "How can we control the power factor"
    },
    {
      "answer": "Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.",
      "question": "What is the difference between extrapolation and interpolation"
    },
    {
      "answer": "Machine Learning: Reinforcement Learning \u2014 Markov Decision Processes.  A mathematical representation of a complex decision making process is \u201cMarkov Decision Processes\u201d (MDP). MDP is defined by: A state S, which represents every state that one could be in, within a defined world.",
      "question": "What is MDP in machine learning"
    },
    {
      "answer": "Sample moments are those that are utilized to approximate the unknown population moments. Sample moments are calculated from the sample data. Such moments include mean, variance, skewness, and kurtosis.",
      "question": "What are sample moments"
    },
    {
      "answer": "For example, Q-learning is an off-policy learner. On-policy methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, off-policy methods evaluate or improve a policy different from that used to generate the data.11\u200f/04\u200f/2020",
      "question": "What is the difference between on policy and off policy"
    },
    {
      "answer": "In the extended Kalman filter, the state transition and observation models don't need to be linear functions of the state but may instead be differentiable functions.  These matrices can be used in the Kalman filter equations. This process essentially linearizes the non-linear function around the current estimate.",
      "question": "How does extended Kalman filter work"
    },
    {
      "answer": "The purpose of Causal Analysis and Resolution (CAR) is to identify causes of defects and other problems and take action to prevent them from occurring in the future. Introductory Notes The Causal Analysis and Resolution process area involves the following: Identifying and analyzing causes of defects and other problems.",
      "question": "What is causal analysis and resolution"
    },
    {
      "answer": "A control problem involves a system that is described by state variables.  The problem is to find a time control stratergy to make the system reach the terget state that is find conditions for application of force as a function of the control variables of the system (V,W,Th).",
      "question": "What is control problem"
    },
    {
      "answer": "You now know that: Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.",
      "question": "What is tradeoff between bias and variance"
    },
    {
      "answer": "You can reduce High variance, by reducing the number of features in the model. There are several methods available to check which features don't add much value to the model and which are of importance. Increasing the size of the training set can also help the model generalise.",
      "question": "How do you handle high variance data"
    },
    {
      "answer": "If the data is symmetrical - normally distributed - then the mean tell you where the line of symmetry falls. The standard deviation tells you more. It tells you if the data is closely distributed to the mean (small standard deviation) or is the data widely distributed (big standard deviation).",
      "question": "Why do we use standard deviation instead of mean deviation"
    },
    {
      "answer": "No, you don't have to transform your observed variables just because they don't follow a normal distribution. Linear regression analysis, which includes t-test and ANOVA, does not assume normality for either predictors (IV) or an outcome (DV). No way!  Yes, you should check normality of errors AFTER modeling.",
      "question": "Does the dependent variable need to be normally distributed in linear regression"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.",
      "question": "What is bootstrap sampling in machine learning and why is it important 1"
    },
    {
      "answer": "Each of the steps should take about 4\u20136 weeks' time. And in about 26 weeks since the time you started, and if you followed all of the above religiously, you will have a solid foundation in deep learning.",
      "question": "How long will it take to learn deep learning"
    },
    {
      "answer": "there are three general categories of learning that artificial intelligence (AI)/machine learning utilizes to actually learn. They are Supervised Learning, Unsupervised Learning and Reinforcement learning.  The machine then maps the inputs and the outputs.",
      "question": "What is learning and types of learning in artificial intelligence"
    },
    {
      "answer": "Machine learning algorithms are almost always optimized for raw, detailed source data. Thus, the data environment must provision large quantities of raw data for discovery-oriented analytics practices such as data exploration, data mining, statistics, and machine learning.",
      "question": "What type of data does machine learning need"
    },
    {
      "answer": "Here is a brief review of our original seven techniques for dimensionality reduction:Missing Values Ratio.  Low Variance Filter.  High Correlation Filter.  Random Forests/Ensemble Trees.  Principal Component Analysis (PCA).  Backward Feature Elimination.  Forward Feature Construction.",
      "question": "Which technique can be implemented if you want to reduce the dimensionality of a certain statistical problem"
    },
    {
      "answer": "Decision Trees in Machine Learning. Decision Tree models are created using 2 steps: Induction and Pruning. Induction is where we actually build the tree i.e set all of the hierarchical decision boundaries based on our data. Because of the nature of training decision trees they can be prone to major overfitting.",
      "question": "How is a decision tree trained"
    },
    {
      "answer": "Normalization usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1. This standardization is called a z-score, and data points can be standardized with the following formula: A z-score standardizes variables.",
      "question": "What does it mean to normalize a variable"
    },
    {
      "answer": "The optimal number of clusters can be defined as follow:Compute clustering algorithm (e.g., k-means clustering) for different values of k.  For each k, calculate the total within-cluster sum of square (wss).Plot the curve of wss according to the number of clusters k.More items",
      "question": "How do you find the optimal number of clusters"
    },
    {
      "answer": "Credit card tokenization substitutes sensitive customer data with a one-time alphanumeric ID that has no value or connection to the account's owner. This randomly generated token is used to access, pass, transmit and retrieve customer's credit card information safely.",
      "question": "What is tokenization and how does it work"
    },
    {
      "answer": "In our implementation of gradient descent, we have used a function compute_gradient(loss) that computes the gradient of a loss operation in our computational graph with respect to the output of every other node n (i.e. the direction of change for n along which the loss increases the most).",
      "question": "Is backpropagation gradient descent"
    },
    {
      "answer": "Distance Learning Off-line is a mode of delivery that does not require online participation. You do not have to come to campus. Course materials may be available through the internet, but they can also be mailed to you if you prefer.",
      "question": "What is meant by offline classes"
    },
    {
      "answer": "one training example",
      "question": "How many training examples are required by one shot learning for each class"
    },
    {
      "answer": "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.",
      "question": "What does normal distribution mean in statistics"
    },
    {
      "answer": "In a true experiment, participants are randomly assigned to either the treatment or the control group, whereas they are not assigned randomly in a quasi-experiment.  Thus, the researcher must try to statistically control for as many of these differences as possible.",
      "question": "What is the difference between field experiment and quasi experiment"
    },
    {
      "answer": "The effect of the logit transformation is primarily to pull out the ends of the distribution. Over a broad range of intermediate values of the proportion (p), the relationship of logit(p) and p is nearly linear.",
      "question": "Why do we use logit transformation"
    },
    {
      "answer": "KNN represents a supervised classification algorithm that will give new data points accordingly to the k number or the closest data points, while k-means clustering is an unsupervised clustering algorithm that gathers and groups data into k number of clusters.",
      "question": "How is Knn different from K means clustering"
    },
    {
      "answer": "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the",
      "question": "Is Random Forest a classification technique"
    },
    {
      "answer": "A Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 0, it indicates that the data point's score is identical to the mean score.",
      "question": "What does the Z in z score stand for"
    },
    {
      "answer": "Hyperparameters are the variables which determines the network structure(Eg: Number of Hidden Units) and the variables which determine how the network is trained(Eg: Learning Rate). Hyperparameters are set before training(before optimizing the weights and bias).",
      "question": "What are the Hyperparameters of a neural network"
    },
    {
      "answer": "Natural numbers are a part of the number system which includes all the positive integers from 1 till infinity and are also used for counting purpose. It does not include zero (0). In fact, 1,2,3,4,5,6,7,8,9\u2026., are also called counting numbers.",
      "question": "Is 0 part of the natural numbers"
    },
    {
      "answer": "SummaryUse the function cor. test(x,y) to analyze the correlation coefficient between two variables and to get significance level of the correlation.Three possible correlation methods using the function cor.test(x,y): pearson, kendall, spearman.",
      "question": "How do you show the relationship between two variables in R"
    },
    {
      "answer": "Quantiles are points in a distribution that relate to the rank order of values in that distribution.  Centiles/percentiles are descriptions of quantiles relative to 100; so the 75th percentile (upper quartile) is 75% or three quarters of the way up an ascending list of sorted values of a sample.",
      "question": "What is difference between quantile and percentile"
    },
    {
      "answer": "Bias machine learning can even be applied when interpreting valid or invalid results from an approved data model. Nearly all of the common machine learning biased data types come from our own cognitive biases. Some examples include Anchoring bias, Availability bias, Confirmation bias, and Stability bias.",
      "question": "What is bias in machine learning example"
    },
    {
      "answer": "How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.",
      "question": "How do you find the distribution in statistics"
    },
    {
      "answer": "A t-value is the relative error difference in contrast to the null hypothesis. A p-value, is the statistical significance of a measurement in how correct a statistical evidence part, is.",
      "question": "What is the difference between a t value and p value"
    },
    {
      "answer": "Explanation: Correlation is the process of studying the cause and effect relationship that exists between two variables. Correlation coefficient is the measure of the correlation that exists between two variables.",
      "question": "What is the difference between correlation coefficient and correlation"
    },
    {
      "answer": "The method of analyzing an image that has undergone binarization processing is called \"blob analysis\". A blob refers to a lump. Blob analysis is image processing's most basic method for analyzing the shape features of an object, such as the presence, number, area, position, length, and direction of lumps.",
      "question": "What is a blob in image processing"
    },
    {
      "answer": "The \u201cmoments\u201d of a random variable (or of its distribution) are expected values of powers or related functions of the random variable. The rth moment of X is E(Xr). In particular, the first moment is the mean, \u00b5X = E(X). The mean is a measure of the \u201ccenter\u201d or \u201clocation\u201d of a distribution.",
      "question": "What is the moment of a random variable"
    },
    {
      "answer": "Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables.  Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).",
      "question": "Is regression an algorithm"
    },
    {
      "answer": "The expected value (EV) is an anticipated value for an investment at some point in the future. In statistics and probability analysis, the expected value is calculated by multiplying each of the possible outcomes by the likelihood each outcome will occur and then summing all of those values.",
      "question": "What is expected value of probability distribution"
    },
    {
      "answer": "Loss is often used in the training process to find the \"best\" parameter values for your model (e.g. weights in neural network).  Once you find the optimized parameters above, you use this metrics to evaluate how accurate your model's prediction is compared to the true data.",
      "question": "Why is it useful to track loss while the model is being trained"
    },
    {
      "answer": "How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.",
      "question": "How do you find the mean of a probability distribution"
    },
    {
      "answer": "Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution. Figure 1 shows density functions for three Chi Square distributions.",
      "question": "What is the skewness of a chi square distribution"
    },
    {
      "answer": "LDA is a probabilistic generative model that extracts the thematic structure in a big document collection. The model assumes that every topic is a distribution of words in the vocabulary, and every document (described over the same vocabulary) is a distribution of a small subset of these topics.",
      "question": "What is LDA clustering"
    },
    {
      "answer": "Connected components labeling scans an image and groups its pixels into components based on pixel connectivity, i.e. all pixels in a connected component share similar pixel intensity values and are in some way connected with each other.",
      "question": "What is labeling in image processing"
    },
    {
      "answer": "When we know an input value and want to determine the corresponding output value for a function, we evaluate the function.  When we know an output value and want to determine the input values that would produce that output value, we set the output equal to the function's formula and solve for the input.",
      "question": "What is output value"
    },
    {
      "answer": "Q-learning is a model-free reinforcement learning algorithm to learn quality of actions telling an agent what action to take under what circumstances.  \"Q\" names the function that the algorithm computes with the maximum expected rewards for an action taken in a given state.",
      "question": "What is Q function in machine learning"
    },
    {
      "answer": "When most dependent variables are numeric, logistic regression and SVM should be the first try for classification. These models are easy to implement, their parameters easy to tune, and the performances are also pretty good. So these models are appropriate for beginners.",
      "question": "Which algorithm is used for classification"
    },
    {
      "answer": "The binomial distribution model allows us to compute the probability of observing a specified number of \"successes\" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure.",
      "question": "What are the application of binomial distribution"
    },
    {
      "answer": "Systematic sampling is frequently used to select a specified number of records from a computer file. Stratified sampling is commonly used probability method that is superior to random sampling because it reduces sampling error. A stratum is a subset of the population that share at least one common characteristic.",
      "question": "What is stratified and systematic sampling"
    },
    {
      "answer": "Univariate and multivariate represent two approaches to statistical analysis. Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables. Most multivariate analysis involves a dependent variable and multiple independent variables.",
      "question": "What is the difference between univariate and multivariate regression"
    },
    {
      "answer": "It appears that the median is always closest to the high point (the mode), while the mean tends to be farther out on the tail. In a symmetrical distribution, the mean and the median are both centrally located close to the high point of the distribution.",
      "question": "Where is the mean located in relationship to the median"
    },
    {
      "answer": "Assumptions. The assumptions of discriminant analysis are the same as those for MANOVA. The analysis is quite sensitive to outliers and the size of the smallest group must be larger than the number of predictor variables. Multivariate normality: Independent variables are normal for each level of the grouping variable.",
      "question": "What are the assumptions of discriminant analysis"
    },
    {
      "answer": "The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape).",
      "question": "When would you use a Wilcoxon rank sum test"
    },
    {
      "answer": "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data.  A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable.",
      "question": "What is meant by linear regression"
    },
    {
      "answer": "Descriptive statistics are used to describe the basic features of the data in a study. They provide simple summaries about the sample and the measures.  Descriptive statistics are typically distinguished from inferential statistics. With descriptive statistics you are simply describing what is or what the data shows.",
      "question": "What do you mean by descriptive statistics"
    },
    {
      "answer": "Odds Ratio is a measure of the strength of association with an exposure and an outcome.OR > 1 means greater odds of association with the exposure and outcome.OR = 1 means there is no association between exposure and outcome.OR < 1 means there is a lower odds of association between the exposure and outcome.",
      "question": "How do you interpret odds ratio"
    },
    {
      "answer": "Named Entity Recognition can automatically scan entire articles and reveal which are the major people, organizations, and places discussed in them. Knowing the relevant tags for each article help in automatically categorizing the articles in defined hierarchies and enable smooth content discovery.",
      "question": "How do you use a named entity recognition"
    },
    {
      "answer": "In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).",
      "question": "What is an agent artificial intelligence"
    },
    {
      "answer": "Clean, augment, and preprocess the data into a convenient form, if needed. Conduct an exploratory analysis of the data to get a better sense of it. Using what you find as a guide, construct a model of some aspect of the data. Use the model to answer the question you started with, and validate your results.",
      "question": "How do you make a predictive model in R"
    },
    {
      "answer": "On a technical note, estimation of a latent variable is done by analyzing the variance and covariance of the indicators. The measurement model of a latent variable with effect indicators is the set of relationships (modeled as equations) in which the latent variable is set as the predictor of the indicators.",
      "question": "How do you calculate latent variables"
    },
    {
      "answer": "T - test is used to if the means of two populations are equal (assuming similar variance) whereas F-test is used to test if the variances of two populations are equal. F - test can also be extended to check whether the means of three or more groups are different or not (ANOVA F-test).",
      "question": "Whats the difference between an F Test and T Test"
    },
    {
      "answer": "The first step in backward elimination is pretty simple, you just select a significance level, or select the P-value. Usually, in most cases, a 5% significance level is selected. This means the P-value will be 0.05. You can change this value depending on the project.",
      "question": "What is significance level in backward elimination"
    },
    {
      "answer": "An SVM possesses a number of parameters that increase linearly with the linear increase in the size of the input. A NN, on the other hand, doesn't. Even though here we focused especially on single-layer networks, a neural network can have as many layers as we want.",
      "question": "What is the difference between SVM and neural networks"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What does variance mean in at test"
    },
    {
      "answer": "The sample mean is a consistent estimator for the population mean. A consistent estimate has insignificant errors (variations) as sample sizes grow larger. More specifically, the probability that those errors will vary by more than a given amount approaches zero as the sample size increases.",
      "question": "Is the sample mean a consistent estimator"
    },
    {
      "answer": "The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.",
      "question": "What is difference between standard deviation and standard error"
    },
    {
      "answer": "Linear Growth Model Organisms generally grow in spurts that are dependent on both environment and genetics. Under controlled laboratory conditions, however, one can often observe a constant rate of growth. These periods of constant growth are often referred to as the linear portions of the growth curve.",
      "question": "What is a linear growth curve"
    },
    {
      "answer": "The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit.",
      "question": "What is forget gate in Lstm"
    },
    {
      "answer": "The Z score is a test of statistical significance that helps you decide whether or not to reject the null hypothesis. The p-value is the probability that you have falsely rejected the null hypothesis. Z scores are measures of standard deviation.  Both statistics are associated with the standard normal distribution.",
      "question": "Is Z score the test statistic"
    },
    {
      "answer": "Sensitivity refers to a test's ability to designate an individual with disease as positive. A highly sensitive test means that there are few false negative results, and thus fewer cases of disease are missed. The specificity of a test is its ability to designate an individual who does not have a disease as negative.",
      "question": "What does it mean if a test is sensitive but not specific"
    },
    {
      "answer": "A matrix is a linear operator acting on the vector space of column vectors. Per linear algebra and its isomorphism theorems, any vector space is isomorphic to any other vector space of the same dimension. As such, matrices can be seen as representations of linear operators subject to some basis of column vectors.",
      "question": "Is a matrix an operator"
    },
    {
      "answer": "The population mean of the distribution of sample means is the same as the population mean of the distribution being sampled from.  Thus as the sample size increases, the standard deviation of the means decreases; and as the sample size decreases, the standard deviation of the sample means increases.",
      "question": "How does standard deviation change with sample size"
    },
    {
      "answer": "If you are broadcasting or reinforcing sound outside, and even your best windscreen can't keep out the persistent low-frequency rumble from wind noise, then stopping it right at the source may be your best option. Highpass filters are excellent for this application.",
      "question": "When should I use high pass filter"
    },
    {
      "answer": "Machine Learning This phenomenon states that with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.",
      "question": "What is the curse of dimensionality in machine learning"
    },
    {
      "answer": "Fractional scaling helps you to fully utilize your HiDPI monitors, high-resolution laptops by making your desktop not too small or not too big and keep things in balance. Although the resolution settings are there to help they sometimes are not feasible due to the operating system limitations.",
      "question": "What is fractional scaling ubuntu"
    },
    {
      "answer": "When small samples are used to estimate a population mean, in cases where the population standard deviation is unknown: the t-distribution must be used to obtain the critical value. the resulting margin of error for a confidence interval estimate will tend to be fairly small.",
      "question": "When small samples are used to estimate a population mean in cases where the population standard deviation is unknown"
    },
    {
      "answer": "In probability theory and statistics, Bayes's theorem (alternatively Bayes's law or Bayes's rule), named after Reverend Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.  Bayesian inference is fundamental to Bayesian statistics.",
      "question": "What is Bayes theorem statistics"
    },
    {
      "answer": "Here are some tips for connecting the shape of a histogram with the mean and median:If the histogram is skewed right, the mean is greater than the median.  If the histogram is close to symmetric, then the mean and median are close to each other.  If the histogram is skewed left, the mean is less than the median.",
      "question": "How do you find the mean and median of a histogram"
    },
    {
      "answer": "2 Answers. If M is your matrix, then it represents a linear f:Rn\u2192Rn, thus when you do M(T) by row times column multiplication you obtain a vectorial expression for your f(T). Thus \u2202M\u2202T is just the derivative of the vector MT, which you do component-wise.",
      "question": "Can you take the derivative of a matrix"
    },
    {
      "answer": "The Formula for the Slope For paired data (x,y) we denote the standard deviation of the x data by sx and the standard deviation of the y data by sy. The formula for the slope a of the regression line is: a = r(sy/sx)",
      "question": "How do you find the slope of the regression line in R"
    },
    {
      "answer": "Marginal probability effects are the partial effects of each explanatory variable on. the probability that the observed dependent variable Yi = 1, where in probit. models.",
      "question": "What is marginal effects in probit model"
    },
    {
      "answer": "A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa.",
      "question": "What is FFT and its applications in DAA"
    },
    {
      "answer": "The variance (symbolized by S2) and standard deviation (the square root of the variance, symbolized by S) are the most commonly used measures of spread. We know that variance is a measure of how spread out a data set is. It is calculated as the average squared deviation of each number from the mean of a data set.",
      "question": "What is variance and deviation"
    },
    {
      "answer": "In the terminology of machine learning, classification is considered an instance of supervised learning, i.e., learning where a training set of correctly identified observations is available.  An algorithm that implements classification, especially in a concrete implementation, is known as a classifier.",
      "question": "What is classification learning"
    },
    {
      "answer": "training set\u2014a subset to train a model. test set\u2014a subset to test the trained model.",
      "question": "What is meant by training set and test set"
    },
    {
      "answer": "Random Forest Algorithm The Random Forest ML Algorithm is a versatile supervised learning algorithm that's used for both classification and regression analysis tasks.",
      "question": "Which algorithms can be used for both classification and regression tasks"
    },
    {
      "answer": "- if R-squared value 0.3 < r < 0.5 this value is generally considered a weak or low effect size, - if R-squared value 0.5 < r < 0.7 this value is generally considered a Moderate effect size, - if R-squared value r > 0.7 this value is generally considered strong effect size, Ref: Source: Moore, D. S., Notz, W.",
      "question": "What does a weak R squared value mean"
    },
    {
      "answer": "the t-test is robust against non-normality; this test is in doubt only when there can be serious outliers (long-tailed distributions \u2013 note the finite variance assumption); or when sample sizes are small and distributions are far from normal. 10 / 20 Page 20 . . .",
      "question": "Is t test robust to violations of normality"
    },
    {
      "answer": "Therefore, a number of alternative ways of handling the missing data has been developed.Listwise or case deletion.  Pairwise deletion.  Mean substitution.  Regression imputation.  Last observation carried forward.  Maximum likelihood.  Expectation-Maximization.  Multiple imputation.More items\u2022",
      "question": "How do you handle missing data in regression analysis"
    },
    {
      "answer": "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).",
      "question": "What is an adversarial neural network"
    },
    {
      "answer": "The normalisation ensures that the inputs have a mean of 0 and a standard deviation of 1, meaning that the input distribution to every neuron will be the same, thereby fixing the problem of internal covariate shift and providing regularisation.",
      "question": "How does Batch normalization address the problem of Internal Covariate Shift"
    },
    {
      "answer": "2.1 The Early Days. Constraint satisfaction, in its basic form, involves finding a value for each one of a set of problem variables where constraints specify that some subsets of values cannot be used together.",
      "question": "What is constraints satisfaction problem in AI"
    },
    {
      "answer": "Cohen came up with a mechanism to calculate a value which represents the level of agreement between judges negating the agreement by chance.  You can see that balls which are agreed on by chance are removed both from agreed and total number of balls. And that is the whole intuition of Kappa value aka Kappa coefficient.",
      "question": "What is an intuitive explanation of Cohens kappa statistic"
    },
    {
      "answer": "The false discovery rate (FDR) is a method of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons.  Thus, FDR-controlling procedures have greater power, at the cost of increased numbers of Type I errors.",
      "question": "What is FDR correction"
    },
    {
      "answer": "Mean and Variance of a Binomial Distribution The variance of a Binomial Variable is always less than its mean. \u2234 npq<np. For Maximum Variance: p=q=0.5 and \u03c3max = n/4.",
      "question": "What is the maximum value of the variance of binomial distribution"
    },
    {
      "answer": "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.",
      "question": "What is classification accuracy"
    },
    {
      "answer": "5 Successful ExamplesSentiment Analysis Examples.Reputation Management - Social Media Monitoring - Brand Monitoring.Market Research, Competitor Analysis.Product Analytics.Customer Analysis.Customer Support.",
      "question": "What are the most popular application areas for sentiment analysis"
    },
    {
      "answer": "This is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting. A simple relation for linear regression looks like this.",
      "question": "What is the use of regularization in machine learning"
    },
    {
      "answer": "Advantages and Disadvantages of Artificial Intelligence Reduction in Human Error: The phrase \u201chuman error\u201d was born because humans make mistakes from time to time.   Takes risks instead of Humans:   Available 24x7:   Helping in Repetitive Jobs:   Digital Assistance:   Faster Decisions:   Daily Applications:   New Inventions:",
      "question": "What are some of the benefits of AI development"
    },
    {
      "answer": "Lab Color is a more accurate color space.  It specifies a color using a 3-axis system. The a-axis (green to red), b-axis (blue to yellow) and Lightness axis. The best thing about Lab Color is that it's device-independent. That means that it's easier to achieve exactly the same color across different media.",
      "question": "What does lab color mean"
    },
    {
      "answer": "In-group favoritism, sometimes known as in-group\u2013out-group bias, in-group bias, intergroup bias, or in-group preference, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.",
      "question": "What does having biased groups mean"
    },
    {
      "answer": "Basically, you're just pre-setting some of the weights of the new network. Be sure to initialize the new connections to have similar distributions. Make the last layer a concatenation of their results and then add another few layers. Make the last layer a concatenation of their results and the original input.",
      "question": "How do I connect two neural networks"
    },
    {
      "answer": "The matrix norm is similar to the magnitude of a vector. It is useful whenever a system/problem can be formulated into a matrix that has some physical meaning.",
      "question": "What is Matrix norm used for"
    },
    {
      "answer": "Factor-Label Method",
      "question": "What does dimensional analysis mean"
    },
    {
      "answer": "In the context of gradient boosting, the training loss is the function that is optimized using gradient descent, e.g., the \u201cgradient\u201d part of gradient boosting models. Specifically, the gradient of the training loss is used to change the target variables for each successive tree.",
      "question": "What is loss function in gradient boosting"
    },
    {
      "answer": "In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.",
      "question": "What does it mean to be exponentially distributed"
    },
    {
      "answer": "Exponential moving averages, or EMA, give more weighting to recent prices. They reduce the effect of the lag that comes from using previous price data and can help you identify a trend earlier, so it's a useful indicator for trading short-term contracts.",
      "question": "In trading why would we use the exponential moving average over the simple moving average"
    },
    {
      "answer": "1 Introduction. The partial least squares (PLS) algorithm was first introduced for regression tasks and then evolved into a classification method that is well known as PLS-discriminant analysis (PLS-DA).",
      "question": "Whats the abbreviation for orthogonal partial least squares discriminant analysis"
    },
    {
      "answer": "Decision tree builds classification or regression models in the form of a tree structure.  The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.",
      "question": "Can decision trees be used for classification"
    },
    {
      "answer": "In simple terms, a quantile is where a sample is divided into equal-sized, adjacent, subgroups (that's why it's sometimes called a \u201cfractile\u201c).  The median cuts a distribution into two equal areas and so it is sometimes called 2-quantile. Quartiles are also quantiles; they divide the distribution into four equal parts.",
      "question": "What is quantile example"
    },
    {
      "answer": "Probabilistic data structures are a group of data structures that are extremely useful for big data and streaming applications. Generally speaking, these data structures use hash functions to randomize and compactly represent a set of items.",
      "question": "What is a probabilistic data structure"
    },
    {
      "answer": "There are several methods through which you can evaluate a Logistic regression model:Goodness of Fit.Likelihood ratio test.Wald's Test.Hosmer-Lemeshov Test.ROC (AUC) curve.Confidence Intervals.Correlation factors and coefficients.Variance Inflation Factor(VIF)More items",
      "question": "How do you evaluate a logit model"
    },
    {
      "answer": "Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several.",
      "question": "What is a Synset in WordNet"
    },
    {
      "answer": "Stratified random sampling refers to a sampling method that has the following properties.The population consists of N elements.The population is divided into H groups, called strata.Each element of the population can be assigned to one, and only one, stratum.More items",
      "question": "What are the properties of stratified random sampling"
    },
    {
      "answer": "The solution involves four steps.Make sure the samples from each population are big enough to model differences with a normal distribution.  Find the mean of the difference in sample proportions: E(p1 - p2) = P1 - P2 = 0.52 - 0.47 = 0.05.Find the standard deviation of the difference.  Find the probability.",
      "question": "How do you find the difference between sample proportions"
    },
    {
      "answer": "The normal distribution is a probability distribution. As with any probability distribution, the proportion of the area that falls under the curve between two points on a probability distribution plot indicates the probability that a value will fall within that interval.",
      "question": "How is the concept of probability related to the normal distribution"
    },
    {
      "answer": "The median is another form of an average. It usually represents the middle number in a given sequence of numbers when it's ordered by rank.",
      "question": "Is the median the average"
    },
    {
      "answer": "Similar to the t-test/correlation equivalence, the relationship between two dichotomous variables is the same as the difference between two groups when the dependent variable is dichotmous. The appropriate test to compare group differences with a dichotmous outcome is the chi-square statistic.",
      "question": "Which statistical technique is appropriate for find out the correlation between two dichotomous variables"
    },
    {
      "answer": "Gaussian RBF(Radial Basis Function) is another popular Kernel method used in SVM models for more. RBF kernel is a function whose value depends on the distance from the origin or from some point. Gaussian Kernel is of the following format; ||X1 \u2014 X2 || = Euclidean distance between X1 & X2.",
      "question": "What is gaussian kernel in SVM"
    },
    {
      "answer": "In short, it ensures each subgroup within the population receives proper representation within the sample. As a result, stratified random sampling provides better coverage of the population since the researchers have control over the subgroups to ensure all of them are represented in the sampling.",
      "question": "What's stratified sampling Why is it preferred"
    },
    {
      "answer": "Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.  dot represent numpy dot product of all input and its corresponding weights.",
      "question": "What is dense layer in sequential model"
    },
    {
      "answer": "Adjusted R-squared value can be calculated based on value of r-squared, number of independent variables (predictors), total sample size. Every time you add a independent variable to a model, the R-squared increases, even if the independent variable is insignificant. It never declines.",
      "question": "How is adjusted r2 calculated"
    },
    {
      "answer": "The primary goal of EDA is to maximize the analyst's insight into a data set and into the underlying structure of a data set, while providing all of the specific items that an analyst would want to extract from a data set, such as: a good-fitting, parsimonious model. a list of outliers.",
      "question": "What are the two goals of exploratory data analysis"
    },
    {
      "answer": "In your case, with three groups, you'd run ANOVA. If you need to compare the 5-point scales one at a time, then non-parametric statistics are more appropriate. To compare two groups use the Mann-Whitney U test. To compare three or more groups use the Kruskal\u2013Wallis H test.",
      "question": "Which statistical test should I use to compare 3 ordinal variables"
    },
    {
      "answer": "In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.",
      "question": "What is convergence in neural network"
    },
    {
      "answer": "In terms of machine learning, \"concept learning\" can be defined as: \u201cThe problem of searching through a predefined space of potential hypotheses for the hypothesis that best fits the training examples.\u201d \u2014 Tom Michell. Much of human learning involves acquiring general concepts from past experiences.",
      "question": "What is concept in machine learning"
    },
    {
      "answer": "The agent function is a mathematical function that maps a sequence of perceptions into action. The function is implemented as the agent program. The part of the agent taking an action is called an actuator. environment -> sensors -> agent function -> actuators -> environment.",
      "question": "What is Agent function in artificial intelligence"
    },
    {
      "answer": "There are two reasons why Mean Squared Error(MSE) is a bad choice for binary classification problems:  If we use maximum likelihood estimation(MLE), assuming that the data is from a normal distribution(a wrong assumption, by the way), we get the MSE as a Cost function for optimizing our model.",
      "question": "Why is squared loss bad for classification"
    },
    {
      "answer": "Sentiment analysis also means you'll be able to detect changes in the overall opinion towards your brand. Because it provides insight into the way your customers are feeling when they approach you, you can monitor trends and see if overall opinion towards your company drops or rises.",
      "question": "What are the benefits of sentiment analysis"
    },
    {
      "answer": "The main difference between probability and likelihood is that the former is normalized.  Probability refers to the occurrence of future events, while a likelihood refers to past events with known outcomes. Probability is used when describing a function of the outcome given a fixed parameter value.",
      "question": "What is the difference between probability and likelihood"
    },
    {
      "answer": "A decision tree is simply a set of cascading questions. When you get a data point (i.e. set of features and values), you use each attribute (i.e. a value of a given feature of the data point) to answer a question. The answer to each question decides the next question.",
      "question": "How do you explain a decision tree"
    },
    {
      "answer": "Logistic regression is quite different than linear regression in that it does not make several of the key assumptions that linear and general linear models (as well as other ordinary least squares algorithm based models) hold so close: (1) logistic regression does not require a linear relationship between the dependent",
      "question": "Does logistic regression data need to be normally distributed"
    },
    {
      "answer": "It is often pointed out that when ANOVA is applied to just two groups, and when therefore one can calculate both a t-statistic and an F-statistic from the same data, it happens that the two are related by the simple formula: t2 = F.",
      "question": "What is the relationship between F statistic and T statistic"
    },
    {
      "answer": "A classification is an ordered set of related categories used to group data according to its similarities. It consists of codes and descriptors and allows survey responses to be put into meaningful categories in order to produce useful data. A classification is a useful tool for anyone developing statistical surveys.",
      "question": "What is meant by classification in statistics"
    },
    {
      "answer": "A set is countable if: (1) it is finite, or (2) it has the same cardinality (size) as the set of natural numbers (i.e., denumerable). Equivalently, a set is countable if it has the same cardinality as some subset of the set of natural numbers. Otherwise, it is uncountable.",
      "question": "What is countable set in analysis"
    },
    {
      "answer": "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.",
      "question": "What is NLP problem"
    },
    {
      "answer": "Z-tests are statistical calculations that can be used to compare population means to a sample's. T-tests are calculations used to test a hypothesis, but they are most useful when we need to determine if there is a statistically significant difference between two independent sample groups.",
      "question": "What is the difference between z test and t test"
    },
    {
      "answer": "If a variable can take on any value between two specified values, it is called a continuous variable; otherwise, it is called a discrete variable. Some examples will clarify the difference between discrete and continuous variables.  The number of heads could be any integer value between 0 and plus infinity.",
      "question": "What is difference between discrete and continuous variable"
    },
    {
      "answer": "Artificial intelligence (AI) is a branch of computer science.  Most AI programs are not used to control robots. Even when AI is used to control robots, the AI algorithms are only part of the larger robotic system, which also includes sensors, actuators, and non-AI programming.",
      "question": "How artificial intelligence is related to robotics"
    },
    {
      "answer": "The model works by first splitting the input image into a grid of cells, where each cell is responsible for predicting a bounding box if the center of a bounding box falls within it. Each grid cell predicts a bounding box involving the x, y coordinate and the width and height and the confidence.",
      "question": "How does a bounding box work"
    },
    {
      "answer": "Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. It is a very simple idea that can result in accurate forecasts on a range of time series problems.",
      "question": "What are autoregressive models in machine learning"
    },
    {
      "answer": "Gradient descent is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.",
      "question": "What are the conditions in which Gradient descent is applied"
    },
    {
      "answer": "Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.  Therefore, Softmax loss is just these two appended together.",
      "question": "Is Softmax a loss function"
    },
    {
      "answer": "Parametric statistics are based on assumptions about the distribution of population from which the sample was taken. Nonparametric statistics are not based on assumptions, that is, the data can be collected from a sample that does not follow a specific distribution.",
      "question": "What is parametric statistics and nonparametric statistics"
    },
    {
      "answer": "Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.",
      "question": "What is dimensional analysis method"
    },
    {
      "answer": "Having good test re-test reliability signifies the internal validity of a test and ensures that the measurements obtained in one sitting are both representative and stable over time.",
      "question": "Why is test retest reliability important"
    },
    {
      "answer": "Multidimensional scaling is a visual representation of distances or dissimilarities between sets of objects.  Objects that are more similar (or have shorter distances) are closer together on the graph than objects that are less similar (or have longer distances).",
      "question": "What is multidimensional scaling in statistics"
    },
    {
      "answer": "Feature Selection vs Dimensionality Reduction While both methods are used for reducing the number of features in a dataset, there is an important difference. Feature selection is simply selecting and excluding given features without changing them. Dimensionality reduction transforms features into a lower dimension.",
      "question": "Whats the difference between dimensionality reduction and feature selection"
    },
    {
      "answer": "Top 10 Machine Learning ApplicationsTraffic Alerts.Social Media.Transportation and Commuting.Products Recommendations.Virtual Personal Assistants.Self Driving Cars.Dynamic Pricing.Google Translate.More items\u2022",
      "question": "What are the applications of machine learning"
    },
    {
      "answer": "Explanation: Simple reflex agent is based on the present condition and so it is condition action rule. 5. What are the composition for agents in artificial intelligence? Explanation: An agent program will implement function mapping percepts to actions.",
      "question": "What are the composition for agents in artificial intelligence"
    },
    {
      "answer": "Linear regression is a linear method to model the relationship between your independent variables and your dependent variables. Advantages include how simple it is and ease with implementation and disadvantages include how is' lack of practicality and how most problems in our real world aren't \u201clinear\u201d.",
      "question": "What are the advantages and disadvantages of linear regression"
    },
    {
      "answer": "A greedy algorithm is used to construct a Huffman tree during Huffman coding where it finds an optimal solution. In decision tree learning, greedy algorithms are commonly used, however they are not guaranteed to find the optimal solution. One popular such algorithm is the ID3 algorithm for decision tree construction.",
      "question": "Where greedy algorithm is used"
    },
    {
      "answer": "This approach involves either forward selection, adding features one at a time, or backward selection, removing features one at a time until some criterion is reached. Additionally, a bidirectional selection method is available that involves adding or removing a feature at each step.",
      "question": "What is backward selection"
    },
    {
      "answer": "Spectroscopy in chemistry and physics, a method of analyzing the properties of matter from their electromagnetic interactions. Spectral estimation, in statistics and signal processing, an algorithm that estimates the strength of different frequency components (the power spectrum) of a time-domain signal.",
      "question": "How is spectral analysis used"
    },
    {
      "answer": "Batch size controls the accuracy of the estimate of the error gradient when training neural networks. Batch, Stochastic, and Minibatch gradient descent are the three main flavors of the learning algorithm. There is a tension between batch size and the speed and stability of the learning process.",
      "question": "Does batch size affect accuracy"
    },
    {
      "answer": "4:1410:53Suggested clip \u00b7 113 secondsStochastic Gradient Descent, Clearly Explained!!! - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you use stochastic gradient descent"
    },
    {
      "answer": "The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.",
      "question": "How do you solve the vanishing gradient problem"
    },
    {
      "answer": "In this view, associative networks are fundamentally unorganized lists of features. By specifying what attributes to include, a frame structure promises to provide the \"framework\" upon which to organize and hang what a consumer knows about a product.",
      "question": "What do you know about associative network and frames"
    },
    {
      "answer": "You might also see this written as something like \u201cAn unbiased estimator is when the mean of the statistic's sampling distribution is equal to the population's parameter.\u201d This essentially means the same thing: if the statistic equals the parameter, then it's unbiased.",
      "question": "How do you prove an estimator is unbiased"
    },
    {
      "answer": "You can use a bivariate Pearson Correlation to test whether there is a statistically significant linear relationship between height and weight, and to determine the strength and direction of the association.",
      "question": "When would you use a bivariate correlation"
    },
    {
      "answer": "Fuelled by successes in Computer Go, Monte Carlo tree search (MCTS) has achieved widespread adoption within the games community. Its links to traditional reinforcement learning (RL) methods have been outlined in the past; however, the use of RL techniques within tree search has not been thoroughly studied yet.",
      "question": "Is Monte Carlo Tree Search reinforcement learning"
    },
    {
      "answer": "A latent variable is a random variable which you can't observe neither in training nor in test phase . It is derived from the latin word lat\u0113re which means hidden. Intuitionally, some phenomenons like incidences,altruism one can't measure while others like speed or height one can.",
      "question": "What are latent variables in machine learning"
    },
    {
      "answer": "The three main metrics used to evaluate a classification model are accuracy, precision, and recall. Accuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.",
      "question": "How do you evaluate machine learning algorithms"
    },
    {
      "answer": "Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. Whereas a classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account.",
      "question": "What is CRF in machine learning"
    },
    {
      "answer": "Formally, a statistic T(X1,\u00b7\u00b7\u00b7,Xn) is said to be sufficient for \u03b8 if the conditional distribution of X1,\u00b7\u00b7\u00b7,Xn, given T = t, does not depend on \u03b8 for any value of t. In other words, given the value of T, we can gain no more knowledge about \u03b8 from knowing more about the probability distribution of X1,\u00b7\u00b7\u00b7,Xn.",
      "question": "How do you prove a statistic is sufficient"
    },
    {
      "answer": "Anomaly detection (or outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.",
      "question": "What is outlier detection in machine learning"
    },
    {
      "answer": "Machine learning usually has to achieve multiple targets, which are often conflicting with each other. Multi-objective model selection to improve the performance of learning models, such as neural networks, support vector machines, decision trees, and fuzzy systems.",
      "question": "What are some Machine Learning techniques for objective optimization"
    },
    {
      "answer": "Two random variables X and Y are said to be bivariate normal, or jointly normal, if aX+bY has a normal distribution for all a,b\u2208R. In the above definition, if we let a=b=0, then aX+bY=0. We agree that the constant zero is a normal random variable with mean and variance 0.",
      "question": "How do you know if a bivariate is normal distribution"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "Where do we use eigenvalues"
    },
    {
      "answer": "Nonparametric tests are sometimes called distribution-free tests because they are based on fewer assumptions (e.g., they do not assume that the outcome is approximately normally distributed).  There are several statistical tests that can be used to assess whether data are likely from a normal distribution.",
      "question": "Why would you use a nonparametric test"
    },
    {
      "answer": "Rather than using the past values of the forecast variable in a regression, a moving average model uses past forecast errors in a regression-like model.  While, the autoregressive model(AR) uses the past forecasts to predict future values.",
      "question": "What are the differences between autoregressive and moving average models"
    },
    {
      "answer": "Coef. A regression coefficient describes the size and direction of the relationship between a predictor and the response variable. Coefficients are the numbers by which the values of the term are multiplied in a regression equation.",
      "question": "What do the coefficients in logistic regression mean"
    },
    {
      "answer": "RELU activation solves this by having a gradient slope of 1, so during backpropagation, there isn't gradients passed back that are progressively getting smaller and smaller. but instead they are staying the same, which is how RELU solves the vanishing gradient problem.",
      "question": "How does ReLU solve vanishing gradient problem"
    },
    {
      "answer": "As you have seen, in order to perform a likelihood ratio test, one must estimate both of the models one wishes to compare. The advantage of the Wald and Lagrange multiplier (or score) tests is that they approximate the LR test, but require that only one model be estimated.",
      "question": "How do you calculate the likelihood ratio"
    },
    {
      "answer": "Answer. When the ROC curve dips prominently into the lower right half of the graph, this is likely a sign that either the wrong State Value has been specified or the wrong Test-State association direction has been specified in the \"Test Direction\" area of the \"ROC Curve:Options\" dialog.",
      "question": "Why is my ROC curve inverted"
    },
    {
      "answer": "The Least Squares AssumptionsUseful Books for This Topic:  ASSUMPTION #1: The conditional distribution of a given error term given a level of an independent variable x has a mean of zero.  ASSUMPTION #2: (X,Y) for all n are independently and identically distributed.  ASSUMPTION #3: Large outliers are unlikely.More items\u2022",
      "question": "What are the least squares assumptions"
    },
    {
      "answer": "Keras is a neural network library while TensorFlow is the open-source library for a number of various tasks in machine learning. TensorFlow provides both high-level and low-level APIs while Keras provides only high-level APIs.",
      "question": "What is the relationship between tensorflow with keras"
    },
    {
      "answer": "It's more of an approach than a process. Predictive analytics and machine learning go hand-in-hand, as predictive models typically include a machine learning algorithm. These models can be trained over time to respond to new data or values, delivering the results the business needs.",
      "question": "Is predictive modeling machine learning"
    },
    {
      "answer": "8 Powerful Tricks That Make You Grasp New Concepts Faster1) Use mental associations. Colours, acronyms and word associations can be especially useful tools to help you hold on to thoughts, patterns and concepts.  2) Apply the 80/20 principle.  3) Break it down.  4) Write it down.  5) Connect existing knowledge.  6) Try Brain exercises.  7) Learn your way.  8) Teach other people.",
      "question": "How do you understand a concept deeply"
    },
    {
      "answer": "Linear regression is used to find the best fitting line between all the points of your dataset (by computing the minimum of a given distance), it does not, in itself, reduce the dimensionality of your data.",
      "question": "Why cant we use linear regression for dimension reduction"
    },
    {
      "answer": "Convergence in distribution is in some sense the weakest type of convergence. All it says is that the CDF of Xn's converges to the CDF of X as n goes to infinity. It does not require any dependence between the Xn's and X. We saw this type of convergence before when we discussed the central limit theorem.",
      "question": "What does convergence in distribution mean"
    },
    {
      "answer": "Hidden Markov models have been around for a pretty long time (1970s at least). It's a misnomer to call them machine learning algorithms.  It is most useful, IMO, for state sequence estimation, which is not a machine learning problem since it is for a dynamical process, not a static classification task.",
      "question": "Is Markov model machine learning"
    },
    {
      "answer": "The Unsharp Mask filter adjusts the contrast of the edge detail and creates the illusion of a more focused image.",
      "question": "What does the unsharp mask filter do"
    },
    {
      "answer": "The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X \u2264 x, Y \u2264 y),where X and Y are continuous or discrete. For example, the probability.  P(x1 \u2264 X \u2264 x2,y1 \u2264 Y \u2264 y2) = F(x2,y2) \u2212 F(x2,y1) \u2212 F(x1,y2) + F(x1,y1).",
      "question": "How do you find the joint distribution of two random variables"
    },
    {
      "answer": "Spearman Rank Correlation: Worked Example (No Tied Ranks)The formula for the Spearman rank correlation coefficient when there are no tied ranks is:  Step 1: Find the ranks for each individual subject.  Step 2: Add a third column, d, to your data.  Step 5: Insert the values into the formula.More items\u2022",
      "question": "How do you use Spearman's rank correlation coefficient"
    },
    {
      "answer": "Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used to solve complex problems.  Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.",
      "question": "What do you mean by knowledge representation"
    },
    {
      "answer": "Feature extraction describes the relevant shape information contained in a pattern so that the task of classifying the pattern is made easy by a formal procedure. In pattern recognition and in image processing, feature extraction is a special form of dimensionality reduction.",
      "question": "What is feature extraction in image processing"
    },
    {
      "answer": "The goodness of fit test is a statistical hypothesis test to see how well sample data fit a distribution from a population with a normal distribution. Put differently, this test shows if your sample data represents the data you would expect to find in the actual population or if it is somehow skewed.",
      "question": "What is the purpose of a goodness of fit test"
    },
    {
      "answer": "If your p-value is less than or equal to the set significance level, the data is considered statistically significant. As a general rule, the significance level (or alpha) is commonly set to 0.05, meaning that the probability of observing the differences seen in your data by chance is just 5%.",
      "question": "How do you test if a difference is statistically significant"
    },
    {
      "answer": "Machine learning is changing the world by transforming all segments including healthcare services, education, transport, food, entertainment, and different assembly line and many more. It will impact lives in almost every aspect, including housing, cars, shopping, food ordering, etc.",
      "question": "How is Machine Learning changing the world"
    },
    {
      "answer": "In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables.",
      "question": "What should I choose simple linear regression or multiple linear regression"
    },
    {
      "answer": "Prior probability represents what is originally believed before new evidence is introduced, and posterior probability takes this new information into account.  A posterior probability can subsequently become a prior for a new updated posterior probability as new information arises and is incorporated into the analysis.",
      "question": "What is prior and posterior"
    },
    {
      "answer": "The Moment Generating Function of the Binomial Distribution (3) dMx(t) dt = n(q + pet)n\u22121pet = npet(q + pet)n\u22121. Evaluating this at t = 0 gives (4) E(x) = np(q + p)n\u22121 = np.",
      "question": "What is the moment generating function of binomial distribution"
    },
    {
      "answer": "It is usually defined as the ratio of the variance to the mean. As a formula, that's: D = \u03c32 / \u03bc.",
      "question": "How do you find the variance of a ratio"
    },
    {
      "answer": "Expectation maximization is applicable whenever the data are missing completely at random or missing at random-but unsuitable when the data are not missing at random.",
      "question": "What is Expectation Maximization for missing data"
    },
    {
      "answer": "Biased but consistent , it approaches the correct value, and so it is consistent. ), these are both negatively biased but consistent estimators.",
      "question": "Can a biased estimator be consistent"
    },
    {
      "answer": "Importance sampling is a variance reduction technique that can be used in the Monte Carlo method. The idea behind importance sampling is that certain values of the input random variables in a simulation have more impact on the parameter being estimated than others.",
      "question": "What is the importance of a sampling approach to the estimation of expected values in Monte Carlo algorithms"
    },
    {
      "answer": "To perform principal component analysis using the correlation matrix using the prcomp() function, set the scale argument to TRUE . Plot the first two PCs of the correlation matrix using the autoplot() function.",
      "question": "How do you do principal component analysis in R"
    },
    {
      "answer": "Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable. The nature of target or dependent variable is dichotomous, which means there would be only two possible classes.  Mathematically, a logistic regression model predicts P(Y=1) as a function of X.",
      "question": "How does logistic regression algorithm work"
    },
    {
      "answer": "In the study of probability theory, the central limit theorem (CLT) states that the distribution of sample approximates a normal distribution (also known as a \u201cbell curve\u201d) as the sample size becomes larger, assuming that all samples are identical in size, and regardless of the population distribution shape.",
      "question": "What is central limit theorem in probability"
    },
    {
      "answer": "Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)",
      "question": "What is learning algorithm in machine learning"
    },
    {
      "answer": "Risk tolerance",
      "question": "What is the opposite of risk aversion"
    },
    {
      "answer": "There are basically two methods to reduce autocorrelation, of which the first one is most important:Improve model fit. Try to capture structure in the data in the model.  If no more predictors can be added, include an AR1 model.",
      "question": "How do you fix autocorrelation"
    },
    {
      "answer": "In statistics, Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference.",
      "question": "Is linear regression Bayesian"
    },
    {
      "answer": "0:3910:15Suggested clip \u00b7 118 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do a regression analysis with multiple variables"
    },
    {
      "answer": "Creative Ways to Benefit From Social Media AnalyticsEngage Better With Your Audience. Many businesses have a hard time keeping up with the vast amount of social media activity that impacts their brand.  Improve Customer Relations.  Monitor Your Competition.  Identify and Engage With Your Top Customers.  Find Out Where Your Industry is Heading.",
      "question": "What are the benefits of social media analytics"
    },
    {
      "answer": "Area in TailsConfidence LevelArea between 0 and z-scorez-score50%0.25000.67480%0.40001.28290%0.45001.64595%0.47501.9602 more rows",
      "question": "What is the z score for 50 confidence interval"
    },
    {
      "answer": "Advantages of Naive Bayes ClassifierIt is simple and easy to implement.It doesn't require as much training data.It handles both continuous and discrete data.It is highly scalable with the number of predictors and data points.It is fast and can be used to make real-time predictions.More items\u2022",
      "question": "What are the advantages of using a naive Bayes classifier as opposed to other methods"
    },
    {
      "answer": "Since a Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.",
      "question": "How does naive Bayes work in text classification"
    },
    {
      "answer": "The Taguchi loss function is graphical depiction of loss developed by the Japanese business statistician Genichi Taguchi to describe a phenomenon affecting the value of products produced by a company.  This means that if the product dimension goes out of the tolerance limit the quality of the product drops suddenly.",
      "question": "What does the Taguchi loss function indicate"
    },
    {
      "answer": "Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.",
      "question": "How does the Adam Optimizer work"
    },
    {
      "answer": "In (and after) TensorFlow version 0.11. 0RC1, you can save and restore your model directly by calling tf. train. export_meta_graph and tf.",
      "question": "How do I save and restore model in Tensorflow"
    },
    {
      "answer": "In computer science, a universal Turing machine (UTM) is a Turing machine that simulates an arbitrary Turing machine on arbitrary input.  In terms of computational complexity, a multi-tape universal Turing machine need only be slower by logarithmic factor compared to the machines it simulates.",
      "question": "What is universal Turing machine in TOC"
    },
    {
      "answer": "A feature vector is just a vector that contains information describing an object's important characteristics. In image processing, features can take many forms. A simple feature representation of an image is the raw intensity value of each pixel. However, more complicated feature representations are also possible.",
      "question": "What is CNN feature vector"
    },
    {
      "answer": "The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.",
      "question": "What is weighted kappa"
    },
    {
      "answer": "Decision Tree node splitting is an important step, the core issue is how to choose the splitting attribute.  5, the splitting criteria is calculating information gain of each attribute, then the attribute with the maximum information gain or information gain ratio is selected as splitting attribute.",
      "question": "What is splitting criterion in data mining"
    },
    {
      "answer": "Multinomial logistic regression does have assumptions, such as the assumption of independence among the dependent variable choices. This assumption states that the choice of or membership in one category is not related to the choice or membership of another category (i.e., the dependent variable).",
      "question": "What are the assumptions of multinomial logistic regression"
    },
    {
      "answer": "he confidence interval tells you more than just the possible range around the estimate. It also tells you about how stable the estimate is. A stable estimate is one that would be close to the same value if the survey were repeated.",
      "question": "What does the confidence interval tell you"
    },
    {
      "answer": "Assuming the sample size is constant across sampling methods, cluster sampling generally provides less precision than either simple random sampling or stratified sampling. This is the main disadvantage of cluster sampling.",
      "question": "What is the disadvantage of cluster sampling"
    },
    {
      "answer": "The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. A supervised machine learning algorithm uses historical data to learn patterns and uncover relationships between other features of your dataset and the target.",
      "question": "What is a target in machine learning"
    },
    {
      "answer": "Bias is stated as a penchant that prevents objective consideration of an issue or situation; basically the formation of opinion beforehand without any examination. Selection is stated as the act of choosing or selecting a preference; resulting in a carefully chosen and representative choice.",
      "question": "What is the difference between bias and selection"
    },
    {
      "answer": "Using proper validation techniques helps you understand your model, but most importantly, estimate an unbiased generalization performance.Splitting your data.  k-Fold Cross-Validation (k-Fold CV)  Leave-one-out Cross-Validation (LOOCV)  Nested Cross-Validation.  Time Series CV.  Comparing Models.",
      "question": "How do you validate a model performance"
    },
    {
      "answer": "One drawback of boxplots is that they tend to emphasize the tails of a distribution, which are the least certain points in the data set. They also hide many of the details of the distribution.",
      "question": "What are the disadvantages of a box plot"
    },
    {
      "answer": "Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.",
      "question": "How would you prepare a dataset for deep learning"
    },
    {
      "answer": "\u2013 Rejection sampling: reject samples disagreeing with evidence. \u2013 Markov chain Monte Carlo (MCMC): sample from a stochastic process. whose stationary distribution is the true posterior.",
      "question": "What does rejection sampling mean in Bayesian nets"
    },
    {
      "answer": "Every probability pi is a number between 0 and 1, and the sum of all the probabilities is equal to 1. Examples of discrete random variables include: The number of eggs that a hen lays in a given day (it can't be 2.3) The number of people going to a given soccer match.",
      "question": "What is an example of a discrete random variable"
    },
    {
      "answer": "A sequence of random variables is covariance stationary if all the terms of the sequence have the same mean, and if the covariance between any two terms of the sequence depends only on the relative positions of the two terms, that is, on how far apart they are located from each other, and not on their absolute position",
      "question": "How do you prove covariance stationary"
    },
    {
      "answer": "Auxiliary Classifiers are type of architectural component that seek to improve the convergence of very deep networks. They are classifier heads we attach to layers before the end of the network.",
      "question": "What is auxiliary classifier"
    },
    {
      "answer": "Try to avoid implementing cheap tricks to make your code run faster.Optimize your Code using Appropriate Algorithm.  Optimize Your Code for Memory.  printf and scanf Vs cout and cin.  Using Operators.  if Condition Optimization.  Problems with Functions.  Optimizing Loops.  Data Structure Optimization.More items\u2022",
      "question": "How do you optimize code"
    },
    {
      "answer": "Word2Vec slightly customizes the process and calls it negative sampling. In Word2Vec, the words for the negative samples (used for the corrupted pairs) are drawn from a specially designed distribution, which favours less frequent words to be drawn more often.",
      "question": "What is negative sampling in Word2Vec"
    },
    {
      "answer": "Feature extraction is a general term for methods of constructing combinations of the variables to get around these problems while still describing the data with sufficient accuracy. Many machine learning practitioners believe that properly optimized feature extraction is the key to effective model construction.",
      "question": "What are feature extraction algorithms"
    },
    {
      "answer": "A discrete distribution is a statistical distribution that shows the probabilities of discrete (countable) outcomes, such as 1, 2, 3  Overall, the concepts of discrete and continuous probability distributions and the random variables they describe are the underpinnings of probability theory and statistical analysis.",
      "question": "What are discrete distributions"
    },
    {
      "answer": "Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing (NLP), speech recognition and machine vision.",
      "question": "Is AI Artificial Intelligence"
    },
    {
      "answer": "2 Answers. If you have two classes (i.e. binary classification), you should use a binary crossentropy loss. If you have more than two you should use a categorical crossentropy loss.",
      "question": "How do I tell which loss function is suitable for image classification"
    },
    {
      "answer": "Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.  Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy.",
      "question": "Does unlabeled data really help in semi supervised learning"
    },
    {
      "answer": "Classification is a type of supervised learning. It specifies the class to which data elements belong to and is best used when the output has finite and discrete values. It predicts a class for an input variable as well.",
      "question": "What is ML classification"
    },
    {
      "answer": "As already discussed, SVM aims at maximizing the geometric margin and returns the corresponding hyperplane.  Such points are called as support vectors (fig. - 1). Therefore, the optimization problem as defined above is equivalent to the problem of maximizing the margin value (not geometric/functional margin values).",
      "question": "What does SVM optimize"
    },
    {
      "answer": "At Google, we call it Wide & Deep Learning. It's useful for generic large-scale regression and classification problems with sparse inputs (categorical features with a large number of possible feature values), such as recommender systems, search, and ranking problems.",
      "question": "What is wide and deep learning"
    },
    {
      "answer": "A studentized residual is calculated by dividing the residual by an estimate of its standard deviation. The standard deviation for each residual is computed with the observation excluded. For this reason, studentized residuals are sometimes referred to as externally studentized residuals.",
      "question": "How do you find the Studentized residual"
    },
    {
      "answer": "Poisson Formula. P(x; \u03bc) = (e-\u03bc) (\u03bcx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to \u03bc . The variance is also equal to \u03bc .",
      "question": "What is Poisson distribution formula"
    },
    {
      "answer": "F-test is used either for testing the hypothesis about the equality of two population variances or the equality of two or more population means. The equality of two population means was dealt with t-test. Besides a t-test, we can also apply F-test for testing equality of two population means.",
      "question": "What are the applications of F test"
    },
    {
      "answer": "The value of the odds ratio tells you how much more likely someone under 25 might be to make a claim, for example, and the associated confidence interval indicates the degree of uncertainty associated with that ratio.",
      "question": "How do you interpret confidence intervals and odds ratio"
    },
    {
      "answer": "Cross Entropy is definitely a good loss function for Classification Problems, because it minimizes the distance between two probability distributions - predicted and actual.  So cross entropy make sure we are minimizing the difference between the two probability. This is the reason.",
      "question": "Why is cross entropy used for classification"
    },
    {
      "answer": "Class limits specify the span of data values that fall within a class. Class boundaries are values halfway between the upper class limit of one class and the lower class limit of the next.  Class limits are not possible data values. Class boundaries specify the span of data values that fall within a class.",
      "question": "What is the difference between a class boundary in a class limit"
    },
    {
      "answer": "Unsupervised feature learning is learning features from unlabeled data. The goal of unsupervised feature learning is often to discover low-dimensional features that captures some structure underlying the high-dimensional input data.",
      "question": "What is unsupervised feature learning"
    },
    {
      "answer": "Statistically significant means a result is unlikely due to chance. The p-value is the probability of obtaining the difference we saw from a sample (or a larger one) if there really isn't a difference for all users.  Statistical significance doesn't mean practical significance.",
      "question": "What does it mean if a test is not statistically significant"
    },
    {
      "answer": "Motivation. Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization.  Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.",
      "question": "Why do we normalize a feature"
    },
    {
      "answer": "Naive Bayes uses a similar method to predict the probability of different class based on various attributes. This algorithm is mostly used in text classification and with problems having multiple classes.",
      "question": "In what real world applications is Naive Bayes classifier used"
    },
    {
      "answer": "Implementing Deep Q-Learning using TensorflowPrerequisites: Deep Q-Learning.Step 1: Importing the required libraries.Step 2: Building the Environment.Step 3: Building the learning agent.Step 4: Finding the Optimal Strategy.The agent tries different methods to reach the top and thus gaining knowledge from each episode.Step 5: Testing the Learning Agent.More items\u2022",
      "question": "How is deep Q learning implemented"
    },
    {
      "answer": "Q-learning is called off-policy because the updated policy is different from the behavior policy, so Q-Learning is off-policy. In other words, it estimates the reward for future actions and appends a value to the new state without actually following any greedy policy.",
      "question": "Why Q learning is off policy"
    },
    {
      "answer": "The formula for calculating a z-score is is z = (x-\u03bc)/\u03c3, where x is the raw score, \u03bc is the population mean, and \u03c3 is the population standard deviation. As the formula shows, the z-score is simply the raw score minus the population mean, divided by the population standard deviation.",
      "question": "How do you calculate z score normalization"
    },
    {
      "answer": "How to find accuracy of ARIMA model?Problem description: Prediction on CPU utilization.  Step 1: From Elasticsearch I collected 1000 observations and exported on Python.Step 2: Plotted the data and checked whether data is stationary or not.Step 3: Used log to convert the data into stationary form.Step 4: Done DF test, ACF and PACF.More items\u2022",
      "question": "How do you know if Arima model is accurate"
    },
    {
      "answer": "Generally a cosine similarity between two documents is used as a similarity measure of documents. In Java, you can use Lucene (if your collection is pretty large) or LingPipe to do this. The basic concept would be to count the terms in every document and calculate the dot product of the term vectors.",
      "question": "How do you find the similarity between two documents"
    },
    {
      "answer": "The significance level for a given hypothesis test is a value for which a P-value less than or equal to is considered statistically significant. Typical values for are 0.1, 0.05, and 0.01. These values correspond to the probability of observing such an extreme value by chance.",
      "question": "What does a significance level of 0.01 mean"
    },
    {
      "answer": "We will learn Classification algorithms, types of classification algorithms, support vector machines(SVM), Naive Bayes, Decision Tree and Random Forest Classifier in this tutorial.",
      "question": "What are the different classifiers in machine learning"
    },
    {
      "answer": "the condition or quality of being true, correct, or exact; freedom from error or defect; precision or exactness; correctness. Chemistry, Physics. the extent to which a given measurement agrees with the standard value for that measurement. Compare precision (def. 6).",
      "question": "What do you mean accuracy"
    },
    {
      "answer": "In statistics, self-selection bias arises in any situation in which individuals select themselves into a group, causing a biased sample with nonprobability sampling.  In such fields, a poll suffering from such bias is termed a self-selected listener opinion poll or \"SLOP\".",
      "question": "What does self selection bias mean"
    },
    {
      "answer": "A normality test is used to determine whether sample data has been drawn from a normally distributed population (within some tolerance). A number of statistical tests, such as the Student's t-test and the one-way and two-way ANOVA require a normally distributed sample population.",
      "question": "What does a normality test show"
    },
    {
      "answer": "Importance sampling is a useful technique for investigating the properties of a distri- bution while only having samples drawn from a different (proposal) distribution.",
      "question": "Whats the advantage of importance sampling"
    },
    {
      "answer": "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.",
      "question": "What is the purpose of batch normalization"
    },
    {
      "answer": "In machine learning, the hinge loss is a loss function used for training classifiers. The hinge loss is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs). For an intended output t = \u00b11 and a classifier score y, the hinge loss of the prediction y is defined as.",
      "question": "What is hinge loss in machine learning"
    },
    {
      "answer": "Adaptive resonance theory is a type of neural network technique developed by Stephen Grossberg and Gail Carpenter in 1987. The basic ART uses unsupervised learning technique.",
      "question": "What type of learning is involved in Adaptive Resonance Theory"
    },
    {
      "answer": "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.",
      "question": "What is the use of matrix factorization"
    },
    {
      "answer": "So, a highly significant intercept in your model is generally not a problem. By the same token, if the intercept is not significant you usually would not want to remove it from the model because by doing this you are creating a model that says that the response function must be zero when the predictors are all zero.",
      "question": "What if intercept is not significant in regression"
    },
    {
      "answer": "In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.",
      "question": "When would you use a hierarchical model"
    },
    {
      "answer": "The true error rate is statistically defined as the error rate of the classifier on a large number of new cases that converge in the limit to the actual population distribution.  It turns out that there are a number of ways of presenting sample cases to a classifier to get better estimates of the true error rate.",
      "question": "What is true error rate"
    },
    {
      "answer": "One-shot learning is a classification task where one example (or a very small number of examples) is given for each class, that is used to prepare a model, that in turn must make predictions about many unknown examples in the future.",
      "question": "How does SHOT learning work"
    },
    {
      "answer": "Keras is a high-level interface and uses Theano or Tensorflow for its backend. It runs smoothly on both CPU and GPU. Keras supports almost all the models of a neural network \u2013 fully connected, convolutional, pooling, recurrent, embedding, etc. Furthermore, these models can be combined to build more complex models.",
      "question": "Is keras a part of TensorFlow"
    },
    {
      "answer": "Disadvantages of Sampling Since choice of sampling method is a judgmental task, there exist chances of biasness as per the mindset of the person who chooses it. Improper selection of sampling techniques may cause the whole process to defunct. Selection of proper size of samples is a difficult job.",
      "question": "What are the disadvantages of sampling"
    },
    {
      "answer": "Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks. Perceptron is a linear classifier (binary). Also, it is used in supervised learning. It helps to classify the given input data.",
      "question": "Is neural network a linear classifier"
    },
    {
      "answer": "AUC represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.  AUC is scale-invariant.",
      "question": "What is AUC score in machine learning"
    },
    {
      "answer": "Def: A uniform random permutation is one in which each of the n! possible permutations are equally likely.  Def Given a set of n elements, a k-permutation is a sequence containing k of the n elements.",
      "question": "What is uniform random permutation"
    },
    {
      "answer": "The standard error is also inversely proportional to the sample size; the larger the sample size, the smaller the standard error because the statistic will approach the actual value. The standard error is considered part of descriptive statistics. It represents the standard deviation of the mean within a dataset.",
      "question": "How does sample size effect standard error"
    },
    {
      "answer": "Therefore, a low test\u2013retest reliability correlation might be indicative of a measure with low reliability, of true changes in the persons being measured, or both. That is, in the test\u2013retest method of estimating reliability, it is not possible to separate the reliability of measure from its stability.",
      "question": "What does low test retest reliability mean"
    },
    {
      "answer": "2.1 Steps of Bayesian Data Analysis Choose a statistical model for the data in relation to the research questions. The model should have good theoretical justification and have parameters that are meaningful for the research questions.  Obtain the posterior distributions for the model parameters.",
      "question": "What are the steps involved in Bayesian data analysis"
    },
    {
      "answer": "A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch.",
      "question": "How does a regression tree work"
    },
    {
      "answer": "Quality Glossary Definition: Reliability. Reliability is defined as the probability that a product, system, or service will perform its intended function adequately for a specified period of time, or will operate in a defined environment without failure.",
      "question": "What do you mean by reliability"
    },
    {
      "answer": "You can tell if two random variables are independent by looking at their individual probabilities. If those probabilities don't change when the events meet, then those variables are independent. Another way of saying this is that if the two variables are correlated, then they are not independent.",
      "question": "How do you prove that two distributions are independent"
    },
    {
      "answer": "The original AlphaGo demonstrated superhuman Go-playing ability, but needed the expertise of human players to get there. Namely, it used a dataset of more than 100,000 Go games as a starting point for its own knowledge. AlphaGo Zero, by comparison, has only been programmed with the basic rules of Go.",
      "question": "Why was AlphaGo able to play go so well"
    },
    {
      "answer": "A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.",
      "question": "What is the difference between false positive and false negative"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.",
      "question": "Why does bootstrap work in machine learning"
    },
    {
      "answer": "7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.",
      "question": "What do you do with an unbalanced data set"
    },
    {
      "answer": "frequency\u2013inverse document frequency",
      "question": "What does TF IDF stand for"
    },
    {
      "answer": "Descriptive, prescriptive, and normative are three main areas of decision theory and each studies a different type of decision making.",
      "question": "What are the different theories of decision making"
    },
    {
      "answer": "Positive feedback occurs to increase the change or output: the result of a reaction is amplified to make it occur more quickly.  Some examples of positive feedback are contractions in child birth and the ripening of fruit; negative feedback examples include the regulation of blood glucose levels and osmoregulation.",
      "question": "What is an example of positive feedback"
    },
    {
      "answer": "Moments are are very useful in statistics because they tell you much about your data. There are four commonly used moments in statistics: the mean, variance, skewness, and kurtosis. The mean gives you a measure of center of the data.",
      "question": "What are the uses of moments"
    },
    {
      "answer": "Kalman filters combine two sources of information, the predicted states and noisy measurements, to produce optimal, unbiased estimates of system states. The filter is optimal in the sense that it minimizes the variance in the estimated states.",
      "question": "Is Kalman filter optimal"
    },
    {
      "answer": "AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.",
      "question": "What is AB testing in Analytics"
    },
    {
      "answer": "The technique of Monte Carlo Simulation (MCS) was originally developed for use in nuclear weapons design. It provides an efficient way to simulate processes involving chance and uncertainty and can be applied in areas as diverse as market sizing, customer lifetime value measurement and customer service management.",
      "question": "What are some interesting applications of Monte Carlo method"
    },
    {
      "answer": "Regularized regression is a type of regression where the coefficient estimates are constrained to zero. The magnitude (size) of coefficients, as well as the magnitude of the error term, are penalized. Complex models are discouraged, primarily to avoid overfitting.",
      "question": "What is regularization coefficient"
    },
    {
      "answer": "Essentially, the process goes as follows:Select k centroids. These will be the center point for each segment.Assign data points to nearest centroid.Reassign centroid value to be the calculated mean value for each cluster.Reassign data points to nearest centroid.Repeat until data points stay in the same cluster.",
      "question": "How do you find the centroid in K means clustering"
    },
    {
      "answer": "Increase Training Dataset Size Leaning on the law of large numbers, perhaps the simplest approach to reduce the model variance is to fit the model on more training data. In those cases where more data is not readily available, perhaps data augmentation methods can be used instead.",
      "question": "How do you reduce variance in machine learning"
    },
    {
      "answer": "Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).",
      "question": "What is conditional probability examples"
    },
    {
      "answer": "Eigenvectors can be used to represent a large dimensional matrix. This means that a matrix M and a vector o can be replaced by a scalar n and a vector o. In this instance, o is the eigenvector and n is the eigenvalue and our target is to find o and n.",
      "question": "What do the eigenvectors indicate"
    },
    {
      "answer": "Singularity enables users to have full control of their environment. Singularity containers can be used to package entire scientific workflows, software and libraries, and even data.  The Singularity software can import your Docker images without having Docker installed or being a superuser.",
      "question": "What is singularity container"
    },
    {
      "answer": "An activation function is a function used in artificial neural networks which outputs a small value for small inputs, and a larger value if its inputs exceed a threshold. If the inputs are large enough, the activation function \"fires\", otherwise it does nothing.",
      "question": "What is the definition of squashing function in machine learning"
    },
    {
      "answer": "The most important difference between deep learning and traditional machine learning is its performance as the scale of data increases. When the data is small, deep learning algorithms don't perform that well. This is because deep learning algorithms need a large amount of data to understand it perfectly.",
      "question": "Which of the following is true with regards to classical machine learning vs deep learning"
    },
    {
      "answer": "A CNN has multiple layers. Weight sharing happens across the receptive field of the neurons(filters) in a particular layer. Weights are the numbers within each filter.  These filters act on a certain receptive field/ small section of the image. When the filter moves through the image, the filter does not change.",
      "question": "What is weight sharing in CNN"
    },
    {
      "answer": "If we assume that there is some variation in our data, we will be able to disregard the possibility that either of these standard deviations is zero. Therefore the sign of the correlation coefficient will be the same as the sign of the slope of the regression line.",
      "question": "Is there a relationship between the correlation coefficient and the slope of a linear regression line"
    },
    {
      "answer": "In General, A Discriminative model \u200cmodels the decision boundary between the classes. A Generative Model \u200cexplicitly models the actual distribution of each class.  A Discriminative model \u200clearns the conditional probability distribution p(y|x). Both of these models were generally used in supervised learning problems.",
      "question": "What is the difference between generative and discriminative models"
    },
    {
      "answer": "In signal processing, the Fourier transform can reveal important characteristics of a signal, namely, its frequency components. y k + 1 = \u2211 j = 0 n - 1 \u03c9 j k x j + 1 . \u03c9 = e - 2 \u03c0 i / n is one of n complex roots of unity where i is the imaginary unit. For x and y , the indices j and k range from 0 to n - 1 .",
      "question": "How do you find the Fourier transform of a signal"
    },
    {
      "answer": "Transfer learning is useful when you have insufficient data for a new domain you want handled by a neural network and there is a big pre-existing data pool that can be transferred to your problem.",
      "question": "What is transfer learning and how is it useful"
    },
    {
      "answer": "In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).",
      "question": "What is agent system in artificial intelligence"
    },
    {
      "answer": "Lasso Regression Another Tolerant Method for dealing with multicollinearity known as Least Absolute Shrinkage and Selection Operator (LASSO) regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity.",
      "question": "Does Lasso regression take care of Multicollinearity"
    },
    {
      "answer": "Classification is one of the most fundamental concepts in data science. Classification algorithms are predictive calculations used to assign data to preset categories by analyzing sets of training data.\u1042\u1040\u1042\u1040\u104a \u1029 \u1042\u1046",
      "question": "What are classification algorithms in machine learning"
    },
    {
      "answer": "The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients. And gradients are used to update the weights of the Neural Net.",
      "question": "What is loss in a neural network"
    },
    {
      "answer": "How to train your Deep Neural NetworkTraining data.  Choose appropriate activation functions.  Number of Hidden Units and Layers.  Weight Initialization.  Learning Rates.  Hyperparameter Tuning: Shun Grid Search - Embrace Random Search.  Learning Methods.  Keep dimensions of weights in the exponential power of 2.More items\u2022",
      "question": "How do I train a deep neural network"
    },
    {
      "answer": "Model calibration is the process of adjustment of the model parameters and forcing within the margins of the uncertainties (in model parameters and / or model forcing) to obtain a model representation of the processes of interest that satisfies pre-agreed criteria (Goodness-of-Fit or Cost Function).",
      "question": "What does model calibration mean"
    },
    {
      "answer": "Statistics is a very good major in terms of job market and salary scale, it also open doors for many graduate courses, unless you are poor at math ,statistics is worth taking.",
      "question": "Is a statistics degree useful"
    },
    {
      "answer": "In this module, we have discussed on various data preprocessing methods for Machine Learning such as rescaling, binarizing, standardizing, one hot encoding, and label encoding.",
      "question": "Which method is used for data preprocessing in machine learning"
    },
    {
      "answer": "KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.",
      "question": "Why KNN algorithm is used"
    },
    {
      "answer": "The Analysis of covariance (ANCOVA) is done by using linear regression. This means that Analysis of covariance (ANCOVA) assumes that the relationship between the independent variable and the dependent variable must be linear in nature.",
      "question": "How is analysis of covariance done"
    },
    {
      "answer": "The difference between quota sampling and stratified sampling is: although both \"group\" participants by an important characteristic, stratified sampling relies on random selection within each group, while quota sampling relies on convenience sampling within each group.",
      "question": "What is the difference between quota sampling and stratified sampling"
    },
    {
      "answer": "Support Vector Machine can also be used as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.",
      "question": "Can SVM used for regression"
    },
    {
      "answer": "Predictive analytics is the use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data. The goal is to go beyond knowing what has happened to providing a best assessment of what will happen in the future.",
      "question": "What do you mean by predictive analytics"
    },
    {
      "answer": "The Bayesian Optimization algorithm can be summarized as follows:Select a Sample by Optimizing the Acquisition Function.Evaluate the Sample With the Objective Function.Update the Data and, in turn, the Surrogate Function.Go To 1.",
      "question": "How do I implement a Bayesian optimization"
    },
    {
      "answer": "Handling overfittingReduce the network's capacity by removing layers or reducing the number of elements in the hidden layers.Apply regularization , which comes down to adding a cost to the loss function for large weights.Use Dropout layers, which will randomly remove certain features by setting them to zero.",
      "question": "How do you deal with Overfitting in deep learning"
    },
    {
      "answer": "In summary, model parameters are estimated from data automatically and model hyperparameters are set manually and are used in processes to help estimate model parameters. Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that must be set manually and tuned.",
      "question": "What is the difference between a model parameter and a learning algorithm\u2019s hyper parameter"
    },
    {
      "answer": "A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input.",
      "question": "What is the use of convolutional neural network"
    },
    {
      "answer": "Concept shift is closely related to concept drift. This occurs when a model learned from data sampled from one distribution needs to be applied to data drawn from another.",
      "question": "What is Concept shift"
    },
    {
      "answer": "Null and alternate hypothesis are different and you can't interchange them. Alternate hypothesis is just the opposite of null which means there is a statistical difference in Mean / median of both the data sets.",
      "question": "Can I switch around the null and alternative hypothesis in hypothesis testing"
    },
    {
      "answer": "Three keys to managing bias when building AIChoose the right learning model for the problem. There's a reason all AI models are unique: Each problem requires a different solution and provides varying data resources.  Choose a representative training data set.  Monitor performance using real data.",
      "question": "How can machine learning overcome bias"
    },
    {
      "answer": "For a hypothesis test, a researcher collects sample data.  If the statistic falls within a specified range of values, the researcher rejects the null hypothesis . The range of values that leads the researcher to reject the null hypothesis is called the region of rejection.",
      "question": "What is the region of rejection"
    },
    {
      "answer": "The Purpose of Statistics: Statistics teaches people to use a limited sample to make intelligent and accurate conclusions about a greater population. The use of tables, graphs, and charts play a vital role in presenting the data being used to draw these conclusions.",
      "question": "What is statistics and its purpose"
    },
    {
      "answer": "To calculate the similarity between two examples, you need to combine all the feature data for those two examples into a single numeric value. For instance, consider a shoe data set with only one feature: shoe size. You can quantify how similar two shoes are by calculating the difference between their sizes.",
      "question": "How do you calculate similarity"
    },
    {
      "answer": "Some of the more common ways to normalize data include:Transforming data using a z-score or t-score.  Rescaling data to have values between 0 and 1.  Standardizing residuals: Ratios used in regression analysis can force residuals into the shape of a normal distribution.Normalizing Moments using the formula \u03bc/\u03c3.More items",
      "question": "How do you normalize data in statistics"
    },
    {
      "answer": "If your regression model contains independent variables that are statistically significant, a reasonably high R-squared value makes sense.  Correspondingly, the good R-squared value signifies that your model explains a good proportion of the variability in the dependent variable.",
      "question": "What do you report in a multiple regression to say whether the variables are significant or not"
    },
    {
      "answer": "Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.",
      "question": "How do you tell if an event is independent or dependent"
    },
    {
      "answer": "3 layers",
      "question": "How many layers are there in deep learning"
    },
    {
      "answer": "There is a broad range of opportunities to study optimization problems that cannot be solved with an exact algorithm.  This work proposes the use of neural networks such as heuristics to resolve optimization problems in those cases where the use of linear programming or Lagrange multipliers is not feasible.",
      "question": "Can neural networks be used for optimization"
    },
    {
      "answer": "While implementing the decision tree we will go through the following two phases:Building Phase. Preprocess the dataset. Split the dataset from train and test using Python sklearn package. Train the classifier.Operational Phase. Make predictions. Calculate the accuracy.",
      "question": "How do you implement a decision tree"
    },
    {
      "answer": "For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length of time, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts.",
      "question": "What is exponential distribution example"
    },
    {
      "answer": "In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body.",
      "question": "What is topic Modelling used for"
    },
    {
      "answer": "Because the distance function used to find the k nearest neighbors is not linear, so it usually won't lead to a linear decision boundary.  kNN does not build a model of your data, it simply assumes that instances that are close together in space are similar.",
      "question": "Can Knn have linear decision boundary"
    },
    {
      "answer": "AlphaGo Zero is a version of DeepMind's Go software AlphaGo.  By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days.",
      "question": "What is significant about Alpha Go Zero"
    },
    {
      "answer": "Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).",
      "question": "What is the difference between discrete and continuous distribution"
    },
    {
      "answer": "The bits of linguistic information that enter into one person's mind, from another, cause people to entertain a new thought with profound effects on his world knowledge, inferencing, and subsequent behavior. Language neither creates nor distorts conceptual life. Thought comes first, while language is an expression.",
      "question": "What is the relationship between language and thought"
    },
    {
      "answer": "Machine learning, a subset of artificial intelligence (AI), depends on the quality, objectivity and size of training data used to teach it.  Machine learning bias generally stems from problems introduced by the individuals who design and/or train the machine learning systems.",
      "question": "Is Machine Learning Biased"
    },
    {
      "answer": "TensorFlow Lite inferenceAndroid Platform.iOS Platform.Linux Platform.",
      "question": "Which devices support TensorFlow Lite for inference"
    },
    {
      "answer": "Jakob Bernoulli",
      "question": "Who created the law of averages"
    },
    {
      "answer": "Simple regression analysis uses a single x variable for each dependent \u201cy\u201d variable. For example: (x1, Y1). Multiple regression uses multiple \u201cx\u201d variables for each independent variable: (x1)1, (x2)1, (x3)1, Y1).",
      "question": "What is a regression model example"
    },
    {
      "answer": "Training deep learning neural networks is very challenging. The best general algorithm known for solving this problem is stochastic gradient descent, where model weights are updated each iteration using the backpropagation of error algorithm. Optimization in general is an extremely difficult task.",
      "question": "What are the challenges in training a neural network"
    },
    {
      "answer": "In robust statistics, robust regression is a form of regression analysis designed to overcome some limitations of traditional parametric and non-parametric methods. Regression analysis seeks to find the relationship between one or more independent variables and a dependent variable.",
      "question": "What are robust regressions and robust statistics"
    },
    {
      "answer": "The term \u201cmultivariate statistics\u201d is appropriately used to include all statistics where there are more than two variables simultaneously analyzed. You are already familiar with bivariate statistics such as the Pearson product moment correlation coefficient and the independent groups t-test.",
      "question": "What is multivariate variable"
    },
    {
      "answer": "Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.",
      "question": "What does regression analysis tell you"
    },
    {
      "answer": "The most common hash functions used in digital forensics are Message Digest 5 (MD5), and Secure Hashing Algorithm (SHA) 1 and 2.",
      "question": "What are the two common hash functions"
    },
    {
      "answer": "Multiclass classification with logistic regression can be done either through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.",
      "question": "How do you use logistic regression for multi class classification"
    },
    {
      "answer": "Bias can damage research, if the researcher chooses to allow his bias to distort the measurements and observations or their interpretation. When faculty are biased about individual students in their courses, they may grade some students more or less favorably than others, which is not fair to any of the students.",
      "question": "Why is being bias bad"
    },
    {
      "answer": "Forward chaining starts from known facts and applies inference rule to extract more data unit it reaches to the goal. Backward chaining starts from the goal and works backward through inference rules to find the required facts that support the goal.  Backward chaining reasoning applies a depth-first search strategy.",
      "question": "What is forward and backward chaining in AI"
    },
    {
      "answer": "Random error can be reduced by: Using an average measurement from a set of measurements, or. Increasing sample size.",
      "question": "What is random error and how can it be reduced"
    },
    {
      "answer": "An example of pattern recognition is classification, which attempts to assign each input value to one of a given set of classes (for example, determine whether a given email is \"spam\" or \"non-spam\").  This is opposed to pattern matching algorithms, which look for exact matches in the input with pre-existing patterns.",
      "question": "What is an example of pattern recognition"
    },
    {
      "answer": "In short, Softmax Loss is actually just a Softmax Activation plus a Cross-Entropy Loss. Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.",
      "question": "Is the softmax loss the same as the cross entropy loss"
    },
    {
      "answer": "In Convolutional Neural Networks, Filters detect spatial patterns such as edges in an image by detecting the changes in intensity values of the image.",
      "question": "What are filters in neural networks"
    },
    {
      "answer": "Covariance Matrix is a measure of how much two random variables gets change together.  The Covariance Matrix is also known as dispersion matrix and variance-covariance matrix. The covariance between two jointly distributed real-valued random variables X and Y with finite second moments is defined as.",
      "question": "What is covariance matrix example"
    },
    {
      "answer": "Deconvolution layer is a very unfortunate name and should rather be called a transposed convolutional layer. Visually, for a transposed convolution with stride one and no padding, we just pad the original input (blue entries) with zeroes (white entries) (Figure 1).",
      "question": "What is a deconvolution layer"
    },
    {
      "answer": "Examples in natural systems of swarm intelligence include bird flocking, ant foraging, and fish schooling. Inspired by swarm's such behavior, a class of algorithms is proposed for tackling optimization problems, usually under the title of swarm intelligence algorithms (SIAs) [203].",
      "question": "What are the common aspects of swarm intelligence observed in nature"
    },
    {
      "answer": "Simple random sampling: By using the random number generator technique, the researcher draws a sample from the population called simple random sampling. Simple random samplings are of two types.  Cluster sampling: Cluster sampling occurs when a random sample is drawn from certain aggregational geographical groups.",
      "question": "Is cluster sampling random or non random"
    },
    {
      "answer": "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.  That when using the bootstrap you must choose the size of the sample and the number of repeats.",
      "question": "What is bootstrap method in statistics"
    },
    {
      "answer": "Principal components analysis (PCA) is a statistical technique that allows identifying underlying linear patterns in a data set so it can be expressed in terms of other data set of a significatively lower dimension without much loss of information.",
      "question": "What is PCA in neural network"
    },
    {
      "answer": "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value.",
      "question": "What is the use of ridge regression"
    },
    {
      "answer": "A hypothesis is an approximate explanation that relates to the set of facts that can be tested by certain further investigations. There are basically two types, namely, null hypothesis and alternative hypothesis. A research generally starts with a problem.",
      "question": "What are the two types of hypothesis testing"
    },
    {
      "answer": "One major disadvantage of non-probability sampling is that it's impossible to know how well you are representing the population. Plus, you can't calculate confidence intervals and margins of error.",
      "question": "What are the disadvantages of non probability sampling"
    },
    {
      "answer": "Univariate analysis is the simplest form of analyzing data. \u201cUni\u201d means \u201cone\u201d, so in other words your data has only one variable. It doesn't deal with causes or relationships (unlike regression ) and it's major purpose is to describe; It takes data, summarizes that data and finds patterns in the data.",
      "question": "How do you analyze univariate data"
    },
    {
      "answer": "Like random forests, gradient boosting is a set of decision trees. The two main differences are: How trees are built: random forests builds each tree independently while gradient boosting builds one tree at a time.",
      "question": "What is the difference between random forest and gradient boosting"
    },
    {
      "answer": "Bias in Machine Learning is defined as the phenomena of observing results that are systematically prejudiced due to faulty assumptions.  This also results in bias which arises from the choice of training and test data and their representation of the true population.",
      "question": "What are bias in machine learning"
    },
    {
      "answer": "Categorical variables require special attention in regression analysis because, unlike dichotomous or continuous variables, they cannot by entered into the regression equation just as they are. Instead, they need to be recoded into a series of variables which can then be entered into the regression model.",
      "question": "Can you do multiple regression with categorical variables"
    },
    {
      "answer": "The larger the sample size is the smaller the effect size that can be detected. The reverse is also true; small sample sizes can detect large effect sizes.  Thus an appropriate determination of the sample size used in a study is a crucial step in the design of a study.",
      "question": "Is it important to determine the sample size"
    },
    {
      "answer": "The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation is the default activation when developing multilayer Perceptron and convolutional neural networks.",
      "question": "What is ReLU function in neural network"
    },
    {
      "answer": "A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.",
      "question": "What's the difference between false negative and false positive"
    },
    {
      "answer": "The mean, expected value, or expectation of a random variable X is writ- ten as E(X) or \u00b5X. If we observe N random values of X, then the mean of the N values will be approximately equal to E(X) for large N. The expectation is defined differently for continuous and discrete random variables.",
      "question": "What is the expectation of a random variable"
    },
    {
      "answer": "Noun. optimizer (plural optimizers) A person in a large business whose task is to maximize profits and make the business more efficient. (computing) A program that uses linear programming to optimize a process. (computing) A compiler or assembler that produces optimized code.",
      "question": "What does Optimizer mean"
    },
    {
      "answer": "It is well known that correlation does not prove causation. What is less well known is that causation can exist when correlation is zero. The upshot of these two facts is that, in general and without additional information, correlation reveals literally nothing about causation.",
      "question": "Is it possible for two things to have a causal relationship but not be correlated"
    },
    {
      "answer": "Cost Function It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. Depending on the problem Cost Function can be formed in many different ways.",
      "question": "What is a cost function in machine learning"
    },
    {
      "answer": "Content-based filtering, makes recommendations based on user preferences for product features. Collaborative filtering mimics user-to-user recommendations. It predicts users preferences as a linear, weighted combination of other user preferences. Both methods have limitations.",
      "question": "What is the difference between content based filtering and collaborative filtering"
    },
    {
      "answer": "Yes, there are. One example is the WEKA MOA framework [1]. This framework implements standard algorithms in the literature of concept drift detection.  The nice thing about this framework is that it allows users to generate new data streams which contains concept drifts of different types.",
      "question": "Is there a good library for concept drift detection algorithms"
    },
    {
      "answer": "The random forest is a model made up of many decision trees. Rather than just simply averaging the prediction of trees (which we could call a \u201cforest\u201d), this model uses two key concepts that gives it the name random: Random sampling of training data points when building trees.",
      "question": "Why is random forest called random"
    },
    {
      "answer": "Logistic Regression, also known as Logit Regression or Logit Model, is a mathematical model used in statistics to estimate (guess) the probability of an event occurring having been given some previous data. Logistic Regression works with binary data, where either the event happens (1) or the event does not happen (0).",
      "question": "What is logistic regression simple explanation"
    },
    {
      "answer": "Explanation: Entropy (S) by the modern definition is the amount of energy dispersal in a system. Therefore, the system entropy will increase when the amount of motion within the system increases. For example, the entropy increases when ice (solid) melts to give water (liquid).",
      "question": "What does it mean when it says increase or decrease in entropy"
    },
    {
      "answer": "The main difference between Binomial and Poisson Distribution is that the Binomial distribution is only for a certain frame or a probability of success and the Poisson distribution is used for events that could occur a very large number of times.",
      "question": "What is the main difference between the binomial distribution and the Poisson distribution"
    },
    {
      "answer": "EXC functions both find a requested quartile of a supplied data set. The difference between these two functions is that QUARTILE. INC bases its calculation on a percentile range of 0 to 1 inclusive, whereas QUARTILE. EXC bases its calculation on a percentile range of 0 to 1 exclusive.",
      "question": "What is the difference between quartile exc and quartile inc"
    },
    {
      "answer": "A multi-agent system (MAS or \"self-organized system\") is a computerized system composed of multiple interacting intelligent agents.  Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning.",
      "question": "What are multi agents in artificial intelligence"
    },
    {
      "answer": "Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them.",
      "question": "What is data augmentation in deep learning"
    },
    {
      "answer": "Log loss is used when we have {0,1} response. This is usually because when we have {0,1} response, the best models give us values in terms of probabilities. In simple words, log loss measures the UNCERTAINTY of the probabilities of your model by comparing them to the true labels.",
      "question": "Why do we use log loss in logistic regression"
    },
    {
      "answer": "As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.",
      "question": "How do you work out Standardised scores"
    },
    {
      "answer": "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.  It is a term and set of techniques known in machine learning in the training and operation of deep learning models can be described in terms of tensors.",
      "question": "What is a tensor ML"
    },
    {
      "answer": "A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease. The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant.",
      "question": "What do negative coefficients mean in regression"
    },
    {
      "answer": "In machine learning, multiclass or multinomial classification is the problem of classifying instances into one of three or more classes (classifying instances into one of two classes is called binary classification).",
      "question": "What is multi class classification in machine learning"
    },
    {
      "answer": "Bias is a disproportionate weight in favor of or against an idea or thing, usually in a way that is closed-minded, prejudicial, or unfair. Biases can be innate or learned. People may develop biases for or against an individual, a group, or a belief. In science and engineering, a bias is a systematic error.",
      "question": "What does bias mean"
    },
    {
      "answer": "Steps for Making decision treeGet list of rows (dataset) which are taken into consideration for making decision tree (recursively at each nodes).Calculate uncertanity of our dataset or Gini impurity or how much our data is mixed up etc.Generate list of all question which needs to be asked at that node.More items\u2022",
      "question": "How do you make a decision in tree machine learning"
    },
    {
      "answer": "On each iteration, we update the parameters in the opposite direction of the gradient of the objective function J(w) w.r.t the parameters where the gradient gives the direction of the steepest ascent. The size of the step we take on each iteration to reach the local minimum is determined by the learning rate \u03b1.",
      "question": "How are the parameters updates during the gradient descent process"
    },
    {
      "answer": "In general, there is no universal rule of thumb indicating that the accuracy of a learner is directly proportional to the number of features used to train it.",
      "question": "Does increasing the number of feature variables of the dataset improve the accuracy of the training model"
    },
    {
      "answer": "Hidden Markov models are known for their applications to thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory, pattern recognition - such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and",
      "question": "Where does the hidden Markov model is used"
    },
    {
      "answer": "Face detection is a broader term than face recognition. Face detection just means that a system is able to identify that there is a human face present in an image or video.  Face recognition can confirm identity. It is therefore used to control access to sensitive areas.",
      "question": "What is difference between face detection and face recognition"
    },
    {
      "answer": "Significance level and p-value \u03b1 is the maximum probability of rejecting the null hypothesis when the null hypothesis is true. If \u03b1 = 1 we always reject the null, if \u03b1 = 0 we never reject the null hypothesis.  If we choose to compare the p-value to \u03b1 = 0.01, we are insisting on a stronger evidence!",
      "question": "How small of an alpha value can you choose and still have sufficient evidence to reject the null hypothesis"
    },
    {
      "answer": "You can use test statistics to determine whether to reject the null hypothesis. The test statistic compares your data with what is expected under the null hypothesis. The test statistic is used to calculate the p-value. A test statistic measures the degree of agreement between a sample of data and the null hypothesis.",
      "question": "What is the appropriate test statistic"
    },
    {
      "answer": "In mathematics, the operator norm is a means to measure the \"size\" of certain linear operators. Formally, it is a norm defined on the space of bounded linear operators between two given normed vector spaces.",
      "question": "What is the operator norm of a matrix"
    },
    {
      "answer": "How to Get Started with AIPick a topic you are interested in.Find a quick solution.Improve your simple solution.Share your solution.Repeat steps 1-4 for different problems.Complete a Kaggle competition.Use machine learning professionally.",
      "question": "How do I start learning artificial intelligence"
    },
    {
      "answer": "EdgeRank",
      "question": "What is the name for Facebook's ranking algorithm"
    },
    {
      "answer": "The distinction between probability and likelihood is fundamentally important: Probability attaches to possible results; likelihood attaches to hypotheses. Explaining this distinction is the purpose of this first column. Possible results are mutually exclusive and exhaustive.",
      "question": "What is difference between probability and likelihood"
    },
    {
      "answer": "Random assignment is however a process of randomly assigning subjects to experimental or control groups. This is a standard practice in true experimental research to ensure that treatment groups are similar (equivalent) to each other and to the control group, prior to treatment administration.",
      "question": "Are based on the idea that subjects are randomly assigned to groups"
    },
    {
      "answer": "A sampling distribution is a probability distribution of a statistic obtained from a larger number of samples drawn from a specific population. The sampling distribution of a given population is the distribution of frequencies of a range of different outcomes that could possibly occur for a statistic of a population.",
      "question": "What is a normal sample distribution"
    },
    {
      "answer": "Well labeled dataset can be used to train a custom model.In the Data Labeling Service UI, you create a dataset and import items into it from the same page.Open the Data Labeling Service UI.  Click the Create button in the title bar.On the Add a dataset page, enter a name and description for the dataset.More items",
      "question": "How do I create a labeled dataset"
    },
    {
      "answer": "Logic, as per the definition of the Oxford dictionary, is \"the reasoning conducted or assessed according to strict principles and validity\". In Artificial Intelligence also, it carries somewhat the same meaning. Logic can be defined as the proof or validation behind any reason provided.",
      "question": "What is logic in artificial intelligence"
    },
    {
      "answer": "Quartile deviation is the difference between \u201cfirst and third quartiles\u201d in any distribution. Standard deviation measures the \u201cdispersion of the data set\u201d that is relative to its mean.",
      "question": "What is the difference between standard deviation and quartile deviation"
    },
    {
      "answer": "Variance: Var(X) To calculate the Variance: square each value and multiply by its probability. sum them up and we get \u03a3x2p. then subtract the square of the Expected Value \u03bc",
      "question": "How do you find a variance of a function"
    },
    {
      "answer": "A deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables. It is a network of symmetrically coupled stochastic binary units. It comprises a set of visible units and layers of hidden units .",
      "question": "What is deep Boltzmann machine"
    },
    {
      "answer": "According to Bezdek (1994), Computational Intelligence is a subset of Artificial Intelligence. There are two types of machine intelligence: the artificial one based on hard computing techniques and the computational one based on soft computing methods, which enable adaptation to many situations.",
      "question": "What is computational intelligence and how is it related to AI"
    },
    {
      "answer": "Definition. Predictive analytics is an area of statistics that deals with extracting information from data and using it to predict trends and behavior patterns.  Predictive analytics statistical techniques include data modeling, machine learning, AI, deep learning algorithms and data mining.",
      "question": "How is predictive analytics done"
    },
    {
      "answer": "It is very much like the exponential distribution, with \u03bb corresponding to 1/p, except that the geometric distribution is discrete while the exponential distribution is continuous.",
      "question": "Is exponential distribution discrete or continuous"
    },
    {
      "answer": "For most common clustering software, the default distance measure is the Euclidean distance.  Correlation-based distance considers two objects to be similar if their features are highly correlated, even though the observed values may be far apart in terms of Euclidean distance.",
      "question": "What is distance measure in clustering"
    },
    {
      "answer": "A/B tests are easy and seem harmless, but many consumers become disturbed when they find out they're being tested without knowing it. Some argue that A/B testing tracks along the same ethical lines as a product launch; others believe organizations\u200b must be transparent about their testing even if it seems harmless.",
      "question": "Is a B testing ethical"
    },
    {
      "answer": "From the mathematical point of view, linear regression and ANOVA are identical: both break down the total variance of the data into different \u201cportions\u201d and verify the equality of these \u201csub-variances\u201d by means of a test (\u201cF\u201d Test).",
      "question": "Is Anova the same as linear regression"
    },
    {
      "answer": "1:3610:15Suggested clip \u00b7 117 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do a regression in Excel with multiple variables"
    },
    {
      "answer": "The General Linear Model (GLM) is a useful framework for comparing how several variables affect different continuous variables. In it's simplest form, GLM is described as: Data = Model + Error (Rutherford, 2001, p.3) GLM is the foundation for several statistical tests, including ANOVA, ANCOVA and regression analysis.",
      "question": "What is the general linear model GLM Why does it matter"
    },
    {
      "answer": "Word2Vec takes texts as training data for a neural network. The resulting embedding captures whether words appear in similar contexts. GloVe focuses on words co-occurrences over the whole corpus. Its embeddings relate to the probabilities that two words appear together.",
      "question": "What is the difference between GloVe and word2vec"
    },
    {
      "answer": "Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance.",
      "question": "What does principal component analysis do"
    },
    {
      "answer": "In a positively skewed distribution, the mean is usually greater than the median because the few high scores tend to shift the mean to the right.  In a positively skewed distribution, the mode is always less than the mean and median.",
      "question": "Which is typical of a positively skewed distribution"
    },
    {
      "answer": "For years, people have been forecasting weather patterns, economic and political events, sports outcomes, and more.  Because we try to predict so many different events, there are a wide variety of ways in which forecasts can be developed.",
      "question": "What is forecasting in machine learning"
    },
    {
      "answer": "Non parametric do not assume that the data is normally distributed.  For example: the Kruskal Willis test is the non parametric alternative to the One way ANOVA and the Mann Whitney is the non parametric alternative to the two sample t test. The main nonparametric tests are: 1-sample sign test.",
      "question": "Which is an example of non parametric statistic"
    },
    {
      "answer": "The decision for converting a predicted probability or scoring into a class label is governed by a parameter referred to as the \u201cdecision threshold,\u201d \u201cdiscrimination threshold,\u201d or simply the \u201cthreshold.\u201d The default value for the threshold is 0.5 for normalized predicted probabilities or scores in the range between 0",
      "question": "What is threshold machine learning"
    },
    {
      "answer": "SummaryWeighted Mean: A mean where some values contribute more than others.When the weights add to 1: just multiply each weight by the matching value and sum it all up.Otherwise, multiply each weight w by its matching value x, sum that all up, and divide by the sum of weights: Weighted Mean = \u03a3wx\u03a3w.",
      "question": "How do you calculate weighted mean"
    },
    {
      "answer": "Try a series of runs with different amounts of training data: randomly sample 20% of it, say, 10 times and observe performance on the validation data, then do the same with 40%, 60%, 80%. You should see both greater performance with more data, but also lower variance across the different random samples.",
      "question": "How do you split your data between training and validation"
    },
    {
      "answer": "The sample standard deviation (s) is a point estimate of the population standard deviation (\u03c3). The sample mean (\u0304x) is a point estimate of the population mean, \u03bc The sample variance (s2 is a point estimate of the population variance (\u03c32).",
      "question": "What is the point estimate of the population standard deviation"
    },
    {
      "answer": "In a nutshell, the goal of Bayesian inference is to maintain a full posterior probability distribution over a set of random variables.  Sampling algorithms based on Monte Carlo Markov Chain (MCMC) techniques are one possible way to go about inference in such models.",
      "question": "What is Bayesian sampling"
    },
    {
      "answer": "The 7 Steps of Machine Learning1 - Data Collection. The quantity & quality of your data dictate how accurate our model is.  2 - Data Preparation. Wrangle data and prepare it for training.  3 - Choose a Model.  4 - Train the Model.  5 - Evaluate the Model.  6 - Parameter Tuning.  7 - Make Predictions.",
      "question": "What are the steps in designing a machine learning problem"
    },
    {
      "answer": "A Blob is a group of connected pixels in an image that share some common property ( E.g grayscale value ). In the image above, the dark connected regions are blobs, and the goal of blob detection is to identify and mark these regions.",
      "question": "What is blob in OBject detection"
    },
    {
      "answer": "Overall, Sentiment analysis may involve the following types of classification algorithms: Linear Regression. Naive Bayes. Support Vector Machines.",
      "question": "Which algorithm is used for sentiment analysis"
    },
    {
      "answer": "One or two of the sections is the \u201crejection region\u201c; if your test value falls into that region, then you reject the null hypothesis. A one tailed test with the rejection rejection in one tail. The critical value is the red line to the left of that region.",
      "question": "How do you find the critical value and rejection region"
    },
    {
      "answer": "Calculation. The formula given in most textbooks is Skew = 3 * (Mean \u2013 Median) / Standard Deviation. This is known as an alternative Pearson Mode Skewness. You could calculate skew by hand.",
      "question": "How do you find the skew of a distribution"
    },
    {
      "answer": "Class Boundaries. Separate one class in a grouped frequency distribution from another. The boundaries have one more decimal place than the raw data and therefore do not appear in the data. There is no gap between the upper boundary of one class and the lower boundary of the next class.",
      "question": "What is class boundary in frequency distribution"
    },
    {
      "answer": "Ambiguity. The main challenge of NLP is the understanding and modeling of elements within a variable context. In a natural language, words are unique but can have different meanings depending on the context resulting in ambiguity on the lexical, syntactic, and semantic levels.",
      "question": "What is the main challenge s of NLP"
    },
    {
      "answer": "Deep learning is an AI function that mimics the workings of the human brain in processing data for use in detecting objects, recognizing speech, translating languages, and making decisions. Deep learning AI is able to learn without human supervision, drawing from data that is both unstructured and unlabeled.",
      "question": "What is deep learning and how does it relate to AI"
    },
    {
      "answer": "0:294:16Suggested clip \u00b7 116 secondsGeometric distribution moment generating function - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you find the moment generating function of a geometric distribution"
    },
    {
      "answer": "The biggest negative of transfer learning is that it's very hard to do right and very easy to mess up. Especially in NLP this kind of approach has only been mainstream for about a year, which just isn't enough time when model runs take weeks.",
      "question": "What are the disadvantages of transfer learning"
    },
    {
      "answer": "The Monty Hall problem is one of those rare curiosities \u2013 a mathematical problem that has made the front pages of national news. Everyone now knows, or thinks they know, the answer but a realistic look at the problem demonstrates that the standard mathematician's answer is wrong.",
      "question": "Is the Monty Hall problem correct"
    },
    {
      "answer": "The t distribution is therefore leptokurtic. The t distribution approaches the normal distribution as the degrees of freedom increase.  Since the t distribution is leptokurtic, the percentage of the distribution within 1.96 standard deviations of the mean is less than the 95% for the normal distribution.",
      "question": "Does a t distribution have a normal distribution"
    },
    {
      "answer": "Let's explore 5 common techniques used for extracting information from the above text.Named Entity Recognition. The most basic and useful technique in NLP is extracting the entities in the text.  Sentiment Analysis.  Text Summarization.  Aspect Mining.  Topic Modeling.",
      "question": "How do I extract information from a text"
    },
    {
      "answer": "Optuna is an automated hyperparameter optimization software framework that is knowingly invented for the machine learning-based tasks. It emphasizes an authoritative, define-by-run approach user API.",
      "question": "What is Optuna"
    },
    {
      "answer": "Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained.  During the fitting process, you run an algorithm on data for which you know the target variable, known as \u201clabeled\u201d data, and produce a machine learning model.",
      "question": "What is fitting in machine learning"
    },
    {
      "answer": "The central limit theorem states that the CDF of Zn converges to the standard normal CDF. converges in distribution to the standard normal random variable as n goes to infinity, that is limn\u2192\u221eP(Zn\u2264x)=\u03a6(x), for all x\u2208R,  The Xi's can be discrete, continuous, or mixed random variables.",
      "question": "Does the central limit theorem apply to discrete random variables"
    },
    {
      "answer": "0:315:15Suggested clip \u00b7 110 secondsMultinomial Distributions: Examples (Basic Probability and Statistics YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you solve a multinomial distribution"
    },
    {
      "answer": "The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",
      "question": "What is difference between regression and classification"
    },
    {
      "answer": "Not only are nose strips bad for those with sensitive skin, they also worsen other skin conditions. Pore strips exacerbate rosacea-prone skin , especially if they contain irritating ingredients like alcohol and astringents. They also aggravate extremely dry skin, eczema and psoriasis .",
      "question": "Is pore strip bad"
    },
    {
      "answer": "If k is given, the K-means algorithm can be executed in the following steps: Partition of objects into k non-empty subsets. Identifying the cluster centroids (mean point) of the current partition.  Compute the distances from each point and allot points to the cluster where the distance from the centroid is minimum.",
      "question": "What is K means algorithm with example"
    },
    {
      "answer": "A sampling distribution is where you take a population (N), and find a statistic from that population.  This is repeated for all possible samples from the population. Example: You hold a survey about college student's GRE scores and calculate that the standard deviation is 1.",
      "question": "How do you describe the sampling distribution"
    },
    {
      "answer": "A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non \u2013 linear functions. Figure 4 shows a multi layer perceptron with a single hidden layer.",
      "question": "What is single layer Perceptron and Multilayer Perceptron"
    },
    {
      "answer": "A continuous distribution has a range of values that are infinite, and therefore uncountable. For example, time is infinite: you could count from 0 seconds to a billion seconds\u2026a trillion seconds\u2026and so on, forever.",
      "question": "What are some examples of continuous distribution probability"
    },
    {
      "answer": "The binomial distribution model allows us to compute the probability of observing a specified number of \"successes\" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure.",
      "question": "What is the importance of binomial distribution"
    },
    {
      "answer": "Regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors in the model constant.  The coefficient indicates that for every additional meter in height you can expect weight to increase by an average of 106.5 kilograms.",
      "question": "What is a coefficient in a regression model"
    },
    {
      "answer": "2:107:35Suggested clip \u00b7 110 secondsLinear Regression R Program Make Predictions - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you predict a value in linear regression in R"
    },
    {
      "answer": "The nominator is the joint probability and the denominator is the probability of the given outcome.  This is the conditional probability: P(A\u2223B)=P(A\u2229B)P(B) This is the Bayes' rule: P(A\u2223B)=P(B|A)\u2217P(A)P(B).",
      "question": "What is the difference between Bayes rule and conditional probability"
    },
    {
      "answer": "The Fourier transform of a function of time is a complex-valued function of frequency, whose magnitude (absolute value) represents the amount of that frequency present in the original function, and whose argument is the phase offset of the basic sinusoid in that frequency.",
      "question": "What does Fourier transform represent"
    },
    {
      "answer": "The Four Assumptions of Linear RegressionLinear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.Independence: The residuals are independent.  Homoscedasticity: The residuals have constant variance at every level of x.Normality: The residuals of the model are normally distributed.",
      "question": "What are the four assumptions of linear regression"
    },
    {
      "answer": "The logarithm is to exponentiation as division is to multiplication: The logarithm is the inverse of the exponent: it undoes exponentiation. When studying logarithms, always remember the following fundamental equivalence: if and only if . Whenever one of these is true, so is the other.",
      "question": "What is the intuition behind the logarithm"
    },
    {
      "answer": "Batch Normalization during inference During testing or inference phase we can't apply the same batch-normalization as we did during training because we might pass only sample at a time so it doesn't make sense to find mean and variance on a single sample.",
      "question": "Is batch normalization used in inference"
    },
    {
      "answer": "(1 p)xp = (1 p)a+1p + \u00b7\u00b7\u00b7 + (1 p)bp = (1 p)a+1p (1 p)b+1p 1 (1 p) = (1 p)a+1 (1 p)b+1 We can take a = 0 to find the distribution function for a geometric random variable. The initial d indicates density and p indicates the probability from the distribution function.",
      "question": "How do you find the distribution function of a random variable"
    },
    {
      "answer": "If the limit of |a[n+1]/a[n]| is less than 1, then the series (absolutely) converges. If the limit is larger than one, or infinite, then the series diverges.",
      "question": "How do you test for convergence and divergence in a series"
    },
    {
      "answer": "Data visualization is a technique that uses an array of static and interactive visuals within a specific context to help people understand and make sense of large amounts of data. The data is often displayed in a story format that visualizes patterns, trends and correlations that may otherwise go unnoticed.",
      "question": "What is visualization in machine learning"
    },
    {
      "answer": "Deep Learning is extensively used for Predictive Analytics, NLP, Computer Vision, and Object Recognition.",
      "question": "Does NLP use deep learning"
    },
    {
      "answer": "If you see a lowercase x or y, that's the kind of variable you're used to in algebra. It refers to an unknown quantity or quantities. If you see an uppercase X or Y, that's a random variable and it usually refers to the probability of getting a certain outcome.",
      "question": "How do you identify a random variable"
    },
    {
      "answer": "Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.",
      "question": "How is gradient descent used in machine learning"
    },
    {
      "answer": "It is a process of converting a sentence to forms \u2013 list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.",
      "question": "What is part of speech tagging in NLP"
    },
    {
      "answer": "Structural equation modeling is a multivariate statistical analysis technique that is used to analyze structural relationships. This technique is the combination of factor analysis and multiple regression analysis, and it is used to analyze the structural relationship between measured variables and latent constructs.",
      "question": "What is structural equation modeling used for"
    },
    {
      "answer": "(Note that how a support vector machine classifies points that fall on a boundary line is implementation dependent. In our discussions, we have said that points falling on the line will be considered negative examples, so the classification equation is w . u + b \u2264 0.)",
      "question": "What equations are used for Classificationion in a support vector machine"
    },
    {
      "answer": "Matrix theory is a branch of mathematics which is focused on study of matrices. Initially, it was a sub-branch of linear algebra, but soon it grew to cover subjects related to graph theory, algebra, combinatorics and statistics as well.",
      "question": "What is the Matrix theory"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What does activation function do in neural network"
    },
    {
      "answer": "While the variance and the standard error of the mean are different estimates of variability, one can be derived from the other. Multiply the standard error of the mean by itself to square it. This step assumes that the standard error is a known quantity.",
      "question": "Is variance and standard error the same"
    },
    {
      "answer": "Variable screening is the process of filtering out irrelevant variables, with the aim to reduce the dimensionality from ultrahigh to high while retaining all important variables.  The main theme of this thesis is to develop variable screening and variable selection methods for high dimensional data analysis.",
      "question": "What is variable screening"
    },
    {
      "answer": "Probability Role of probability in statistics:  Use probability to predict results of experiment under assumptions. Compute probability of error larger than given amount. Compute probability of given departure between prediction and results under assumption.",
      "question": "What is the role of probability to statistic"
    },
    {
      "answer": "Probability is the study of random events. It is used in analyzing games of chance, genetics, weather prediction, and a myriad of other everyday events. Statistics is the mathematics we use to collect, organize, and interpret numerical data.",
      "question": "What are statistics and probability"
    },
    {
      "answer": "Probability density function (PDF) is a statistical expression that defines a probability distribution (the likelihood of an outcome) for a discrete random variable (e.g., a stock or ETF) as opposed to a continuous random variable.",
      "question": "What does probability density function represent"
    },
    {
      "answer": "Train a neural network with TensorFlowStep 1: Import the data.Step 2: Transform the data.Step 3: Construct the tensor.Step 4: Build the model.Step 5: Train and evaluate the model.Step 6: Improve the model.",
      "question": "How do you train a neural network in TensorFlow"
    },
    {
      "answer": "Covariance: An Overview. Variance and covariance are mathematical terms frequently used in statistics and probability theory. Variance refers to the spread of a data set around its mean value, while a covariance refers to the measure of the directional relationship between two random variables.",
      "question": "What is the meaning of covariance in statistics"
    },
    {
      "answer": "The Random Variable is X = \"The sum of the scores on the two dice\". Let's count how often each value occurs, and work out the probabilities: 2 occurs just once, so P(X = 2) = 1/36. 3 occurs twice, so P(X = 3) = 2/36 = 1/18.",
      "question": "How do you find the random variable"
    },
    {
      "answer": "NMF stands for non-negative matrix factorization, a technique for obtaining low rank representation of matrices with non-negative or positive elements.  In information retrieval and text mining, we rely on term-document matrices for representing document collections.",
      "question": "What is NMF machine learning"
    },
    {
      "answer": "Error -- subtract the theoretical value (usually the number the professor has as the target value) from your experimental data point. Percent error -- take the absolute value of the error divided by the theoretical value, then multiply by 100.",
      "question": "How do you determine data error"
    },
    {
      "answer": "In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.",
      "question": "What is a nonparametric test what is a parametric test"
    },
    {
      "answer": "The Structural Topic Model allows researchers to flexibly estimate a topic model that includes document-level metadata.  The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.",
      "question": "What is structural topic modeling"
    },
    {
      "answer": "We can interpret the Poisson regression coefficient as follows: for a one unit change in the predictor variable, the difference in the logs of expected counts is expected to change by the respective regression coefficient, given the other predictor variables in the model are held constant.",
      "question": "How do you interpret Poisson regression results"
    },
    {
      "answer": "The obvious difference between ANOVA and a \"Multivariate Analysis of Variance\" (MANOVA) is the \u201cM\u201d, which stands for multivariate. In basic terms, A MANOVA is an ANOVA with two or more continuous response variables. Like ANOVA, MANOVA has both a one-way flavor and a two-way flavor.",
      "question": "What is the difference between Anova and Manova"
    },
    {
      "answer": "Humans are error-prone and biased, but that doesn't mean that algorithms are necessarily better.  But these systems can be biased based on who builds them, how they're developed, and how they're ultimately used. This is commonly known as algorithmic bias.",
      "question": "How are algorithms biased"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is supervised and unsupervised data"
    },
    {
      "answer": "Bad Sampling. The data can be misleading due to the sampling method used to obtain data. For instance, the size and the type of sample used in any statistics play a significant role \u2014 many polls and questionnaires target certain audiences that provide specific answers, resulting in small and biased sample sizes.",
      "question": "How can statistics be mislead"
    },
    {
      "answer": "In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors.  Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers. AI is going to make our lives better in the future.",
      "question": "How AI will change the future"
    },
    {
      "answer": "We will run the ANOVA using the five-step approach.Set up hypotheses and determine level of significance. H0: \u03bc1 = \u03bc2 = \u03bc3 = \u03bc4 H1: Means are not all equal \u03b1=0.05.Select the appropriate test statistic.  Set up decision rule.  Compute the test statistic.  Conclusion.",
      "question": "What are the steps to carry out analysis of variance"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What are the differences between supervised and unsupervised learning"
    },
    {
      "answer": "A heuristic is a mental shortcut that allows people to solve problems and make judgments quickly and efficiently. These rule-of-thumb strategies shorten decision-making time and allow people to function without constantly stopping to think about their next course of action.",
      "question": "How do heuristics affect decision making"
    },
    {
      "answer": "A distribution with a single mode is said to be unimodal. A distribution with more than one mode is said to be bimodal, trimodal, etc., or in general, multimodal.",
      "question": "Is the distribution unimodal or multimodal"
    },
    {
      "answer": "The least squares method is a statistical procedure to find the best fit for a set of data points by minimizing the sum of the offsets or residuals of points from the plotted curve. Least squares regression is used to predict the behavior of dependent variables.",
      "question": "What are the uses of least square method"
    },
    {
      "answer": "The planning problem in Artificial Intelligence is about the decision making performed by intelligent creatures like robots, humans, or computer programs when trying to achieve some goal.  In the following we discuss a number of ways of formalizing planning, and show how the planning problem can be solved automatically.",
      "question": "What is planning problem in AI"
    },
    {
      "answer": "In order to fit the best intercept line between the points in the above scatter plots, we use a metric called \u201cSum of Squared Errors\u201d (SSE) and compare the lines to find out the best fit by reducing errors.",
      "question": "What is the metric used by ordinary least squares OLS to determine the best fit line"
    },
    {
      "answer": "In statistics, a sequence (or a vector) of random variables is homoscedastic /\u02ccho\u028amo\u028ask\u0259\u02c8d\u00e6st\u026ak/ if all its random variables have the same finite variance. This is also known as homogeneity of variance. The complementary notion is called heteroscedasticity.",
      "question": "What is Homoscedasticity in statistics"
    },
    {
      "answer": "Overall, Sentiment analysis may involve the following types of classification algorithms:Linear Regression.Naive Bayes.Support Vector Machines.RNN derivatives LSTM and GRU.",
      "question": "Which algorithm is best for sentiment analysis"
    },
    {
      "answer": "While measures of central tendency are used to estimate \"normal\" values of a dataset, measures of dispersion are important for describing the spread of the data, or its variation around a central value. A proper description of a set of data should include both of these characteristics.",
      "question": "Why are measures of dispersion used in addition to measures of central tendency"
    },
    {
      "answer": "Logistic regression is a model for binary classification predictive modeling.  Under this framework, a probability distribution for the target variable (class label) must be assumed and then a likelihood function defined that calculates the probability of observing the outcome given the input data and the model.",
      "question": "What is likelihood function in logistic regression"
    },
    {
      "answer": "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction\u2014forward\u2014from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.",
      "question": "How does feedforward neural network work"
    },
    {
      "answer": "Increase the sample size. Often, the most practical way to decrease the margin of error is to increase the sample size.  Reduce variability. The less that your data varies, the more precisely you can estimate a population parameter.  Use a one-sided confidence interval.  Lower the confidence level.",
      "question": "How do you reduce the margin of error in statistics"
    },
    {
      "answer": "A Bayesian network is a compact, flexible and interpretable representation of a joint probability distribution. It is also an useful tool in knowledge discovery as directed acyclic graphs allow representing causal relations between variables. Typically, a Bayesian network is learned from data.",
      "question": "What is Bayesian network in machine learning"
    },
    {
      "answer": "A t score is one form of a standardized test statistic (the other you'll come across in elementary statistics is the z-score). The t score formula enables you to take an individual score and transform it into a standardized form>one which helps you to compare scores.",
      "question": "What is the T score in statistics"
    },
    {
      "answer": "We can call a Logistic Regression a Linear Regression model but the Logistic Regression uses a more complex cost function, this cost function can be defined as the 'Sigmoid function' or also known as the 'logistic function' instead of a linear function.",
      "question": "What is the cost function used in logistic regression"
    },
    {
      "answer": "Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics.",
      "question": "Why is Bayesian inference"
    },
    {
      "answer": "3.2 How to test for differences between samplesDecide on a hypothesis to test, often called the \u201cnull hypothesis\u201d (H0 ). In our case, the hypothesis is that there is no difference between sets of samples.  Decide on a statistic to test the truth of the null hypothesis.Calculate the statistic.Compare it to a reference value to establish significance, the P-value.",
      "question": "How do you know if two samples are significantly different"
    },
    {
      "answer": "Mean, variance, and standard deviation The mean of the sampling distribution of the sample mean will always be the same as the mean of the original non-normal distribution. In other words, the sample mean is equal to the population mean. where \u03c3 is population standard deviation and n is sample size.",
      "question": "Is sample mean equal to population mean"
    },
    {
      "answer": "In sampling with replacement the mean of all sample means equals the mean of the population:  Whatever the shape of the population distribution, the distribution of sample means is approximately normal with better approximations as the sample size, n, increases.",
      "question": "What is sampling distribution of mean with replacement"
    },
    {
      "answer": "A statistical model is a mathematical representation (or mathematical model) of observed data. When data analysts apply various statistical models to the data they are investigating, they are able to understand and interpret the information more strategically.",
      "question": "What are statistical models used for"
    },
    {
      "answer": "If the mean more accurately represents the center of the distribution of your data, and your sample size is large enough, use a parametric test. If the median more accurately represents the center of the distribution of your data, use a nonparametric test even if you have a large sample size.",
      "question": "How do you know whether to use parametric or nonparametric"
    },
    {
      "answer": "The Basics of a One-Tailed Test Hypothesis testing is run to determine whether a claim is true or not, given a population parameter. A test that is conducted to show whether the mean of the sample is significantly greater than and significantly less than the mean of a population is considered a two-tailed test.",
      "question": "What is a one sided vs a two sided hypothesis test"
    },
    {
      "answer": "The distribution for z is the standard normal distribution; it has a mean of 0 and a standard deviation of 1. For Ha: p \u2260 26, the P-value would be P(z \u2264 -1.83) + P(z \u2265 1.83) = 2 * P(z \u2264 -1.83). Regardless of Ha, z = (p\u0302 - p0) / sqrt(p0 * (1 - p0) / n), where z gives the number of standard deviations p\u0302 is from p0.",
      "question": "How do you find the p value in a normal distribution"
    },
    {
      "answer": "A certain continuous random variable has a probability density function (PDF) given by: f ( x ) = C x ( 1 \u2212 x ) 2 , f(x) = C x (1-x)^2, f(x)=Cx(1\u2212x)2, where x x x can be any number in the real interval [ 0 , 1 ] [0,1] [0,1]. Compute C C C using the normalization condition on PDFs.",
      "question": "How do you find the probability density function of a continuous random variable"
    },
    {
      "answer": "There is no non-parametric form of any regression. Regression means you are assuming that a particular parameterized model generated your data, and trying to find the parameters. Non-parametric tests are test that make no assumptions about the model that generated your data.",
      "question": "What is the non parametric equivalent of the linear regression"
    },
    {
      "answer": "How to Deal with MulticollinearityRedesign the study to avoid multicollinearity.  Increase sample size.  Remove one or more of the highly-correlated independent variables.  Define a new variable equal to a linear combination of the highly-correlated variables.",
      "question": "How do you handle multicollinearity in regression modeling"
    },
    {
      "answer": "The F ratio is the ratio of two mean square values. If the null hypothesis is true, you expect F to have a value close to 1.0 most of the time. A large F ratio means that the variation among group means is more than you'd expect to see by chance.",
      "question": "What does an F ratio mean"
    },
    {
      "answer": "The ability to detect certain types of stimuli, like movements, shape, and angles, requires specialized cells in the brain called feature detectors. Without these, it would be difficult, if not impossible, to detect a round object, like a baseball, hurdling toward you at 90 miles per hour.",
      "question": "What do feature detectors detect"
    },
    {
      "answer": "NLP is short for natural language processing while NLU is the shorthand for natural language understanding. Similarly named, the concepts both deal with the relationship between natural language (as in, what we as humans speak, not what computers understand) and artificial intelligence.",
      "question": "What is NLU and NLP"
    },
    {
      "answer": "A curve that represents the cumulative frequency distribution of grouped data on a graph is called a Cumulative Frequency Curve or an Ogive.",
      "question": "Which plot is required for cumulative frequency distribution"
    },
    {
      "answer": "Depth is the number of filters. Depth column (or fibre) is the set of neurons that are all pointing to the same receptive field. Stride has the objective of producing smaller output volumes spatially. For example, if a stride=2, the filter will shift by the amount of 2 pixels as it convolves around the input volume.",
      "question": "What is depth in CNN"
    },
    {
      "answer": "In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased.  When a biased estimator is used, bounds of the bias are calculated.",
      "question": "What is bias function"
    },
    {
      "answer": "Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample.  Poisson distribution describes the distribution of binary data from an infinite sample.",
      "question": "What is the difference between binomial Poisson and normal distributions"
    },
    {
      "answer": "How To Develop a Machine Learning Model From ScratchDefine adequately our problem (objective, desired outputs\u2026).Gather data.Choose a measure of success.Set an evaluation protocol and the different protocols available.Prepare the data (dealing with missing values, with categorial values\u2026).Spilit correctly the data.More items",
      "question": "How do you make a deep learning model from scratch"
    },
    {
      "answer": "We can use MLE in order to get more robust parameter estimates. Thus, MLE can be defined as a method for estimating population parameters (such as the mean and variance for Normal, rate (lambda) for Poisson, etc.) from sample data such that the probability (likelihood) of obtaining the observed data is maximized.",
      "question": "Why do we use maximum likelihood estimation"
    },
    {
      "answer": "An RNN has a looping mechanism that acts as a highway to allow information to flow from one step to the next. Passing Hidden State to next time step. This information is the hidden state, which is a representation of previous inputs. Let's run through an RNN use case to have a better understanding of how this works.",
      "question": "What is a hidden state in RNN"
    },
    {
      "answer": "In simple random sampling, each member of a population has an equal chance of being included in the sample. Also, each combination of members of the population has an equal chance of composing the sample. Those two properties are what defines simple random sampling.",
      "question": "What is the probability of a simple random sample"
    },
    {
      "answer": "jackknifing is calculation with data sets sampled randomly from the original data.  Bootstrapping is similar to jackknifing except that the position chosen at random may include multiple copies of the same position, to form data sets of the same size as original, to preserve statistical properties of data sampling.",
      "question": "Why is it called bootstrapping statistics"
    },
    {
      "answer": "Gradient boosted regression and classification is an additive training tree classification method where trees are build in series (iteratively) and compared to each other based on a mathematically derived score of splits. The trees are compared based on weighted leaf scores within each tree.",
      "question": "How does gradient boosting work for classification"
    },
    {
      "answer": "AlphaGo was initially trained to mimic human play by attempting to match the moves of expert players from recorded historical games, using a database of around 30 million moves.",
      "question": "How was AlphaGo trained"
    },
    {
      "answer": "Classification accuracy is the ratio of correct predictions to total predictions made. classification accuracy = correct predictions / total predictions. 1. classification accuracy = correct predictions / total predictions. It is often presented as a percentage by multiplying the result by 100.",
      "question": "What is accuracy in confusion matrix"
    },
    {
      "answer": "MANOVA is useful in experimental situations where at least some of the independent variables are manipulated. It has several advantages over ANOVA. First, by measuring several dependent variables in a single experiment, there is a better chance of discovering which factor is truly important.",
      "question": "Why use a Manova instead of Anova"
    },
    {
      "answer": "Essentially, multivariate analysis is a tool to find patterns and relationships between several variables simultaneously. It lets us predict the effect a change in one variable will have on other variables.",
      "question": "What is multivariate analysis used for"
    },
    {
      "answer": "7 Best Models for Image Classification using Keras1 Xception. It translates to \u201cExtreme Inception\u201d.  2 VGG16 and VGG19: This is a keras model with 16 and 19 layer network that has an input size of 224X224.  3 ResNet50. The ResNet architecture is another pre-trained model highly useful in Residual Neural Networks.  4 InceptionV3.  5 DenseNet.  6 MobileNet.  7 NASNet.",
      "question": "What is the best model for image classification"
    },
    {
      "answer": "Definition 1. Suppose that events A and B are defined on the same probability space, and the event B is such that P(B) > 0. The conditional probability of A given that B has occurred is given by P(A|B) = P(A \u2229 B)/P(B).",
      "question": "How do you prove conditional probability"
    },
    {
      "answer": "Message passing algorithm which is an iterative decoding algorithm factorizes the global function of many variables into product of simpler local functions, whose arguments are the subset of variables. In order to visualize this factorization we use factor graph.",
      "question": "What is message passing algorithm"
    },
    {
      "answer": "This means that the sum of two independent normally distributed random variables is normal, with its mean being the sum of the two means, and its variance being the sum of the two variances (i.e., the square of the standard deviation is the sum of the squares of the standard deviations).",
      "question": "Is the sum of two normal distributions normal"
    },
    {
      "answer": "Postprocessing procedures usually include various pruning routines, rule quality processing, rule filtering, rule combination, model combination, or even knowledge integration. All these procedures provide a kind of symbolic filter for noisy, imprecise, or non-user-friendly knowledge derived by an inductive algorithm.",
      "question": "What is post processing in machine learning"
    },
    {
      "answer": "Summary: Population variance refers to the value of variance that is calculated from population data, and sample variance is the variance calculated from sample data.  As a result both variance and standard deviation derived from sample data are more than those found out from population data.",
      "question": "What is the difference between population variance and sample variance"
    },
    {
      "answer": "Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models.",
      "question": "What is filter method in feature selection"
    },
    {
      "answer": "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.",
      "question": "What does a normal distribution model"
    },
    {
      "answer": "Generally, z-tests are used when we have large sample sizes (n > 30), whereas t-tests are most helpful with a smaller sample size (n < 30). Both methods assume a normal distribution of the data, but the z-tests are most useful when the standard deviation is known.",
      "question": "When is the t test preferred to the Z test"
    },
    {
      "answer": "Here are 5 common machine learning problems and how you can overcome them.1) Understanding Which Processes Need Automation.  2) Lack of Quality Data.  3) Inadequate Infrastructure.  4) Implementation.  5) Lack of Skilled Resources.",
      "question": "What are the problems of machine learning"
    },
    {
      "answer": "Select a File for Image ChangeFrom the Toolbox, select Change Detection > Image Change Workflow. Select an input file from the File Selection dialog.  To apply a mask, select the Input Mask tab in the File Selection panel.  Select the Input Files tab again.Enter the path and filename for the Time 2 File.  Click Next.",
      "question": "How do you do change detection ENVI"
    },
    {
      "answer": "The sampling distribution of the sample mean is very useful because it can tell us the probability of getting any specific mean from a random sample.",
      "question": "What is the sampling distribution of the means and why is it useful"
    },
    {
      "answer": "While the chi-squared test relies on an approximation, Fisher's exact test is one of exact tests. Especially when more than 20% of cells have expected frequencies < 5, we need to use Fisher's exact test because applying approximation method is inadequate.",
      "question": "When should Fisher's exact test be used"
    },
    {
      "answer": "Strictly speaking, a neural network (also called an \u201cartificial neural network\u201d) is a type of machine learning model that is usually used in supervised learning.  A perceptron is a simplified model of a human neuron that accepts an input and performs a computation on that input.",
      "question": "Does machine learning use neural networks"
    },
    {
      "answer": "Here are 25 phases that you can use to increase confidence and self-esteem in your children.\u201cYou are capable.\"  \u201cThat was brave.\"  \u201cYou've got this.\"  \u201cI believe in you.\"  \u201cYou can do hard things.\"  \u201cNo matter what happens, I love you.\"  \u201cLet's try it together.\"  \u201cHow'd you do that?\"More items",
      "question": "What words improve your confidence levels"
    },
    {
      "answer": "An object detector that uses anchor boxes can process an entire image at once, making real-time object detection systems possible. Because a convolutional neural network (CNN) can process an input image in a convolutional manner, a spatial location in the input can be related to a spatial location in the output.",
      "question": "How do anchor boxes in object detection really work"
    },
    {
      "answer": "To conclude, the important thing to remember about the odds ratio is that an odds ratio greater than 1 is a positive association (i.e., higher number for the predictor means group 1 in the outcome), and an odds ratio less than 1 is negative association (i.e., higher number for the predictor means group 0 in the outcome",
      "question": "How do you interpret the odds ratio in logistic regression"
    },
    {
      "answer": "Multinomial Na\u00efve Bayes uses term frequency i.e. the number of times a given term appears in a document.  After normalization, term frequency can be used to compute maximum likelihood estimates based on the training data to estimate the conditional probability.",
      "question": "How does multinomial naive Bayes work"
    },
    {
      "answer": "Energy is quantized in some systems, meaning that the system can have only certain energies and not a continuum of energies, unlike the classical case. This would be like having only certain speeds at which a car can travel because its kinetic energy can have only certain values.",
      "question": "Why is energy quantized"
    },
    {
      "answer": "The More Formal Formula You can solve these types of problems using the steps above, or you can us the formula for finding the probability for a continuous uniform distribution: P(X) = d \u2013 c / b \u2013 a. This is also sometimes written as: P(X) = x2 \u2013 x1 / b \u2013 a.",
      "question": "How do you find the continuous probability of a uniform"
    },
    {
      "answer": "The use of sigmoidal nonlinear functions was inspired by the ouputs of biological neurons.  However, this function is not smooth (it fails to be differential at the threshold value). Therefore, the sigmoid class of functions is a differentiable alternative that still captures much of the behavior of biological neurons.",
      "question": "Why is sigmoid nonlinear"
    },
    {
      "answer": "Chi-square Test. The Pearson's \u03c72 test (after Karl Pearson, 1900) is the most commonly used test for the difference in distribution of categorical variables between two or more independent groups.",
      "question": "How do you find the difference between two categorical variables"
    },
    {
      "answer": "Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. The additional term controls the excessively fluctuating function such that the coefficients don't take extreme values.",
      "question": "Why is regularization used"
    },
    {
      "answer": "2:1510:12Suggested clip \u00b7 108 secondsHistograms In Photography - YouTubeYouTubeStart of suggested clipEnd of suggested clip",
      "question": "How are histograms used in photography"
    },
    {
      "answer": "Abstract: The dimensionality curse phenomenon states that in high dimensional spaces distances between nearest and farthest points from query points become almost equal. Therefore, nearest neighbor calculations cannot discriminate candidate points.",
      "question": "What is curse of dimensionality in Knn"
    },
    {
      "answer": "The following are common methods:Mean imputation. Simply calculate the mean of the observed values for that variable for all individuals who are non-missing.  Substitution.  Hot deck imputation.  Cold deck imputation.  Regression imputation.  Stochastic regression imputation.  Interpolation and extrapolation.",
      "question": "How do you impute missing values"
    },
    {
      "answer": "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.",
      "question": "What is the difference between boosting and bagging"
    },
    {
      "answer": "There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.",
      "question": "Is a way of finding the K value for K means clustering"
    },
    {
      "answer": "Say we want to estimate the mean of a population. While the most used estimator is the average of the sample, another possible estimator is simply the first number drawn from the sample.  In theory, you could have an unbiased estimator whose variance is asymptotically nonzero, and that would be inconsistent.",
      "question": "Can an estimator be unbiased or inconsistent"
    },
    {
      "answer": "The term normal score is used with two different meanings in statistics.  A given data point is assigned a value which is either exactly, or an approximation, to the expectation of the order statistic of the same rank in a sample of standard normal random variables of the same size as the observed data set.",
      "question": "What is a normal score in statistics"
    },
    {
      "answer": "You can use a generative model. You can also use simple tricks. For example, with photograph image data, you can get big gains by randomly shifting and rotating existing images. It improves the generalization of the model to such transforms in the data if they are to be expected in new data.",
      "question": "How can you improve the generalization of the deep learning model"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What is activation function used in a neural network"
    },
    {
      "answer": "The objective of Unsupervised Anomaly Detection is to detect previously unseen rare objects or events without any prior knowledge about these. The only information available is that the percentage of anomalies in the dataset is small, usually less than 1%.",
      "question": "What is unsupervised anomaly detection"
    },
    {
      "answer": "Steps for Using ANOVAStep 1: Compute the Variance Between. First, the sum of squares (SS) between is computed:  Step 2: Compute the Variance Within. Again, first compute the sum of squares within.  Step 3: Compute the Ratio of Variance Between and Variance Within. This is called the F-ratio.",
      "question": "How is analysis of variance calculated"
    },
    {
      "answer": "Use simple logistic regression when you have one nominal variable and one measurement variable, and you want to know whether variation in the measurement variable causes variation in the nominal variable.",
      "question": "When should you use logistic regression"
    },
    {
      "answer": "A multinomial experiment is almost identical with one main difference: a binomial experiment can have two outcomes, while a multinomial experiment can have multiple outcomes.  A binomial experiment will have a binomial distribution.",
      "question": "What is difference between binomial and multinomial distribution"
    },
    {
      "answer": "Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.",
      "question": "What are regression models used for"
    },
    {
      "answer": "The primary reason skew is important is that analysis based on normal distributions incorrectly estimates expected returns and risk.  Knowing that the market has a 70% probability of going up and a 30% probability of going down may appear helpful if you rely on normal distributions.",
      "question": "Why is skewness important in statistics"
    },
    {
      "answer": "What you want is multi-label classification, so you will use Binary Cross-Entropy Loss or Sigmoid Cross-Entropy loss. It is a Sigmoid activation plus a Cross-Entropy loss.",
      "question": "What loss function will you use to measure multi label problems"
    },
    {
      "answer": "According to Cohen's original article, values \u2264 0 as indicating no agreement and 0.01\u20130.20 as none to slight, 0.21\u20130.40 as fair, 0.41\u2013 0.60 as moderate, 0.61\u20130.80 as substantial, and 0.81\u20131.00 as almost perfect agreement.",
      "question": "What is acceptable inter rater reliability"
    },
    {
      "answer": "Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.",
      "question": "What is Gan in deep learning"
    },
    {
      "answer": "Models that are pre-trained on ImageNet are good at detecting high-level features like edges, patterns, etc. These models understand certain feature representations, which can be reused.",
      "question": "Why it is beneficial to use pre trained models"
    },
    {
      "answer": "Time series data means that data is in a series of particular time periods or intervals. The data is considered in three types: Time series data: A set of observations on the values that a variable takes at different times. Cross-sectional data: Data of one or more variables, collected at the same point in time.",
      "question": "What is time series data in statistics"
    },
    {
      "answer": "There are two types of hierarchical clustering, Divisive and Agglomerative.",
      "question": "What are the two types of hierarchical clustering"
    },
    {
      "answer": "In terms of linear regression, variance is a measure of how far observed values differ from the average of predicted values, i.e., their difference from the predicted value mean. The goal is to have a value that is low.",
      "question": "What is variance in multiple regression"
    },
    {
      "answer": "PDF according to input X being discrete or continuous generates probability mass functions and CDF does the same but generates cumulative mass function. That means, PDF is derivative of CDF and CDF can be applied at any point where PDF has been applied.  The cumulative function is the integral of the density function.",
      "question": "What is the difference between a probability distribution function and a cumulative"
    },
    {
      "answer": "6 Freebies to Help You Increase the Performance of Your Object Detection ModelsVisually Coherent Image Mix-up for Object Detection (+3.55% mAP Boost)Classification Head Label Smoothening (+2.16% mAP Boost)Data Pre-processing (Mixed Results)Training Scheduler Revamping (+1.44% mAP Boost)More items",
      "question": "How can you improve the accuracy of an object detection"
    },
    {
      "answer": "The chi-square goodness of fit test is appropriate when the following conditions are met: The sampling method is simple random sampling. The variable under study is categorical. The expected value of the number of sample observations in each level of the variable is at least 5.",
      "question": "What are the conditions for conducting a chi square goodness of fit test"
    },
    {
      "answer": "In this context, correlation only makes sense if the relationship is indeed linear. Second, the slope of the regression line is proportional to the correlation coefficient: slope = r*(SD of y)/(SD of x) Third: the square of the correlation, called \"R-squared\", measures the \"fit\" of the regression line to the data.",
      "question": "Is R the slope of the regression line"
    },
    {
      "answer": "Weaknesses. Histograms have many benefits, but there are two weaknesses. A histogram can present data that is misleading. For example, using too many blocks can make analysis difficult, while too few can leave out important data.",
      "question": "What are the disadvantages of using a histogram"
    },
    {
      "answer": "The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.",
      "question": "How do you determine a false positive rate"
    },
    {
      "answer": "Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items\u2022",
      "question": "Which regression model is best"
    },
    {
      "answer": "In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.",
      "question": "What is a positive skew in statistics"
    },
    {
      "answer": "Ridge regression has an additional factor called \u03bb (lambda) which is called the penalty factor which is added while estimating beta coefficients. This penalty factor penalizes high value of beta which in turn shrinks beta coefficients thereby reducing the mean squared error and predicted error.",
      "question": "Why does ridge regression reduce variance"
    },
    {
      "answer": "Eigenface",
      "question": "Which algorithm is used for face detection"
    },
    {
      "answer": "Learning Rate and Gradient Descent Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. The learning rate controls how quickly the model is adapted to the problem.",
      "question": "What is the learning rate in the context of deep learning"
    },
    {
      "answer": "Informally, a neural attention mechanism equips a neural network with the ability to focus on a subset of its inputs (or features): it selects specific inputs.",
      "question": "What is Attention neural network"
    },
    {
      "answer": "Seriously, the p value is literally a confounded index because it reflects both the size of the underlying effect and the size of the sample. Hence any information included in the p value is ambiguous (Lang et al. 1998).  The smaller the sample, the less likely the result will be statistically significant.",
      "question": "Why are p values considered confounded statistics"
    },
    {
      "answer": "However, experts expect that it won't be until 2060 until AGI has gotten good enough to pass a \"consciousness test\". In other words, we're probably looking at 40 years from now before we see an AI that could pass for a human.",
      "question": "How far away are we from AGI"
    },
    {
      "answer": "A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function. We must compose multiple logical operations by using a hidden layer to represent the XOR function.",
      "question": "Can a 2 layer neural network represent the XOR function"
    },
    {
      "answer": "The F Distribution The distribution of all possible values of the f statistic is called an F distribution, with v1 = n1 - 1 and v2 = n2 - 1 degrees of freedom. The curve of the F distribution depends on the degrees of freedom, v1 and v2.",
      "question": "What is an F distribution in statistics"
    },
    {
      "answer": "The focus will especially be on applications of stochastic processes as key technologies in various research areas, such as Markov chains, renewal theory, control theory, nonlinear theory, queuing theory, risk theory, communication theory engineering and traffic engineering.",
      "question": "What are the applications of stochastic process"
    },
    {
      "answer": "Advantages of Machine LearningContinuous Improvement. Machine Learning algorithms are capable of learning from the data we provide.  Automation for everything.  Trends and patterns identification.  Wide range of applications.  Data Acquisition.  Highly error-prone.  Algorithm Selection.  Time-consuming.",
      "question": "What are the advantages of machine learning"
    },
    {
      "answer": "The potential solutions include the following:Remove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.",
      "question": "What do you do when a variable is correlated"
    },
    {
      "answer": "According to SAS, predictive analytics is \u201cthe use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data.  In short, predictive intelligence drives marketing decisions.\u201d",
      "question": "Do predictive analytics drive more informed decisions"
    },
    {
      "answer": "POS tags make it possible for automatic text processing tools to take into account which part of speech each word is. This facilitates the use of linguistic criteria in addition to statistics.",
      "question": "Why is POS tagging useful"
    },
    {
      "answer": "(Example: a test with 90% specificity will correctly return a negative result for 90% of people who don't have the disease, but will return a positive result \u2014 a false-positive \u2014 for 10% of the people who don't have the disease and should have tested negative.)",
      "question": "What is a good false positive rate"
    },
    {
      "answer": "It basically defined on probability estimates and measures the performance of a classification model where the input is a probability value between 0 and 1. It can be understood more clearly by differentiating it with accuracy.",
      "question": "What is performance measure in machine learning"
    },
    {
      "answer": "TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. TensorBoard currently supports five visualizations: scalars, images, audio, histograms, and graphs.",
      "question": "What is tensor board"
    },
    {
      "answer": "For a discrete random variable, the expected value, usually denoted as or , is calculated using: \u03bc = E ( X ) = \u2211 x i f ( x i )",
      "question": "What is the expected value of a discrete distribution"
    },
    {
      "answer": "The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image.  The result shows how abruptly or smoothly the image changes at each pixel, and therefore how likely it is that that pixel represents an edge.",
      "question": "How does Sobel edge detection work"
    },
    {
      "answer": "Multinomial logistic regression is used when the dependent variable in question is nominal (equivalently categorical, meaning that it falls into any one of a set of categories that cannot be ordered in any meaningful way) and for which there are more than two categories.",
      "question": "When would you use a multinomial"
    },
    {
      "answer": "A Z score is the number of standard deviations a given result is above (positive score) or below (negative score) the age- and sex-adjusted population mean. Results that are within the IGF-1 reference interval will have a Z score between -2.0 and +2.0.",
      "question": "What is Z score in blood test"
    },
    {
      "answer": "Sensitivity is a measure of the proportion of actual positive cases that got predicted as positive (or true positive).  This implies that there will be another proportion of actual positive cases, which would get predicted incorrectly as negative (and, thus, could also be termed as the false negative).",
      "question": "What is sensitivity in machine learning"
    },
    {
      "answer": "The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.",
      "question": "Where do we use eigen values"
    },
    {
      "answer": "IBM SPSS Statistics for Mac is the ultimate tool for managing your statistics data and research. This super-app affords you complete control over your data.",
      "question": "Can you get SPSS on Mac"
    },
    {
      "answer": "Despite having similar aims and processes, there are two main differences between them: Machine learning works out predictions and recalibrates models in real-time automatically after design. Meanwhile, predictive analytics works strictly on \u201ccause\u201d data and must be refreshed with \u201cchange\u201d data.",
      "question": "What is the difference between analytics and machine learning"
    },
    {
      "answer": "The main difference between Independant and Independent is that the Independant is a misspelling of independent and Independent is a Not dependent; free; not subject to control by others; not relying on others.",
      "question": "What is the difference between independent and independant"
    },
    {
      "answer": "Statistical researchers often use a linear relationship to predict the (average) numerical value of Y for a given value of X using a straight line (called the regression line). If you know the slope and the y-intercept of that regression line, then you can plug in a value for X and predict the average value for Y.",
      "question": "How do you use linear regression to predict future values"
    },
    {
      "answer": "The binomial theorem is valid more generally for any elements x and y of a semiring satisfying xy = yx. The theorem is true even more generally: alternativity suffices in place of associativity. The binomial theorem can be stated by saying that the polynomial sequence {1, x, x2, x3, } is of binomial type.",
      "question": "What is binomial theorem"
    },
    {
      "answer": "In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss. A variant for classification is also sometimes used.",
      "question": "What is Huber regression"
    },
    {
      "answer": "The p-value is calculated using the sampling distribution of the test statistic under the null hypothesis, the sample data, and the type of test being done (lower-tailed test, upper-tailed test, or two-sided test).  an upper-tailed test is specified by: p-value = P(TS ts | H 0 is true) = 1 - cdf(ts)",
      "question": "What is the P value formula"
    },
    {
      "answer": "A unimodal distribution only has one peak in the distribution, a bimodal distribution has two peaks, and a multimodal distribution has three or more peaks. Another way to describe the shape of histograms is by describing whether the data is skewed or symmetric.",
      "question": "How many peaks does a multimodal distribution have"
    },
    {
      "answer": "Since this derivation of the LDA direction via least squares does not use a Gaussian assumption for the features, its applicability extends beyond the realm of Gaussian data. However the derivation of the particular intercept or cut-point given in (4.11) does require Gaussian data.",
      "question": "Does Linear Discriminant Analysis work for distributions other than Gaussian"
    },
    {
      "answer": "Consistency refers to logical and numerical coherence. Context: An estimator is called consistent if it converges in probability to its estimand as sample increases (The International Statistical Institute, \"The Oxford Dictionary of Statistical Terms\", edited by Yadolah Dodge, Oxford University Press, 2003).",
      "question": "What does consistent mean in statistics"
    },
    {
      "answer": "For a normal distribution, the average deviation is somewhat less efficient than the standard deviation as a measure of scale, but this advantage quickly reverses for distributions with heavier tails.",
      "question": "What is the advantage of the standard deviation over the average deviation"
    },
    {
      "answer": "The principle of maximum likelihood is a method of obtaining the optimum values of the parameters that define a model. And while doing so, you increase the likelihood of your model reaching the \u201ctrue\u201d model.",
      "question": "What is the principle of maximum likelihood"
    },
    {
      "answer": "Loss value implies how poorly or well a model behaves after each iteration of optimization. An accuracy metric is used to measure the algorithm's performance in an interpretable way. The accuracy of a model is usually determined after the model parameters and is calculated in the form of a percentage.",
      "question": "What is loss value"
    },
    {
      "answer": "Sampling error is one of two reasons for the difference between an estimate and the true, but unknown, value of the population parameter.  The sampling error for a given sample is unknown but when the sampling is random, the maximum likely size of the sampling error is called the margin of error.",
      "question": "What is the difference between sampling error and margin of error"
    },
    {
      "answer": "Below are the different regression techniques: Ridge Regression. Lasso Regression. Polynomial Regression. Bayesian Linear Regression.",
      "question": "What are the types of regression analysis"
    },
    {
      "answer": "Support vectors are the elements of the training set that would change the position of the dividing hyperplane if removed. d+ = the shortest distance to the closest positive point d- = the shortest distance to the closest negative point The margin (gutter) of a separating hyperplane is d+ + d\u2013.",
      "question": "How do you find the support vector"
    },
    {
      "answer": "Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.",
      "question": "What is one shot learning in neural networks"
    },
    {
      "answer": "Fine tuning is one approach to transfer learning. In Transfer Learning or Domain Adaptation we train the model with a dataset and after we train the same model with another dataset that has a different distribution of classes, or even with other classes than in the training dataset).",
      "question": "Is fine tuning a pre trained model equivalent to transfer learning"
    },
    {
      "answer": "A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.",
      "question": "What is ResNet neural network"
    },
    {
      "answer": "Optimization falls in this category \u2014 given an optimization problem, you can, in principle, find a solution to the problem, without any ambiguity whatsoever. Machine learning, on the other hand, falls in the domain of engineering. Problems in engineering are often not mathematically well-defined.",
      "question": "What is the difference between an optimization problem and a machine learning problem"
    },
    {
      "answer": "Class limits specify the span of data values that fall within a class. Class boundaries are possible data values. Class boundaries are not possible data values.",
      "question": "What is the difference between class limits and class boundaries in statistics"
    },
    {
      "answer": "Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model with training data distributed over a large number of clients each with unreliable and relatively slow network connections.",
      "question": "What is a federated learning model"
    },
    {
      "answer": "In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.",
      "question": "What does neural network convergence mean"
    },
    {
      "answer": "The mean is an important measure because it incorporates the score from every subject in the research study. The required steps for its calculation are: count the total number of cases\u2014referred in statistics as n; add up all the scores and divide by the total number of cases.",
      "question": "Why is the mean useful in statistics"
    },
    {
      "answer": "Interpreting. If skewness is positive, the data are positively skewed or skewed right, meaning that the right tail of the distribution is longer than the left. If skewness is negative, the data are negatively skewed or skewed left, meaning that the left tail is longer.",
      "question": "How do you interpret a positively skewed distribution"
    },
    {
      "answer": "Principal Component Analysis (PCA) is used to explain the variance-covariance structure of a set of variables through linear combinations. It is often used as a dimensionality-reduction technique.",
      "question": "What is the use of principal component analysis"
    },
    {
      "answer": "Y hat (written \u0177 ) is the predicted value of y (the dependent variable) in a regression equation. It can also be considered to be the average value of the response variable.  The equation is calculated during regression analysis.",
      "question": "What is Y hat in regression"
    },
    {
      "answer": "15:3248:19Suggested clip \u00b7 37 secondsMotion 5 | How to Use Motion Tracking, Analyze Motion, and Match YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you analyze motion"
    },
    {
      "answer": "A parameter is any summary number, like an average or percentage, that describes the entire population. The population mean (the greek letter \"mu\") and the population proportion p are two different population parameters. For example:  The population comprises all likely American voters, and the parameter is p.",
      "question": "What is parameter with example"
    },
    {
      "answer": "FP. N. FN. TN. where: P = Positive; N = Negative; TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.",
      "question": "What is TP TN FP FN"
    },
    {
      "answer": "Epsilon greedy policy is a way of selecting random actions with uniform distribution from a set of available actions.  This policy selects random actions in twice if the value of epsilon is 0.2. Consider a following example, There is a robot with capability to move in 4 direction. Up,down,left,right.",
      "question": "What is Epsilon greedy policy"
    },
    {
      "answer": "7 Advantages of Robots in the WorkplaceSafety. Safety is the most obvious advantage of utilizing robotics.  Speed. Robots don't get distracted or need to take breaks.  Consistency. Robots never need to divide their attention between a multitude of things.  Perfection. Robots will always deliver quality.  Happier Employees.  Job Creation.  Productivity.",
      "question": "What are the positive effects of robots"
    },
    {
      "answer": "Given any collection of pairs of numbers (except when all the x-values are the same) and the corresponding scatter diagram, there always exists exactly one straight line that fits the data better than any other, in the sense of minimizing the sum of the squared errors. It is called the least squares regression line.",
      "question": "What is special about a least squares regression line"
    },
    {
      "answer": "There are two main differences between regression and structural equation modelling. The first is that SEM allows us to develop complex path models with direct and indirect effects. This allows us to more accurately model causal mechanisms we are interested in. The second key difference is to do with measurement.",
      "question": "What is the difference between regression and structural equation modeling"
    },
    {
      "answer": "A unit of measurement is some specific quantity that has been chosen as the standard against which other measurements of the same kind are made.  The term standard refers to the physical object on which the unit of measurement is based.",
      "question": "What is unit and standard unit"
    },
    {
      "answer": "Eigenvalues and eigenvectors allow us to \"reduce\" a linear operation to separate, simpler, problems. For example, if a stress is applied to a \"plastic\" solid, the deformation can be dissected into \"principle directions\"- those directions in which the deformation is greatest.",
      "question": "What is the application of eigenvalues and eigenvectors"
    },
    {
      "answer": "Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. Random Forest is a tree-based model and hence does not require feature scaling.",
      "question": "Is feature scaling required for random forest"
    },
    {
      "answer": "2 Multivariate Data. Multivariate data contains, at each sample point, multiple scalar values that represent different simulated or measured quantities.",
      "question": "What is a multivariate data set"
    },
    {
      "answer": "Uncertainty is a popular phenomenon in machine learning and a variety of methods to model uncertainty at different levels has been developed.  Different types of uncertainty can be observed: (i) Input data are subject to noise, outliers, and errors.",
      "question": "What is uncertainty in machine learning"
    },
    {
      "answer": "In computer vision, the bag-of-words model (BoW model) sometimes called bag-of-visual-words model can be applied to image classification, by treating image features as words. In document classification, a bag of words is a sparse vector of occurrence counts of words; that is, a sparse histogram over the vocabulary.",
      "question": "What is Bag of Words in image processing"
    },
    {
      "answer": "The main benefit claimed for feature selection, which is the main focus in this manuscript, is that it increases classification accuracy. It is believed that removing non-informative signal can reduce noise, and can increase the contrast between labelled groups.",
      "question": "Does feature selection improve classification accuracy"
    },
    {
      "answer": "When used as nouns, quantile means one of the class of values of a variate which divides the members of a batch or sample into equal-sized subgroups of adjacent values or a probability distribution into distributions of equal probability, whereas quartile means any of the three points that divide an ordered",
      "question": "In statistics what is the difference between a quartile and a quantile"
    },
    {
      "answer": "A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.",
      "question": "How does residual network work"
    },
    {
      "answer": "Thus, the t-statistic measures how many standard errors the coefficient is away from zero. Generally, any t-value greater than +2 or less than \u2013 2 is acceptable. The higher the t-value, the greater the confidence we have in the coefficient as a predictor.",
      "question": "What is a good T stat"
    },
    {
      "answer": "A facial recognition system uses biometrics to map facial features from a photograph or video. It compares the information with a database of known faces to find a match.  That's because facial recognition has all kinds of commercial applications. It can be used for everything from surveillance to marketing.",
      "question": "How does facial verification work"
    },
    {
      "answer": "If X takes values in [a, b] and Y takes values in [c, d] then the pair (X, Y ) takes values in the product [a, b] \u00d7 [c, d]. The joint probability density function (joint pdf) of X and Y is a function f(x, y) giving the probability density at (x, y).",
      "question": "How do you find the joint probability density function"
    },
    {
      "answer": "Some common types of problems built on top of classification and regression include recommendation and time series prediction respectively. Some popular examples of supervised machine learning algorithms are: Linear regression for regression problems. Random forest for classification and regression problems.",
      "question": "What problems are suitable for supervised machine learning"
    },
    {
      "answer": "In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input.",
      "question": "What is an activation function in machine learning"
    },
    {
      "answer": "In statistical classification, Bayes error rate is the lowest possible error rate for any classifier of a random outcome (into, for example, one of two categories) and is analogous to the irreducible error. A number of approaches to the estimation of the Bayes error rate exist.",
      "question": "What is the Bayesian probability of an error"
    },
    {
      "answer": "A cross-sectional study involves looking at data from a population at one specific point in time.  Cross-sectional studies are observational in nature and are known as descriptive research, not causal or relational, meaning that you can't use them to determine the cause of something, such as a disease.",
      "question": "What is a cross sectional study in statistics"
    },
    {
      "answer": "A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit overfitting without substantially increasing error due to bias is why they are such powerful models. One way Random Forests reduce variance is by training on different samples of the data.",
      "question": "Is Random Forest a decision tree"
    },
    {
      "answer": "Low Pass filtering: It is also known as the smoothing filter. It removes the high-frequency content from the image.  Median Filtering: It is also known as nonlinear filtering. It is used to eliminate salt and pepper noise.",
      "question": "Is median filter a low pass filter"
    },
    {
      "answer": "Linear regression is the next step up after correlation. It is used when we want to predict the value of a variable based on the value of another variable. The variable we want to predict is called the dependent variable (or sometimes, the outcome variable).",
      "question": "What is linear regression used for"
    },
    {
      "answer": "A person who engages in banditry is known as a bandit and primarily commits crimes such as extortion, robbery, and murder, either as an individual or in groups. Banditry is a vague concept of criminality and in modern usage can be synonymous for gangsterism, brigandage, marauding, and thievery.",
      "question": "What did bandits do"
    },
    {
      "answer": "Difference between K Means and Hierarchical clustering Hierarchical clustering can't handle big data well but K Means clustering can. This is because the time complexity of K Means is linear i.e. O(n) while that of hierarchical clustering is quadratic i.e. O(n2).",
      "question": "Which is better K means or hierarchical clustering"
    },
    {
      "answer": "In statistics, the phrase \"correlation does not imply causation\" refers to the inability to legitimately deduce a cause-and-effect relationship between two variables solely on the basis of an observed association or correlation between them.",
      "question": "If correlation does not imply causation what does it do"
    },
    {
      "answer": "Tests of Correlation: The validity of a test is measured by the strength of association, or correlation, between the results obtained by the test and by the criterion measure.",
      "question": "How do you measure validity in statistics"
    },
    {
      "answer": "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",
      "question": "What does gradient mean in Machine Learning"
    },
    {
      "answer": "To deal with categorical variables that have more than two levels, the solution is one-hot encoding. This takes every level of the category (e.g., Dutch, German, Belgian, and other), and turns it into a variable with two levels (yes/no).",
      "question": "How do you handle a categorical variable with many levels"
    },
    {
      "answer": "Brief Description. The Fourier Transform is an important image processing tool which is used to decompose an image into its sine and cosine components. The output of the transformation represents the image in the Fourier or frequency domain, while the input image is the spatial domain equivalent.",
      "question": "What is Fourier transform of an image"
    },
    {
      "answer": "The Bayes theorem describes the probability of an event based on the prior knowledge of the conditions that might be related to the event. If we know the conditional probability , we can use the bayes rule to find out the reverse probabilities .",
      "question": "When can Bayes theorem be used"
    },
    {
      "answer": "Type 1 error, in statistical hypothesis testing, is the error caused by rejecting a null hypothesis when it is true. Type II error is the error that occurs when the null hypothesis is accepted when it is not true.",
      "question": "What is the difference between a Type I error and a Type II error"
    },
    {
      "answer": "Distance MatrixThe proximity between object can be measured as distance matrix.  For example, distance between object A = (1, 1) and B = (1.5, 1.5) is computed as.Another example of distance between object D = (3, 4) and F = (3, 3.5) is calculated as.More items",
      "question": "How do you find the distance of a clustered Matrix"
    },
    {
      "answer": "What Are Moments in Statistics?Moments About the MeanFirst, calculate the mean of the values.Next, subtract this mean from each value.Then raise each of these differences to the sth power.Now add the numbers from step #3 together.Finally, divide this sum by the number of values we started with.",
      "question": "How do you find the moment in statistics"
    },
    {
      "answer": "Additivity is a property pertaining to a set of interdependent index numbers related by definition or by accounting constraints under which an aggregate is defined as the sum of its components; additivity requires this identity to be preserved when the values of both an aggregate and its components in some reference",
      "question": "What is additivity in statistics"
    },
    {
      "answer": "The first four are: 1) The mean, which indicates the central tendency of a distribution. 2) The second moment is the variance, which indicates the width or deviation. 3) The third moment is the skewness, which indicates any asymmetric 'leaning' to either left or right.",
      "question": "What are the four moments of statistics"
    },
    {
      "answer": "You probably have a numerical stability issue. This may happen due to zero division or any operation that is making a number(s) extremely big.",
      "question": "Why do l get NaN values when l train my neural network with a rectified linear unit"
    },
    {
      "answer": "The beta distribution of the first kind, usually written in terms of the incom- plete beta function, can be used to model the distribution of measurements whose values all lie between zero and one. It can also be used to model the distribution for the probability of occurrence of some discrete event.",
      "question": "What is the significance of the beta distribution What are some common applications"
    },
    {
      "answer": "Random event/process/variable: an event/process that is not and cannot be made exact and, consequently, whose outcome cannot be predicted, e.g., the sum of the numbers on two rolled dice.",
      "question": "What random events mean"
    },
    {
      "answer": "metric system. A system of measurement in which the basic units are the meter, the second, and the kilogram. In this system, the ratios between units of measurement are multiples of ten. For example, a kilogram is a thousand grams, and a centimeter is one-hundredth of a meter.",
      "question": "What is the definition of metric system"
    },
    {
      "answer": "A correlation between two variables does not imply causation. On the other hand, if there is a causal relationship between two variables, they must be correlated. Example: A study shows that there is a negative correlation between a student's anxiety before a test and the student's score on the test.",
      "question": "Are there ever any circumstances when a correlation can be interpreted as evidence for a causal connection between two variables"
    },
    {
      "answer": "A negative binomial random variable is the number X of repeated trials to produce r successes in a negative binomial experiment. The probability distribution of a negative binomial random variable is called a negative binomial distribution.  Suppose we flip a coin repeatedly and count the number of heads (successes).",
      "question": "What does the negative in negative binomial distribution signify"
    },
    {
      "answer": "The standard deviation of this set of mean values is the standard error. In lieu of taking many samples one can estimate the standard error from a single sample. This estimate is derived by dividing the standard deviation by the square root of the sample size.",
      "question": "What is the standard error of the mean difference"
    },
    {
      "answer": "An autoregressive model is when a value from a time series is regressed on previous values from that same time series.  The order of an autoregression is the number of immediately preceding values in the series that are used to predict the value at the present time.",
      "question": "What is autoregression time series"
    },
    {
      "answer": "Technically, the probability density of variable X , means the probability per unit increment of X . The units of probability density are the reciprocal of the units of X \u2014 if the units of X are dollars, the units of probability density are probability per dollar increment.",
      "question": "What are the units of a probability density function"
    },
    {
      "answer": "The term \"running median\" is typically used to refer to the median of a subset of data.",
      "question": "What is a running median"
    },
    {
      "answer": "How to calculate margin of errorGet the population standard deviation (\u03c3) and sample size (n).Take the square root of your sample size and divide it into your population standard deviation.Multiply the result by the z-score consistent with your desired confidence interval according to the following table:",
      "question": "How do you calculate the margin of error"
    },
    {
      "answer": "Spatiotemporal models arise when data are collected across time as well as space and has at least one spatial and one temporal property. An event in a spatiotemporal dataset describes a spatial and temporal phenomenon that exists at a certain time t and location x.",
      "question": "What is spatio temporal model"
    },
    {
      "answer": "In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation.  The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.",
      "question": "What is vanishing gradient problem in neural networks"
    },
    {
      "answer": "In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum.",
      "question": "How do you plot a box plot"
    },
    {
      "answer": "Inference over a Bayesian network can come in two forms. The first is simply evaluating the joint probability of a particular assignment of values for each variable (or a subset) in the network.  We would calculate P(\u00acx | e) in the same fashion, just setting the value of the variables in x to false instead of true.",
      "question": "What is inference in Bayesian networks"
    },
    {
      "answer": "Decision trees provide an effective method of Decision Making because they: Clearly lay out the problem so that all options can be challenged. Allow us to analyze fully the possible consequences of a decision. Provide a framework to quantify the values of outcomes and the probabilities of achieving them.",
      "question": "How is the decision tree useful"
    },
    {
      "answer": "There are several ways to check your Linear Regression model accuracy. Usually, you may use Root mean squared error. You may train several Linear Regression models, adding or removing features to your dataset, and see which one has the lowest RMSE - the best one in your case.",
      "question": "How do you find the accuracy of a linear regression model"
    },
    {
      "answer": "There are two types of factor analyses, exploratory and confirmatory. Exploratory factor analysis (EFA) is method to explore the underlying structure of a set of observed variables, and is a crucial step in the scale development process. The first step in EFA is factor extraction.",
      "question": "What are the types of factor analysis"
    },
    {
      "answer": "Advantages and disadvantagesAre simple to understand and interpret.  Have value even with little hard data.  Help determine worst, best and expected values for different scenarios.Use a white box model.  Can be combined with other decision techniques.",
      "question": "What are the advantages and disadvantages of decision tree"
    },
    {
      "answer": "If there are other predictor variables, all coefficients will be changed.  All the coefficients are jointly estimated, so every new variable changes all the other coefficients already in the model. This is one reason we do multiple regression, to estimate coefficient B1 net of the effect of variable Xm.",
      "question": "Why do coefficients change in multiple regression"
    },
    {
      "answer": "Random errors are statistical fluctuations (in either direction) in the measured data due to the precision limitations of the measurement device. Random errors usually result from the experimenter's inability to take the same measurement in exactly the same way to get exact the same number.",
      "question": "What are random errors"
    },
    {
      "answer": "The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.",
      "question": "Why is sigmoid a good activation function"
    },
    {
      "answer": "Ensemble learning methods are widely used nowadays for its predictive performance improvement. Ensemble learning combines multiple predictions (forecasts) from one or multiple methods to overcome accuracy of simple prediction and to avoid possible overfit.",
      "question": "Is it possible to use ensemble learning for time series forecast"
    },
    {
      "answer": "The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed.",
      "question": "What is the use of finding the root mean square error"
    },
    {
      "answer": "The distribution pX (x) is called the target distribution, while qX (x) is the sampling distribution or the proposal distribution.",
      "question": "In importance sampling what is the difference between p x and q x"
    },
    {
      "answer": "If there is no relationship between X and Y, the best guess for all values of X is the mean of Y. At any rate, the regression line always passes through the means of X and Y. This means that, regardless of the value of the slope, when X is at its mean, so is Y.",
      "question": "Why does regression line go through mean"
    },
    {
      "answer": "How to Calculate a CorrelationFind the mean of all the x-values.Find the standard deviation of all the x-values (call it sx) and the standard deviation of all the y-values (call it sy).  For each of the n pairs (x, y) in the data set, take.Add up the n results from Step 3.Divide the sum by sx \u2217 sy.More items",
      "question": "How do you find the correlation coefficient between two sets of data"
    },
    {
      "answer": "Selection bias can result when the selection of subjects into a study or their likelihood of being retained in the study leads to a result that is different from what you would have gotten if you had enrolled the entire target population.",
      "question": "How does selection bias affect results"
    },
    {
      "answer": "Regression analysis refers to assessing the relationship between the outcome variable and one or more variables.  For example, a correlation of r = 0.8 indicates a positive and strong association among two variables, while a correlation of r = -0.3 shows a negative and weak association.",
      "question": "What is meant by correlation and regression analysis"
    },
    {
      "answer": "The standard error of the regression (S), also known as the standard error of the estimate, represents the average distance that the observed values fall from the regression line. Conveniently, it tells you how wrong the regression model is on average using the units of the response variable.",
      "question": "What does standard error of estimate tell you"
    },
    {
      "answer": "A sampling frame is a list of all the items in your population. It's a complete list of everyone or everything you want to study. The difference between a population and a sampling frame is that the population is general and the frame is specific.",
      "question": "Can a sampling frame be seen as a population"
    },
    {
      "answer": "Fewer than 1,000 steps a day is sedentary. 1,000 to 10,000 steps or about 4 miles a day is Lightly Active. 10,000 to 23,000 steps or 4 to 10 miles a day is considered Active. More than 23,000 steps or 10 miles a day is Highly active.",
      "question": "What is considered active activity level"
    },
    {
      "answer": "A series converges uniformly on if the sequence of partial sums defined by. (2) converges uniformly on . To test for uniform convergence, use Abel's uniform convergence test or the Weierstrass M-test.",
      "question": "What is uniform convergence series"
    },
    {
      "answer": "Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)",
      "question": "What is meant by machine learning algorithms"
    },
    {
      "answer": "Transfer learning without any labeled data from the target domain is referred to as unsupervised transfer learning.",
      "question": "Is transfer learning unsupervised"
    },
    {
      "answer": "Bootstrapping is any test or metric that uses random sampling with replacement, and falls under the broader class of resampling methods. Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates.",
      "question": "What does bootstrapping mean in statistics"
    },
    {
      "answer": ": a function (such as y = loga x or y = ln x) that is the inverse of an exponential function (such as y = ax or y = ex) so that the independent variable appears in a logarithm.",
      "question": "What is a logarithmic function definition"
    },
    {
      "answer": "Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods.",
      "question": "What do you mean by constraint satisfaction problem"
    },
    {
      "answer": "A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.",
      "question": "What is mean by sampling error"
    },
    {
      "answer": "The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.",
      "question": "How do you fix a vanishing gradient problem"
    },
    {
      "answer": "Fisher's exact test is a statistical test used to determine if there are nonrandom associations between two categorical variables. . For each one, calculate the associated conditional probability using (2), where the sum of these probabilities must be 1.",
      "question": "What is Fisher's exact test used for"
    },
    {
      "answer": ": being or having the shape of a normal curve or a normal distribution.",
      "question": "What does Gaussian mean"
    },
    {
      "answer": "A low R-squared value indicates that your independent variable is not explaining much in the variation of your dependent variable - regardless of the variable significance, this is letting you know that the identified independent variable, even though significant, is not accounting for much of the mean of your",
      "question": "What does a low R squared value mean"
    },
    {
      "answer": "A little bit of coding skills is enough, but it's better to have knowledge of data structures, algorithms, and OOPs concept. Some of the popular programming languages to learn machine learning in are Python, R, Java, and C++.",
      "question": "Is coding required in machine learning"
    },
    {
      "answer": "Natural Language processing is considered a difficult problem in computer science. It's the nature of the human language that makes NLP difficult.  While humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.",
      "question": "Why is NLP difficult"
    },
    {
      "answer": "A high-pass filter (HPF) is an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency. The amount of attenuation for each frequency depends on the filter design.",
      "question": "How does a high pass RC filter work"
    },
    {
      "answer": "For example, a two-way ANOVA allows a company to compare worker productivity based on two independent variables, such as salary and skill set. It is utilized to observe the interaction between the two factors and tests the effect of two factors at the same time.",
      "question": "What is analysis of variance example"
    },
    {
      "answer": "Best practices \u2013 Machine Learning models and applicationsIdentify the business problem and the right success metrics.  Begin with it.  Gather correct data.  Move the algorithms instead of your data.  Initiate tests before the actual launch.  Avoid data dropping while machine learning algorithms train.  Keep away from objectives that are unaligned.  Keep using codes.More items\u2022",
      "question": "What are some best practices for training machine learning models"
    },
    {
      "answer": "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.",
      "question": "How do you find the similarity between two vectors"
    },
    {
      "answer": "Train the model using a suitable machine learning algorithm such as SVM (Support Vector Machines), decision trees, random forest, etc. Training is the process through which the model learns or recognizes the patterns in the given data for making suitable predictions. The test set contains already predicted values.",
      "question": "Which machine learning technique is used for pattern recognition"
    },
    {
      "answer": "The 2nd moment around the mean = \u03a3(xi \u2013 \u03bcx)2. The second is the variance. In practice, only the first two moments are ever used in statistics.",
      "question": "How do you find second moment in statistics"
    },
    {
      "answer": "In statistics and research, internal consistency is typically a measure based on the correlations between different items on the same test (or the same subscale on a larger test). It measures whether several items that propose to measure the same general construct produce similar scores.",
      "question": "What is Internal Consistency in testing"
    },
    {
      "answer": "Gravity tries to keep things together through attraction and thus tends to lower statistical entropy. The universal law of increasing entropy (2nd law of thermodynamics) states that the entropy of an isolated system which is not in equilibrium will tend to increase with time, approaching a maximum value at equilibrium.",
      "question": "How is gravity related to entropy"
    },
    {
      "answer": "Connectionism, an approach to artificial intelligence (AI) that developed out of attempts to understand how the human brain works at the neural level and, in particular, how people learn and remember.  (For that reason, this approach is sometimes referred to as neuronlike computing.)",
      "question": "What is connectionist AI"
    },
    {
      "answer": "An (ordinary) Poisson process is a special Markov process [ref. to Stadje in this volume], in continuous time, in which the only possible jumps are to the next higher state. A Poisson process may also be viewed as a counting process that has particular, desirable, properties.",
      "question": "Is Poisson process a Markov process"
    },
    {
      "answer": "Clustering analysis is broadly used in many applications such as market research, pattern recognition, data analysis, and image processing. Clustering can also help marketers discover distinct groups in their customer base. And they can characterize their customer groups based on the purchasing patterns.",
      "question": "Where can cluster analysis be applied"
    },
    {
      "answer": "The false alarm probability is the probability that exceeds a certain threshold when there is no signal.",
      "question": "What is probability of false alarm"
    },
    {
      "answer": "Classification Accuracy It is the ratio of number of correct predictions to the total number of input samples. It works well only if there are equal number of samples belonging to each class. For example, consider that there are 98% samples of class A and 2% samples of class B in our training set.",
      "question": "How do you know if a classification model is accurate"
    },
    {
      "answer": "In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.",
      "question": "What is the difference between supervised and unsupervised machine learning"
    },
    {
      "answer": "Correlation is the concept of linear relationship between two variables.  Whereas correlation coefficient is a measure that measures linear relationship between two variables.",
      "question": "What is the difference between correlation and correlation coefficient"
    },
    {
      "answer": "Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.",
      "question": "How are decision trees used for regression"
    },
    {
      "answer": "Increase the power of your analysis.larger sample size.better data collection (reducing error)better/correct model (more complex model, account for covariates, etc.)use a one-sided test instead of a two-sided test.",
      "question": "How do you decrease P value in regression"
    },
    {
      "answer": "In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.",
      "question": "What are fixed effects in regression"
    },
    {
      "answer": "Specifical- ly, for periodic signals we can define the Fourier transform as an impulse train with the impulses occurring at integer multiples of the fundamental frequency and with amplitudes equal to 27r times the Fourier series coefficients.",
      "question": "What is the Fourier transform of a periodic signal"
    },
    {
      "answer": "The crucial difference between FIR and IIR filter is that the FIR filter provides an impulse response of finite period. As against IIR is a type of filter that generates impulse response of infinite duration for a dynamic system.",
      "question": "What is difference between FIR and IIR filters"
    },
    {
      "answer": "Bivariate statistics is a type of inferential statistics that deals with the relationship between two variables.  When bivariate statistics is employed to examine a relationship between two variables, bivariate data is used. Bivariate data consists of data collected from a sample on two different variables.",
      "question": "What is bivariate in statistics"
    },
    {
      "answer": "IAT is a popular measure in social psychology to measure the relative strength of association between pairs of concepts (Greenwald, McGhee, & Schwartz, 1998).  Studies have found that racial bias IAT studies have a test-retest reliability score of only 0.44, while the IAT overall is just around 0.5.",
      "question": "Is the Implicit Association Test having poor test retest reliability"
    },
    {
      "answer": "Bimodal Distribution: Two Peaks. The bimodal distribution has two peaks.  However, if you think about it, the peaks in any distribution are the most common number(s). The two peaks in a bimodal distribution also represent two local maximums; these are points where the data points stop increasing and start decreasing.",
      "question": "How do you describe bimodal distribution"
    },
    {
      "answer": "The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases.  Therefore, as a sample size increases, the sample mean and standard deviation will be closer in value to the population mean \u03bc and standard deviation \u03c3 .",
      "question": "What happens if the sample size increases"
    },
    {
      "answer": "5:1515:11Suggested clip \u00b7 109 secondsStatQuest: Linear Discriminant Analysis (LDA) clearly explained YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do linear discriminant analysis"
    },
    {
      "answer": "1 Answer. Normalized discounted cumulative gain is one of the standard method of evaluating ranking algorithms. You will need to provide a score to each of the recommendations that you give. If your algorithm assigns a low (better) rank to a high scoring entity, your NDCG score will be higher, and vice versa.",
      "question": "How do you evaluate a rank algorithm"
    },
    {
      "answer": "Linear Activation Function A linear activation function takes the form: A = cx. It takes the inputs, multiplied by the weights for each neuron, and creates an output signal proportional to the input. In one sense, a linear function is better than a step function because it allows multiple outputs, not just yes and no.",
      "question": "What is linear activation function in neural network"
    },
    {
      "answer": "\u23e9 optimal policy: the best action to take at each state, for maximum rewards over time. To help our agent do this, we need two things: A way to determine the value of a state in MDP. An estimated value of an action taken at a particular state.",
      "question": "What is optimal policy in reinforcement learning"
    },
    {
      "answer": "Classification is a machine learning concept. It is used for categorical dependent variables, where we need to classify into required groups. Logistic regression is a algorithm within classification.",
      "question": "What is the difference between logistic regression and classification"
    },
    {
      "answer": "In the mathematical discipline of linear algebra, a matrix decomposition or matrix factorization is a factorization of a matrix into a product of matrices. There are many different matrix decompositions; each finds use among a particular class of problems.",
      "question": "Can you Factorise matrices"
    },
    {
      "answer": "The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image.",
      "question": "What is Histogram of Oriented Gradients and how does it work"
    },
    {
      "answer": "The t\u2010distribution is used as an alternative to the normal distribution when sample sizes are small in order to estimate confidence or determine critical values that an observation is a given distance from the mean.",
      "question": "Why do we use t distribution"
    },
    {
      "answer": "Mixed effects models are useful when we have data with more than one source of random variability. For example, an outcome may be measured more than once on the same person (repeated measures taken over time). When we do that we have to account for both within-person and across-person variability.",
      "question": "When would you use a mixed model"
    },
    {
      "answer": "Inverted dropout is a variant of the original dropout technique developed by Hinton et al.  The one difference is that, during the training of a neural network, inverted dropout scales the activations by the inverse of the keep probability q=1\u2212p q = 1 \u2212 p .",
      "question": "What is inverted dropout technique"
    },
    {
      "answer": "Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference.  Particle filters update their prediction in an approximate (statistical) manner.",
      "question": "What is a particle filter used for"
    },
    {
      "answer": "Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.",
      "question": "What do you understand by bias variance trade off"
    },
    {
      "answer": "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated. One cycle through the entire training dataset is called a training epoch.",
      "question": "How does batch gradient descent work"
    },
    {
      "answer": "Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels. it can be done with convolution. For examples, mean/average filters or Gaussian filtering. A non-linear filtering is one that cannot be done with convolution or Fourier multiplication.",
      "question": "What is difference between linear filtersand nonlinear filters"
    },
    {
      "answer": "For linear algebra, it's very helpful to prepare by doing simple practice problems with the basic axioms of vector spaces and inner products. I was always mediocre at algebra, but good at visualizing 2D and 3D things.",
      "question": "How do you prepare linear algebra"
    },
    {
      "answer": "Joint probability is calculated by multiplying the probability of event A, expressed as P(A), by the probability of event B, expressed as P(B). For example, suppose a statistician wishes to know the probability that the number five will occur twice when two dice are rolled at the same time.",
      "question": "How do you find joint probability"
    },
    {
      "answer": "Variance (\u03c32) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.",
      "question": "What is the meaning of variance"
    },
    {
      "answer": "3.1. Coreference resolution (or anaphora) is an expression, the interpretation of which depends on another word or phrase presented earlier in the text (antecedent). For example, \u201cTom has a backache. He was injured.\u201d Here the words \u201cTom\u201d and \u201cHe\u201d refer to the same entity.",
      "question": "How do coreference resolution anaphora resolution algorithms work"
    },
    {
      "answer": "Multinomial logistic regression is used to predict categorical placement in or the probability of category membership on a dependent variable based on multiple independent variables. The independent variables can be either dichotomous (i.e., binary) or continuous (i.e., interval or ratio in scale).",
      "question": "What is meant by multinomial logistic regression"
    },
    {
      "answer": "Marginal probability: the probability of an event occurring (p(A)), it may be thought of as an unconditional probability. It is not conditioned on another event. Example: the probability that a card drawn is red (p(red) = 0.5).",
      "question": "What is marginal probability in statistics"
    },
    {
      "answer": "DBSCAN works as such: Divides the dataset into n dimensions. For each point in the dataset, DBSCAN forms an n dimensional shape around that data point, and then counts how many data points fall within that shape. DBSCAN counts this shape as a cluster.",
      "question": "How does Dbscan algorithm work"
    },
    {
      "answer": "The general procedure for using regression to make good predictions is the following:Research the subject-area so you can build on the work of others.  Collect data for the relevant variables.Specify and assess your regression model.If you have a model that adequately fits the data, use it to make predictions.",
      "question": "How do you predict regression"
    },
    {
      "answer": "Q-Learning is a value-based reinforcement learning algorithm which is used to find the optimal action-selection policy using a Q function. Our goal is to maximize the value function Q. The Q table helps us to find the best action for each state.  Initially we explore the environment and update the Q-Table.",
      "question": "What is Q function explain Q learning with suitable example"
    },
    {
      "answer": "A decision tree is a simple representation for classifying examples. For this section, assume that all of the input features have finite discrete domains, and there is a single target feature called the \"classification\". Each element of the domain of the classification is called a class.",
      "question": "What is a class in decision tree learning"
    },
    {
      "answer": "A qualitative variable, also called a categorical variable, is a variable that isn't numerical. It describes data that fits into categories. For example: Eye colors (variables include: blue, green, brown, hazel).",
      "question": "Is colour a qualitative variable"
    },
    {
      "answer": "One-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is a heuristic method for using binary classification algorithms for multi-class classification. It involves splitting the multi-class dataset into multiple binary classification problems.",
      "question": "What is one vs all classification in machine learning"
    },
    {
      "answer": "Any sum or difference or independent normal random variables is also normally distributed. A binomial setting arises when we perform several independent trials of the same chance process and record the number of times a particular outcome occurs.",
      "question": "What happens if two independent normal random variables are combined"
    },
    {
      "answer": "Cluster sampling refers to a type of sampling method . With cluster sampling, the researcher divides the population into separate groups, called clusters. Then, a simple random sample of clusters is selected from the population. The researcher conducts his analysis on data from the sampled clusters.",
      "question": "How does cluster sampling work"
    },
    {
      "answer": "According to the realistic conflict theory, ingroup bias arises from competition for resources between groups. Since different groups are all competing for the same available resources, it serves the best interests of the group to favor members while spurning outsiders.",
      "question": "Why does ingroup bias occur"
    },
    {
      "answer": "The cosine similarity is the cosine of the angle between two vectors. Figure 1 shows three 3-dimensional vectors and the angles between each pair. In text analysis, each vector can represent a document. The greater the value of \u03b8, the less the value of cos \u03b8, thus the less the similarity between two documents.",
      "question": "How do you find the cosine similarity between two documents"
    },
    {
      "answer": "Another view however is that the parameter value used to generate the data that are obtained in your study is just one drawn parameter value, where the draw is from some distribution (the prior).  as parameters, but rather as random or latent effects.",
      "question": "Are parameters random"
    },
    {
      "answer": "So here are some signs you're highly intelligent, even if you don't feel like it.You're Empathetic And Compassionate. Andrew Zaeh for Bustle.  You're Curious About The World.  You're Observant.  You Have Self-Control.  You Have A Good Working Memory.  You Like To Go With The Flow.More items\u2022",
      "question": "How can you tell if someone is highly intelligent"
    },
    {
      "answer": "In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge.",
      "question": "What are convolutional filters"
    },
    {
      "answer": "Covariance is calculated by analyzing at-return surprises (standard deviations from the expected return) or by multiplying the correlation between the two variables by the standard deviation of each variable.",
      "question": "How do you find the covariance between two variables"
    },
    {
      "answer": "Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Supervised learning allows you to collect data or produce a data output from the previous experience. Unsupervised machine learning helps you to finds all kind of unknown patterns in data.",
      "question": "Is Machine Learning supervised or unsupervised"
    },
    {
      "answer": "You can use tf. function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use SavedModel .  function works under the hood so you can use it effectively.",
      "question": "What is TF function"
    },
    {
      "answer": "Frequency distribution in statistics is a representation that displays the number of observations within a given interval. The representation of a frequency distribution can be graphical or tabular so that it is easier to understand.",
      "question": "What is a frequency distribution in statistics"
    },
    {
      "answer": "Feature Extraction using Convolution Neural Networks (CNN) and Deep Learning.  It is a process which involves the following tasks of pre-processing the image (normalization), image segmentation, extraction of key features and identification of the class.",
      "question": "What is feature extraction in CNN"
    },
    {
      "answer": "Sometimes we want to know the probability of getting one result or another. When events are mutually exclusive and we want to know the probability of getting one event OR another, then we can use the OR rule.  P(A or B) = P(A) + P(B) for mutually exclusive events.",
      "question": "What is the OR rule in probability"
    },
    {
      "answer": "K nearest neighbors is a simple algorithm that stores all available cases and predict the numerical target based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.",
      "question": "Can Knn be used for prediction"
    },
    {
      "answer": "First, logistic regression does not require a linear relationship between the dependent and independent variables. Second, the error terms (residuals) do not need to be normally distributed.  This means that the independent variables should not be too highly correlated with each other.",
      "question": "Should independent variables be normally distributed for ordered logit model"
    },
    {
      "answer": "The pdf represents the relative frequency of failure times as a function of time. The cdf is a function, F(x)\\,\\!, of a random variable X\\,\\!, and is defined for a number x\\,\\!",
      "question": "What is the relationship between PDF and CDF"
    },
    {
      "answer": "In regression analysis, the dependent variable is denoted \"Y\" and the independent variables are denoted by \"X\".",
      "question": "How do you identify independent and dependent variables in regression analysis"
    },
    {
      "answer": "11 websites to find free, interesting datasetsFiveThirtyEight.  BuzzFeed News.  Kaggle.  Socrata.  Awesome-Public-Datasets on Github.  Google Public Datasets.  UCI Machine Learning Repository.  Data.gov.More items",
      "question": "How do I find datasets"
    },
    {
      "answer": "Random error varies unpredictably from one measurement to another, while systematic error has the same value or proportion for every measurement. Random errors are unavoidable, but cluster around the true value.",
      "question": "What is the difference between random errors and non random errors in experimental data"
    },
    {
      "answer": "In mathematics, a generating function is a way of encoding an infinite sequence of numbers (an) by treating them as the coefficients of a formal power series.  Generating functions are often expressed in closed form (rather than as a series), by some expression involving operations defined for formal series.",
      "question": "What is meant by generating function"
    },
    {
      "answer": "The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution. But where the chi-squared distribution deals with the degree of freedom with one set of variables, the F-distribution deals with multiple levels of events having different degrees of freedom.",
      "question": "What is af distribution"
    },
    {
      "answer": "10:1614:33Suggested clip \u00b7 106 secondsPermutation Hypothesis Test in R with Examples | R Tutorial 4.6 YouTubeStart of suggested clipEnd of suggested clip",
      "question": "How do you do permutation test in R"
    },
    {
      "answer": "Real numbers consist of zero (0), the positive and negative integers (-3, -1, 2, 4), and all the fractional and decimal values in between (0.4, 3.1415927, 1/2). Real numbers are divided into rational and irrational numbers.",
      "question": "Is 0 a real number"
    },
    {
      "answer": "XGboost is the most widely used algorithm in machine learning, whether the problem is a classification or a regression problem. It is known for its good performance as compared to all other machine learning algorithms.",
      "question": "Is XGBoost good for regression"
    },
    {
      "answer": "Warren McCulloch and Walter Pitts (1943).\n",
      "question": "Who did the first work generally recognized as AI?"
    },
    {
      "answer": "knowledge of the basic physiology and function of neurons in the brain; a formal analysis of propositional logic due to Russell and Whitehead; and Turing's theory of computation.\n",
      "question": "What sources was drawn on the formation of the first work generally recognized as AI?"
    },
    {
      "answer": "Donald Hebb (1949).\n",
      "question": "Who created the Hebbian learning rule?"
    },
    {
      "answer": "1950.\n",
      "question": "When the first neural network is built?"
    },
    {
      "answer": "The SNARC.\n",
      "question": "What is the first neural network called?"
    },
    {
      "answer": " machine learning",
      "question": "\"Who introduced the Turing test"
    },
    {
      "answer": "He prefer to develop learning algorithms and then teach the machine rather than by programming its intelligence by hand.\n",
      "question": "Alan Turing prefer what method on creating human-level Al?"
    },
    {
      "answer": "Allen Newell and Herbert Simon from Carnegie Tech.\n",
      "question": "Who presented the Logic Theorist (LT)?"
    },
    {
      "answer": "GPS was designed from the start to imitate human problem-solving protocols.\n",
      "question": "What does General Problem Solver (GPS) is designed for?"
    },
    {
      "answer": "General Problem Solver (GPS).\n",
      "question": "Which model was robably the first program to embody the \u201cthinking humanly\u201d approach?"
    },
    {
      "answer": "Allen Newell and Herbert Simon.\n",
      "question": "Who formulate the famous physical symbol system hypothesis?"
    },
    {
      "answer": "a physical symbol system has the necessary and sufficient means for general intelligent action.\n",
      "question": "What does physical symbol system hypothesis states?"
    },
    {
      "answer": "Herbert Gelernter (1959).\n",
      "question": "Who constructed the Geometry Theorem Prover?"
    },
    {
      "answer": " on checkers",
      "question": "\"Who"
    },
    {
      "answer": "John McCarthy.\n",
      "question": "Who defined the high-level language Lisp?"
    },
    {
      "answer": " in 1958",
      "question": "\"Whatlanguage"
    },
    {
      "answer": "J. A. Robinson's\n",
      "question": "who discovered a complete theorem-proving algorithm for first-order logic in 1965?"
    },
    {
      "answer": "James Slagle's Saint program\n",
      "question": "Which program in 1963 was able to solve closed-form calculus integration problems typical of MIT's first-year college courses?"
    },
    {
      "answer": "The blocks world.\n",
      "question": "What is the most famous microworld?"
    },
    {
      "answer": "\"The theorem says that the learning algorithm can adjust the connection strengths of a perceptron to match any input data",
      "question": "What does the perceptron convergence theorem say?"
    },
    {
      "answer": "\"Although perceptrons (a simple form of neural network) could be shown to learn anything they were capable of representing",
      "question": "What does the book Preceptrons (1969) mentioned?"
    },
    {
      "answer": "a general-purpose search mechanism trying to string together elementary reasoning steps to find complete solutions.\n",
      "question": "What is the weak methods in 1969?"
    },
    {
      "answer": "They do not scale up to large or difficult problem instances.\n",
      "question": "Why weak methods in 1969 are called weak methods?"
    },
    {
      "answer": " according to its authors?\"",
      "question": "\"Why is the DENDRAL program powerful"
    },
    {
      "answer": "The DENDRAL program.\n",
      "question": "Which program is the first successful knowledge-intensive system?"
    },
    {
      "answer": "A system that its expertise derived from large numbers of special-purpose rules.\n",
      "question": "What does knowledge-intensive system mean?"
    },
    {
      "answer": "It is to investigate the extent to which the new methodology of expert systems could be applied to other areas.\n",
      "question": "What is the content of the Heuristic Programming Project (HPP)?"
    },
    {
      "answer": "diagnosing blood infections.\n",
      "question": "What function does MYCIN system contribute in?"
    },
    {
      "answer": "\"First",
      "question": "What is the major differences between MYCIN and DENDRAL?"
    },
    {
      "answer": "certainty factors.\n",
      "question": "What calculus of uncertainty does MYCIN incorporated?"
    },
    {
      "answer": "It seemed (at the time) to fit well with how doctors assessed the impact of evidence on the diagnosis.\n",
      "question": "How is the performance of certainty factors in MYCIN?"
    },
    {
      "answer": "R1.\n",
      "question": "Which system is the first successful commercial expert system?"
    },
    {
      "answer": "\"The Digital Equipment Corporation (McDermott",
      "question": "Where does the first successful commercial expert system began operation?"
    },
    {
      "answer": "general knowledge about the world and a general method for using that knowledge.\n",
      "question": "What does robust language understanding requires?"
    },
    {
      "answer": "assembling facts about particular object and event types and arranging the types into a large taxonomic hierarchy analogous to a biological taxonomy.\n",
      "question": "What does Minsky's idea of frames (1975) implies?"
    },
    {
      "answer": "\"A 10-year plan to build massively parallel",
      "question": "What is the content of the \u201cFifth Generation\u201d project announced by the Japanese government in 1981?"
    },
    {
      "answer": "Many companies fell by the wayside as they failed to deliver on extravagant promises.\n",
      "question": "\"What caused the \"\"AI winter\"\"?\""
    },
    {
      "answer": " after 1988",
      "question": "\"Why"
    },
    {
      "answer": "Geoff Hinton\n",
      "question": "Who described symbols as the \u201cluminiferous aether of Al\u201d?"
    },
    {
      "answer": "A reference to the non-existent medium through which many 19th-century physicists believed that electromagnetic waves propagated.\n",
      "question": "What does \u201cluminiferous aether of Al\u201d by Geoff Hinton mean?"
    },
    {
      "answer": "It forms internal concepts in a more fluid and imprecise way.\n",
      "question": "How is the connectionist models better suited to the messiness of the real world?"
    },
    {
      "answer": "\"It is an approach incorporating probability rather than Boolean logic",
      "question": "What approach does the brittleness of expert systems led to?"
    },
    {
      "answer": "The approach using hidden Markov models (HMMs).\n",
      "question": "What approach dominate the field of speech recognition?"
    },
    {
      "answer": "\"First",
      "question": "What are the characteristics of HMMs in the feild of speech recognition?"
    },
    {
      "answer": "1988\n",
      "question": "Which year is an important year for the connection between Al and other fields?"
    },
    {
      "answer": " what fields does AI connected to?\"",
      "question": "\"In 1998"
    },
    {
      "answer": "Judea Pearl's (1988).\n",
      "question": "Whose research led to a new acceptance of probability and decision theory in Al?"
    },
    {
      "answer": "It yielded a rigorous and efficient formalism for representing uncertain knowledge as well as practical algorithms for probabilistic reasoning\n",
      "question": "What does Pearl's development of Bayesian networks yielded?"
    },
    {
      "answer": "connecting reinforcement learning to the theory of Markov decision processes (MDPs) developed in the field of operations research.\n",
      "question": "What major contribution is done by Rich Sutton in 1988?"
    },
    {
      "answer": "Remarkable advances in computing power and the creation of the World Wide Web.\n",
      "question": "What kind of advances facilitated the big data phenomenon?"
    },
    {
      "answer": "Banko and Brill (2001)\n",
      "question": "Who argued that the improvement in performance obtained from increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be obtained from tweaking the algorithm?"
    },
    {
      "answer": "Hays and Efros (2007).\n",
      "question": "Who developed a clever method for filling in holes in photographs by blending in pixels from similar images?"
    },
    {
      "answer": "\"It refers to machine learning using multiple layers of simple",
      "question": "What does the term deep learning refers to?"
    },
    {
      "answer": "convolutional neural networks.\n",
      "question": "What method do experiments found some success in handwritten digit recognition in the 1990s?"
    },
    {
      "answer": "representing the evaluation function.\n",
      "question": "How does deep network contribute to ALPHAGO's victories over the leading human Go players?"
    },
    {
      "answer": "2099\n",
      "question": "What is the mean for Ford (2018) interviews of AI experts in the question of when (if ever) will AI systems achieve human-level performance across a broad variety of tasks?"
    },
    {
      "answer": "\" a Dynamic Analysis and Replanning Tool",
      "question": "What system does U.S. forces deployed to do automated logistics planning and scheduling for transportation?"
    },
    {
      "answer": "Deep Blue\n",
      "question": "What AI system defeated world chess champion Garry Kasparov in 1997?"
    },
    {
      "answer": "ALPHAGO\n",
      "question": "What AI system defeated the world GO champion Ke Jie?"
    },
    {
      "answer": "\"It used no input from humans (except for the rules of the game)",
      "question": "What ALPHAZERO can do?"
    },
    {
      "answer": " which won the 2018 Gordon Bell Prize",
      "question": "\"What does the deep learning model"
    },
    {
      "answer": " serving as well for hurt as for remedy\u201d?\"",
      "question": "\"Who noted that the \u201cmechanical arts are of ambiguous use"
    },
    {
      "answer": " serving as well for hurt as for remedy\u201d be noted?\"",
      "question": "\"Where does the statement \u201cmechanical arts are of ambiguous use"
    },
    {
      "answer": " then use Al to solve everything else.\u201d?\"",
      "question": "\"Who suggested that \u201cFirst solve Al"
    },
    {
      "answer": "\"weapons that can locate",
      "question": "\"How does United Nations define \"\"Lethal Autonomous Weapons\"\"?\""
    },
    {
      "answer": "\"Lethal Autonomous Weapons",
      "question": "What possible risks we might face on devoloping AI?"
    },
    {
      "answer": "Nils Nilsson (1995)\n",
      "question": "Who reminded that the field of those broader goals and warned that the subfields were in danger of becoming ends in themselves?"
    },
    {
      "answer": "Norbert Wiener\n",
      "question": "Who was motivated to consider the long-term future of Al after seeing Arthur Samuel's checker-playing program learn to beat its creator?"
    },
    {
      "answer": "\"Midas",
      "question": "What does the Kind Midas problem implies?"
    },
    {
      "answer": "anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.\n",
      "question": "What is the definition of agent?"
    },
    {
      "answer": "It refer to the content an agent's sensors are perceiving.\n",
      "question": "What the word percept refer to?"
    },
    {
      "answer": "the complete history of everything the agent has ever perceived.\n",
      "question": "What is an agent's percept sequence?"
    },
    {
      "answer": " what does an agent's choice of action at any given instant depend on?\"",
      "question": "\"In general"
    },
    {
      "answer": "An agent's behavior is described by the agent function that maps any given percept sequence to an action.\n",
      "question": "What can we say mathematically on an agent's behavior?"
    },
    {
      "answer": "We evaluate an agent's behavior by its consequences.\n",
      "question": "How AI is stucked to consequentialism?"
    },
    {
      "answer": "It can be captured by a performance measure that evaluates any given sequence of environment states.\n",
      "question": "How can we capture the desirability related to consequentialism of an AI model?"
    },
    {
      "answer": "\"Human measures it from their point of view",
      "question": "What is the difference on desirability between human and machine?"
    },
    {
      "answer": "Norbert Wiener.\n",
      "question": "Who warns to ensure that \u201cthe purpose put into the machine is the purpose which we really desire\u201d?"
    },
    {
      "answer": " better",
      "question": "\"How"
    },
    {
      "answer": "We must accept the possibility that we might put the wrong purpose into the machine.\n",
      "question": "What does the King Midas problem inspire us?"
    },
    {
      "answer": "The performance measure that defines the criterion of success; The agent's prior knowledge of the environment; The actions that the agent can perform; The agent\u2019s percept sequence to date.\n",
      "question": "What can the definition of rational depends on?"
    },
    {
      "answer": "An omniscient agent knows the actual outcome of its actions and can act accordingly; but omniscience is impossible in reality.\n",
      "question": "What is the difference of omniscience from rationality?"
    },
    {
      "answer": "\"Rationality maximizes expected performance",
      "question": "What is the relationship between rationality and perfection?"
    },
    {
      "answer": "Doing actions in order to modify future percepts.\n",
      "question": "What information gathering means?"
    },
    {
      "answer": "An agent relies on the prior knowledge of its designer rather than on its own percepts and learning processes.\n",
      "question": "How we will say that an agent lacks autonomy?"
    },
    {
      "answer": "It should learn what it can to compensate for partial or incorrect prior knowledge.\n",
      "question": "What does an autonomous rational agent do?"
    },
    {
      "answer": "They are essentially the \u201cproblems\u201d to which rational agents are the \u201csolutions.\u201d\n",
      "question": "What is task environments?"
    },
    {
      "answer": "\"Specify the performance measure",
      "question": "What is PEAS description?"
    },
    {
      "answer": "We can identify a fairly small number of dimensions along which task environments can be categorized.\n",
      "question": "What we can do as the range of task environments that might arise in Al is obviously vast?"
    },
    {
      "answer": "Fully observable vs. partially observable; single-agent vs. multiagent; deterministic vs. nondeterministic; episodic vs. sequential; static vs. dynamic; discrete vs. continuous; known vs. unknown\n",
      "question": "What dimensions we can indentify on task environments?"
    },
    {
      "answer": "an agent's sensors give it access to the complete state of the environment at each point in time.\n",
      "question": "How can we say a task environment is fully observable?"
    },
    {
      "answer": "The next state of the environment is completely determined by the current state and the action executed by the agent(s).\n",
      "question": "How can we say a task environment is deterministic?"
    },
    {
      "answer": "fully observable and deterministic.\n",
      "question": "What task environment makes an agent need not worry about uncertainty?"
    },
    {
      "answer": "\"We say that a model of the environment is stochastic if it explicitly deals with probabilities (e.g.",
      "question": "What is the difference between stochastic and nondeterministic?"
    },
    {
      "answer": "\"The agent's experience is divided into atomic episodes",
      "question": "How can we say a task environment is episodic?"
    },
    {
      "answer": "The current decision of agent could affect all future decisions.\n",
      "question": "How can we say a task environment is sequential?"
    },
    {
      "answer": "Many classification tasks are episodic; Chess and taxi driving are sequential.\n",
      "question": "What are the examples of episodic and sequential task environments?"
    },
    {
      "answer": "The agent does not need to think ahead.\n",
      "question": "Why episodic environments are much simpler than sequential environments?"
    },
    {
      "answer": "The environment can change while an agent is deliberating.\n",
      "question": "How can we say a task environment is dynamic for that agent?"
    },
    {
      "answer": "The environment cannot change while an agent is deliberating.\n",
      "question": "How can we say a task environment is static for that agent?"
    },
    {
      "answer": "\"The agent need not keep looking at the world while it is deciding on an action",
      "question": "Why static task envrionments are easy to deal with?"
    },
    {
      "answer": "The environment itself does not change with the passage of time but the agent's performance score does.\n",
      "question": "How can we say a task environment is semidynamic?"
    },
    {
      "answer": " semidynamic and static task environments?\"",
      "question": "\"What are the examples of dynamic"
    },
    {
      "answer": "\"The state of the environment",
      "question": "What are the differences between discrete and continuous task environments?"
    },
    {
      "answer": "\"Chess has a finite number of distinct states (excluding the clock)",
      "question": "What are the examples of discrete and continuous task environments?"
    },
    {
      "answer": " The agent's (or designer's) state of knowledge about the \u201claws of physics\u201d of the environment.\n",
      "question": "What does a known / unknown task environment refers to?"
    },
    {
      "answer": "The outcomes (or outcome probabilities if the environment is nondeterministic) for all actions are given.\n",
      "question": "How can we say a task environment is known?"
    },
    {
      "answer": "The agent will have to learn how it works in order to make good decisions.\n",
      "question": "How can we say a task environment is unknown?"
    },
    {
      "answer": "\"In solitaire card games",
      "question": "What is an example of partially observable and known task environment?"
    },
    {
      "answer": "\"In a new video game",
      "question": "What is an example of fully observable and unknown task environment?"
    },
    {
      "answer": "\"partially observable",
      "question": "What kind of task environment should be the hardest case?"
    },
    {
      "answer": "The mapping from percepts to actions.\n",
      "question": "What is an agent function?"
    },
    {
      "answer": "A program will run on some sort of computing device with physical sensors and actuators\n",
      "question": "What is the agent architecture?"
    },
    {
      "answer": "\"In general",
      "question": "What the architecture does to a program?"
    },
    {
      "answer": "Simple reflex agents; Model-based reflex agents; Goal-based agents; and Utility-based agents.\n",
      "question": "What are the four basic kinds of agent programs that embody the principles underlying almost all intelligent systems?"
    },
    {
      "answer": "\"These agents select actions on the basis of the current percept",
      "question": "What does simple reflex agents do?"
    },
    {
      "answer": "if-then statements.\n",
      "question": "What does condition-action rule similar to?"
    },
    {
      "answer": "Firstly build a general-purpose interpreter for condition-action rules and then to create rule sets for specific task environments.\n",
      "question": "What is the more general and flexible approach for simple reflex agent?"
    },
    {
      "answer": "The agent can randomize its actions.\n",
      "question": "How can a simple reflex agen escape from infinite loops?"
    },
    {
      "answer": "A more sophisticated deterministic agent.\n",
      "question": "What is better instead of allowing simple reflex agents to randomize its actions?"
    },
    {
      "answer": "The agent should maintain some sort of internal state that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. \n",
      "question": "What is the most effective way to handle partial observability for the agent?"
    },
    {
      "answer": "\"First",
      "question": "What kind of knowledge is required in updating model-based reflex agents' internal state information as time goes by?"
    },
    {
      "answer": "The effects of the agent's actions and how the world evolves independently of the agent.\n",
      "question": "How the information about how the world changes over time in model-based reflex agent can be divided?"
    },
    {
      "answer": "The transition model of the world.\n",
      "question": "What does the knowledge about \u201chow the world works\u201d is called?"
    },
    {
      "answer": "\"A kind of knowledge",
      "question": "What is sensor model in model-based reflex agent?"
    },
    {
      "answer": "An agent using transition model and sensor model.\n",
      "question": "What is the definition of model-based reflex agent?"
    },
    {
      "answer": "allow an agent to keep track of the state of the world.\n",
      "question": "How transition model and sensor model function in model-based reflex agent?"
    },
    {
      "answer": "The function which is responsible for creating the new internal state description.\n",
      "question": "Which part in model-based reflex agent's structure is interesting?"
    },
    {
      "answer": "\"It represents the agent's \u201cbest guess\u201d",
      "question": "What does the model-based reflex agent's knowing of the current world actually is?"
    },
    {
      "answer": "It describes situations that are desirable.\n",
      "question": "What does goal information do to agents?"
    },
    {
      "answer": "It may appears less efficient.\n",
      "question": "How a goal-based agent appears being more flexible?"
    },
    {
      "answer": "\"It is because it sounds more scientific then words like \"\"happy\"\".\"\n",
      "question": "Why economists and computer scientists use the term utility instead?"
    },
    {
      "answer": "An agent that chooses actions to maximize its utility will be rational according to the external performance measure.\n",
      "question": "What will happen if the internal utility function and the external performance measure are in agreement?"
    },
    {
      "answer": "It specifies the appropriate tradeoff.\n",
      "question": "What does a utility function do when there are conflicting goals?"
    },
    {
      "answer": "It provides a way in which the likelihood of success can be weighed against the importance of the goals.\n",
      "question": "What does a utility function do when there are several goals that the agent can aim for?"
    },
    {
      "answer": "\"It chooses the action that maximizes the expected utility of the action outcomes\u2014that is",
      "question": "How can we say technically about a rational utility-based agent?"
    },
    {
      "answer": "It can make rational decisions with a general-purpose algorithm that does not depend on the specific utility function being maximized.\n",
      "question": "What will happen if an agent possesses an explicit utility function?"
    },
    {
      "answer": "A utility-based agent has to model and keep track of its environment; Choosing the utility-maximizing course of action.\n",
      "question": "What is hard in utility-based function?"
    },
    {
      "answer": "It allows the agent to operate in initially unknown environments and to become more competent than its initial knowledge alone might allow.\n",
      "question": "What is the advantage for agent to learn?"
    },
    {
      "answer": "Learning element; Performance element; Critic; Problem Generator.\n",
      "question": "What is the conceptual components for a learning agent?"
    },
    {
      "answer": "It is responsible for making improvements.\n",
      "question": "What does the learning element in the components for a learning agent do?"
    },
    {
      "answer": "It is responsible for selecting external actions.\n",
      "question": "What does the performance element in the components for a learning agent do?"
    },
    {
      "answer": "The critic tells the learning element how well the agent is doing with respect to a fixed performance standard.\n",
      "question": "What does the critic in the components for a learning agent do?"
    },
    {
      "answer": "The first question is not \u201cHow am I going to get it to learn this?\u201d but \u201cWhat kind of performance element will my agent use to do this once it has learned how?\u201d \n",
      "question": "How should we think when we are trying to design an agent that learns a certain capability?"
    },
    {
      "answer": "The percepts themselves provide no indication of the agent's success. \n",
      "question": "Why critic is necessary for a learning agent?"
    },
    {
      "answer": "It is responsible for suggesting actions that will lead to new and informative experiences.\n",
      "question": "What does the problem generator in the components for a learning agent do?"
    },
    {
      "answer": "It might discover much better actions for the long run.\n",
      "question": "What will happen if an agent is willing to explore a little and do some perhaps suboptimal actions in the short run?"
    },
    {
      "answer": "Information from the external standard.\n",
      "question": "What is needed when we are trying to learn a reflex component or a utility function?"
    },
    {
      "answer": "A reward or penalty that provides direct feedback on the quality of the agent's behavior.\n",
      "question": "What does the performance standard distinguishes part of the incoming percept as?"
    },
    {
      "answer": "\"Atomic",
      "question": "How can we rank the representations of task environments in their expressiveness?"
    },
    {
      "answer": "\"It describes the changes that might occur in the environment as the result of taking an action",
      "question": "What does a particular agent component that deals with \u201cWhat my actions do\u201d do?"
    },
    {
      "answer": "Each state of the world is indivisible\u2014it has no internal structure.\n",
      "question": "What happens in an atomic representation?"
    },
    {
      "answer": "\"Search and game-playing",
      "question": "What are the examples of areas work with atomic representations?"
    },
    {
      "answer": "\"It splits up each state into a fixed set of variables or attributes",
      "question": "What does a factored representation do?"
    },
    {
      "answer": "\"Constraint satisfaction algorithms",
      "question": "What are the examples of areas work with factored representations?"
    },
    {
      "answer": "Objects and their various and varying relationships can be described explicitly\n",
      "question": "What happens in a structured representation?"
    },
    {
      "answer": "\"When we need to understand the world as having things in it that are related to each other",
      "question": "When we need the structured representation?"
    },
    {
      "answer": "\"Relational databases and first-order logic",
      "question": "What are the examples of areas work with structured representations?"
    },
    {
      "answer": "Reasoning and learning become more complex as the expressive power of the representation increases.\n",
      "question": "How reasoning and learning changes following to the expressive power of the representation of an agent's environment?"
    },
    {
      "answer": "Intelligent systems for the real world may need to operate at all points along the axis simultaneously\n",
      "question": "How can we gain the benefits of expressive representations of agent environments while avoiding their drawbacks?"
    },
    {
      "answer": "There is a one-to-one mapping between concepts and memory locations.\n",
      "question": "What happens in a localist representation?"
    },
    {
      "answer": "\"The representation of a concept is spread over many memory locations",
      "question": "What happens in a distributed representation?"
    },
    {
      "answer": " localist one or distributed one?\"",
      "question": "\"Which representations are more robust against noise and information loss"
    },
    {
      "answer": "\"The mapping from concept to memory location is arbitrary",
      "question": "What bad situation might happen using localist representations?"
    },
    {
      "answer": "An agent that need to plan ahead: to consider a sequence of actions that form a path to a goal state.\n",
      "question": "What is the definition of problem-solving agent?"
    },
    {
      "answer": "The computational process that a problem-solving agent undertakes.\n",
      "question": "What is the definition of search?"
    },
    {
      "answer": "Atomic representations.\n",
      "question": "What representations do Problem-solving agents use?"
    },
    {
      "answer": "The agent can estimate how far it is from the goal.\n",
      "question": "What happens to informed algorithms?"
    },
    {
      "answer": "The agent cannot estimate how far it is from the goal.\n",
      "question": "What happens to uninformed algorithms?"
    },
    {
      "answer": "Goal formulation; problem formulation; Search; Execution.\n",
      "question": "What is the four-phrase problem-solving process?"
    },
    {
      "answer": "The agent adopts the goal of a task.\n",
      "question": "What an agent does in goal formulation phase?"
    },
    {
      "answer": "Goals organize behavior by limiting the objectives and hence the actions to be considered.\n",
      "question": "How does the goals act in an agent's goal formulation phase?"
    },
    {
      "answer": "The agent devises a description of the states and actions necessary to reach the goal\u2014an abstract model of the relevant part of the world.\n",
      "question": "What an agent does in problem formulation phase?"
    },
    {
      "answer": "\"Before taking any action in the real world",
      "question": "What an agent does in search phase?"
    },
    {
      "answer": "A sequence of actions that reaches the goal.\n",
      "question": "What is the definition of solution for problem-solving agent?"
    },
    {
      "answer": "\"The agent excute the actions in the solution",
      "question": "What an agent does in execution phase?"
    },
    {
      "answer": " deterministic",
      "question": "\"How is the solution in a fully observable"
    },
    {
      "answer": "A system ignoring the percepts breaks the loop between agent and environment.\n",
      "question": "What open-loop system is by the control theorists?"
    },
    {
      "answer": " open-loop or closed-loop?\"",
      "question": "\"Which loop is more safer for a problem-solving agent"
    },
    {
      "answer": "A solution would be a branching strategy that recommends different future actions depending on what percepts arrive.\n",
      "question": "How is the solution in a partially observable or nondeterministic environment?"
    },
    {
      "answer": "A set of possible states that the environment can be in.\n",
      "question": "What is the definition of the state space?"
    },
    {
      "answer": "The state that the agent starts in.\n",
      "question": "What is the definition of the initial state?"
    },
    {
      "answer": "A set of states that are goals to the agent.\n",
      "question": "What is the definition of the goal states?"
    },
    {
      "answer": "A model which describes what each action does.\n",
      "question": "What is the definition of transition model to problem-solving agent?"
    },
    {
      "answer": "A function reflects an agent's own performance measure.\n",
      "question": "What is the definition of action cost function?"
    },
    {
      "answer": "\"The combination of a state space",
      "question": "\"What is the definition of a search \"\"problem\"\"?\""
    },
    {
      "answer": "The solution having the lowest path cost.\n",
      "question": "What is the definition of an optimal solution?"
    },
    {
      "answer": "\"An abstract mathematical description",
      "question": "What is the possible meaning of model?"
    },
    {
      "answer": "The process of removing detail from a representation.\n",
      "question": "What is the definition of abstraction?"
    },
    {
      "answer": "It involves removing as much detail as possible while retaining validity and ensuring that the abstract actions are easy to carry out.\n",
      "question": "How can we say an abstraction is good?"
    },
    {
      "answer": "The intelligent agents would be completely swamped by the real world.\n",
      "question": "What will happen if we don't have the ability to construct useful abstractions?"
    },
    {
      "answer": "It is intended to illustrate or exercise various problem-solving methods.\n",
      "question": "What is the definition of standardized problem?"
    },
    {
      "answer": "A standardized problem is suitable as a benchmark for researchers to compare the performance of algorithms.\n",
      "question": "How can researchers use a standardized problem?"
    },
    {
      "answer": "\"It is one whose solutions people actually use",
      "question": "What is the definition of real-world problem?"
    },
    {
      "answer": "It is a two-dimensional rectangular array of square cells in which agents can move from cell to cell.\n",
      "question": "What is a grid world problem?"
    },
    {
      "answer": "\"Cells can contain objects",
      "question": "What agents can do to objects in cells in a grid world problem?"
    },
    {
      "answer": "Those things in a cell prevents an agent from moving into that cell.\n",
      "question": "What wall or impassible obstacles do in a grid world problem?"
    },
    {
      "answer": "Sokoban puzzle.\n",
      "question": "What is the example of a grid world problem?"
    },
    {
      "answer": "\"It is a puzzle that the agent's goal is to push a number of boxes",
      "question": "What is a sokoban puzzle?"
    },
    {
      "answer": "It is a puzzle that a number of tiles (sometimes called blocks or pieces) are arranged in a grid with one or more blank spaces so that some of the tiles can slide into the blank space.\n",
      "question": "What is a sliding-tile puzzle?"
    },
    {
      "answer": "\"It is a problem that describes a set of locations that must be visited",
      "question": "What is a touring problem?"
    },
    {
      "answer": "It is a touring problem in which every city on a map must be visited.\n",
      "question": "What is the traveling salesperson problem (TSP)?"
    },
    {
      "answer": "It requires positioning millions of components and connections on a chip.\n",
      "question": "What does a VLSI layout problem requires?"
    },
    {
      "answer": "\"It aims to minimize area",
      "question": "What does a VLSI layout problem aims to?"
    },
    {
      "answer": "It is split into two parts: cell layout and channel routing.\n",
      "question": "How does the VLSI layout problem be splited?"
    },
    {
      "answer": "\"A robot can roam around",
      "question": "What is the difference of robot navigation from following distinct paths?"
    },
    {
      "answer": "\"Their sensor readings and motor controls",
      "question": "What problem do real robots must also deal with in robot navigation?"
    },
    {
      "answer": "1970s.\n",
      "question": "Since when does the automatic assembly sequencing of complex objects (such as electric motors) by a robot have been standard industry practice?"
    },
    {
      "answer": "\"It is an assembly problem",
      "question": "What is protein design?"
    },
    {
      "answer": "\"A search algorithm takes a search problem as input and returns a solution",
      "question": "What is the definition of search algorithm?"
    },
    {
      "answer": "A state in the state space.\n",
      "question": "What does a node in a search tree corresponds to?"
    },
    {
      "answer": "An action.\n",
      "question": "What does an edge in a search tree corresponds to?"
    },
    {
      "answer": "The initial state of the problem.\n",
      "question": "What does the root in a search tree corresponds to?"
    },
    {
      "answer": "\"The state space describes the (possibly infinite) set of states in the world",
      "question": "What is the distinction of the state space from the search tree?"
    },
    {
      "answer": "\"The search tree describes paths between these states",
      "question": "What is the distinction of the search tree from the state space?"
    },
    {
      "answer": "\"We can expand the node",
      "question": "What is the process of expanding a node?"
    },
    {
      "answer": " what B is of A?\"",
      "question": "\"If A is a child node of B"
    },
    {
      "answer": "Following up one option now and putting the others aside for later.\n",
      "question": "What is the essence of search?"
    },
    {
      "answer": "The node has had a node generated for it.\n",
      "question": "How can we say a node is reached?"
    },
    {
      "answer": "\"We choose a node",
      "question": "What is best-first search?"
    },
    {
      "answer": "A node in the tree is represented by a data structure with four components: State; Parent; Action; Path cost.\n",
      "question": "What is node?"
    },
    {
      "answer": "State; Parent; Action; Path cost.\n",
      "question": "What is the componenets of a node?"
    },
    {
      "answer": "A data structure used to store the frontier.\n",
      "question": "What is queue?"
    },
    {
      "answer": "check whether it is empty; remove the top node; return the top node; insert node into proper place\n",
      "question": "What are the possible operations on a frontier?"
    },
    {
      "answer": "\"A kind of queue which first pops the node with the minimum cost according to some evaluation function",
      "question": "What is a priority queue?"
    },
    {
      "answer": "It is used in best-first search.\n",
      "question": "Where does a priority queue might be used?"
    },
    {
      "answer": "A kind of queue which  first pops the node that was added to the queue first.\n",
      "question": "What is a first-in-first-out (FIFO) queue?"
    },
    {
      "answer": "It is used in breadth-first search.\n",
      "question": "Where does a FIFO queue might be used?"
    },
    {
      "answer": "A kind of queue which  first pops the node that was added most recently to the queue.\n",
      "question": "What is a last-in-first-out (LIFO) queue?"
    },
    {
      "answer": "It is used in depth-first search.\n",
      "question": "Where does a LIFO queue might be used?"
    },
    {
      "answer": "The search goes repeatedly between two states.\n",
      "question": "What is the example of loopy path in a search?"
    },
    {
      "answer": "The complete search tree is infinite.\n",
      "question": "what is the possible consequence if loopy path occurs in a search?"
    },
    {
      "answer": "Redundant paths.\n",
      "question": "What should be eliminated in the search?"
    },
    {
      "answer": "Remember all previously reached states to detect redundant paths; do not consider it for minor problem formulations; only check for cycles but not for redundant paths in general.\n",
      "question": "What possible methods can be used to eliminate redundant paths?"
    },
    {
      "answer": "A search algorithm which checks for redundant paths.\n",
      "question": "What is a graph search?"
    },
    {
      "answer": "A search algorithm which does not check for redundant paths.\n",
      "question": "What is a tree-like search?"
    },
    {
      "answer": "The Brst-First-Search algorithm.\n",
      "question": "What is an example of graph search algorithm?"
    },
    {
      "answer": "Completeness; Cost optimality; Time complexity; Space complexity.\n",
      "question": "What are the evaluation methods on an algorithm\u2019s performance?"
    },
    {
      "answer": "\"Is the algorithm guaranteed to find a solution when there is one",
      "question": "What does Completeness evaluates specificly on an algorithm's performance?"
    },
    {
      "answer": "Does it find a solution with the lowest path cost of all solutions?\n",
      "question": "What does Cost optimality evaluates specificly on an algorithm's performance?"
    },
    {
      "answer": "\"How long does it take to find a solution? This can be measured in seconds",
      "question": "What does Time complexity evaluates specificly on an algorithm's performance?"
    },
    {
      "answer": "How much memory is needed to perform the search?\n",
      "question": "What does Space complexity evaluates specificly on an algorithm's performance?"
    },
    {
      "answer": "\"A search algorithm which is systematic in the way it explores an infinite state space",
      "question": "What kind of search algorithm will be complete?"
    },
    {
      "answer": "Time and space complexity.\n",
      "question": "What evaluation methods on an algorithm\u2019s performance are considered with respect to some measure of the problem difficulty?"
    },
    {
      "answer": "\"d",
      "question": "What variables can we use in measuring the complexity of an algorithm?"
    },
    {
      "answer": "One that uses domain-specific hints about the location of goals.\n",
      "question": "What is an informed search strategy?"
    },
    {
      "answer": "The estimated cost of the cheapest path from the state at node n to a goal state.\n",
      "question": "What is heuristic function?"
    },
    {
      "answer": "Greedy best -first search is a form of best-first search that expands first the node with the lowest value on the grounds that this is likely to lead to a solution quickly.\n",
      "question": "What is Greedy best-first search?"
    },
    {
      "answer": "\"On each iteration it tries to get as close to a goal as it can",
      "question": "Why the algorithm is called \u201cgreedy\u201d?"
    },
    {
      "answer": "A* search is a best-first search that uses the evaluation function f(n) = g(n) + h(n).\n",
      "question": "What is A* search?"
    },
    {
      "answer": "g(n) is the path cost from the initial state to node n.\n",
      "question": "What is g(n)?"
    },
    {
      "answer": "f(n) is the estimated cost of the best path that continues from n to a goal.\n",
      "question": "What is f(n)?"
    },
    {
      "answer": "\"A* search is complete",
      "question": "What is the properties of A* search?"
    },
    {
      "answer": "A* search uses a lot of space and memory.\n",
      "question": "What is the drawback of A* search?"
    },
    {
      "answer": "An admissible heuristic is one that never overestimates the cost to reach a goal. \n",
      "question": "What is an admissible heuristic?"
    },
    {
      "answer": "A contour is a useful way to visualize a search by drawing it in the state space.\n",
      "question": "What is a contour?"
    },
    {
      "answer": "\"Yes",
      "question": "Does uniform-cost search has contours?"
    },
    {
      "answer": "\"The contours with uniform-cost search will be \u201ccircular\u201d around the start state",
      "question": "What does the contours with uniform-cost search look like?"
    },
    {
      "answer": "\"Satisficing solutions are when we accept solutions that are suboptimal",
      "question": "What is satisficing solutions?"
    },
    {
      "answer": "We look for a solution that is guaranteed to be within a constant factor W of the optimal cost.\n",
      "question": "What is bounded suboptimal search?"
    },
    {
      "answer": "Weighted A* provides bounded suboptimal search.\n",
      "question": "Which algorith provides bounded suboptimal search?"
    },
    {
      "answer": "We look for a solution whose cost is less than some constant C.\n",
      "question": "What is bounded-cost search?"
    },
    {
      "answer": "\"We accept a solution of any cost",
      "question": "What is unbounded-cost search?"
    },
    {
      "answer": "An example of an unbounded-cost search algorithm is speedy search.\n",
      "question": "What is the example of an unbounded-cost search algorithm?"
    },
    {
      "answer": "\"The speedy search is a version of greedy best-first search that uses as a heuristic the estimated number of actions required to reach a goal",
      "question": "What is speedy search?"
    },
    {
      "answer": "Iterative-deepening A* search (IDA*) is to A* what iterative-deepening search is to depthfirst.\n",
      "question": "What is Iterative-deepening A* search?"
    },
    {
      "answer": "\"Iterative-deepening A* search gives us the benefits of A* without the requirement to keep all reached states in memory",
      "question": "What is the benefits of Iterative-deepening A* search?"
    },
    {
      "answer": "\"Recursive best-first search attempts to mimic the operation of standard best-first search",
      "question": "What is recursive best-first search?"
    },
    {
      "answer": "\"Beam search puts a limit on the size of the frontier; that makes it incomplete and suboptimal",
      "question": "What is beam search?"
    },
    {
      "answer": "\" One can sometimes construct good heuristics by relaxing the problem definition",
      "question": "How to construct good heuristics?"
    },
    {
      "answer": "\"Local search algorithms operate by searching from a start state to neighboring states",
      "question": "How do local search algoritms function?"
    },
    {
      "answer": "\"No",
      "question": "Are local search algoritms systematic?"
    },
    {
      "answer": "They use very little memory; and they can often find reasonable solutions in large or infinite state spaces for which systematic algorithms are unsuitable.\n",
      "question": "What are the advantages of local search algorithms?"
    },
    {
      "answer": "The hill-climbing search algorithm keeps track of one current state and on each iteration moves to the neighboring state with highest value.\n",
      "question": "What is hill-climbing search algorithm?"
    },
    {
      "answer": "Hill climbing is called greedy local search because it grabs a good neighbor state without thinking ahead about where to go next.\n",
      "question": "Why hill climbing is called greedy local search?"
    },
    {
      "answer": "\"Hill climbing can get stuck when it reaches local maxima",
      "question": "What is the drawback of hill climbing?"
    },
    {
      "answer": "A local maximum is a peak that is higher than each of its neighboring states but lower than the global maximum.\n",
      "question": "What is a local maximum?"
    },
    {
      "answer": "A plateau is a flat area of the state-space landscape.\n",
      "question": "What is a plateau?"
    },
    {
      "answer": "\"A plauteau is a flat local maximum",
      "question": "What are the examples of plauteau?"
    },
    {
      "answer": "Stochastic hill climbing  chooses at random from among the uphill moves; the probability of selection can vary with the steepness of the uphill move. \n",
      "question": "What is stochastic hill climbing?"
    },
    {
      "answer": "A first-choice hill climbing implements stochastic hill climbing by generating successors randomly until one is generated that is better than the current state.\n",
      "question": "What is first-choice hill climbing?"
    },
    {
      "answer": "\"A random-restart hill climbing conducts a series of hill-climbing searches from randomly generated initial states",
      "question": "What is random-restart hill climbing?"
    },
    {
      "answer": "\"A success hill climbing depends very much on the shape of the state-space landscape: if there are few local maxima and plateaus",
      "question": "How to get a success hill climbing?"
    },
    {
      "answer": "A simulated annealing combines hill climbing with a random walk in a way that yields both efficiency and completeness.\n",
      "question": "What is simulated annealing?"
    },
    {
      "answer": "\"Annealing is the process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them",
      "question": "What is annealing?"
    },
    {
      "answer": "The local beam search algorithm keeps track of k states rather than just one. \n",
      "question": "What is local beam search?"
    },
    {
      "answer": "\"It begins with k randomly generated states. At each step",
      "question": "How does the local beam search operate?"
    },
    {
      "answer": "Evolutionary algorithms can be seen as variants of stochastic beam search that are explicitly motivated by the metaphor of natural selection in biology.\n",
      "question": "What is evolutionary algoritms?"
    },
    {
      "answer": "\"Genetic algorithms are similar to stochastic beam search",
      "question": "What is genetic algorithm?"
    },
    {
      "answer": "Genetic algorithm is advantageous when there are blocks that perform useful functions.\n",
      "question": "When is the genetic algorithm advantageous?"
    },
    {
      "answer": "Empirical gradient methods are methods that measure progress by the change in the value of the objective function between two nearby points\n",
      "question": "What are empirical gradient methods?"
    },
    {
      "answer": " A belief state is a set of physical states that the agent believes are possible.\n",
      "question": "What is a belief state?"
    },
    {
      "answer": "A sensorless problem is when the agent\u2019s percepts provide no information at all.\n",
      "question": "What is a sensorless problem?"
    },
    {
      "answer": "Offline search algorithms compute a complete solution before taking their first action.\n",
      "question": "What are offline search algorithms?"
    },
    {
      "answer": "\"Online search algorithms take an action first",
      "question": "What are online search algorithms?"
    },
    {
      "answer": "\"An online search problem is solved by interleaving computation",
      "question": "How is an online search problem solved?"
    },
    {
      "answer": "Competitive ratio is the comparison of the cost with the path cost the agent would incur if it knew the search space in advance.\n",
      "question": "What is competitive ratio?"
    },
    {
      "answer": "Dead ends are states from which no goal state is reachable.\n",
      "question": "What are dead ends?"
    },
    {
      "answer": "Safely explorable is when some goal state is reachable from every reachable state. \n",
      "question": "What is the meaning of safely explorable?"
    },
    {
      "answer": "A random walk simply selects at random one of the available actions from the current state\n",
      "question": "What is random walk?"
    },
    {
      "answer": "Competitive environments are in which two or more agents have conflicting goals. \n",
      "question": "What are competitive environments?"
    },
    {
      "answer": "An economy is to consider a very large number of agents in the aggregate.\n",
      "question": "What is an economy?"
    },
    {
      "answer": "The examples are rolling dice or shuffling cards.\n",
      "question": "What are the examples of games that include an element of chance?"
    },
    {
      "answer": "\"The examples are poker and bridge",
      "question": "What are the examples of games of imperfect information?"
    },
    {
      "answer": "Perfect information is when the game is fully observable.\n",
      "question": "\"What is \"\"perfect information\"\"?\""
    },
    {
      "answer": "\u201cZero-sum\u201d means that what is good for one player is just as bad for the other: there is no \u201cwin-win\u201d outcome.\n",
      "question": "\"What is \"\"zero-sum\"\"?\""
    },
    {
      "answer": "\"A game can be formally defined with initial state",
      "question": "What are the formally defined elements of a game?"
    },
    {
      "answer": "A terminal test is true when the game is over and false if otherwise.\n",
      "question": "What is a terminal test?"
    },
    {
      "answer": "Terminal states are states where the game has ended.\n",
      "question": "What is terminal states?"
    },
    {
      "answer": "A utility function defines the final numeric value to player p when the game ends in terminal state s.\n",
      "question": "What is a utility function?"
    },
    {
      "answer": "The other names of a utility function are an objective function or payoff function.\n",
      "question": "What are the other names of a utility function?"
    },
    {
      "answer": "\"A state space graph is a graph where the vertices are states",
      "question": "What is a state space graph?"
    },
    {
      "answer": "We uses minimax search for games with multiple outcome scores.\n",
      "question": "When do we use minimax search?"
    },
    {
      "answer": "\"Ply is used to unambiguously mean one move by one player",
      "question": "What is ply?"
    },
    {
      "answer": "The minimax search algorithm finds the best move for MAX by trying all actions and choosing the one whose resulting state has the highest MINIMAX value.\n",
      "question": "What is the minimax search algorithm?"
    },
    {
      "answer": "\"Yes",
      "question": "Is the minimax search algorithm recursive?"
    },
    {
      "answer": "The time complexity of the minimax algorithm is O(b^m) if the maximum depth of the tree is m and there are b legal moves at each point.\n",
      "question": "What is the time complexity for the minimax search algorithm?"
    },
    {
      "answer": "The alpha\u2013beta pruning is the particular technique when we compute the correct minimax decision without examining every state by pruning large parts of the tree that make no difference to the outcome.\n",
      "question": "What is alpha\u2013beta pruning?"
    },
    {
      "answer": "\"A Type A strategy considers all possible moves to a certain depth in the search tree",
      "question": "What is Type A strategy?"
    },
    {
      "answer": "\"A Type B strategy ignores moves that look bad",
      "question": "What is Type B strategy?"
    },
    {
      "answer": "\"Type A strategy explores a wide but shallow portion of the tree",
      "question": "What is the difference between the Type A strategy and Type B strategy?"
    },
    {
      "answer": "Most of the chess programs have been Type A strategy.\n",
      "question": "What is the example of games with Type A strategy?"
    },
    {
      "answer": "Most of the Go programs are more often Type B strategy.\n",
      "question": "What is the example of games with Type B strategy"
    },
    {
      "answer": "\"A forward pruning prunes moves that appear to be poor moves",
      "question": "What is forward pruning?"
    },
    {
      "answer": "\"We use Monte Carlo tree search because  alpha\u2013beta search would be limited to only 4 or 5 ply and ",
      "question": "Why we use Monte Carlo tree search?"
    },
    {
      "answer": "\"Stochastic games bring us a little closer to the unpredictability of real life by including a random element",
      "question": "What are sto4chastic games?"
    },
    {
      "answer": "Backgammon is a typical stochastic game that combines luck and skill. \n",
      "question": "What is the example of stochastic games?"
    },
    {
      "answer": "Partially observable games  includes the use of scouts and spies to gather information and the use of concealment and bluff to confuse the enemy.\n",
      "question": "What are partially obsercable games?"
    },
    {
      "answer": "Video games such as StarCraft is the example of partially obsercable game.\n",
      "question": "What are the examples of partially obsercable games?"
    },
    {
      "answer": "Stochastic partial observable games are where the missing information is generated by the random dealing of cards.\n",
      "question": "What are stochastic partial observable games?"
    },
    {
      "answer": "\"Card games such as bridge",
      "question": "What are the examples of stochastic partial observable games?"
    },
    {
      "answer": "\"When the branching factor is high or it is difficult to define an evaluation function",
      "question": "When is Monte Carlo search preferred?"
    },
    {
      "answer": "The limitation of alpha\u2013beta search is its vulnerability to errors in the heuristic function.\n",
      "question": "What is the limitation of alpha\u2013beta search?"
    },
    {
      "answer": "The limitation of Monte Carlo is that it is designed to calculate the values of legal moves. \n",
      "question": "What is the limitation of Monte Carlo search?"
    },
    {
      "answer": "Metareasoning is the kind of reasoning about what computations to do.\n",
      "question": "What is metareasoning?"
    },
    {
      "answer": "A constraint satisfaction problem is A problem that is solved when each variable has a value that satisfies all the constraints on the variable.\n",
      "question": "What is a constraint satisfaction problem?"
    },
    {
      "answer": "\"The three components are a set of variables (X)",
      "question": "What are the components of a constraint satisfaction problem?"
    },
    {
      "answer": "A consistent or legal assignment is an assignment that does not violate any constraints.\n",
      "question": "What is a consistent or legal assignment?"
    },
    {
      "answer": "A complete assignment is one in which every variable is assigned a value.\n",
      "question": "What is a complete assignment?"
    },
    {
      "answer": "\"A solution to a CSP is a consistent",
      "question": "What is a solution to a CSP?"
    },
    {
      "answer": "A partial assignment is one that leaves some variables unassigned.\n",
      "question": "What is a partial assignment?"
    },
    {
      "answer": "A partial solution is a partial assignment that is consistent.\n",
      "question": "What is a partial solution?"
    },
    {
      "answer": "One reason is that the CSPs yield a natural representation for a wide variety of problems; it is often easy to formulate a problem as a CSP.\n",
      "question": "Why do we formulate a problem as a CSP?"
    },
    {
      "answer": "Linear constraints are  constraints in which each variable appears only in linear form. \n",
      "question": "What are linear constraints?"
    },
    {
      "answer": "A unary constraint restricts the value of a single variable. \n",
      "question": "What is unary constraint?"
    },
    {
      "answer": "A global constraint is a constraint involving an arbitrary number of variables.\n",
      "question": "What is a global constraint?"
    },
    {
      "answer": "\"It is using the constraints to reduce the number of legal values for a variable",
      "question": "What is constraint propagation?"
    },
    {
      "answer": "A single variable is node-consistent if all the values in the variable\u2019s domain satisfy the variable\u2019s unary constraints. \n",
      "question": "What is node-consistency?"
    },
    {
      "answer": "A variable in a CSP is arc-consistent if every value in its domain satisfies the variable\u2019s binary constraints. \n",
      "question": "What is arc-consistent?"
    },
    {
      "answer": "The most popular algorithm for enforcing arc consistency is called AC-3. \n",
      "question": "What is the example of algorithm that enforce arc consistency?"
    },
    {
      "answer": "Path consistency tightens the binary constraints by using implicit constraints that are inferred by looking at triples of variables.\n",
      "question": "What can path consistency do?"
    },
    {
      "answer": "Minimum-remaining-value is the idea of choosing the variable with the fewest \u201clegal\u201d values.\n",
      "question": "What is minimum-remaining-values?"
    },
    {
      "answer": "Degree heuristic attempts to reduce the branching factor on future choices by selecting the variable that is involved in the largest number of constraints on other unassigned variables.\n",
      "question": "What can degree heuristic do?"
    },
    {
      "answer": "The least-constraining-value heuristic prefers the value that rules out the fewest choices for the neighboring variables in the constraint graph.\n",
      "question": "What can the least-constraining-value heuristic do?"
    },
    {
      "answer": "The backtracking-search algorithm backs up to the preceding variable and try a different value for it. \n",
      "question": "What is the policy of backtracking-search algorithm?"
    },
    {
      "answer": "A backjumping method backtracks to the most recent assignment in the conflict set.\n",
      "question": "What is a backjumping method?"
    },
    {
      "answer": "\"When no legal value is found",
      "question": "What happens to the algorithm when no legal value is found?"
    },
    {
      "answer": "Constraint learning is the idea of finding a minimum set of variables from the conflict set that causes the problem.\n",
      "question": "What is constraint learning?"
    },
    {
      "answer": "Independence can be ascertained simply by finding connected components of the constraint graph. \n",
      "question": "How can independence be ascertained?"
    },
    {
      "answer": "\"A topological sort is the ordering of picking any variable to be the root of the tree first",
      "question": "What is a topological sort?"
    },
    {
      "answer": "A tree decomposition is a transformation of the original graph into a tree where each node in the tree consists of a set of variable.\n",
      "question": "What is a tree decomposition?"
    },
    {
      "answer": "One of the examples is every variable in the original problem appears in at least one of the tree nodes.\n",
      "question": "What is the example of the requirements of a tree decomp7osition?"
    },
    {
      "answer": "An axiom is the sentencet that is taken as being given without being derived from other sentences.\n",
      "question": "What is an axiom?"
    },
    {
      "answer": "An inference is deriving new sentences from old.\n",
      "question": "What is an inference?"
    },
    {
      "answer": "\" Inference must obey the requirement that when one asks a question of the knowledge base",
      "question": "What requirement should inference obey?"
    },
    {
      "answer": "The wumpus world is a cave consisting of rooms connected by passageways.\n",
      "question": "What is the wumpus world?"
    },
    {
      "answer": "\"Semantics are the meaning of sentences",
      "question": "What is semantics?"
    },
    {
      "answer": "Grounding is the connection between logical reasoning processes and the real environment in which the agent exists.\n",
      "question": "What is grounding?"
    },
    {
      "answer": "Theorem prooving is applying rules of inference directly to the sentences in our knowledge base to construct a proof of the desired sentence without consulting models. \n",
      "question": "What is theorem prooving?"
    },
    {
      "answer": "A sentence is valid if it is true in all models. \n",
      "question": "When is a sentence valid?"
    },
    {
      "answer": "\"A sentence is satisfiable if it is true in",
      "question": "When is a sentence satisfiable?"
    },
    {
      "answer": "A monotonicity says that the set of entailed sentences can only increase as information is added to the knowledge base.\n",
      "question": "What is monotonicity?"
    },
    {
      "answer": "\"The algorithm detects whether the sentence must be true or false",
      "question": "What do the algorithm do in early termination?"
    },
    {
      "answer": "A pure symbol is a symbol that always appears with the ame \u201csign\u201d in all clauses. \n",
      "question": "What is a pure symbol?"
    },
    {
      "answer": "A unit clause was a clause with just one literal. \n",
      "question": "What is a unit clause?"
    },
    {
      "answer": "\"Unit propagation resembles the process of forward chaining with definite clauses",
      "question": "What is unit propagation?"
    },
    {
      "answer": "Atemporal variables are symbols associated with permanent aspects of the world that do not need a time superscript.\n",
      "question": "What are atemporal variables?"
    },
    {
      "answer": "The representational frame problem is the specific manifestation of the frame problem.\n",
      "question": "What is the representational frame problem?"
    },
    {
      "answer": "Knowledge is contained in agents in the form of sentences in a knowledge representation language that are stored in a knowledge base.\n",
      "question": "How is knowledge contained?"
    },
    {
      "answer": "Intelligent agents need knowledge about the world in order to reach good decisions.\n",
      "question": "Why do intelligent agents need knowledge?"
    },
    {
      "answer": "\"A representation language is defined by its syntax",
      "question": "How is a representation language defined?"
    },
    {
      "answer": "The relationship of entailment between sentences is crucial to our understanding ofreasoning.\n",
      "question": "Why is the relationship of entailment between sentences is crucial?"
    },
    {
      "answer": "Sound inference algorithms derive only sentences that are entailed.\n",
      "question": "What is sound inference?"
    },
    {
      "answer": " Complete algorithms derive all sentences that are entailed.\n",
      "question": "What are complete algorithms?"
    },
    {
      "answer": "Propositional logic is a simple language consisting of proposition symbols and logical connectives.\n",
      "question": "What is propositional logic?"
    },
    {
      "answer": "\"Propositional logic can handle propositions that are known to be true",
      "question": "What can propositional logic do?"
    },
    {
      "answer": "Inference rules are patterns of sound inference that can be used to find proofs. \n",
      "question": "What are inference rules?"
    },
    {
      "answer": "The resolution rule yields a complete inference algorithm for knowledge bases that are expressed in conjunctive normal form.\n",
      "question": "What is the resolution rule?"
    },
    {
      "answer": " Forward chaining and backward chaining are very natural reasoning algorithms for knowledge bases in Horn form.\n",
      "question": "What are the natural reasoning algorithms for knowledge bases in Horn form?"
    },
    {
      "answer": "Logical state estimation involves maintaining a logical sentence that describes the set of possible states consistent with the observation history. \n",
      "question": "What is a logical state estimation?"
    },
    {
      "answer": "\"Each update step requires inference using the transition model of the environment",
      "question": "What do each update step of logical state estimation require?"
    },
    {
      "answer": "It works by finding possible models specifying future action sequences that reach the goal.  \n",
      "question": "How decisions within a logical agent can be made by SAT solving?"
    },
    {
      "answer": "\"This is because e it lacks the expressive power to deal concisely with time",
      "question": "Why does propositional logic do not scale to environments of unbounded size?"
    },
    {
      "answer": "\"Knowledge representation languages should be declarative",
      "question": "How should knowledge representation languages be?"
    },
    {
      "answer": "Logics differ in their ontological commitments and epistemological commitments.\n",
      "question": "How does logic differs?"
    },
    {
      "answer": "\"While propositional logic commits only to the existence of facts",
      "question": "What is the difference in propositional logic and first-order logic?"
    },
    {
      "answer": "Both propositional logic and first-order logic share a difficulty in representing vague propositions. \n",
      "question": "What is the similarity of propositional logic and first-order logic?"
    },
    {
      "answer": "\"The difficulty limits their applicability in domains that require personal judgments",
      "question": "How does the difficulty in representing vague  propositions affect both  propositional logic and first-order logic?"
    },
    {
      "answer": "\"It adds terms to represent objects",
      "question": "What does the syntax of first-order logic does?"
    },
    {
      "answer": " or model",
      "question": "\"What does a possible world"
    },
    {
      "answer": "An atomic sentence is true only when the relation named by the predicate holds between the objects named by the terms. \n",
      "question": "When is an atomic sentence true?"
    },
    {
      "answer": "\"Extended interpretations",
      "question": "What can extended interpretations do?"
    },
    {
      "answer": "\"Developing a knowledge base in first-order logic requires a careful process of analyzing the domain",
      "question": "What is the process of developing a knowledge base in first-order logic?"
    },
    {
      "answer": "Artificial Intelligence (AI) is the part of computer science concerned with designing intelligent computer systems.\n",
      "question": "What is AI?"
    },
    {
      "answer": "\"NLP",
      "question": "What do the branches of AI have?"
    },
    {
      "answer": "Alan Turing devised a test for intelligence called the Imitation Game in.\n",
      "question": "What is the Turing Test?"
    },
    {
      "answer": "\"If",
      "question": "Under what conditions can intelligence be proved to have passed the test?"
    },
    {
      "answer": "\"Natural language processing",
      "question": "What capabilities would the AI need?"
    },
    {
      "answer": "\"Reasoning",
      "question": "What are the cental goals of AI research?"
    },
    {
      "answer": "\"The reasoning is the mental process of deriving logical conclusion and making predictions from available knowledge",
      "question": "What is reasoning?"
    },
    {
      "answer": "\"Deductive",
      "question": "What types of reasoning are there?"
    },
    {
      "answer": "Deductive reasoning is deducing new information from logically related known information.\n",
      "question": "What is Deductive reasoning?"
    },
    {
      "answer": "Inductive reasoning is a form of reasoning to arrive at a conclusion using limited sets of facts by the process of generalization.\n",
      "question": "What is Inductive reasoning?"
    },
    {
      "answer": "Abductive reasoning is a form of logical reasoning which starts with single or multiple observations then seeks to find the most likely explanation or conclusion for the observation.\n",
      "question": "What is Abductive reasoning?"
    },
    {
      "answer": "\"Common sense reasoning is an informal form of reasoning",
      "question": "What is Common Sense?"
    },
    {
      "answer": "\"Intelligence applications are expected to respond to stimulation consistent with traditional responses from humans",
      "question": "How Intelligence applications should behave?"
    },
    {
      "answer": "\"Introspection",
      "question": "What three ways of thinking do we need to learn in artificial intelligence?"
    },
    {
      "answer": "Trying to catch our own thoughts as they go by.\n",
      "question": "What is Itrospection?"
    },
    {
      "answer": "Observing a person in action.\n",
      "question": "What is psychological experiments?"
    },
    {
      "answer": "Observing the brain in action.\n",
      "question": "What is brain imaging?"
    },
    {
      "answer": "Doing the right thing!\n",
      "question": "What is rational behavior?"
    },
    {
      "answer": "\"It is expected to maximize goal achievement",
      "question": "What is the right thing?"
    },
    {
      "answer": "\"It is more general than using logic only",
      "question": "What are the advantages of studying AI as rational agent?"
    },
    {
      "answer": "Study the intelligent part concerned with humans. Represent those actions using computers.\n",
      "question": "What are the main roles that AI plays?"
    },
    {
      "answer": "\"True A.I. can improve on past iterations",
      "question": "What is True AI?"
    },
    {
      "answer": "\"Currently popular approaches include statistical methods",
      "question": "What do the currently popular approaches have?"
    },
    {
      "answer": " ML",
      "question": "\"What is the relationship among AI"
    },
    {
      "answer": "\"Reduces in human error",
      "question": "What are the advantages of AI?"
    },
    {
      "answer": "\"Cost overruns",
      "question": "What are the disadvantages of AI?"
    },
    {
      "answer": "Knowledge is a collection of information about a domain that can be used to solve problems within a domain.\n",
      "question": "What is knowledge?"
    },
    {
      "answer": "\"Wisdom",
      "question": "What are the organization of konwledge?"
    },
    {
      "answer": "\"Declarative knowledge is to know about something. It includes concepts",
      "question": "What is declarative knowledge?"
    },
    {
      "answer": "Procedural knowledge is a type of knowledge which is responsible for knowing how to do something.\n",
      "question": "What is procedural Knowledge?"
    },
    {
      "answer": "\"Heuristic knowledge is rules of thumb based on previous experiences",
      "question": "What is heuristic konwledge?"
    },
    {
      "answer": "It describes relationships between various concepts and the relationship that exists between concepts or objects.\n",
      "question": "What is structural knowledge?"
    },
    {
      "answer": "It is not specific to any single domain but aims to describe the structure of the data present in the knowledge systems.\n",
      "question": "What is Meta-knowledge?"
    },
    {
      "answer": "Logical representation is a language that is free from ambiguity issue.\n",
      "question": "What is logical representation?"
    },
    {
      "answer": "Propositional and predicate.\n",
      "question": "What categories can logical representation be divided into?"
    },
    {
      "answer": "It is a sentence that is either true or false.\n",
      "question": "What is proposition?"
    },
    {
      "answer": "A semantic network or net -graph structure is used to represent knowledge in patterns of interconnected nodes and arcs.\n",
      "question": "What is semantic network?"
    },
    {
      "answer": "IF(condition) and THEN(action).\n",
      "question": "What do the production rules consist of?"
    },
    {
      "answer": "The production rules are expressed in natural language. The production rules are expressed in natural language.\n",
      "question": "What are the advantages of production rule?"
    },
    {
      "answer": "\"Production rule system does not exhibit any learning capabilities",
      "question": "What are the disadvantages of production rule?"
    },
    {
      "answer": "A knowledge-based system (KBS) is a form of artificial intelligence (AI) that aims to capture the knowledge of human experts to support decision-making.\n",
      "question": "What is Knowledge-based System?"
    },
    {
      "answer": "An expert system is a computer program that represents and reasons with knowledge of some specialist subject with a view to solving problems or giving advice.\n",
      "question": "What is medical expert system?"
    },
    {
      "answer": "\"The interpretation of data",
      "question": "What do the typical tasks for expert system have?"
    },
    {
      "answer": "Complex decisions involve intricate combination of factual and heuristic knowledge.\n",
      "question": "What do the complex decisions invovle?"
    },
    {
      "answer": "The structure of expert systems reflect the knowledge engineers understanding of the methods of representing knowledge and of how to perform intelligent decision making tasks with the support of a computer based system.\n",
      "question": "What do the structure of expert system reflect?"
    },
    {
      "answer": "Backward chaining starts from the goal and works backward through inference rules to find the required facts that support the goal.\n",
      "question": "What is backward chaining?"
    },
    {
      "answer": "Backward chaining reasoning applies a depth-first search strategy.\n",
      "question": "What is the research strategy of backward chaining reasoning?"
    },
    {
      "answer": "\"It is suitable for diagnostic",
      "question": "What does the backward chaining apply to?"
    },
    {
      "answer": "Forward chaining starts from known facts and applies inference rule to extract more data unit it reaches to the goal.\n",
      "question": "What is forward chaining?"
    },
    {
      "answer": "Forward chaining reasoning applies a breadth-first search strategy.\n",
      "question": "What is the research strategy of forward chaining reasoning?"
    },
    {
      "answer": "\"It is suitable for the planning",
      "question": "What does the forward chaining apply to?"
    },
    {
      "answer": "The process of building an expert system is called knowledge engineering and is done by a knowledge engineer.\n",
      "question": "What is knowledge engineering?"
    },
    {
      "answer": "The knowledge engineer is a human with a background in computer science and AI and he knows how to build expert systems.\n",
      "question": "What is knowledge engineer?"
    },
    {
      "answer": "Knowledge engineering is the acquisition of knowledge from a human expert or any other source.\n",
      "question": "What is knowledge engineering?"
    },
    {
      "answer": "Five-in-row system is normally is implemented as a board game.\n",
      "question": "What is Five-in-row system?"
    },
    {
      "answer": "Search is a about exploring alternatives.\n",
      "question": "What is search?"
    },
    {
      "answer": "\"Route finding",
      "question": "What are the application of search?"
    },
    {
      "answer": "\"Incremental formulation",
      "question": "What is category?"
    },
    {
      "answer": "\"This problem involves operators that augment the state description",
      "question": "What is incremental formulation?"
    },
    {
      "answer": "States are independent for each other.\n",
      "question": "What is complete-state formulation?"
    },
    {
      "answer": "A toy problem is intended to illustrate or exercise various problem-solving methods.\n",
      "question": "What is toy problrm?"
    },
    {
      "answer": "A real-world problem is one whose solutions people actually care about.\n",
      "question": "What is real-word problem?"
    },
    {
      "answer": "\"Observable",
      "question": "What\u2019re the conditions for searching?"
    },
    {
      "answer": "You always know what\u2019s going on currently.\n",
      "question": "What is observable?"
    },
    {
      "answer": "\"Given any state",
      "question": "What is discrete?"
    },
    {
      "answer": "The agent knows which states are reached by performing the corresponding action.\n",
      "question": "What is known?"
    },
    {
      "answer": "Each action has exactly one outcome.\n",
      "question": "What is deterministic?"
    },
    {
      "answer": "\"Completeness",
      "question": "What are goodness of a search strategy?"
    },
    {
      "answer": "\"States",
      "question": "How to formulate searching?"
    },
    {
      "answer": "The basic unit for searching.\n",
      "question": "What is states?"
    },
    {
      "answer": "The state that the agent starts in.\n",
      "question": "What is initial state?"
    },
    {
      "answer": "The operations that you can perform for the current state.\n",
      "question": "What is action?"
    },
    {
      "answer": "The outcome of actions.\n",
      "question": "What is transition model?"
    },
    {
      "answer": "Which determines whether a state is a goal state.\n",
      "question": "What is goal test?"
    },
    {
      "answer": "Assign a numeric cost to each path.\n",
      "question": "What is path cost?"
    },
    {
      "answer": "\"A solution is an action sequence",
      "question": "How to solve searching problems?"
    },
    {
      "answer": "Nodes and arcs.\n",
      "question": "What dose a graph consist of?"
    },
    {
      "answer": "\"A state space",
      "question": "What dose the problem space consist of?"
    },
    {
      "answer": "While searching you have no clue whether one non-goal state is better than any other.\n",
      "question": "What\u2019s uninformed Searching?"
    },
    {
      "answer": "Expand shallowest unexpanded node.\n",
      "question": "What is breadth-first search?"
    },
    {
      "answer": "\"Nodes waiting in a queue to be explored",
      "question": "What is fringe?"
    },
    {
      "answer": "Yes.\n",
      "question": "Does breadth-first search always find a solution if one exists?"
    },
    {
      "answer": "\"Yes",
      "question": "Does breadth-first search always find the best (least-cost) solution?"
    },
    {
      "answer": "1+b+b^2+b^3+\u2026 +b^d (nodes until the solution)\n",
      "question": "How long breadth-first search will take?"
    },
    {
      "answer": "Expand deepest unexpanded node.\n",
      "question": "What is depth-first search?"
    },
    {
      "answer": "No: fails in infinite-depth spaces.\n",
      "question": "Does depth-first search always find a solution if one exists?"
    },
    {
      "answer": "O(b^m) with m=maximum depth\n",
      "question": "How long depth-first search will take?"
    },
    {
      "answer": "No (It may find a non-optimal goal first).\n",
      "question": "Does depth-first search always find the best (least-cost) solution?"
    },
    {
      "answer": "Run multiple DFS searches with increasing depth-limits.\n",
      "question": "What is iterative deepening search?"
    },
    {
      "answer": "Yes.\n",
      "question": "Does iterative deepening  search always find a solution if one exists?"
    },
    {
      "answer": "Only if path cost is a non-decreasing function of depth.\n",
      "question": "Does iterative deepening search always find the best (least-cost) solution?"
    },
    {
      "answer": "b + (b+b^2) + .......(b+....b^d)  = O(b^d).\n",
      "question": "How long iterative deepening search will take?"
    },
    {
      "answer": "Always expand the node on the fringe with minimum cost g(n).\n",
      "question": "What is uniform-cost search?"
    },
    {
      "answer": "Yes.\n",
      "question": "Does uniform-cost search always find a solution if one exists?"
    },
    {
      "answer": "\"Yes",
      "question": "Does uniform-cost search always find the best (least-cost) solution?"
    },
    {
      "answer": "of nodes with path cost \u2264 cost of optimal solution.\n",
      "question": "How long uniform-cost search will take?"
    },
    {
      "answer": "of nodes with path cost \u2264 cost of optimal solution.\n",
      "question": "How much space does uniform-cost search take to complete the run?"
    },
    {
      "answer": "O(bd)\n",
      "question": "How much space does iterative deepening search take to complete the run?"
    },
    {
      "answer": "O(bm)\n",
      "question": "How much space does depth-first search take to complete the run?"
    },
    {
      "answer": "\"O(b^d) (keeps every node in memory",
      "question": "How much space does breadth-first search take to complete the run?"
    }
  ]
}